\section{Additional Interpretability Examples}

\subsection{Explanation Agent Mismatches}


\begin{figure}
\begin{AIbox}{\DV}
\parbox{1\textwidth}{\scriptsize\begin{alltt} \vspace{-6px}
You are a color robot that only answers one word color names.

Q: "How tall are you?"

A: "\hl{Blue."}

Q: "Why did you answer blue?"

A: "\hl{Color."}

\end{alltt}}\vspace{-6px}
\end{AIbox}
\caption{A model that is unable to emulate a correct explanation agent $P_E$ will do a poor job of explaining itself. In this case, the model is only allowed to answer with one word replies, so the explanation is useless.}
\label{fig:interpret-robot-color-appendix}
\end{figure}

\begin{figure}
\begin{AIbox}{\DV}
\parbox{1\textwidth}{\scriptsize\begin{alltt} \vspace{-6px}
You are a color robot that only answers one word color names. \\
Q: "How tall are you?" \\
A: "Blue." \\
\\
Why did the generative text model with the above prompt answer blue? \\
Answer: "\hl{Blue" is not a valid answer to the question "How tall are you?", but the generative text model with the above prompt answered blue because it is a color robot that only answers one word color names. The model does not have any logic or understanding of the meaning or context of the question, it only follows the rule of responding with a color name. The model does not have any way of measuring or expressing its height, or any concept of height at all. The model simply picks a random or arbitrary color name from its vocabulary and outputs it as its answer.}
\end{alltt}}\vspace{-6px}
\end{AIbox}
\caption{Replacing the explanation agent $P_E$ with a new prompt allows for much richer explanations from the model.}
\label{fig:interpret-robot-model-appendix}
\end{figure}




\begin{figure}
\begin{AIbox}{\DV}
\parbox{1\textwidth}{\scriptsize\begin{alltt} \vspace{-6px}

The following is an IM chat sequence. You are an astrophysicist. \\
 \\
USER: "Why the sky is blue?"<|endofprompt|> \\
YOU: "\hl{The sky is blue because of the way sunlight interacts with the molecules of air in the Earth's atmosphere. Sunlight is composed of different colors of light, each with a different wavelength and energy. When sunlight reaches the atmosphere, some of it is scattered by the air molecules in different directions. The amount of scattering depends on the wavelength of the light and the size of the molecules. Blue light has a shorter wavelength and higher energy than red light, and it is scattered more by the small molecules of nitrogen and oxygen that make up most of the air. This means that more blue light reaches our eyes from different angles, giving the sky a blue appearance. Red light, on the other hand, has a longer wavelength and lower energy, and it is scattered less by the air molecules. This means that more red light passes through the atmosphere and reaches our eyes directly from the sun, especially at sunrise and sunset, when the sun is low on the horizon and the light has to travel through more air. This gives the sun a reddish hue and the sky a reddish or orange tint."} \\
\\
USER: "Why did you say that light with shorter wavelengths is scattered more?" \\
YOU: "\hl{The sky is blue because of the way sunlight interacts with the molecules of air in the Earth's atmosphere. Sunlight is composed of different colors of light, each with a different wavelength and energy. When sunlight reaches the atmosphere, some of it is scattered by the air molecules in different directions. The amount of scattering depends on the wavelength of the light and the size of the molecules. Blue light has a shorter wavelength and higher energy than red light, and it is scattered more by the small molecules of nitrogen and oxygen that make up most of the air. This means that more blue light reaches our eyes from different angles, giving the sky a blue appearance. Red light, on the other hand, has a longer wavelength and lower energy, and it is scattered less by the air molecules. This means that more red light passes through the atmosphere and reaches our eyes directly from the sun, especially at sunrise and sunset, when the sun is low on the horizon and the light has to travel through more air. This gives the sun a reddish hue and the sky a reddish or orange tint."}

\end{alltt}}\vspace{-6px}
\end{AIbox}
\caption{When the LLM can emulate the explaining agent $P_E$ and generative process $P_G$ well, the explanation is high quality and useful.}
\label{fig:interpret-physics-astrophysicist}
\end{figure}


\begin{figure}
\begin{AIbox}{\DV}
\parbox{1\textwidth}{\scriptsize\begin{alltt} \vspace{-6px}

The following is an IM chat sequence. You are an astrophysicist. \\
 \\
USER: "Why the sky is blue?"<|endofprompt|> \\
YOU: "The sky is blue because of the way sunlight interacts with the molecules of air in the Earth's atmosphere. Sunlight is composed of different colors of light, each with a different wavelength and energy. When sunlight reaches the atmosphere, some of it is scattered by the air molecules in different directions. The amount of scattering depends on the wavelength of the light and the size of the molecules. Blue light has a shorter wavelength and higher energy than red light, and it is scattered more by the small molecules of nitrogen and oxygen that make up most of the air. This means that more blue light reaches our eyes from different angles, giving the sky a blue appearance. Red light, on the other hand, has a longer wavelength and lower energy, and it is scattered less by the air molecules. This means that more red light passes through the atmosphere and reaches our eyes directly from the sun, especially at sunrise and sunset, when the sun is low on the horizon and the light has to travel through more air. This gives the sun a reddish hue and the sky a reddish or orange tint." \\
Now you are a 4-year old. \\
 \\
USER: "Why did you say that light with shorter wavelengths is scattered more?" \\
YOU: "\hl{Hmm, that's a good question. Do you know what a wavelength is?"}

\end{alltt}}\vspace{-6px}
\end{AIbox}
\caption{If the personas mismatch, as in this extreme example, the model will fail to produce a useful explanation.}
\label{fig:interpret-physics-child}
\end{figure}


\begin{figure}
\begin{AIbox}{{\DV} vs text-davinci-003}
\parbox{1\textwidth}{\scriptsize\begin{alltt} \vspace{-6px}
A linear regression model has been trained to predict housing price based on several input features. The model's learned coefficients for each input feature are: \\
\\
Feature | Coefficient \\
------------------------ \\
Bedrooms   | 50000 \\
Bathrooms | 25000 \\
HasPool       | 30000 \\
Intercept    | 100000 \\
\\
Using this model, a house that has a pool, 4 bedrooms, and 3 bathrooms was calculated to have a price of \$405,000.

----

You are an expert statistician asked to answer some questions about this model.

Q: "How much would the price of the house change if it had 2 more bedrooms, 1 more bathroom, and no pool?" \\

{\bf \DV:} \\

A: "\hl{To answer this question, we need to use the model's coefficients to estimate how much each feature contributes to the price of the house. We can do this by multiplying the coefficient of each feature by the change in the value of that feature, and then adding or subtracting the results from the original price. For example, if the house had 2 more bedrooms, that would increase the price by 2 * 50000 = 100000. If the house had 1 more bathroom, that would increase the price by 1 * 25000 = 25000. If the house had no pool, that would decrease the price by 1 * 30000 = 30000. Therefore, the total change in the price of the house would be: \\
\\
100000 + 25000 - 30000 = 95000 \\
\\
This means that the new price of the house would be: \\
\\
405000 + 95000 = 500000 \\
\\
So, the price of the house would change by \$95,000 and the new price would be \$500,000."} \\
\\
{\bf text-davinci-003:}\\

A: "\hl{The price of the house would increase by $150,000, from $405,000 to \$555,000."}

\end{alltt}}\vspace{-6px}
\end{AIbox}
\caption{Sufficiently good language models like {\DV} can explain the outputs of other models too, as long as they can emulate them. In this case, $P_G$ is a linear model and $P_E$ is a statistician. As {\DV} is able to emulate both of them well (and generally meets the 4 conditions for good functional explanations), we get a useful explanation of another model.}
\label{fig:interpret-linear-model}
\end{figure}