\section{Discriminative Capabilities}
\label{sec:discriminative}
% \varun{General flow is the following:}

% \begin{enumerate}
% \item We will motivate how \DV is good at discriminative tasks based on our experience with PII detection; we will compare the model (with zero shot + few shots) against a custom classifier for this task and regex; observation will be that \DV is better
% \item we will segue into two deeper case-studies: (a) misinformation/toxicity detection and (b) hallucination detection. 
% \item for the former, the findings are going to be that (i) \DV is better than prior models at this task, (ii) \DV provides higher probabilities for toxic outcomes (both hamid numbers + new numbers based on ratings), (iii) \DV is not well calibrated. other findings (for misinformation) will include that \DV returns more truthful outcomes + also responses that are more plausible (based on human evaluation as well) and that metrics that capture truthfulness are bad
% \item for the latter, we will have to discuss with scott/marco/harsha if they are comfortable including these results; will broadly echo the same themes as earlier.
% \end{enumerate}

Discrimination is a component of intelligence that allows an agent to make distinctions between different stimuli, concepts, and situations. This ability, in turn, enables the agent to understand and respond to various aspects of their environment in a more effective manner. For example, the ability to discriminate between different types of foods can help an animal identify which are safe to eat and which could be poisonous. Overall, the ability to discriminate is important because it allows one to make more accurate judgments and decisions, which is a crucial component of intelligence. We also stress that through this paper, we have discussed the generative capabilities of \DV. It is often assumed that stronger generative capabilities only refines discriminative capabilities.

In this section, we first motivate \DV's discriminative prowess by describing its performance identifying personally identifiable information in sentences. We then proceed to discuss how {\DV} is adept at answering challenging questions (that may result in misconceptions) when compared to its contemporaries. {\DV} is also able to understand why a (model generated) answer is closer to the ``gold'' answer; these explanations are mostly sound. By doing so, it is able to determine which answer in a pair is closer to the gold answer, and this determination reasonably aligns with a human performing the same task. 
% Next, we discuss how {\DV}, with no explicit training, is able to determine if a sentence is toxic or not. In this setting, we require {\DV} to generate a toxicity score (a probability value determining if a statement is toxic), and measure how well calibrated such scores are. 

Throughout this section, when we refer to GPT-3, we refer to the model \texttt{text-davinci-002}; this model is instruction fine-tuned.
%and when we refer to GPT-3.5, we refer to the model \texttt{text-davinci-003}.

%Finally, we judge \DV's ability at determining hallucinations by extracting and verifying claims in a synthetic summarization task.

\paragraph{Important Disclaimer:} As explained in the Introduction (see footnote 1 for example) our experiments were run on an early version of GPT-4. In particular all quantitative results will be different on the final version of GPT-4, although the general trends remain the same. We provide numbers here for illustration purpose only, the definitive benchmark results can be found in OpenAI's technical report \cite{gpt4}.

\input{contents/7.1_pii}
\input{contents/7.2_misconceptions}
% \input{contents/7.3_toxicity}
%\input{contents/7.4_hallucination}
