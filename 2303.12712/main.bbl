\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{DARW{\etalchar{+}}19}

\bibitem[ABC{\etalchar{+}}22]{ahn2022learning}
Kwangjun Ahn, S{\'e}bastien Bubeck, Sinho Chewi, Yin~Tat Lee, Felipe Suarez,
  and Yi~Zhang.
\newblock Learning threshold neurons via the ``edge of stability".
\newblock {\em arXiv preprint arXiv:2212.07469}, 2022.

\bibitem[AWV{\etalchar{+}}19]{amershi2019}
Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi,
  Penny Collisson, Jina Suh, Shamsi Iqbal, Paul~N Bennett, Kori Inkpen, Jaime
  Teevan, Ruth Kikin-Gil, and Eric Horvitz.
\newblock Guidelines for human-{AI} interaction.
\newblock In {\em Proceedings of the 2019 CHI Conference on Human Factors in
  Computing Systems}, pages 1--13, 2019.

\bibitem[BB19]{bordia2019identifying}
Shikha Bordia and Samuel~R Bowman.
\newblock Identifying and reducing gender bias in word-level language models.
\newblock {\em arXiv preprint arXiv:1904.03035}, 2019.

\bibitem[BBDIW20]{blodgett2020language}
Su~Lin Blodgett, Solon Barocas, Hal Daum{\'e}~III, and Hanna Wallach.
\newblock Language (technology) is power: A critical survey of" bias" in nlp.
\newblock {\em arXiv preprint arXiv:2005.14050}, 2020.

\bibitem[BCLF85]{baron1985does}
Simon Baron-Cohen, Alan~M Leslie, and Uta Frith.
\newblock Does the autistic child have a “theory of mind”?
\newblock {\em Cognition}, 21(1):37--46, 1985.

\bibitem[BCZ{\etalchar{+}}16]{bolukbasi2016man}
Tolga Bolukbasi, Kai-Wei Chang, James~Y Zou, Venkatesh Saligrama, and Adam~T
  Kalai.
\newblock Man is to computer programmer as woman is to homemaker? {D}ebiasing
  word embeddings.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem[BEG{\etalchar{+}}22]{barak2022hidden}
Boaz Barak, Benjamin~L. Edelman, Surbhi Goel, Sham~M. Kakade, eran malach, and
  Cyril Zhang.
\newblock Hidden progress in deep learning: {SGD} learns parities near the
  computational limit.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem[BGMMS21]{bender2021dangers}
Emily~M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
  Shmitchell.
\newblock On the dangers of stochastic parrots: Can language models be too big?
\newblock In {\em Proceedings of the 2021 ACM Conference on Fairness,
  Accountability, and Transparency}, pages 610--623, 2021.

\bibitem[BH09]{bohus2009}
Dan Bohus and Eric Horvitz.
\newblock Models for multiparty engagement in open-world dialog.
\newblock In {\em Proceedings of the SIGDIAL 2009 Conference, The 10th Annual
  Meeting of the Special Interest Group on Discourse and Dialogue}, page~10,
  2009.

\bibitem[BIK22]{bommarito2022gpt}
Michael Bommarito~II and Daniel~Martin Katz.
\newblock Gpt takes the bar exam.
\newblock {\em arXiv preprint arXiv:2212.14402}, 2022.

\bibitem[BM17]{brynjolfsson2017}
Erik Brynjolfsson and Tom Mitchell.
\newblock What can machine learning do? workforce implications.
\newblock {\em Science}, 358(6370):1530--1534, 2017.

\bibitem[BMR{\etalchar{+}}20]{gpt3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~33, pages 1877--1901, 2020.

\bibitem[BNK{\etalchar{+}}19]{bansal2019}
Gagan Bansal, Besmira Nushi, Ece Kamar, Daniel~S Weld, Walter~S Lasecki, and
  Eric Horvitz.
\newblock Updates in human-ai teams: Understanding and addressing the
  performance/compatibility tradeoff.
\newblock In {\em Proceedings of the {AAAI} Conference on Artificial
  Intelligence}, volume~33, pages 2429--2437, 2019.

\bibitem[BNK{\etalchar{+}}21]{bansal2021}
Gagan Bansal, Besmira Nushi, Ece Kamar, Eric Horvitz, and Daniel~S Weld.
\newblock Is the most accurate ai the best teammate? {O}ptimizing {AI} for
  teamwork.
\newblock In {\em Proceedings of the {AAAI} Conference on Artificial
  Intelligence}, volume~35, pages 11405--11414, 2021.

\bibitem[BS21]{NEURIPS2021_f197002b}
Sebastien Bubeck and Mark Sellke.
\newblock A universal law of robustness via isoperimetry.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman
  Vaughan, editors, {\em Advances in Neural Information Processing Systems},
  volume~34, pages 28811--28822. Curran Associates, Inc., 2021.

\bibitem[Cho19]{chollet2019measure}
Fran{\c{c}}ois Chollet.
\newblock On the measure of intelligence.
\newblock {\em arXiv preprint arXiv:1911.01547}, 2019.

\bibitem[CKB{\etalchar{+}}21]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz
  Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
  et~al.
\newblock Training verifiers to solve math word problems.
\newblock {\em arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[CKY{\etalchar{+}}18]{cote2018textworld}
Marc-Alexandre C{\^o}t{\'e}, Akos K{\'a}d{\'a}r, Xingdi Yuan, Ben Kybartas,
  Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla~El Asri,
  Mahmoud Adada, et~al.
\newblock Textworld: A learning environment for text-based games.
\newblock In {\em Workshop on Computer Games}, pages 41--75. Springer, 2018.

\bibitem[CTJ{\etalchar{+}}21]{humaneval}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique~Ponde
  de~Oliveira~Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
  Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy
  Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder,
  Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens
  Winter, Philippe Tillet, Felipe~Petroski Such, Dave Cummings, Matthias
  Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss,
  William~Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor
  Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher
  Hesse, Andrew~N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa,
  Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter
  Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
  Wojciech Zaremba.
\newblock Evaluating large language models trained on code.
\newblock 2021.

\bibitem[CWF{\etalchar{+}}22]{collins2022structured}
Katherine~M Collins, Catherine Wong, Jiahai Feng, Megan Wei, and Josh
  Tenenbaum.
\newblock Structured, flexible, and robust: benchmarking and improving large
  language models towards more human-like behavior in out-of-distribution
  reasoning tasks.
\newblock In {\em Proceedings of the Annual Meeting of the Cognitive Science
  Society}, volume~44, 2022.

\bibitem[DARW{\etalchar{+}}19]{de2019bias}
Maria De-Arteaga, Alexey Romanov, Hanna Wallach, Jennifer Chayes, Christian
  Borgs, Alexandra Chouldechova, Sahin Geyik, Krishnaram Kenthapadi, and
  Adam~Tauman Kalai.
\newblock Bias in bios: A case study of semantic representation bias in a
  high-stakes setting.
\newblock In {\em proceedings of the Conference on Fairness, Accountability,
  and Transparency}, pages 120--128, 2019.

\bibitem[DM15]{davis2015commonsense}
Ernest Davis and Gary Marcus.
\newblock Commonsense reasoning and commonsense knowledge in artificial
  intelligence.
\newblock {\em Communications of the ACM}, 58(9):92--103, 2015.

\bibitem[ES16]{pmlr-v49-eldan16}
Ronen Eldan and Ohad Shamir.
\newblock The power of depth for feedforward neural networks.
\newblock In {\em 29th Annual Conference on Learning Theory}, volume~49 of {\em
  Proceedings of Machine Learning Research}, pages 907--940. PMLR, 2016.

\bibitem[GHT15]{gershman2015computational}
Samuel~J Gershman, Eric~J Horvitz, and Joshua~B Tenenbaum.
\newblock Computational rationality: A converging paradigm for intelligence in
  brains, minds, and machines.
\newblock {\em Science}, 349(6245):273--278, 2015.

\bibitem[Goe14]{goertzel2014artificial}
Ben Goertzel.
\newblock Artificial general intelligence: concept, state of the art, and
  future prospects.
\newblock {\em Journal of Artificial General Intelligence}, 5(1):1, 2014.

\bibitem[Got97]{gottfredson1997mainstream}
Linda~S Gottfredson.
\newblock Mainstream science on intelligence: An editorial with 52 signatories,
  history, and bibliography, 1997.

\bibitem[GPN{\etalchar{+}}22]{gokhale2022benchmarking}
Tejas Gokhale, Hamid Palangi, Besmira Nushi, Vibhav Vineet, Eric Horvitz, Ece
  Kamar, Chitta Baral, and Yezhou Yang.
\newblock Benchmarking spatial relationships in text-to-image generation.
\newblock {\em arXiv preprint arXiv:2212.10015}, 2022.

\bibitem[Gug23]{CNETdirectorstatement2023}
Connie Guglielmo.
\newblock {CNET} is experimenting with an {AI} assist. {H}ere's why, January
  2023.
\newblock [Online; posted 16-January-2023].

\bibitem[HB95]{aidisplay1995}
Eric Horvitz and Matthew Barry.
\newblock Display of information for time-critical decision making.
\newblock In {\em Proceedings of the UAI}, 1995.

\bibitem[HBK{\etalchar{+}}21]{hendrycksmath2021}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric
  Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock {\em NeurIPS}, 2021.

\bibitem[Hor99]{mixedinit1999}
Eric Horvitz.
\newblock Principles of mixed-initiative user interfaces.
\newblock In {\em Proceedings of the SIGCHI conference on Human Factors in
  Computing Systems}, pages 159--166, 1999.

\bibitem[Hor07]{mixedinitfutures2007}
Eric Horvitz.
\newblock Reflections on challenges and promises of mixed-initiative
  interaction.
\newblock {\em AI Magazine}, 28(2), 2007.

\bibitem[Hor22]{disinfoICMI2022}
Eric Horvitz.
\newblock On the horizon: Interactive and compositional deepfakes.
\newblock In {\em Proceedings of the 2022 International Conference on
  Multimodal Interaction}, page 653–661. Association for Computing Machinery,
  2022.

\bibitem[HP07]{complementary2007}
Eric Horvitz and Tim Paek.
\newblock Complementary computing: {P}olicies for transferring callers from
  dialog systems to human receptionists.
\newblock {\em User Modeling and User-Adapted Interaction}, 17(1):159--182,
  2007.

\bibitem[HS16]{hovy2016social}
Dirk Hovy and Shannon~L Spruit.
\newblock The social impact of natural language processing.
\newblock In {\em Proceedings of the 54th Annual Meeting of the Association for
  Computational Linguistics (Volume 2: Short Papers)}, pages 591--598, 2016.

\bibitem[JSL22]{jelassi2022vision}
Samy Jelassi, Michael~E Sander, and Yuanzhi Li.
\newblock Vision transformers provably learn spatial structure.
\newblock {\em arXiv preprint arXiv:2210.09221}, 2022.

\bibitem[Kah11]{kahneman2011thinking}
Daniel Kahneman.
\newblock {\em Thinking, fast and slow}.
\newblock macmillan, 2011.

\bibitem[KHH12]{kamar2012}
Ece Kamar, Severin Hacker, and Eric Horvitz.
\newblock Combining human and machine intelligence in large-scale
  crowdsourcing.
\newblock In {\em AAMAS}, volume~12, pages 467--474, 2012.

\bibitem[LAD{\etalchar{+}}22]{lewkowycz2022solving}
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk
  Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo
  Gutman-Solo, et~al.
\newblock Solving quantitative reasoning problems with language models.
\newblock {\em arXiv preprint arXiv:2206.14858}, 2022.

\bibitem[LAG{\etalchar{+}}22]{liu2022transformers}
Bingbin Liu, Jordan~T Ash, Surbhi Goel, Akshay Krishnamurthy, and Cyril Zhang.
\newblock Transformers learn shortcuts to automata.
\newblock {\em arXiv preprint arXiv:2210.10749}, 2022.

\bibitem[LBFL93]{lindsay1993dendral}
Robert~K Lindsay, Bruce~G Buchanan, Edward~A Feigenbaum, and Joshua Lederberg.
\newblock Dendral: {A} case study of the first expert system for scientific
  hypothesis formation.
\newblock {\em Artificial Intelligence}, 61(2):209--261, 1993.

\bibitem[LeC22]{lecun2022path}
Yann LeCun.
\newblock A path towards autonomous machine intelligence.
\newblock {\em Open Review}, 2022.

\bibitem[Lef23]{CNETpause2023}
Lauren Leffer.
\newblock {CNET} is reviewing the accuracy of all its {AI}-written articles
  after multiple major corrections, January 2023.
\newblock [Online; posted 17-January-2023].

\bibitem[Leg08]{legg2008machine}
Shane Legg.
\newblock {\em Machine super intelligence}.
\newblock PhD thesis, Universit{\`a} della Svizzera italiana, 2008.

\bibitem[Len95]{lenat1995cyc}
Douglas~B. Lenat.
\newblock Cyc: A large-scale investment in knowledge infrastructure.
\newblock {\em Communications fo the ACM}, 38(11):33–38, nov 1995.

\bibitem[LH07]{legg2007universal}
Shane Legg and Marcus Hutter.
\newblock Universal intelligence: A definition of machine intelligence.
\newblock {\em Minds and machines}, 17(4):391--444, 2007.

\bibitem[LHE21]{lin2021truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock Truthfulqa: Measuring how models mimic human falsehoods.
\newblock {\em arXiv preprint arXiv:2109.07958}, 2021.

\bibitem[Lin04]{lin2004rouge}
Chin-Yew Lin.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In {\em Text summarization branches out}, pages 74--81, 2004.

\bibitem[LKCH17]{Lakkaraju2017}
Himabindu Lakkaraju, Ece Kamar, Rich Caruana, and Eric Horvitz.
\newblock Identifying unknown unknowns in the open world: Representations and
  policies for guided exploration.
\newblock In {\em Thirty-first {AAAI} conference on artificial intelligence},
  2017.

\bibitem[LPP{\etalchar{+}}20]{lewis2020retrieval}
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
  Karpukhin, Naman Goyal, Heinrich K{\"u}ttler, Mike Lewis, Wen-tau Yih, Tim
  Rockt{\"a}schel, et~al.
\newblock Retrieval-augmented generation for knowledge-intensive nlp tasks.
\newblock {\em Advances in Neural Information Processing Systems},
  33:9459--9474, 2020.

\bibitem[MIB{\etalchar{+}}23]{mahowald2023dissociating}
Kyle Mahowald, Anna~A Ivanova, Idan~A Blank, Nancy Kanwisher, Joshua~B
  Tenenbaum, and Evelina Fedorenko.
\newblock Dissociating language and thought in large language models: a
  cognitive perspective.
\newblock {\em arXiv preprint arXiv:2301.06627}, 2023.

\bibitem[MMLR22]{murty2022fixing}
Shikhar Murty, Christopher~D Manning, Scott Lundberg, and Marco~Tulio Ribeiro.
\newblock Fixing model bugs with natural language patches.
\newblock {\em arXiv preprint arXiv:2211.03318}, 2022.

\bibitem[MMRS06]{mccarthy2006proposal}
John McCarthy, Marvin~L Minsky, Nathaniel Rochester, and Claude~E Shannon.
\newblock A proposal for the {D}artmouth summer research project on artificial
  intelligence, {A}ugust 31, 1955.
\newblock {\em AI magazine}, 27(4):12--12, 2006.

\bibitem[MNBM20]{maynez2020faithfulness}
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald.
\newblock On faithfulness and factuality in abstractive summarization.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 1906--1919, 2020.

\bibitem[MRT18]{mohri2018foundations}
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.
\newblock {\em Foundations of Machine Learning}.
\newblock MIT press, 2018.

\bibitem[NHB{\etalchar{+}}21]{nakano2021webgpt}
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina
  Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders,
  et~al.
\newblock Webgpt: Browser-assisted question-answering with human feedback.
\newblock {\em arXiv preprint arXiv:2112.09332}, 2021.

\bibitem[Nis09]{nissenbaum2009privacy}
Helen Nissenbaum.
\newblock Privacy in context.
\newblock In {\em Privacy in Context}. Stanford University Press, 2009.

\bibitem[NPH{\etalchar{+}}22]{codegen}
Erik Nijkamp, Bo~Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio
  Savarese, and Caiming Xiong.
\newblock Codegen: An open large language model for code with multi-turn
  program synthesis.
\newblock {\em arXiv preprint}, 2022.

\bibitem[NSS59]{newellshawsimonGPS1959}
Allen Newell, John~C Shaw, and Herbert~A Simon.
\newblock Report on a general problem solving program.
\newblock In {\em IFIP congress}, volume 256, page~64. Pittsburgh, PA, 1959.

\bibitem[OCS{\etalchar{+}}20]{olah2020zoom}
Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, and
  Shan Carter.
\newblock Zoom in: An introduction to circuits.
\newblock {\em Distill}, 5(3):e00024--001, 2020.

\bibitem[OEN{\etalchar{+}}22]{olsson2022context}
Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma,
  Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, et~al.
\newblock In-context learning and induction heads.
\newblock {\em arXiv preprint arXiv:2209.11895}, 2022.

\bibitem[oM22]{tannerlecture2022}
The~University of~Michigan.
\newblock Tanner {L}ecture on {AI} and {H}uman {V}alues by {E}ric {H}orvitz.
\newblock \url{https://www.youtube.com/watch?v=vsewugyXYXI}, November 2022.

\bibitem[Ope23]{gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.
\newblock arXiv preprint arXiv:2303.08774 [cs.CL].

\bibitem[Pay20]{payne2020privacy}
Brad Payne.
\newblock Privacy protection with ai: Survey of data-anonymization techniques.
\newblock 2020.

\bibitem[PL{\O}{\etalchar{+}}22]{pilan2022text}
Ildik{\'o} Pil{\'a}n, Pierre Lison, Lilja {\O}vrelid, Anthi Papadopoulou, David
  S{\'a}nchez, and Montserrat Batet.
\newblock The text anonymization benchmark (tab): A dedicated corpus and
  evaluation framework for text anonymization.
\newblock {\em arXiv preprint arXiv:2202.00443}, 2022.

\bibitem[PRWZ02]{papineni2002bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In {\em Proceedings of the 40th annual meeting of the Association for
  Computational Linguistics}, pages 311--318, 2002.

\bibitem[PSZ{\etalchar{+}}21]{NEURIPS2021_260c2432}
Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean
  Welleck, Yejin Choi, and Zaid Harchaoui.
\newblock Mauve: Measuring the gap between neural text and human text using
  divergence frontiers.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~34, pages 4816--4828, 2021.

\bibitem[RKN{\etalchar{+}}19]{ramakrishnan2019}
Ramya Ramakrishnan, Ece Kamar, Besmira Nushi, Debadeepta Dey, Julie Shah, and
  Eric Horvitz.
\newblock Overcoming blind spots in the real world: Leveraging complementary
  abilities for joint execution.
\newblock In {\em Proceedings of the {AAAI} Conference on Artificial
  Intelligence}, volume~33, pages 6137--6145, 2019.

\bibitem[RL22]{Reeder2022}
Kristen Reeder and Hwan Lee.
\newblock Impact of artificial intelligence on us medical students' choice of
  radiology.
\newblock {\em Clinical Imaging}, 81:67--71, 2022.

\bibitem[Ros20]{ross2020everyday}
Howard~J Ross.
\newblock {\em Everyday bias: Identifying and navigating unconscious judgments
  in our daily lives}.
\newblock Rowman \& Littlefield, 2020.

\bibitem[SAT{\etalchar{+}}22]{singhal2022large}
Karan Singhal, Shekoofeh Azizi, Tao Tu, S~Sara Mahdavi, Jason Wei, Hyung~Won
  Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et~al.
\newblock Large language models encode clinical knowledge.
\newblock {\em arXiv preprint arXiv:2212.13138}, 2022.

\bibitem[SBD{\etalchar{+}}96]{selman1996challenge}
Bart Selman, Rodney~A Brooks, Thomas Dean, Eric Horvitz, Tom~M Mitchell, and
  Nils~J Nilsson.
\newblock Challenge problems for artificial intelligence.
\newblock In {\em Proceedings of the National Conference on Artificial
  Intelligence}, pages 1340--1345, 1996.

\bibitem[SDP20]{sellam2020bleurt}
Thibault Sellam, Dipanjan Das, and Ankur~P Parikh.
\newblock Bleurt: Learning robust metrics for text generation.
\newblock {\em arXiv preprint arXiv:2004.04696}, 2020.

\bibitem[SH10]{Shahaf2010}
Dafna Shahaf and Eric Horvitz.
\newblock Generalized task markets for human and machine computation.
\newblock In {\em Twenty-Fourth {AAAI} Conference on Artificial Intelligence},
  2010.

\bibitem[SHKK15]{singla2015}
Adish Singla, Eric Horvitz, Pushmeet Kohli, and Andreas Krause.
\newblock Learning to hire teams.
\newblock In {\em Third {AAAI} Conference on Human Computation and
  Crowdsourcing}, 2015.

\bibitem[SRR{\etalchar{+}}22]{srivastava2022beyond}
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal~Md Shoeb, Abubakar
  Abid, Adam Fisch, Adam~R Brown, Adam Santoro, Aditya Gupta, Adri{\`a}
  Garriga-Alonso, et~al.
\newblock Beyond the imitation game: Quantifying and extrapolating the
  capabilities of language models.
\newblock {\em arXiv preprint arXiv:2206.04615}, 2022.

\bibitem[SSBD14]{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock {\em Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem[VBB19]{venturi2019spurious}
Luca Venturi, Afonso~S Bandeira, and Joan Bruna.
\newblock Spurious valleys in one-hidden-layer neural network optimization
  landscapes.
\newblock {\em Journal of Machine Learning Research}, 20:133, 2019.

\bibitem[VSP{\etalchar{+}}17]{Vas17}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~30, 2017.

\bibitem[Wel92]{wellman1992child}
Henry~M Wellman.
\newblock {\em The child's theory of mind.}
\newblock The MIT Press, 1992.

\bibitem[WHK20]{wilder2020}
Bryan Wilder, Eric Horvitz, and Ece Kamar.
\newblock Learning to complement humans.
\newblock In {\em Proceedings of the {AAAI} Conference on Artificial
  Intelligence}, 2020.

\bibitem[WTB{\etalchar{+}}22]{wei2022emergent}
Jason Wei, Yi~Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian
  Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed~H.
  Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William
  Fedus.
\newblock Emergent abilities of large language models.
\newblock {\em Transactions on Machine Learning Research}, 2022.
\newblock Survey Certification.

\bibitem[WWS{\etalchar{+}}22]{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed~Chi, Quoc Le, and
  Denny Zhou.
\newblock Chain of thought prompting elicits reasoning in large language
  models.
\newblock {\em arXiv preprint arXiv:2201.11903}, 2022.

\bibitem[ZBB{\etalchar{+}}22]{zhang2022unveiling}
Yi~Zhang, Arturs Backurs, S{\'e}bastien Bubeck, Ronen Eldan, Suriya Gunasekar,
  and Tal Wagner.
\newblock Unveiling transformers with lego: a synthetic reasoning task.
\newblock {\em arXiv preprint arXiv:2206.04301}, 2022.

\end{thebibliography}
