% !TEX root = scott-1980.tex
%\usepackage[dotinlabels]{titletoc}
%\titlelabel{{\thetitle}.\quad}
%\input{../helpers/psu-plain-titles.tex}
%\input{../helpers/psu-sc-headers.tex}
%\input{../helpers/fix-revtex-12.tex}
%\DeclareSymbolFont{CMlargesymbols}{OMX}{cmex}{m}{n}
%\DeclareMathSymbol{\sum}{\mathop}{CMlargesymbols}{"50}

\date{}
\def\to{\rightarrow}
\def\imp{\shortrightarrow}
\def\iff{\leftrightarrow}
\def\union{\cup}
\def\inc{\subseteq}
\def\dom{\mathop{\rm dom}}
\def\cod{\mathop{\rm cod}}
\def\id{{\mathrm 1}}
\def\res{\!\upharpoonleft\!}
\def\ffam{\varphi}
\def\comp{\circ}
\def\bbone{\mathbb 1}
\def\zeromap{0}
\def\bbzero{{\mathbb O}}
\def\ccc{{c.c.c.}}
\def\ev{\varepsilon}
\def\ebc{\varepsilon_{BC}}
\def\L{\Lambda}
\def\l{\lambda}
\def\lm#1.#2{\lambda#1.\, #2}
\def\br#1{[\, #1 \, ]}
\def\V{V}
\def\U{U}
\def\D{D}
\def\C{\mathcal C}
\def\S{\mathcal S}
\def\lxy{\l x\, \l y . \,}
\def\lmm#1#2.#3{\l #1\, \l #2 . \, #3}
\def\sss{(*\!*\!*)}
\def\ss{(**)}
\def\ssn{(**_n)}
\def\scop{\S^{\C^{op}}}
\def\PU{\mathcal P U}
\def\P{\mathcal P}

% make a ||- symbol
\def\mm{\mathrel{||}\mathrel{\mkern-4.1mu}\relbar}

\def\UU{(U\to U)}
\def\BA{B \to A}
\def\AB{A \to B}

\makeatletter
\newcommand*\dotop{\mathpalette\bigcdot@{.6}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\title{\large Relating Theories of the $\l$-Calculus}
\author{\normalsize Dana Scott \\
{\small\it Merton College}\\
{\small\it Oxford}}
\begin{document}
\maketitle
\bigskip
{\centerline
{\small\it Dedicated to Professor H. B. Curry on the occasion of his 80th Birthday\footnote{
This is a remake of the paper {\it Relating Theories of the 
$\l$-Calculus} originally published in In R. Hindley and J. Seldin, 
editors, To H.B. Curry: Essays in Combinarory Logic, Lambda Calculus and Formalisms. 
Academic Press, 1980. This file was created in May 2021.}}}
\bigskip

\medskip
\noindent
Mathematical theories arise for many different reasons, sometimes in connection with
specific applications and often owing to accidental inspiration. From time to time we
ought to ask ourselves concerning our theories where should they have come from; usually
the answer will have little to do with the exact historical development. The $\l$-calculus
is, I feel, a case in point. In Scott (1980), in the Kleene Festschrift, I made up a story
of where the theory of type-free $\l$-calculus could have come from. Any number of people
who heard my lecture and read the manuscript were cross with me. They said ``But it didn't
develop that way! And besides we doubt it ever would have.'' But this reaction misses the
point of my story. I shall not, however repeat the earlier story here, for the point of
the present paper is different. For those people who do not like to discuss philosophy ---
even Philosophy of Mathematics --- my remarks here can be taken as a suggestion of how to
group diverse models of $\l$-calculus rather uniformly under a general scheme. The scheme
is by now rather well known and not at all original with me. What I hope can be regarded
as a useful contribution is my putting of the ideas in a certain order. As I consider the
order to be a natural one, I feel there is a philosophical significance to my activity;
but I should not want to force this view on anyone.

\newpage

\section{Theories of Functions}


Everyone agrees that $\l$-calculus is a theory of functions. But we must ask: ``What kind
of a theory?'' And also: ``Have we got the best theory?'' Personally, I think we should
also inquire: ``How does it relate to other theories?'' I certainly find many discussions
far too silent on this last issue. Well, what other theories are there? Certainly set
theory comes to mind at once, and no set theory would be worth its salt if it did not
provide a theory of functions. Let us not try to catalogue the various known theories here
but look at a theory in the style of Zermelo --- and we do not have even to be too
specific, since in any case such a theory is very standard. What is ``unsatisfactory''
about Zermelo's theory is the limitization-of-size view of sets: any {\it one} set $A$ is
extremely small compared to the size of $\V$, the class or universe of {\it all} sets.
Thus, functions $f : \AB$ mapping one set $A$ into another set $B$ tell us very little
about operations on all sets, maps on $\V$ into $\V$. We therefore have an urge to
``improve'' our set theory by constructing a class theory. Sets are elements $A \in \V$;
while classes are sub-collections $B \subseteq \V$. As $\V$ is (by the usual assumptions)
so highly closed under so many operations, we have no difficulty in construing certain
classes as maps $F: \V \to \V$. For example for all $X \in \V$ we could have $F(X) =
\{X\}$ or $F(X) = A \times X$ (where $A$ is a fixed set).

The passage from sets to classes is a familiar and useful move in the formalization of the
theory: many things can be done generally for classes and then specialized to sets. And
having a notation for functions defined on all sets is in many cases a great advantage.
But wait. What about operations on classes? What should we say about them? Given any two
classes $A$ and $B$, we can form their union, $A \union  B$. The operation, $\union\!: \V
\times \V \to \V$, of union of {\it sets} does not directly apply to {\it classes} even
though there is a connection. Do we also want a theory of class operations? Do we have to
go to hyperclasses (classes of classes)? Is there any end to this expansion?


[{\it An Aside}: The story of Scott (1980) was meant to suggest one answer --- the one
known to Plotkin (1972). Namely, we consider only ``continuous'' class operations. These
are objects $F$ such that $F(X)$ is defined for every class $X \subseteq \V$ and $F(X)$ is
a class, too. Moreover $F$ should satisfy:

\begin{enumerate}

\item $X \inc Y$ always implies $F(X)\inc F(Y)$

\item Whenever $A \inc F(X)$ and $A$ is a set, then $A\inc F(B)$ for some set $B \inc X$.

\end{enumerate}
%
We do not have time to discuss the justification of the word ``continuous'' here; suffice
it to say that conditions (1) and (2) are not as strict as they at first might seem. Every
{\it ordinary} map $f : \V \to \V$ determines a continuous class operator by the
definition:
$$
F(X) = \{f(x) \mid x \in X\}.
$$
%
Furthermore, $F$ determines $f$, for we have: $y = f(x)$ if and only if $\{y\} =
F(\{x\})$, for all $x,y \in \V$. In a suitable sense, then, nothing has been lost; but
what has been gained? The reply is that continuous class operators can be {\it identified}
with classes. We could write, for instance:
$$ F = \{(A,B) \mid A,B \in \V {\textrm { and }} A \inc F(B) \},$$ where, say:
$$
(A,B) = \{\{A\}, \{A,B\}\},
$$
More in harmony with Scott (1980) would be: $F = \{(a,B) \mid  a,B \in \V {\textrm { and }
} a \in F(B)\}$.

Either trick reduces operator theory to class theory --- in the continuous case. And the
same trick could be carried over to other kinds of set theory (e.g. Quine's). What we know
is that operator theory gives a model for $\l$-calculus; it is a quite elementary model,
too. Nice as this connection is, it is not the topic of the pre sent paper: we do not want
to make $\l$-calculus depend on set theory, since then we have still to explain where set
theory comes from. But the connection should be borne in mind.]

Perhaps set theory brings in too many extraneous issues. $\V$, after all, is a massive
object closed under all manner of strange operations. What we are probably seeking is a
``purer'' view of functions: a theory of functions in themselves, not a theory of
functions derived from sets. What, then, is a pure theory of functions? Answer: category
theory.

{\it General} category theory is a very pure theory: it is the milk-and-water theory of
functions under {\it composition}. This composition operation is associative and possesses
neutral elements (compositions of zero terms). That is about all you can say about it
except to stress that it is also a rather bland theory of types. Every function $f$ has a
(unique) {\it domain} and {\it codomain}, and we write:
$$f: \dom f \to \cod f.$$
%
Every possible domain is a codomain (and conversely), because if $A$ is such, then
$$\dom \id_A = A = \cod \id_A$$
%
where $\id_A$ is the neutral element of type $A$ (If we want to be especially parsimonious
in entities, we can even write $\id_A = A$, because each of $\id_A$ and $A$ uniquely
determines the other.).

The point of distinguishing domains and codomains is that not only do they specify the
type of $f$, but a composition $g \comp f$ is defined if, and only if, $\dom g = \cod f$.
And then $\dom(g \comp f) = \dom f$ and $\cod (g \comp f) = \cod (g)$. We usually write
this as a ``rule of inference'':
$$
\inferrule
  {{f: \AB} \\ {g: B \to C}}
  {g \comp f: A \to C}
$$
with the understanding that the typing of $f \comp  g$ can only be obtained by such an
application of the rule. The types, then, are invoked just to type functions, and the only
theory involved is that of the ``transition'' of types under composition.

Sets (and set-theoretical mappings) do of course form a category; category theory is meant
to be more general than set theory. We should construe the function entities here as
triples of sets $(A,f,B)$ where
$$
f \inc A \times B {\textrm{ and }}\, \forall x \in A \,\, \exists! y \in B\,\, s.t. \,\, (x,y) \in f.
$$
%
The definition of composition is obvious. Sets, in this way, give us only one special
example of a category. I beg forgiveness of the reader for boring him. All of this is well
known to the moderately awake undergraduate in mathematics. Indeed, that is the point:
there is plenty of evidence now that category theory is a natural and useful theory of
functions. I do not have to rehearse the examples as they can be found in any number of
books (e.g. Mac Lane (1971]). There is a rather important logical point to stress, however
important for anyone who has thought about $\l$-calculus models. Category theory is very
{\it extensional}. We assume as axioms the {\it equations}:
%
$$\id_A \comp f = f \comp \id_B =  f$$
%
and
$$h\comp (g \comp f) = (h \comp g) \comp f,$$
%
provided $A= \dom f$ and $B = \cod f$ and the double compositions are defined. These are
{\it functional} equations, and they say that two functions defined in {\it different}
ways are in fact {\it identical}. Furthermore, identical things can everywhere replace one
another.

This point about extensionality may not seem exciting or important, but the logician
should remember that, in certain {\it intensional} theories of functions, ``obvious''
definitions will not provide categories. We shall return to this point later. But is
category theory the long-sought answer? No, no, not at all. Category theory {\it pure}
provides nothing explicitly aside from identity functions --- and they occur only if we
have some possible domain. We do get compositions if we have the necessary terms. Thus, as
it stands, category theory has no existential import. (It was not meant to.) Set theory
has ``too much'' existential import. (It was meant to.) What we seek is the middle way ---
and an argument that the middle way is natural and general.

There is no need to build up unnecessary suspense: the middle way is the theory of the (so
called) {\it cartesian closed categories}. Fortunately Lambek has written extensively
about the theory, and I can refer the reader to his papers for further details; I also am
happy to acknowledge his writings as helping me understand what is going on. If we remark
that his paper in this volume is called ``From $\l$-calculus to cartesian closed
categories'', then we might say that my present paper ought to be called ``From cartesian
closed categories to $\l$-calculus.'' I am trying to find out where $\l$-calculus should
come from, and the fact that the notion of a cartesian closed category (\ccc) is a late
developing one (Eilenberg \& Kelly (1966)), is not relevant to the argument: I shall try
to explain in my own words in the next section why we should look to it {\it first}.

\section{A Theory of Types}

I say ``a theory'', because there are many possible theories; indeed pure category theory
is one of the theories. Its weakness lies in the fact that we are given no construction
principles, no way of making new types from old. From the point of view of logic what
should we expect? What more do we want to say beyond relations between types which hold
when a mapping statement $f : A\to B$ obtains.

An immediate question that must come to anyone's mind concerns the {\it arity} of
functions. The usual way of reading a mapping statement is to take it as a statement about
{\it one-place} functions, and the $\circ$ of composition is the composition of one place
functions. This seems very restricted.

People have suggested generalizing categories to {\it multi-place} functions with
concomitant compositions (e.g. the book Szabo (1978)), but it does not seem the neatest
solution. Much easier is to assume that the category has cartesian products --- and more
specifically particular representatives of the product domains are chosen. As a special
case we will know what the cartesian power $A^n$ is for each $n=0,1,2,\cdots$, and $n$-ary
functions are then maps $f: A^n\to B$. Not much of a surprise.

We have to take care, however. In the first place, a given category may not have cartesian
products (it fails to have enough types). Even if it does, the maps allowed may be too
restricted --- for logical purposes. Take the category of groups and homomorphisms, for
example. The required products exist. A map $f : A^2 \to B$ in this category has to be a
group homomorphism, naturally. Suppose two maps $u,v: \AB$ were given. Intuitively we
think in terms of elements and that we are mapping $x \mapsto u(x)$ and $y \mapsto v(y)$.
The pointwise group product of the maps, namely, $x,y \mapsto  u(x) \cdot v(y)$ is a very
nice map $g : A^2 \to B$ in the ordinary sense --- but unless the group $B$ is abelian,
$g$ is not a homomorphism. It is a ``logical'' map but not an ``algebraic'' map. Pure
category theory applies to many algebraic situations (as everyone knows that is why it is
a good theory), but not all categories are ``logical'' even if they have products. In the
example of groups, what was ``missing'' was the group multiplication $\mu: B^2 \to B$ as a
map in the category. (Inverse is missing as well, since it reverses order.) There is an
interesting theory of algebraic theories that address the question of the proper
categorial construction of categories of algebras, but I do not think we should invoke
that theory here.

The precise description of products is as follows. We assume our category has a special
domain $\bbone$ (the empty product, so $A^0 = B^0 = {\bbone}$), and for each domain $A$ a
special map $\zeromap_A: A \mapsto \bbone$. (The domain $\bbone$, intuitively, has just
one ``element''.)  Moreover the rule about maps is that $\zeromap_A$ is unique; that is
whenever $f : A \mapsto \bbone$, then we have the equation
$$f = \zeromap_A .$$
%
Concerning {\it binary} products, we have for any two domains $A$ and $B$ a special choice
of a domain $A \times B$ (and so $A^{n+1} = A^n \times A$), and special maps
\begin{align*}
p_{AB}&: A \times \BA\\
q_{AB}&: A \times B \to B
\end{align*}
%
But the mere existence of ``projections'' does not characterize $A \times B$ as a product.
We have to assume that there is a chosen pairing operation $\langle f,g \rangle$ on maps
such that types are assigned by the rule:
%
$$
\inferrule
  {{f: C \to A} \\ {g: C \to B}}
  {\langle f,g \rangle: C \to A \times B}
$$
%
Moreover, provided $f$ and $g$ are as above and $h: C \to A \times B $ we have to assume
\begin{align*}
p_{AB} \comp \langle f,g \rangle &= f\\
q_{AB} \comp \langle f,g \rangle &= g\\
\langle p_{AB}\comp h, q_{AB}\comp h\rangle &= h
\end{align*}
%
that is to say, there is an explicit one-one correspondence between the pairs of maps $f$,
$g$ and the map $h$ into the product. This all now makes $A \times B$ well behaved within
the category.

So much for a theory of tuples and multiary maps. But we still want a theory of functions:
a category allows us to talk of {\it selected} functions, while we would want various
equations to have a force relating to {\it arbitrary} functions. The answer to this desire
is {\it function spaces} as explicit domains in the category. Given $A$ and $B$ we want to
form $(\AB)$ as a domain in its own right; if so, there are many maps that have to be set
down to make the function space behave. (And here we must definitely leave the category of
groups.)

In the first place there has to be an evaluation map $\ebc : (B \to C) \times B \to C$
with the intuitive interpretation that it is the map $ f,x \mapsto f(x)$. In the second
place there has to be a map for shifting around variables; more precisely, suppose $h:
A\times B \to C$ is a map with two arguments. In an evaluation $h(x,y)$, we can think of
holding $x$ constant and regarding $h(x,y)$ as a function of $y$. We need a name for this
function --- and for the correspondence with possible values of x. We write
$$
\L_{ABC}\, h : A\times B \to C
$$
%
so that the function we were thinking of --- given $x$ --- was $(\L_{ABC} h)\, (x)$. But
all this function-value notation is not categorical notation; what we have to say is that
there is a one one correspondence via $\L$ between maps $h : A\times B \to C$ and maps $k:
A \to (B \to C)$. This comes down to these two equations:
%
\begin{align*}
\ev \comp \langle (\L h)\comp p, q\rangle &= h, {\textrm{ and}} \\
\L(\ev \comp \langle k \comp p, q \rangle) &= k.
\end{align*}
%
(It is necessary to have subscripts here: $\L_{ABC}$, $p_{AB}$, $q_{AB}$, and $\ebc$; but
we leave them off when there is no ambiguity.)

The notation is now wholly categorical (and mostly unreadable). Category theorists put the
whole thing (that is, the definition of a \ccc, which is what we have just given) into the
language of functors, which has a lot of sense. But if you have never seen any abstract
category theory before, it is really rather too abstract. The idea of a \ccc\ as a system
of types is, I think, reasonably simple. Each \ccc\ represents a theory of functions. The
maps in the category are certain special functions that are used to express the relations
between the types (the domains of the category). In order to be able to deal with multiary
functions, we assume we can form (and analyze) products. In order to be able to work with
transformations of arbitrary functions (``arbitrary'' within the theory), we assume we can
form function spaces: this is where ``higher'' types enter the theory, as in the sequence
of domains:
$$
A, (A \to A), ((A \to A) \to A), (((A \to A) \to A) \to A), \cdots
$$
To be able really to view these domains as function spaces, certain operations, $\ev$ and
$\L$, with characteristic equations have to be laid down. If a \ccc\ is a theory of
functions (and we include here higher-type functions), then the theory of \ccc's is the
theory of types of the title of this section. It is only one such theory. ``Bigger''
theories could be obtained by demanding more types: for example we could axiomatize {\it
coproduct}s (disjoint sums), $\bbzero$ and $A+ B$. We could demand infinite products and
co products. We could throw in a type $\Omega$ of ``propositions'' so that higher types
like $(A^n \to \Omega)$ correspond to $n$-ary predicates. This gets into topos theory (as
in Johnstone (1977) or Goldblatt (1979) --- just to name two recent texts). But the bigger
the theory, the more involved, and full definitions at this point would not help this
discussion very much. We could also look for ``smaller'' theories. Some examples --- of a
rather highly formal nature --- can be found in Szabo (1978) with an indication of the
algebraic interest of these other type theories. However, a \ccc\ is rather more
``logical'' and good as a middle ground; further Lambek has explained the logical
interest; {\it there is a perfect correspondence between \ccc's and (extensional) typed
$\l$-calculi}. The reader can turn to Lambek's paper for details and references.

\def\means#1{\llbracket\, #1 \,\rrbracket}

Roughly put, when we formally define the typed $\l$-language (with types in the given
\ccc), then if $\tau$ is a typed $\l$-expression with free variables of types $A_0,
A_1,\cdots, A_{n-1}$ we can de fine the ``meaning'' of $\tau$ as a map
%
$$
\means{\tau}: A_0 \times A_1 \times \dots A_{n-1} \to B
$$
%
where $B$ is the type of $\tau$. For example if $u$ is a variable of type $(B \to C)$ and
$v$ a variable of type $B$, then
$$
\means{u(v)}: (B \to C) \times B \to C,
$$
%
and in fact $\means{u(v)} = \ebc$. Also if $x$ is the variable in $\tau$ of type $A_{n-1}$
then
$$
\means{\lm{x}.\, \tau}: A_0 \times A_1 \times \dots A_{n-2} \to (A_{n-1} \to B),
$$
%
and in fact $\means{\l x.\, \tau} = \L\means{\tau}$. (Warning: for other of the variables
that are not the last mentioned, it is not so easy to write down the answer: some
permutations of the products have to be introduced.)

The two characteristic equations for $\ev$ and $\L$ in the axioms for a \ccc, have very
familiar translations:
\begin{align*}
( \lm{y}. h(x,y))(y') &= h(x,y') \quad {\textrm {and}} \\
\lm{y}. k(x)(y) &= k(x),
\end{align*}
%
where the type of $x$ is $A$, the type of $y$ and of $y'$ is $B$. (That is to say, the
$\means{\cdot}$-meaning of the two sides of the equation is the same map in the category.)
Of course this all has to be defined more rigorously, but I hope I have conveyed the main
part of the idea of Lambek's correspondence. A typed $\l$-calculus (with pairs, products,
and function spaces) is just another notation for a {c.c.c}.

No, we have to be more specitic than that. Take a \ccc\ How does it correspond to a theory
(of functions)? The domains of the category are the types of the theory, and they are
structured by the $\bbone$, $(A \times B)$, $(\AB)$ operations on types. Things like
$\comp$, $0$, $p$, $q$, $\langle\cdot,\cdot\rangle$, $\ev$, and $\L$ stand for logical
constants (or operators) --- with type subscripts as needed. Maps $f : \AB$ of the
category stand for the non-logical constants of the theory. The equations $f = g$ between
maps are the assertions of the theory. The logical axioms are those special equations
common to all \ccc's --- the other equations are those that just happen to work out in the
category. From this point of view the theory has {\it no free variables}: all assertions
are written with constant terms. Equations with free variables can be construed as
functional equations (by a heavy use of $\L$).

Conversely, a more conventional typed $\l$-calculus is an equational theory with both the
familiar logical axioms as well as with non-logical axioms as desired. The equations can
involve free variables. Aside from the usual deduction rules for equality, we must employ
the extensionality rule
$$
\inferrule
  {\tau = \sigma}
  {\l x .\, \tau = \l x .\, \sigma}
$$
%
A category is formed from the types (which are {\it given} as closed under $\bbone$, $(A
\times B)$, $(\AB)$). The terms all have unambiguous types, and they are divided into
equivalence classes by the theory. As the maps of the category we take the equivalence
classes $\br{\lm{x}.\tau}$ where the term $\tau$ of type $B$ has at most the variable $x$
of type $A$ free, and we write $\br{\lm{x}.\tau} : \AB$. Of course
\begin{align*}
\id_A &= \br{\lm{x}.x}, \, \textrm{and}\\
\br{\lm{y}.\sigma} \comp \br{\lm{x}.\tau} &= \br{\lm{x}.\sigma(\tau/y)}
\end{align*}
where $\tau$ is substituted for $y$ in $\sigma$. We must verify that a category is
obtained --- using the laws of $\l$-calculus.  And we must see that if we go back again to
a $\l$-calculus from the category we have essentially the same theory.

A \ccc\ (or typed $\l$-calculus --- with non-logical axioms) is a satisfactory
(extensional) theory of functions because all we have built into the theory is the idea of
the product and the function space. The axioms set down are just those needed to make this
structuring explicit. The reason that category theory is a convenient way to formalize
this definition is that starting from the especially elementary concept of maps under
composition, we can see that we have done nothing more than close up under products and
function spaces. $\l$-calculus, then, becomes mostly a notational device for setting down
our functional equations. At least for typed $\l$-calculus, we can see in this way that it
is harmless.

The typed $\l$-calculus is even more harmless than these last remarks suggested. By the
well-known Yoneda embedding, one can prove that an arbitrary (small) category has a full
and faithful embedding into a \ccc\ This means that starting with a given category and its
maps, there is a precise sense in which it is consistent to close up under products and
function spaces. No new maps are added to the given category; no new equations between the
given maps are imposed by the adjunction of higher types. One can say even more than this
about relative consistency, but the remark is best deferred to Section 4, where references
to the proof are provided.

A final remark must be added to this section to clear up a possible confusion between {\it
theories} and {\it models}. Up to this point we have been talking about theories. In many
systems of logic models can be described by theories: every model has a ``diagram''
involving constants for all the ``elements'' of the model and taking as axioms all
statements in the language ``true'' about the model. It depends on the nature of the
logic how hard it is to show that every ``consistent'' theory has a model.

In the case of a \ccc, a domain $A$ could be said to have an ``element'' $a$ if there is a
map $a: \bbone \to A$. The question is: {\it are there enough elements}? Suppose $f,g:
\AB$ are two maps. If $a : \bbone \to A$, then $f \comp a: \bbone \to B$; so in a certain
sense maps in the category behave as functions on elements. (This is not an original
suggestion but is one well known in category theory.) It is natural to ask whether, if  $f
\comp a = g\comp a$ for all $a : \bbone \to A$, then $f = g$. If this is true in a \ccc,
then it is said to have ``enough'' elements or to be concrete. In case it is concrete,
domains can be identified with sets, maps with functions, products $A \times B$ in the
category with the corresponding cartesian product of the sets (ask: which $c : \bbone \to
A \times B$ ?), and function spaces $(\AB)$ with spaces of actual functions (be cause
there is a one-one correspondence between maps $f : \AB$ and elements $e: \bbone \to
(\AB)$.

For a theory in the form of a \ccc, to ask whether it has a (non-trivial) model is to ask
whether it can be expanded to a concrete \ccc\ by the adjunction of elements (and other
maps and additional equations, but no new domains) which is non trivial in the sense of
not making all domains isomorphic to $\bbone$.

An answer --- though perhaps a rather formal one --- is supplied by the method of
adjunction of indeterminates $x: \bbone \to A$ presented in Lambek's paper (this volume).
We just have to adjoin infinitely many for each domain, one after the other. Each
polynomial involves only finitely many indeterminates. But the results stated by Lambek
(esp. Corollary to Theorem 2) show us at once that this expanded category is concrete. The
idea is really just like the idea of having ``free algebras'' for any equational theory.
(In $\l$-calculus an algebraic equation that is regarded as universally quantified, say $x
+ y = y + x$, is replaced by the functional equation
$$
\l x \l y . \, x + y = \l x \l y . \, y + x.
$$
%
More thoughts on concreteness will be brought out in Section 4.

That is the (easy) passage from theories to (certain) models. But remember, a theory is
not a model: the maps in a given \ccc\ are not concrete maps, they are just the definable
maps in the language of the theory, and the equations between them are the ``theorems'' of
the theory. It is no surprise that a given theory may not have enough {\it definable}
elements: we may need to expand the stock of elements in order to have a model. For a
\ccc\ we find we can. So far, so good; and this is the (known) story of typed
$\l$-calculus.

\section{``Type Free'' Domains}

In the paper of Lambek, the analogy between typed and type free is illustrated (in the
obvious way), but no real {\it connection} or {\it relation} is established. This we shall
now do, and the relationship will be deepened in the next section. In the first place, we
shall only consider the $\l$-calculus (or $\l K$-calculus) and not the $\l \eta$-calculus;
the latter can be regarded as a special case. What is needed is a notion of domain
appropriate to the interpretation of the ``type-free'' calculus.

In a category, a retraction between two domains $A$ and $B$ is a pair of maps $i: A\to B$
and $j : \BA$ where $j \comp i = \id_A$. Regard $A$ as the ``smaller'' domain; it is
injected into $B$, and $B$ is surjectively mapped onto $A$. The notion shares qualities,
then, of $A$ being both a {\it subspace} of $B$ and at the same time a {\it quotient}. But
the injection and surjection have to be related.

Now, suppose that in a cartesian closed category a domain $\U$ satisfies the condition
that the function space $(\U\to \U)$ is a retract of the domain $\U$ itself. (This is
always so for $\U = \bbone$, but we seek non-trivial examples.) Let the retraction maps be
$i: (\U \to \U) \to \U$ and $j : \U \to (\U \to \U)$. Then $\U$ (as it sits in its
category) gives us an interpretation of the type-free calculus, which we now explain. Let
the type-free terms be constructed in the usual way from variables $x,y,z, \dots$ by means
of application and $\l$-abstraction. Think of all variables as being of type $\U$ and
define a translation $\tau^*$ from untyped terms to typed terms so that
\begin{align*}
x^* &= x, \\
(\tau(\sigma))^* &= j(\tau^*)(\sigma^*),\\
(\lm{x}.\tau)^* &= i(\lm{x}.\tau^*).
\end{align*}
We intend this in such a way that $\tau^*$ is always of type $\U$. The type-free theory
(determined by the category, the domain $\U$, and by the choice of $i$ and $j$) has as its
assertions exactly those equations $\tau = \sigma$ where $\tau^* = \sigma^*$ in the
category. The theory satisfies $(\alpha)$, $(\beta)$-conversion-conversion, all the rules
of equality, and the rule $\xi$: from $\tau = \sigma$ to deduce $\l x .\, \tau = \l x .\,
\sigma$. This much is surely obvious to anyone reading Lambek's paper.

What I would like to point out here is the converse: given any type-free theory, there is
a \ccc\ and a domain $\U$ (with a suitable retraction pair $i,j$) so that the above
interpretation gives exactly the same type-free theory. Consequently, nothing is lost in
considering type-free theories just as special parts of typed theories. I do not find this
result mentioned by Lambek.

The proof is elementary. Let the domains for the category be the $\l$-terms $A$, without
free variables, for which we can prove in the theory:
$$
A = \lm{x}. A(A(x)).
$$
The maps $f: \AB$ are terms $f$ without free variables for which we can prove
$$
f = \lm{x}. B(f(A(x))).
$$
The equations between maps are the equations we can prove in the theory. [Actually, it
might be better to construe maps as triples $(A,f,B)$, but never mind.] It is not hard to
show that this is a category where
\begin{align*}
\id_A &= A, {\textrm{ and}}\\
f \comp g &= \lm{x}. f(g(x)).
\end{align*}
[More properly spoken, the maps should be equivalence classes of terms based on the
equations of theory, but never mind.] To show this construction gives a \ccc\ we need to
define:
$$
A \times B = \lmm{u}{z}.z(A(u(\lxy x))) (B(u(\lxy y))).
$$
where
\begin{align*}
p_{AB} &= \lm{u}. (A \times B)(u)(\lxy x),\\
q_{AB} &= \lm{u}. (A \times B)(u)(\lxy y),
\end{align*}
%
and if $f:C\to A$ and $g: C\to B$ then
$$
\langle f,g \rangle = \lmm{t}{z}.z(f(t))(g(t)).
$$
All of this is based on the familiar pairing functions of $\l$-calculus.

For function spaces, we define
$$
\AB = \lm{f}. B \comp f \comp A.
$$
where
$$
\ebc = \lm{u}. C(u(\lxy x)(B(u(\lxy y)))).
$$
and
$$
\L_{ABC}\, h = \lxy h(\lm{z}. z(x)(y)).
$$
provided $h: (A \times B) \to C$.

There are a jolly lot of equations to verify, but the work is all straight-forward
conversion. The method of retracts as a \ccc\ has in any case been exposed before with
respect to the $P\omega$ model in Scott (1976). Note here, however, we are to verify the
required equations in a theory (not a model) making use of nothing but the ``logical''
axioms of $\l$-calculus.

It remains to identify the domain $\U$ in the constructed category. We define:
$$
\U = \lm{x}. x\, .
$$
Clearly
$$
\U = \lm{x}.U(U(x)) = \U \comp \U .
$$
Note that every $A$ in the category is a retract of $\U$; indeed, for retractions define
$A : A \to \U$ and $A: \U\to A$ and
$$
A \comp A = A = \id_A.
$$
We thus speak of these A's also as retractions. We can write:
$$
(\U\to \U) = \lmm{x}{f}. f(x),
$$
and it is thus easy to verify now that $(\U\to \U)$ is a retraction of $\U$. As $\U$ is in
fact the identity function, the reinterpretation via $U$ of the type-free calculus will
obviously translate every term into itself. I just note in writing down the definition of
the \ccc, I forgot to define $\bbone$ --- because it is so dull, I suppose! For this we
have to map everything onto a constant:
\begin{align*}
\bbone &= \lmm{u}{x}.x, {\textrm{ and}} \\
\zeromap &= \bbone
\end{align*}
I think the calculations suggested provide an argument that the type-free $\l$-calculus
takes {\it second} place to typed $\l$-calculus --- foundationally speaking. Type-free
domains are \emph{special kinds} of types. As I have said before in other writings, to get
$(\U \to \U)$ inside $U$, we have to pass to an {\it infinite} type. I thought this was
made very clear in the so-called $\D_{\infty}$-construction. The category of
\emph{continuous lattices and continuous functions} is a \ccc. Starting with any domain
$\D_0$, in that category the sequence of types $\D_n$ where $\D_{n+l} =  (\D_n \to \D_x)$
has a certain limit $\D$ with $\D_0$ (and all the $\D$'s) as retracts, and with
$(\D_\infty \to \D_\infty)$ not only a retract but an isomorph of $\D_\infty$ That is one
choice of an $\U$, and I showed many variations are possible for other type-free domains
$U$ in this one category.

We hasten to note that in the \ccc\ of {\it sets and arbitrary functions}, a non-trivial
domain $\U$ with $(\U\to \U)$ a retract is impossible (by cardinality considerations).
This means that not all \ccc\ lead directly to interpretations of the type-free theory.
Hence, we must conclude, {\it the typed theory is the more general one, and the prior
one}.

Such a conclusion will not be welcome, however. The type-free theory from our experience
seems general enough. Even though we have shown two good ways of relating the two kinds of
theories, we would like something more. We do not want just some \ccc\ related to a given
type-free theory, but we would like to find a relation that achieved any desired \ccc,
provided we cook up the type-free one properly. This problem is the topic of the next
section.

Before we turn to this new relationship, a word about {\it models} of the type-free
calculus would be to the point. There is considerable discussion of the notion of a model
in Hindley and Longo (1980) and Barendregt (1980) (where other references are given). We
should state how this all fits in with the present view.

When presenting a theory in the usual $\l$-notation, free variables are permitted as well
as full use of the rule ($\xi$). But, when thinking of elements (relative to a theory)
only terms (better: equivalence classes of terms) {\it without free variables} should be
considered. As is known from many examples, there may not be enough of them. This can of
course be so even if we allow in our language many non-logical constants. What does
``enough'' mean? Well, if f and g are closed terms, it may be that $f(a) = g(a)$ is
provable for all closed $a$, but $f = g$ is not provable. The fact that this happens for
some theories should come as no surprise. (For the explicit examples consult Barendregt
(1980).)

The remedy is to adjoin indeterminates (constants without new axioms) until ``enough'' is
reached. (A proof is also found in Barendregt (1980).) As with the typed calculus, every
the ory has a model which satisfies exactly the same equations as are provable in the
theory (one might call it a conservative model). The notion of a $\l$-model has not struck
people as quite satisfactory because the extensionality principle in the ``enough'' clause
is not very algebraic. A suggestion of mine is mention ed in the cited references, but I
think it would be useful to recast the idea in the light of the present discussion.

In typed $\l$-calculus, the categorical formulation is one way of eliminating all use of
variables. In type-free $\l$-calculus, the usual plan is to use the combinators --- and
the plan leads to awfully long formulae, Let us not try to give a variable free
formulation, but talk in terms of first-order models. What is unalgebraic in the model
definition is the $\l$-operator, since a bound variable is of the essence of the use of
$\l$, So let us replace $\l$ by the combinators in the usual way. We take $S$ and $K$ as
primitive, and a $\l$-model is (at least), a structure of the form $\langle U,
\cdot(\cdot), S, K\rangle$ with a domain, a binary operation, and two distinguished
constants, The problem is: {\it what are the axioms}? Clearly we want:
%
\[
(*) \,\,
\begin{dcases}
K(x)(y) = x, {\textrm { and}}\\
S(u)(v)(x) = u(x)(v(x)),
\end{dcases}
\]
%
as usual. But these are not sufficient to express extensionallity which in $\l$-notation
reads
$$
\forall x.\, \tau = \sigma \imp \lm{x}. \tau = \lm{x}. \sigma
$$
If we convert out the variable $x$, we are tempted to write:
$$
\forall x.\, f(x) = g(x) \imp f = g.
$$
But this is too strong. (It corresponds to $\U = (\U \to \U)$ rather than the weaker: $(\U
\to \U)$ is a retract of $\U$.) If we wrote:
$$
\forall x.\, f(x) = g(x) \imp \lm{x}.f(x) = \lm{x}.g(x),
$$
the statement would at least be correct --- even if containing the unwanted $\l$. Well, we
just have to define this $\l$ in terms of $S$ and $K$. Introduce the standard definitions:
\begin{align*}
I &= S(K)(K)\\
B &= S(K(S))(K).
\end{align*}
%
Then, with $\l$-notation
$$
\lm{x}.f(x) = B(I)(f).
$$
So the desired axiom now reads
$$
({\mathrm {**}}) \quad \forall x.\, f(x) = g(x) \imp B(I)(f) = B(I)(g).
$$
We are not quite done, however, We want $S$ and $K$ to correspond to $\l$-expressions
(eventually), so we need an axiom which makes them suitably unique. Now we note
intuitively that
$$
\lm{x_0}. \lm{x_1}. \dots \lm{x_{n-1}}. f(x_0)f(x_1)\dots f(x_{n-1}) = B^n(I)(f)
$$
Thus what we need to say is
\[
\sss \,\,
\begin{dcases}
S = B(B(B(I)))(S), {\textrm { and}}\\
K = B(B(I))(K)
\end{dcases} .
\]
To see that $(*)$, $\ss$, and $\sss$ are adequate, we note first that
$$
B(I)(f)(x) = f(x)
$$
by $(*)$. From $\ss$ it follows that
$$
B(I)(B(I)(f)) = B(I)(f).
$$
This means that we can reformulate $\ss$ as:
$$
(**_1) f = B(I)(f) \land\, g = B(I)(g) \land\,\, \forall x.\,f(x) = g(x) \, \imp\, f = g.
$$
[This does not seem to be equivalent to $\ss$ unless we have the equation about
$B(I)(B(I)(f))$ just noted --- the retraction equation.] We now generalize $(**_1)$ to $n$
variables:
\begin{multline*}
\ssn \,\,
f = B^n(I)(f) \land\, g = B^n(I)(g) \,\,\land\,\, \\
\forall x_0, x_1, \dots x_{n-1}.\,f(x_0)f(x_1)\dots f(x_{n-1}) = g(x_0)g(x_1)\dots g(x_{n-1})\\
 \, \imp\, f = g.
\end{multline*}
If we prove this, then by $\sss$ we see that the original axioms $(*)$ uniquely determine
$S$ and $K$; further we have the uniqueness required to define $\lm{x}.\tau$ for any term
(cf. the references cited).

To establish $\ssn$, we need some lemmas.  From $(*)$ and $\sss$ and the definitions, we
can easily prove:
\begin{align*}
S(u) &= B^2(I)(S(u))\\
S(u)(v) &= B(I)(S(u)(v))\\
B(u) &= S(K(u)).
\end{align*}
%
We then establish for $n\geq 1$:
$$
B(I)(B^n(I)(f)) = B^n(I)(f),
$$
because $B^n(I)(f)$ has the form $S(u)(v)$. Suppose then that, e.g.
$$
\forall x, y, z .\, f(x)(y)(z) = g(x)(y)(z).
$$
By $\ss$ we find
$$
\forall x, y. \, B(I)f(x)(y) = B(I)g(x)(y).
$$
This can be rewritten as
$$
\forall x,y. \, B^2(I)(f(x))(y) = B^2(I)(g(x))(y).
$$
But again by $\ss$we find:
$$
\forall x.\ , B(I)(B^2(I)(f(x)))=B(I)(B^2(I)(f(x))).
$$
By the lemma, drop the $B(I)$. Throw on another $B$, use $\ss$, drop off the $B(I)$, and
get:
$$
B^3(I)(f) = B^3(I)(g).
$$
The method is perfectly general and proves $(**_n)$.

The import of this axiomatization is that $B(I)$ is the retraction of the universe $\U$
onto $(\U \to \U)$ and $B^n (I)$ retracts onto
$$
\underbrace{(\U \to (\U \to (\U \to \dots (\U \to \U)}_{n {\textrm{ times}}} \dots ))).
$$
We need $\sss$ to show that e.g.:
$$
S: \U \to (\U \to (\U \to\ U)).
$$
We need $(**_n)$ to show that the maps in these function spaces are uniquely determined by
their values. We have just been speaking in terms of models; but the calculations just
carried out were formal. The axiomatic question, then, is: what is the relationship
between the equational theories and the first-order theories? We shall now see the
relation is a close one --- even if the logic is allowed to go beyond the first order.


\section{A Role for Intuitionistic Logic}

The (rather cheap) method of adjoining indeterminates proves that every typed or untyped
theory of $\l$-calculus has an extensional model. This can also be put as a conservative
extension result for theories: a $\l$-theory is an equational theory, and every such
equational theory can be expanded to a first-order theory {\it without} forcing any new
equations on us,  In the untyped case, the style of first-order theory is that of axioms
$(*)$, $\ss$, $\sss$ of the previous section. These are the ``logical'' axioms (i.e.
common to all such tneories); the non-logical axioms would be all the equations between
closed $\l$-terms demanded by whatever equational theory we started with --- and these
special equations could involve special ``non-logical'' constants.

In the typed case, we would get a many-sorted theory with a sort for each domain in the
given category. As we have already pointed out, an untyped theory can always be
reformulated as a typed theory by the method of retracts. So we now concentrate on typed
theories --- that is to say, cartesian closed categories.

But the writing down of {\it first-order} theories is not all that interesting: we clearly
have nice axioms for a theory of functions, but first-order theories do not impress us as
being very categorical. Such theories do not really capture the idea of the ``arbitrary''
function. We began our discussion with set theory, where the intention was that function
spaces did really contain ``all'' functions --- they did not just appear as an ``algebra''
of functions. Leaving aside for the moment the (philosophical) question of whether the
desire for the {\it all} is a rational one, we can ask the (formal) question of whether
there is a conservative extension result for {\it higher-order} theories. Surprisingly,
category theorists have known the answer for some time. Now we cannot hope to embed the
theory of a typed $\l$-calculus into a {\it classical} higher-order theory with a full
comprehension axiom of the form
$$
\forall x:A .\, \exists !y: B .\,  \ffam(x,y)  \, \to  \exists f: \AB \, \forall x: A .\, \ffam(x,f(x)).
$$
Because in higher-order logic we can prove Cantor's Theorem which implies that the only
type $U$ which has a surjective map $j : U \to \UU$ is the one-element type. Thus, if a
typed theory had such a type (and we know many), then the adding of the standard
higher-order axioms (where we construe $(\AB)$ as the total function space of all
functions) would not at all be conservative. Something else has to be tried, and the
answer is higher-order {\it intuitionistic} logic.

As we shall now have to consider more than one category, let me call our given \ccc\ the
category $\C$. To fix ideas, the constructions to be carried out will be done in ordinary
set theory --- with classical logic! The models obtained, however, will only satisfy
intuitionistic logic. The obvious lack of harmony can be repaired, but it would take too
much explanation here. Moreover, we are also going to assume that the given category $\C$
is a set. This is not much of a restriction, since we were thinking of $\C$ as a theory
and usually a theory has a limited number of symbols in any case.

Before saying where the intuitionistic logic comes from, let me give the construction. Let
$\S$ be the category of all sets and arbitrary functions; we know it is a \ccc\  The
construction we need here is the well known one of the {\it functor category} $\scop$ of
all contravariant functors from $\C$ into $\S$ with the natural transformations as the
maps --- full definitions follow. The result is that the functor category is a model for
higher order intuitionistic logic, in particular it is a \ccc; more over the original
category $\C$ has a full and faithful embedding in $\scop\!\!$, and this shows the
conservative extension property. So much for the outline of the method, now for the
details. Needless to say this represents a {\it very early} chapter in topos theory; it
should be more widely known,

What is a {\it contravariant functor}? It is a mapping $F: \C\to \S$ that associates to
every domain $A$ of $\C$ a set $F(A)$ of $\S$ and to every map $f: \BA$ of $\C$ a function
$F(f) : F(A) \to F(B)$ (and note the change of order!) so that:
\begin{align*}
F(\id_A) &= \id_{F(A)} , {\textrm{ and}}\\
F(f \comp g) &= F(g) \comp F(f),
\end{align*}
%
provided $f: \BA$ and $g: C \to B$ in $\C$.

It was one of the major early insights of category theory to see that the functors form a
category in themselves. What is needed is a definition of transformation between functors.
We call such maps $\nu : F \to G$ ``natural transformations'' for reasons explained in
category theory books.

What is a {\it natural transformation} $v : F\to G$? It is an association with every
domain $A$ of $\C$ of a function $\nu_A: F(A)\to G(A)$ so that whenever $f : \BA$ in $\C$,
then the following diagram commutes in $\S$:
\[
\begin{tikzcd}[row sep=.75in, column sep = .75in]
    F(A) \arrow{d}{\nu_A} \arrow{r}{F(f)}  & F(B) \arrow{d}{\nu_B} \\
    G(A)  \arrow{r}{G(f)} & G(B)
\end{tikzcd}
\]
This means $\nu_B \comp F(f) = G(f) \comp \nu_A$. And example will help explain this.

For each $C$ of $\C$, let $H_C = \{ h \mid h: A \to C \}$ and if $f: \BA$ in $\C$ let
$H_C(f)$ be the map taking $h \in H_C(A)$ into $h \comp f \in H_C(B)$. It is easy to show
$H_C$ is a (contravariant) functor. It is often called the {\it representable functor}
(corresponding to C), and we shall see that it is very ``representative''.

Now let $g: C \to D$ in $\C$. There is a natural transformation $H_g: H_C \to H_D$
because, for each $h \in H_C(A)$ we can map it to go $g \comp h \in H_D(A)$, naturally.
The composite map for $f : \BA$ takes $h \in H_C(A)$ into $g \comp h \comp f \in H_D(B)$,
and there are two equal ways to calculate it owing to the associativity of composition (in
$\C$); that is why the necessary diagram commutes.

Not only are the $H_C$ pleasant functors with cooperative natural transformations between
them, but the by now classic {\it Yoneda Lemma} proves for us that the only natural
transformamations $\nu \in H_C \to H_D$ are those of the form $H_g$ for some $g: C\to D$.
If we remark that if $k:D\to E$, then
\[
H_k \comp H_g = H_{k \comp g}.
\]
%
This shows us that $H : \C \to \S^{\C^{op}}$ is a ({\it covariant}) functor between these
categories. Of course $H_C$ uniquely determines $C$ and $H_g$ determines $g$, so we
conclude from this and the Yoneda Lemma that $H$ is a full and faithful embedding of $\C$
into the functor category (all of this on p.2 of Johnstone (1977)!).

All of this discussion is ``abstract nonsense'' in the sense that its validity is
perfectly general for any category $\C$. If we assume that $\C$ is a \ccc, then we can say
more. The point is that $\scop$ is a very powerful category. For example, it is always a
\ccc\  even if $\C$ is not. The cartesian closed structure of the functor category is
obtained through the following definitions.

Before getting down to details, however, some more vivid terminology might help.

Think of a functor $U$ in $\scop\!\!$, following Lawvere, as a ``variable domain''.  That
is to say, for each $A \in \C$ we have an associated domain (set) $U_A = U(A)$. The maps
$f:\BA$ in $\C$ give us transitions between ``stages'' $A$ and ``later'' stages $B$; and
each such transition ``restricts'' elements in $U_A$ to elements in $U_B$ ``along'' the
map $f$. To save writing, let us set $a \res f = (Uf)(a)$ when the functor $U$ is
understood. That $U$ is indeed a functor comes down to these equations:
$$
a \res \id_A = a \,\textrm{ and }\, (a \res f) \res g = a \res (f \comp g),
$$
where  $f : \BA$ and $g: C\to B$ in $\C$. To define a functor $U$, then, we just have to
give the domains and the restrictions. For example the unit functor $\bbone$ has $\bbone_A
= {0}$, a one-point set, and all restrictions constant $0 \res f = 0$. And all natural
transformations into $\bbone$ are constant.

Now suppose $U$ and $V$ are two functors. We define $U \times V$ so that for all $A \in
\C$:
$$
(U \times V)_A = U_A \times V_A .
$$
%
Whenever $a \in U_A$ and $b \in U_A$ and $f: \BA$ then
$$
(a,b) \res f = (a \res f, b \res f) .
$$
(Note that the restriction symbol above is used in three different senses.) The natural
transformations $p : U \times V \to U$ and $q: U\times V \to V$ have obvious pointwise
definitions  (e.g. $P_A= P_{{U_A}{V_A}} : U_A \times V_A \to UA$) and they clearly commute
with restrictions. Similarly if $\mu: W \to U$ and $\nu: W\to V$ are given natural
transformations then $\langle \mu, \nu \rangle: W \to U \times V$ is also defined
pointwise:
$$
{\langle \mu, \nu \rangle}_A = \langle \mu_A, \nu_A \rangle : W_A \to U_A \times V_A .
$$
%
Again it is obvious that these maps commute with restrictions, so ${\langle \mu, \nu
\rangle}$ is natural. As all of this is pointwise; the verification of such equations as
$p \comp \langle \mu, \nu \rangle = \mu$ is easy. Again suppose $U$ and $V$ are given. In
defining $(U \to V)$, we cannot be quite as pointwise. That is, $(U \to V)_A$ cannot be
taken simply as the set of functions $(U_A \to V_A)$, the function space in sets. The
reason, roughly, is that when we have a function at {\it one} stage, we also have to know
how it restricts at {\it later} stages; a simple mapping from $U_A$ into $V_A$ does not
give us enough information for that. When $f : \BA$, restriction on $U_A$ maps into $U_B$;
this is the wrong direction for us to be able to pass from an arbitrary function defined
on $U_A$ to one defined on $U_B$. So an element of $(U \to V)_A$ has to be a whole {\it
family} of functions:
$$
\ffam_f: U_B \to V_B,
$$
%
one for each $f: \BA$. (Note: $A$ is fixed, $f$ and $B$ are variable.) Moreover, we must
assume that all is harmonious with restrictions: $c \res g = \ffam_{f \comp g} (b \res g)$
whenever $c = \ffam_f(b)$, for $b,c \in U_B$ and $g : C\to B$ in $\C$. In words,
$\ffam_{\id_A}$ is the ``present'' function; while $\ffam_f$ is what becomes of it in the
``future'', supposing time evolves along $f$. Now families $\ffam$ of this kind in $(U\to
V)_A$ have to be restricted. By what we just said, the following is more or less forced
upon us:
$$
(\ffam \res f)_g = \ffam_{f\comp g},
$$
%
where $f : \BA$ and $g: C\to B$ so that $(\ffam \res f)$ is a family in $(U\to V)_B$.

That defines $(U\to V)$ as a functor. To have $\scop$ be a \ccc, certain maps $\ev$ and
$\L$ are, alas, still required. The evaluation map $\ev : ((V\to W) \times V) \to W$ is
fortunately rather clear (as a natural transformation). Suppose $\ffam \in (V \to W)_A$
and $a \in V_A$ Then
$$
\ev_A(\ffam, a) = \ffam_{\id_A} (a).
$$
%
So $\ev_A : ((V \to W)_A \times V_A) \to W_A$. If $f: \BA$ then
\begin{align*}
\ev_A(\ffam, a) &= \ffam_{\id_A}(a) \res f\\
&= \ffam_f(a \res f)\\
&= (\ffam \res f)_{\id_B} (a \res f)\\
&= \ev_B(\ffam \res f, a \res f).
\end{align*}
%
This proves $\ev$ is natural.

Next, suppose $\psi: (U \times V) \to W$ is natural. Define $\L \psi  : U\to (V\to W)$ by
%
$$
(\L \psi)_A: U_A \to (V \to W)_A
$$
%
where for $a \in U_A$ and $b \in V_B$, and $f: \BA$ we have:
$$
(\L \psi)_A (a)_f (b) = \psi_B (a \res f, b).
$$
To show $\L\psi$ is natural, we must calculate:
\begin{align*}
(\L \psi)_A (a)\res f)_g (c) &= (\L \psi)_A(a)_{f \comp g} (c)\\
&= \psi_c(a \res f \res g,c)\\
&= (\L \psi)_B(a \res f)_g (c)
\end{align*}
%
for $a \in U_A$, $f : \BA$ and $g: C\to B$, $c \in U_C$. It follows that
$$
(\L \psi)_A \res f = (\L \psi)_B (a \res f).
$$
%
We have to leave to the reader the verification of the two basic equations of \ccc's
involving $\ev$, $A$, $p$ and $q$. As there was only one way that the definitions could be
written, the verification is quite mechanical, however. As I said before, the functor
category is ``powerful'', and indeed it is much more than a \ccc\  For instance, we can de
fine the analogue of the {\it power set} for arbitrary functors. For any $U$, let
$(\PU)_A$ be the collection of all families $S_f$ indexed by $f: \BA$ where $S_f \subseteq
U_B$ and such that $b\res g \in S_{f \comp g}$ whenever $b\in S_f$ and $g: C\to B$ in
$\C$. Restriction is defined by
$$
(\S \res f)_g = S_{f \comp g}.
$$
%
The significance of the power operator will become clear when we speak about higher-order
logic.

Having seen why the functor category is a \ccc, it is good to pause a moment to appreciate
the difference between the elements $a \in U_A$ as sets and the ``elements'' of $U$ in the
categorical sense. If $\alpha : \bbone \to U$ is natural it means that $\alpha_A  :
\bbone_A  \to U_A \in \S$. Let $a_A = \alpha_a(0)$, then $a_A \in U_A$. If $f:\BA$, then
because $\alpha$ is natural we find:
\begin{align*}
a \res f &= \alpha_A(0) \res f\\
&= \alpha_B(0 \res f)\\
&= \alpha_B(0)\\
&= a_B .
\end{align*}
This is very strong indeed, since usually if $a \in U_A$ and $f_0, f_1 :\BA$, there is no
reason why $a \res f_0 = a \res f_1$. So the number of ``elements'' of U will very likely
be rather small. (And, even worse, $a_A$ has to be chosen for all $A$ in $\C$.)

In the special case $\sigma :\bbone \to \PU$ we can simplify the choices out of $(\PU)_A$
even further. Write $S_A= \sigma_A(O)$ , then $S_A\subseteq U_A$ for all $A \in \C$.
Moreover, when $f: \BA$, then
\begin{align*}
S_B &= \sigma_B(0)_{\id_b}\\
&= \sigma_B(0 \res f)_{\id _B}\\
&= (\sigma_A(0) \res f)_{\id _B}\\
&= \sigma_A(0)_f .
\end{align*}
This means that $\sigma_A(0)_f$ is determined from the $S_B$'s. And if they are chosen so
that
$$
b \in S_B {\textrm{ implies }} b \res g \in S_C
$$
whenever $g: C\to B$, then the $\sigma_A$ so defined from them provides a natural
transformation. Again, we see the elements of $\PU$ are rather special. We can say that
elements of a functor provide information about the ``global'' nature of the functor; but
this is far from determining it, for there can be considerable ``local'' activity that
cannot be sensed globally. For example, the sets UB can be empty for a long ``time'', only
becoming non empty in the ``future''. The functor $U$ is non trivial, but it has no global
elements.

We should also pause to see why the functor $H$ maps $\C$ into a subcartesian closed
category of $\scop$ (up to isomorphism). It is easy to check that the functors $H_A \times
H_B$ and $H_{A \times B}$ are naturally isomorphic. We also have to do the same for $(H_A
\to H_B)$ and $H_{\AB}$. Consider an element of $(H_A\to H_B)_C$. It is a family of maps
$$
\phi_f : H_A(D) \to H_B(D)
$$
for $f: D\to C$. In particular consider the standard maps $p: (C x A) \to C$ and $q : (C x
A)\to A$. Then $\phi_p(q) : (C \times A)\to B$. So, since $\C$ is a \ccc, we find
$\L\phi_p(q) \in (H_{\AB})_C$. In the other direction, let $t : C\to (\AB)$. Define
$\tau_f$ for $f : D\to C$ by
$$
(\tau_f)(g) = \ev \comp \langle t \comp f \comp k, g \comp k \rangle
$$
where $g : D \to A$. We see this lies in $H_B(D)$. Now
$$
\ev \comp \langle t \comp f, g\rangle \comp k = \ev \comp \langle t \comp f \comp k, g \comp k\rangle
$$
whenever $k: E \to D$. Thus,
$$
(\tau f)(g) \res k = \tau_{f \comp k}(g \res k).
$$
This proves that the family $\tau_f$ lies in $(H_A \to H_B)_C$. It has to be left without
proof that these two correspondences are in verse to one another and provide a natural
isomorphism.

Well, this is a rather heavy construction starting from one little category $\C$. The
question: {\it what does it prove}? Why worry about the functor category? The answer is
that the functors give an interpretation of higher-order logic, as we hinted earlier, and
now we have to pay up and demonstrate how to construe logical formulae. The idea from
topos theory when specialized to the functor category looks very much like Kripke models
of intuitionistic logic --- except that the ``times'' form a category $\C$ rather than
just a partially ordered set, as has often been emphasized by Lawvere (see, e.g. Lawvere
(1975)).

To make the logical language more definite, let us think of the domains $A$ in $\C$ as
being (in a one-one correspondence with) type symbols. Introduce new type symbols built
from the ones in $\C$ (the ``ground'' types) by forming $\bbone$, $(T \times S)$, $(T\to
S)$, $\P T$ for all type symbols. (Note: $A \times B$ in $\C$ is being distinguished from
the type symbol $A \times B$. But the ``meaning'' of the symbol $A\times B$ will turn out
to be something ``isomorphic'' to $A\times B$ in $\C$. The trouble is that the domain $A
\times B$ does not in itself determine the $A$ and the $B$; whereas the type symbol does.)
We extend the notation $H_A$ to $H_T$ for any type symbol in the obvious way; that is,
$H_{T \times S}$ is the product $H_T \times H_S$ in the functor category. This is the
first step in treating the functor category as an interpretation of a higher-order theory.

Next we must imagine a logical language with a supply of variables of each type. Atomic
formulae will be of these forms: $\bot$; $x = y$, where $x$ and $y$ have the same type; $y
= f x$ where $f$ is a constant symbol corresponding to a map $f: A \to B$ in $\C$ and $x$
has type $A$ and $y$ type $B$; $z = (x,y)$ where $x$ has type $T$, $y$ type $S$, $z$ type
$T \times S;$ $z = x(y)$, where $z$ has type $S$, $y$ has type $T$ and $x$ type $(S \to
T)$; $y \in x$ where $y$ has type $T$ and $x$ type $\P T$. Atomic formulae are then made
into compound formulae by the usual constructs: $\Phi \land \Psi$, $\Phi \lor \Psi$, $\Phi
\to \Psi$, $\forall x. \, \Phi$, $\exists x. \, \Psi$.


Suppose $A$ is a domain of $\C$, $\Phi$ is a formula, and $s$ is a valuation of the free
variables of $\Phi$. We are going to define what Joyal-Reyes (1980) call the {\it
forcing-satisfaction} relation $A \mm \Phi[s]$. The definition here will be in one respect
simpler than theirs since the category $\C$ carries no topology; in an other respect it is
more complicated because we have the whole higher-order language. But the adaptation is
straight forward. Before we can give the clauses, we must say what kind of a creatures is.
We must make $s$ relative to $A$ in the first place. So if $x$ has type $T$, then $s(x)$
is to belong to the set $H_T(A)$. Now here are the clauses:
\begin{align*}
  A & \mm \bot [s] & {\textrm{ iff }} & {\mathit { false }} &\\
  A & \mm x = y  [s] & {\textrm{ iff }} & s(x) = s(y) &\\
  A & \mm y = f(x) [s] & {\textrm{ iff }} & s(y) = f \comp s(x) &\\
  A & \mm z = (x,y) [s] & {\textrm{ iff }} & s(z) = s(x,y) &\\
  A & \mm z = x(y) [s] & {\textrm{ iff }} & s(z) = s(x)_{\id_A} s(y) &\\
  A & \mm y \in x [s] & {\textrm{ iff }} & s(y) \in s(x)_{\id_A} &
\end{align*}
These were for the atomic cases and the reader should stop and think how the types are
supposed to match. For the compound cases we have:

\begin{align*}
  A & \mm [\Phi \land \Psi] [s] & {\textrm{ iff }} & A \mm \Phi[s] \textrm{ and } A \mm \Psi[s]\\
  A & \mm [\Phi \lor \Psi] [s] & {\textrm{ iff }} & A \mm \Phi[s] \textrm{ or } A \mm \Psi[s]\\
  A & \mm [\Phi \imp \Psi] [s] & {\textrm{ iff }} & \textrm{whenever } f:\BA\\
  &&& \textrm{and } B \mm \Phi[s \res f], \textrm{ then} \\
  &&& B \mm \Psi[s \res f]\\
  A & \mm [\forall x.\, \Phi [s] & {\textrm{ iff }} & \textrm{whenever } f:\BA\\
  &&& \textrm{and } b \in H_{T}(B), \textrm{ then} \\
  &&& B \mm \Phi[s \res f (b/x)]\\
  A & \mm [\exists x.\, \Phi [s] & {\textrm{ iff }} & \textrm{there is an } a \in H_T(A)\\
  &&& \textrm{such that } A \mm \Phi[s(a/x)]
\end{align*}
In the above, the notation $s(a/x)$ means the valuation is fixed so that $a$ matches $x$;
of course the type of $x$ must be $T$. By $s \res f$ we mean the valuation that matches
$s(x)\res f$ with each of the relevant variables $x$. In each case the restriction
operation must be made appropriate to the functor $H_T$ where $T$ is the type of $x$.

This is so much like Kripke models, the reader will have no problem in showing every
intuitionistic quantificational valid $\Phi$, is such that $A \mm \Pi[s]$ for all $A$ and
all appropriate $s$. We only have to take care that we remember that some ranges of
variables can be empty (that a set $H_T(A)$ may be empty), and so the logic is the
so-called ``free'' logic (cf. Scott (1979) for a discussion).

In order to verify the special axioms of higher-order logic, we need to remark first on
what Joyal-Reyes call the ``functorial'' character of $\mm$ :
$$
\textrm{if } A\mm\Phi[s] \textrm{ and } f:\BA \textrm{ then } B \mm \Phi[s \res f] .
$$
This, too, is a property familiar from Kripke models. It plays a direct role in the
verification of the comprehension axiom:
$$
\forall\, u_0, \dots, u_{n-1} \,\, \exists x \forall y .\,\,  [ y \in x \iff \Phi]
$$
where the free variables of $\Phi$ are among $u_0, \dots, u_{n-1}$ and $x$ is a new
variable not free in $\Phi$ of type $\P T$ where $T$ is the type of $y$.

To show the above valid in the interpretation we only have to show that for every $A$ of
$\C$ and for all $b_O, \dots ,b_{n-l}$ in the $H_S(A)$ of the appropriate types $S$, there
is an element $c \in H_{P(T)}(A)$ such that
$$
A \mm \forall\, y \,\, [y \in x \iff \Phi][s] .
$$
%
Here $s$ is the valuation where $s(x) = c$ and $s(u_i) = b_i$. We have to define $c$. For
each $f: \BA$ let
$$
c_f = \{t \in H_T(B) \mid B \mm \Phi [s \res f(t/y] \} .
$$
%
The functorial character of $\mm$ proves for us that $c \in H_{P(T)}(A)$. It is now easy
to check from the clauses of the definition of $\mm$ that at $A$ the above formula is
indeed forced.

In a similar way we can verify the functional version of comprehension:
$$
\forall x \, \exists y \, \forall z \, [ z = y \iff \Phi] \imp \exists f\, \forall x,z\, [z = f(x) \iff \Phi ]
$$
%
where we have $x$ of type $T$, $y$ and $z$ of type $S$; f of type $(T\to S)$ and $y$ not
free in $\Phi$. Again, the functorial character of $\mm$ connects with the way we had to
define $(H_T \to H_S)$.

We also have to verity such extensionality properties as:
\begin{align*}
&\forall f,g \, [\forall x,y \, [ y = f(x) \iff y = g(x) ] \imp f = g],\\
&\forall x,y \, [\forall z \, [ z \in x \iff z \in y ] \imp x = y],
\end{align*}
%
where the variables have to be given the appropriate types. But in defining the function
spaces and the powersets in the functor category, we only put in just enough of a mapping
or a set to get an appropriate functorial character. Hence, if two such objects are
extensionally equal by the formulae above, they will be equal. This has to be spelled out
via $\mm$, but it is not surprising.

The higher-order axioms for ordered pairs are obvious, and their satisfaction relates at
once to the definition of product of functors. As for the embedding of $\C$ into the
higher-order theory we find
$$
\forall x,y \, [y = f x \iff y = gx]
$$
is valid if and only if $f = g$ in $\C$. Also, when $h = g \comp f$ we have as valid:
$$
\forall x,y,z\, [[(y = fx \land z = gy] \imp z = hx].
$$
Further, functions like fare well defined:
$$
\forall x\, \exists y.\, y = fx .
$$
There are many principles of identity that should be men tioned, but we will not write
them down here. Among them we would also find the statements that there is a unique
element of type $\bbone$ and all maps of type $(T\to \bbone )$ are constant. (Perhaps the
constant 0 should figure in the language, but it is not all that essential.)

As for questions of uniqueness, if the sentence
$$\forall x\, \exists y\, \forall z\, [z = y \iff \Phi]$$ is valid (i.e. forced at all
$A$), then provided $x$ and $y$ have ground types $B$ and $C$, respectively, there is an
$f : B\to C$ in $\C$ such that
$$\forall x,z\, [z = fx \iff \Phi]$$ is valid too. The validities, then give us an exact
picture of $\C$ at the level of ground types: the higher-order theory is conservative over
$\C$.

But the higher-order intuitionistic theory of the functor category is much more than just
a conservative extension; it is a full-blown {\it higher-order} theory with full
comprehension axioms. That is to say, we started out with a category $\C$ we regarded
algebraically as a theory of functions. Well, the construction of the functor category
shows us that we can indeed construe $\C$ and its maps as normal, everyday functions in a
normal, every day higher-order logic. This works as long as we agree to keep our logic
intuitionistic. But experience with intuitionistic logic really shows that the system is a
natural one and that it leads to very, very interesting theories. Even if $\C$ is a \ccc,
we can show that the embedding of $\C$ in the higher-order logic preserves all the
cartesian closed structure, so that the function spaces in $\C$ really become spaces of
all possible functions in the higher-order theory. The principles of $\l$-calculus are
thus consequences of the standard logical axioms. This seems to me to establish complete
harmony between (intuitionistic) logic and (typed) $\l$-calculus.

The next step in this investigation would be to see what other properties of the
higher-order logic could be enforced and still preserve the conservative extension over
the given category $\C$. The functor category is just a very first stage of the
investigation: In topos theory the categories of sheaves result from putting a kind of
modal operator into the logic, and making a reinterpretation of the logical connectives
and quantifiers. The passage from $\scop$ is one of finding \ccc\ as cartesian closed
subcategories of the functor category. There are many of them and many still contain $\C$
as a  cartesian closed subcategory, So, there is much to look for, and --- I am sure ---
much left to be discovered of definite logical interest.

\section{Type-Free Domains Revisited}

Having made any given \ccc\ $\C$ ``honest'' as a theory of functions in higher-order
logic, we can conclude from the method of retracts of Section 3 that any type-free
$\l$-theory can similarly be made honest. Intuitionistic logic is very tolerant of types
$U$ where $\UU$ is a retract; so tolerant in fact that {\it any} $\l$ theory can be
embedded in a suitable higher-order logic. Self application is no longer odd: it is
something that may very well turn up when we weaken our logic to be intuitionistic but
still require that functions spaces like $\UU$ contain all functions.

This provides a certain kind of rescue for the type-free calculus, but the move fails to
give it a universal role: the creators of the type-free theory hoped that such a universe
U could be thought of as containing all the functions there were. We shall not try to go
so far in the present context, but vari ous constructions can be used to show that not
only is it possible to have {\it one} such type-free domain, but it is always possible to
find them being richer and richer and containing more and more functions. Only a sketch of
the construction can be given here.

Suppose, for the sake of illustration, we have some types $A$, $B$, $C$ that we happen to
like, and that we are interested in the functions between them --- possibly also in
functions of the type $(A^2 \times B) \to C$, and similar multivariable types. We could
probably work up a \ccc\  containing $A$, $B$, $C$ and these functions, but the
straight-forward construction would contain no type free domains (cf. the category of sets
and maps in ordinary logic). We need a new method. My first approach is to use the idea of
continuous lattices. I do not want to go into a lot of detail (cf. Gierz et al. (1980) for
just such details), but there is an easy definition that can be invoked at least to make
the statements precise.

We shall employ what are not technically lattices but ``half'' lattices without unit
elements (top elements). Fortunately we do not have to go into a long list of definitions,
since I have been able to characterize them rightly as special {\it topological spaces}.
They are in fact $T_0$-spaces (i.e. spaces where points are uniquely determined by their
neighborhoods) $D$ such that whenever $X$ is a dense subspace of a topological space $Y$,
and $f : X\to D$ is a continuous function, then $f$ has a continuous extension $f:Y\to D$.
What I proved is that the category of such spaces $D$ together with continuous maps
between them is a \ccc . (There are very many intriguing \ccc's related to the category of
topological spaces!) Let us employ the temporary name ``injective'' for these spaces.

As an example of injective spaces, consider one of our given types $A$, which for
simplicity we construe just as a set. The injective space $A_*$ corresponding to $A$
results from adding one new point $*$. Or, if classical logic is not assumed, we take
$A_*$ as the space of subsets of $A$ with at most one element. The topology is generated
by sets of the form ${x \in A_* \mid  a \in x}$ where $a \in A$, Thus, a function $f : X
\to A_*$ is {\it continuous} if $\{x \in X \mid a \in f(x)\}$ is open in $X$ for each $a
\in A$. Now if $X \subseteq Y$ as a dense subspace, we have only to define
$$
\bar{f}(y) = \bigcup \bigl\{\{a \in A \mid \forall x\, \in N \cap X.\, a \in f(x)\} \mid y \in N\bigr \},
$$
where N ranges over the open sets of Y. Because every non-empty open set has a non-empty
intersection with $X$, it follows that $\bar{f} : Y \to A_*$. To prove $\bar{f}$
continuous, we remark that $\{a \in \bar{f}(y)\}$ is the largest open subset of $Y$ whose
intersection with $X$ gives $\{x \in X \mid a \in f(x)\}$. It is also easy to calculate
that $\bar{f}$ extends $f$. So $A_*$ is injective. Note, too, that $A$ may be regarded as
a dense subspace of $A_*$ if we map $a$ to $\{a\}$.

Hence, every function $g:\AB$ has a unique counterpart $g_* : A_*\to B_*$ so that the
``restriction'' of $g_*$ to $A$ gives $g$ back again (indeed $g_*(\{a\}) = \{g(a)\}$).
This really means that the *-construction is a faithful functor from the category of our
sets $A$, $B$, $C$ into the category of injective spaces and continuous functions.

But now we can apply my construction of $\l$-calculus models to find an injective space
$U$ which, in the category of injective spaces, has $\UU$ as a (continuous) retract and in
addition has $A_*$, $B_*$, and $C_*$ as retracts. (In fact, for those who know the method,
we solve the domain equation
$$
u = A_* \times B_* \times c_* \times (U \to U),
$$
where of course a factor is always a retract of a product; be cause in the category of
injective spaces the one-point space is a retract of every space.) This idea could be
extended to obtain any given set of injective spaces as retracts of a {\it single} space
$U$.

Next we invoke the plan of the previous section using as the category $\C$ the retracts of
$U$ (and continuous functions), which we can regard as a small category (as a set). The
functor category has all higher-order logic as well as a full and faithful picture of
$\C$. We are definitely going to take advantage of the higher-order structure in looking
at subtypes of the functors $H_V$ where $V$ is a domain in $\C$ --- more precisely, we
will look at the category generated by certain of these subtypes or subfunctors in the
functor category

In the first place, consider $H_{A_*}$. Let $K_A$ be the functor where $K_A(V)$ is just
the set of all continuous functions $f: V\to A_*$ where for some $a \in A$, we have $a \in
f(x)$ for all $x \in V$. (The retracts of $U$ are simply being regarded as injective
spaces, and we do not distinguish between $A_*$ as a constructed space based on the set
$A$ and as a retract of $U$.) The restriction operation $\res f : K_A(V)\to K_A(W)$ is the
one for the functor $H_{A_*}$ with the domain cut down: $K_A$ is a {\it subfunctor} of
$H_{A_*}$.

We can think of the maps in $K_A(V)$ as being the {\it constant} maps with values in $A$.
So what then can we have for natural transformations $\nu: K_A \to K_B$, the maps in the
functor category? Well, imagine one. Now if $a \in A$, we can take the appropriate
constant map $k_a \in K_A(\bbone)$, where $\bbone$ is the one-element space. Then
$\nu(k_a) \in K_A(\bbone)$. But this too is a constant map and determines a unique $b \in
B$; so $\nu$ defines a function $|\nu| : \AB$. And, since every constant map factors
through the one-element space $\bbone$, the map $|\nu|$ uniquely determines $\nu$. But
{\it any} map from $A$ into $B$ can be made to turn up in this way by trivially fooling
around with constants. We conclude, therefore, that $K_A$ as a functor --- of our given
sets $A$ --- is a full and faithful embedding.

What have we done? First, starting in sets --- or perhaps, better, in higher-order logic
--- we found (or gave ourselves) a category of types we liked. To be more definite, they
could have been unioned together so they were all subtypes (subsets) of a single set, $V$,
say. We then embedded faithfully this category of sets and maps into the category of
injective spaces via the very elementary $A_*$ construction. Of course, the spaces $A_*$
are very special, so the ``universal'' space $U$ with $\UU$ as a retract is much more
messy than $V_*$. But the category of retracts of $U$ contains all the maps between the
$A_*$. Finally this category of retracts is fully and faithfully embedded in the the
functor category. The latter has the advantage of subtypes in profusion, so we were able
to recapture the original cate gory of subsets of Vas a full and faithful subcategory of
the functor category.

And having done all this, what have we bought? Well, the (pictures of) the $A$'s were
subtypes of the $A_*$'s which are both retracts and subtypes of $U$, and in the functor
category $U$ is a model for the untyped $\l$-calculus. So that means that starting with
our original notion of function, we have --- in the logic of the functor category ---
consistently been able to assume that there are types giving models for the ``type-free''
$\l$-calculus, and further, that these types are rich enough to contain our original
category in a full and faithful way. In more detail: the new logic allows us to think of
$A$ and $B$ as subtypes of $U$, where $\UU$ is a retract, so that any function from $A$
into $B$ is the result of restricting a function in $\UU$ down to the subset $A$. Warning:
this does not hold for all subtypes of $U$, the $A$, $B$, $C$ were given in {\it advance}
and $U$ was constructed relative to them. Still, this means that even in models for type
free $\l$-calculus(which can be regarded as ordinary function spaces), we are not losing
sight of the standard idea of function. To have $\UU$ as a retract of $U$, the functions
have to ``bend'' a little, but we have kept them ``straight'' as far as the given $A$,
$B$, and $C$ go.

We have just shown how a type-free domain $U$ can incorporate given domains as well as the
``arbitrary'' functions on them. In Engeler (1979) it is shown that $\l$-calculus models
can also in corporate any {\it algebra}; specifically it is shown that any algebra can be
made isomorphic to a subset of the model where the operation is functional application
itself. We shall give a proof here using the constructs we have mentioned.

Let $A$ be set. An ``algebra'' can be regarded as any binary operation $\dotop : A\times
A\to A$. A partial algebra can be taken to be any continuous $\dotop : A_* \times A_* \to
A$. It is easy to argue that any algebra on $A$ determines a partial algebra on $A_*$.

Now let the $\l$-calculus model $U$ be taken so that $U = A_* \times  \UU$. We regard
elements $x \in U$ as pairs $(x_0 , x_1 )$. The application operation $f(x)$ on $U$ can be
defined as $f_1(x)$ because $f_1 \in \UU$. Now recall that $\l$-calculus models satisfy
the fixed-point theorem; so we can define a map $\rho: A_*\to U$ by the functional
equation:
$$
\rho(a)  =  (a, \l x: U. \,\,\rho (a \dotop x_0)
$$
where the $\l$-operator gives an element in $\UU$. This map is continuous and one-one
into. Now calculate in $U$:
\begin{align*}
\rho(a)(\rho(b)) &= \rho(a\dotop \rho(b)_0)\\
&= \rho( a  \dotop  b)
\end{align*}
So the image of $\rho$ is closed under application, and the resulting applicative
subalgebra is {\it isomorphic} to the given algebra $\langle A_*, \dotop \rangle$.

This result would seem to have a potentially useful implication for {\it non-extensional}
models of combinatory algebra: any such can be embedded in an application-preserving way
into an extensional model. This works even if we regard application as a partial
operation. {\it Warning}: we do not obtain a combinator preserving embedding, however.
That is, if the algebra $\langle A_*, \dotop \rangle$ has elements $S$ and $K$, satisfying
the usual equations in $A_*$ we cannot conclude that the embedding $\rho : A_* \to U$ will
map the $S$ and $K$ of $A_*$ to the ``true'' $S$ and $K$ of the $\l$-calculus model $U$.
The ``functions'' in $A_*$ operate only on $A_*$, which is quite a limited part of $U$;
clearly $\rho$ does not give elements $\rho(a) \in U$ very broad roles. But at least we
can say that anything that even looks a little like application can be assumed to be
application in a suitable domain.


\section{Summary and Conclusions}

The constructions reviewed and outlined here have been rather lengthy, so it would seem
best to summarize the principal conclusions we have reached.

\begin{enumerate}

\item {\it A theory in typed $\l$-calculus is just the same as a cartesian closed category.}

As was stated, this has been known for well over ten years from the work of Lambek. It
should be stressed, however, that category theory achieves a greater generality than the
usual logical presentations, because in category theory the type con structions are
axiomatized. Thus, the types form an ``algebra'' under the operations $T \times U$ and
$(T\to U)$. We need not assume that we always have a ``free'' algebra of types built out
of ``ground'' types.

\item {\it In a \ccc\  a reflexive domain provides an interpretation of the ``type-free'' theory.}

We can call $U$ ``reflexive'' if $\UU$ is a retract. The last statement is of course
obvious. What makes it interesting is:

\item {\it Every type-free theory is the theory of a reflexive do main in a \ccc\ }

The proof of this result was by the author's method of retracts. The use of idempotents in
a category as forming a category is well known, but the author believes that he was the
first to note that in a \ccc\  we really have a calculus of retracts --- especially when
there are reflexive domains available. Then some remarks were made about theories and
models and the significance of adding indeterminants (also well known). What might not
have been clear from other works was the type free theory in terms of application, $S$,
and $K$. Up to that point the theories had been equational; and, though the first order
version (with extensionality) was pleasant, it was not of great philosophical interest
since it does not relate the idea of $\l$-calculus to any broad notion of functions. This
desire was taken care of by:

\item {\it Every \ccc\  can be fully and faithfully embedded in an intuitionistic 
theory of types with the full (impredicative) power-set construct and function spaces 
(higher-order intuitionistic logic).}

The domains of the \ccc\  become types in the theory. The word ``fully'' means that the
definable maps between the types all come from maps in the category; ``faithfully'' means
that in the higher-order theory no new equations between these maps are introduced over
what we already had in the category. In other words, this is a conservative extension
result. It has been known for quite a time in category theory, and the functor category we
employed in the construction is one of the very first examples of a topos; there must be
considerable use possible of more interesting examples of topoi.

However, there was already enough philosophical interest in this easy construction.
Namely, it was seen that equational $\l$- calculus is perfectly consistent with
higher-order logic where --- provided we only employ intuitionistic logic --- we can speak
of function spaces in the normal way in type theory. Some people can, if they like, stick
to $\l$-terms and equations; but others can use whatever logical means they like for dis
cussing functions. However, if the logician {\it proves} in his higher-order theory that a
certain property picks out a function $f : \AB$, then, if $A$ and $B$ are from our given
category, this definable $f$ must be given by a standard $\l$-term. So the logic in that
sense gives nothing new, but at least we know that the sense for $\l$-calculus is exactly
that it can always be taken to be talking about functions and {\it full} function spaces
in a higher-order theory.

Turning things around the other way, it is interesting to see from what we know about
``type-free'' theories that intuitionistic logic allows for reflexive domains --- and even
lots of them. It would be even more interesting if it were possible to strengthen
higher-order logic (say, by adding some new primitives), so that we could express in the
logic the axiom that every \ccc\  (a structure satisfying a simple first-order statement)
had a full and faithful representation in a category of subsets (better: quotients of
subsets) of a reflexive domain. I conjecture that this is possible and that the theory can
be taken conservative over any given \ccc\

Though we did not prove such a sweeping result, we did sketch a proof of:

\item {\it Every given \ccc\  can be realized fully and faithfully as a category of 
subtypes of a reflexive type in a higher-order theory.}

We did not work out the cartesian closed details of this assertion but contented ourselves
with showing how to accomodate a finite number of types. By the way, it should be remarked
that 4 and 5 hold for an arbitrary (small) category, so in par ticular we have the (known)
result that every category can be conservatively extended to a \ccc\  The method of proof
for 5 was via the author's original construction of $\l$-calculus models, which can be
conveniently carried out in the category of ``injective'' $T_0$-spaces. There are many
variations on this construction, and it might be interesting to see how different the
different categories with reflexive domains really are from the point of view of
higher-order logic.

Another remark: the construction has many connections with {\it Curry's Theory of
Functionality} (i.e. the problem of finding other \ccc's inside a $\l$-calculus model).
But as I have indicated several times it is really better to work with equivalence
relations (on subtypes of a reflexive domain $U$) because in typing the functions we have
to make them hereditarily ex tensional in order to be able to have a category. Thus a
reflexive domain has (at least) two interesting \ccc's associated with it: the category of
retracts and the category of equivalence relations. The second, by the way, contains the
first as a sub-\ccc\

Finally we recalled a result of Engeler which was very appropriate to the present
discussion:

\item {\it Any (partial) algebra can be isomorphically represented as an 
applicative sub-algebra of a reflexive domain.}

I think that this means in particular that non-extensional theories of functions can be
subsumed under the extensional theory: the non-extensional function algebras are just sub
algebras of normal function algebras. There is certainly a conservative extension result
here, but whether it helps to prove any new theorems is another question.

What has to be investigated next, I think, is the problem of how strong the higher-order
theories can be made and still have them as conservative extensions of given categories.
Much is known in topos theory about constructions of categories of sheaves (these are
subcategories of the functor category), but much remains to be explained to the logician.
Thus, there are several interesting categories made up out of continuous functions or out
of computable functions (when we look at them from the outside), but what we would like to
know is what logical sentences (internal properties) are satisfied for the various functor
or sheaf categories. The so-called Church's Thesis (all number-theoretic functions are
recursive) or Brouwer's Theorem (all real functions are continuous) are cases in point,
and they are satisfied in certain topoi. It would be an important next step for
$\l$-calculus to relate these model constructions to interpretations of $\l$-calculus, The
author hopes that the present paper will encourage others to look further.

\end{enumerate}


\begin{thebibliography}{86}

\bibitem[1]{1} Barendregt, H., (1980). {\it The Lambda Calculus: its Syntax and
Semantics}, North-Holland, Amsterdam, to appear.

\bibitem[2]{2} Engeler, E., (1979).  {\it Algebras and combinators}, preprint ETH Zllrich.

\bibitem[3]{3} Gierz, G., Hofmann, K.H., Keimel, K., Lawson, J.D., Mislove, M., and Scott,
D.S., (1980). {\it A Compendium of Continuous Lattices}, Springer-Verlag, Heidelberg, to
appear.

\bibitem[4]{4} Goldblatt, R., (1979). {\it Topoi: The Categorial Analysis of Logic},
North-Holland, Amsterdam.

\bibitem[5]{5} Hindley, R., and Longo, G., (1980). {\it Lambda calculus models and
extensionality}, Math. Logik u. Grundl. d. Math, to appear.

\bibitem[6]{6}Johnstone, P., (1977). ``Topos Theory'', London Math. Soc. Monographs No.
10, Academic Press, London.

\bibitem[7]{6} Joyal, A., and Reyes, G.E., (1980). {\it Forcing and generic models in
categorical logic}, J. Pure and Applied Algebra, to appear.

\bibitem[8]{7} Lawvere, F.W., (1975). {\it Continuously variable sets: algebraic
geometry$\,=\,$geometric logic}, In ``Logic Colloquium '73'', (Eds. H.E. Rose and J.C.
Shepherdson), North-Holland, Amsterdam, pp. 135-156.

\bibitem[9]{8} MacLane, S. (1971). {\it Categories for the Working Mathematician},
Springer-Verlag, Heidelberg.

\bibitem[10]{9} Plotkin, G. (1972). {\it A set-theoretical definition of application},
Memo, MIP-R-95, School of Artificial Intelligence, Univ. of Edinburgh. Scott, D.S.,
(1976). Data types as lattices, Siam J. Computing, Vol. 5, pp. 522-587.

\bibitem[11]{10} Scott, D.S., (1979). {\it Identity and existence in intuitionistic
logic}, In ``Applications of Sheaves'', Springer-Verlag, Lecture Notes in Math. Vol. 753,
pp. 660-696.

\bibitem[12]{11} Scott, D.S., (1980). {\it Lambda calculus: Some models, some philosophy},
In The Kleene Symposium, (Eds. J. Barwise, H.J. Keisler, and K. Kunen), North-Holland,
Amsterdam, pp. 381-421. Szabo, M.E., (1978). "Algebra of proofs", North-Holland,
Amsterdam.

\bibitem[13]{12} Szabo, M.E., (1978). {\it Algebra of proofs}, North-Holland, Amsterdam.

\end{thebibliography}
