% !TEX TS-program = pdflatexmk      
\documentclass[12pt]{article}   
\usepackage{authblk}                  

\usepackage[colorlinks=true
,urlcolor=blue
,anchorcolor=blue
,citecolor=blue
,filecolor=blue
,linkcolor=blue
,menucolor=blue
,linktocpage=true]{hyperref}
\hypersetup{
bookmarksopen=true,
bookmarksnumbered=true,
bookmarksopenlevel=10
}
%\usepackage{amssymb}
%\usepackage{amsmath,amsthm,amscd,amssymb}
\usepackage[noBBpl]{mathpazo}
\linespread{1.1}
%\usepackage[letterpaper, margin=1.2in]{geometry}
\usepackage[papersize={6.9in, 10in}, left=.5in, right=.5in, top=1in, bottom=1in]{geometry}
\tolerance=2000
\hbadness=2000
\usepackage[small]{titlesec}
 
\input{preamble_PAPER.tex}  
\usepackage{tikzfig}                    

 
\title{Categorical Quantum Mechanics I:\\  Causal Quantum Processes}                                                                                                                                                                     
\author[1]{Bob Coecke}
\author[2]{Aleks Kissinger}

\date{}

\affil[1]{Department of Computer Science, Oxford. {\tt coecke@cs.ox.ac.uk}}          
\affil[2]{iCIS, Radboud University, Nijmegen. {\tt aleks@cs.ru.nl}}      



\begin{document}     

\maketitle

\begin{abstract}
We derive the category-theoretic backbone of quantum theory  from a process  ontology. More specifically, we treat quantum theory as a theory of systems, processes and their interactions. %Classical and quantum systems are treated as distinct types, of which the respective behavioural properties are  also specified in terms of processes and their compositions.  % THIS SENTENCE IS MORE ABOUT PART II

In this first part of a three-part overview, we first present a general theory of diagrams, and in particular, of string diagrams.  We discuss why diagrams are a very natural starting point for developing scientific theories.  Then we define process theories, and define a very general notion of quantum type. We show how our process  ontology  enables us to assert causality, that is, compatibility of quantum theory and relativity theory, and we prove the no-signalling theorem.   

Other notable contributions include new, elegant derivations of the no-broadcasting theorem, unitarity of evolution, and Stinespring dilation, all for any `quantum' type in a general class of process theories.        
\end{abstract}    

\section{Introduction}    

This chapter is the first  of a three-part  overview  on categorical quantum mechanics (CQM), an area of applied category-theory that over the past twelve years or so has become increasingly prominent within physics, mathematics and computer science, and even has spin-offs in other areas such as computational linguistics. Probably the most appealing feature of CQM is the use of diagrams, which are related to the usual Hilbert space model via symmetric monoidal categories and structures therein.  However, we have written this overview in such a way that no prior knowledge on category theory is required. In fact,  it can be seen as a first encounter with the relevant parts of category theory.      

We start with boxes and wires, which together make up diagrams.  The wires stand for systems, and the boxes stand for processes.  Symmetric monoidal categories then arise when endowing diagrams with operations of sequential and parallel composition. There are very good reasons to start with diagrams, rather than with traditional category-theoretic axioms, one being that the set-theoretic underpinning of category theory invokes an additional level of bureaucracy, namely dealing with such details as the bracketing of expressions, which has no counterpart in the reality that one aims to describe.  In other words, the traditional symbolic presentation of monoidal categories suffers from a substantial overhead as compared to its diagrammatic counterpart, to the extent that  monoidal category theory itself  becomes much simpler if one takes diagrams as  a starting point.  From this perspective, the role of the traditional presentation of  monoidal categories is reduced to providing a bridge to standard mathematical models, for example, the presentation of quantum theory using Hilbert space.

Next we define very general \em quantum types\em.  Despite this generality, we are able to derive important results that characterise the behaviour of quantum systems, most notably, the \em no-broadcasting theorem \em \cite{Nobroadcast}.  The diagrammatic formalism also makes it remarkably easy to assert  compliance with the theory of relativity, namely, in terms of a \em causality postulate \em \cite{chiri1}, which, in category-theoretic terms, simply boils down to the tensor unit being terminal \cite{Cnonsig}.  Again, important results follow straightforwardly, such as \em unitarity of evolution \em and \em Stinesping dilation\em.

\paragraph{Other overviews, surveys and tutorials on CQM.}  This three-part overview %tutorial 
has a big brother, namely, a forthcoming textbook \cite{CKbook}  by the same authors. This three-part overview,  which amounts to some 70 pages, strives to be self-contained, but the book (which is about 12 times that size) will provide a more comprehensive introduction suitable for students and researchers in a wide variety of disciplines and levels of experience.

There is  another forthcoming book \cite{HVbook}, but rather than providing a complete presentation of quantum theory  from first principles, it puts  many of the core aspects of CQM studied in earlier papers in one place, and  also emphasises how the structures used in CQM  appear in other areas of mathematics.

A tutorial that provides a pedestrian introduction to the relevant category theory for CQM, and is complementary to this three-part one, is \cite{CatsII}.   
  
There have been shorter overviews on CQM before in the spirit of this one, e.g.~\cite{Kindergarten, ContPhys}, but the material simply wasn't ripe enough at that time for a fully-comprehensive presentation of quantum theory. 

\paragraph{Comparison to previous versions of CQM.}  The most prominent difference between this overview and the way CQM has been presented in the past is the fact that we take diagrams as our starting point, rather than standard category-theoretic structures and consistently introduce all new ingredients of the formalism in those terms.  While process ontology has played a motivational role throughout the entire CQM endeavour, see e.g.~\cite{JTF}, only now does every single ingredient emerge from this ontology.  This idea to start with diagrams as a primitive notion, even when a symbolic alternative is available, has also been advocated by Hardy \cite{HardyJTF}.

As compared to the paper by Abramsky and Coecke that initiated CQM \cite{AC1}, a  now well-established difference is  that we no longer rely on biproducts  (a non-diagrammatic concept) for the description of classical types.  They have been superseded  by special processes called \textit{spiders},  which allow one to express the characteristic processes associated with classical data (most importantly: `copy' and `delete') and reason about them diagrammatically \cite{CPav, CPaqpav}.

A more recent  innovation is the central role  now played by Chiribella, D'Ariano and Perinotti's causality postulate \cite{chiri1}.  In the past, issues of normalisation were mostly ignored in CQM.  Only recently it became apparent that the type of normalisation captured in the causality postulate is something structurally very fundamental  to processes which are physically realisable. Notably, all the results in Section \ref{sec:causality} of this chapter rely on it.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Process theories}

\begin{quote}
\em The art of progress is to preserve order amid change, and to preserve change amid order.\par \em \hfill    --- Alfred North Whitehead, Process and Reality, 1929.       
\end{quote}

\noindent
After his attempt to complete the set-theoretic foundations of mathematics in collaboration with Russell, Whitehead's venture into the natural sciences made him realise  that the traditional timeless ontology of substances, and not in the least their static set-theoretic underpinning, does not suit natural phenomena.  Instead, he claims, it is processes and their relationships which should underpin our understanding of those phenomena.

Can one turn this stance into a formal underpinning for natural sciences?  Category theory is a big step in that direction, but falls short of shaking off its set-theoretic  shackles.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Processes as diagrams}\label{sec:procs-as-diagrams}

We shall use the term \em process \em to refer to anything that has zero or more inputs and zero or more outputs. For instance, the function:
\beq\label{eq:fstfunctf}
f:  {\mathbb R}\times {\mathbb R} \to {\mathbb R}:: (x, y) \mapsto  x^2 + y
\eeq
is a process which takes two real numbers as input and produces one real number as output. We represent such a process as a \textit{box} with some \textit{wires}  coming in the bottom to represent input systems and some wires coming out the top to represent output systems. For example, we could write the function  (\ref{eq:fstfunctf}) like this:  
\begin{equation}\label{eq:R-function-ex}
  \tikzfig{f-ex}
\end{equation}
The labels on wires are called \textit{system-types} or simply \textit{types}.

Similarly, a computer program is a process which takes some data (e.g. from memory) as input and produces some new data as output. For example, a program that sorts lists might look like this:
\ctikzfig{quicksort-ex} 
The following are also perfectly good processes:
\[
\tikzfig{physical-processes1}
\qquad\quad \ \, \ \tikzfig{physical-processes2}    
\qquad\qquad \tikzfig{physical-processes3} 
\]
Clearly the world around us is packed with processes!

We can \textit{wire together} simple processes to make more complicated processes,  which are described by \em diagrams\em:
\ctikzfig{compound-process}
We form diagrams by plugging the outputs of some processes into the inputs of others. This is allowed only if the types of the output and the input match.  For example, the following two processes: 
\ctikzfig{type-restriction1}
can be connected in some ways, but not in others, depending on the types of their wires:
\ctikzfig{type-restriction2}
This restriction on which wirings are allowed is an essential part of the language of diagrams,  in that it tells us when it makes sense to apply a process to a certain system and prevents occurrences like this:
\[
\quad\tikzfig{poosort} 
\]
which  probably wouldn't be very good for your computer!    

One thing to note is we haven't yet been too careful to say 
what a diagram actually {\em is}. A complete description of a diagram consists of:  
\ben
\item what boxes it contains, and 
\item how those boxes are connected.  
\een
So the diagram refers to the `drawing' of boxes and wires without the interpretation of the diagram as a process. However, it makes no reference to where boxes are written on the page.  Hence, if two diagrams can be deformed into each other (without changing connections of course) then they are equal:  
\begin{equation}\label{eq:circuit-equiv}
  \tikzfig{circuit_diagram_equiv2_BOOK}
\end{equation}

When we think about interpreting the boxes in a diagram as processes, we are usually not interested in all possible processes, but rather in a certain class of related processes.  For example, practicioners of a particular scientific discipline will typically only study a particular class of processes: physical processes, chemical processes, biological processes, computational processes, etc. For that reason, we organise processes into \textit{process theories}. 

\begin{definition}\label{def:process-theory}
  A \textit{process theory} consists of:
  \begin{enumerate}
    \item[(i)] a collection $T$ of \textit{system-types} represented by wires,
    \item[(ii)] a  collection $P$ of \textit{processes} represented by boxes, where for each process in $P$ the input types and output types are taken from $T$, and
    \item[(iii)] a means of `wiring processes together'. That is, an operation that interprets a diagram of processes in $P$ as a process in $P$.
  \end{enumerate}
\end{definition}

\noindent In particular, (iii) guarantees that: 
\begin{center}
\em process theories are `closed under wiring processes together',  \em
\end{center}
since it is this operation that tells us what `wiring processes together' means. In some cases this operation consists of literally plugging things together with physical wires, like in the  theory of {\bf electrical devices}:  
\[
   \tikzfig{electricity-example2} \quad := \quad
  \raisebox{-2.7cm}{\includegraphics[width=2.4cm]{power_drill.png}}
\]
In other cases this will require some more work, and sometimes there is more than one obvious choice available. We shall see below that in traditional mathematical practice one typically breaks down `wiring processes together' in two sub-operations: parallel composition and sequential composition of processes.

According to Definition~\ref{def:process-theory} a process theory tells us how to \textit{interpret} the boxes and wires in a diagram. But, crucially, by doing so it also tells us which diagrams consisting of those processes should be considered \textit{equal}.  

For example, suppose we define a simple process theory for \textbf{computer programs}, where the types are data-types (e.g. integers, booleans, lists, etc.) and the processes are computer programs. Then, consider a short program, which takes a list as input and sorts it. It might be defined this way (don't worry if you can't read the code, neither can half of the authors):
\[
\tikzfig{quicksortbis} \ \ \ := \ \ \ 
\begin{cases} 
  \,\verb!qs [] = []!\\
  \,\verb!qs (x :: xs) = !\\
  \,\verb!  qs [y | y <- xs; y < x] ++ [x] ++! \\
  \,\verb!  qs [y | y <- xs; y >= x]!
\end{cases}
\]
Wiring together programs means sending the output of one program to the input of another program. Taking two programs to be equal if they behave the same (disregarding some details like execution time, etc.), our process theory yields equations like this one:
\ctikzfig{quicksort_idempotent}
i.e.~sorting a list twice has the same effect as sorting it once. Unlike equation~\eqref{eq:circuit-equiv}, this is not just a matter of deforming one diagram into another, but actually represents a non-trivial equation between processes.

The reason we call a process theory a \textit{theory} is that it comes with lots of such equations, and these equations are precisely what allows us to draw conclusions about the processes we are studying.  Another thing one expects from a theory is that it makes predictions. In particular, one usually expects a theory to produce some numbers (e.g.~probabilities) that can verified by experiments. Toward that end, we first identify two special kinds of processes:
\bit
\item \em States \em are processes without any inputs. In  operational terms they are `preparation procedures'. We represent them as follows:
\[
\pointmap{\psi}
\]
\item
\em Effects \em are processes without any outputs. We have borrowed this terminology from quantum theory, where effects play a key role.  From now on we  represent them as follows:
\[
\copointmap{\,\pi\,} 
\]
\eit
When composing a state and an effect a third special kind of process arises which neither has inputs nor outputs, called a \em number\em.  Every process theory has at least one number, given by the `empty diagram':
\[ 
1 \ :=\ \emptydiag 
\]
We label this number `$1$' because combining the empty diagram with any other process yields the same process again.

It is natural to interpret the number arising from the composition of a state and an effect as the \textit{probability} that, given the system is in that state, the effect happens: 
\ctikzfig{state_test_paper}
We refer to this procedure as the \textit{generalised Born rule}.

In the introduction we announced that we would introduce category-theoretic definitions after we introduced the relevant diagrammatic notion.  However, the simple notion of a diagram introduced above, has a not so simple category-theoretic description.  We will now first introduce a more sophisticated notion of a diagram, which actually has a simpler category-theoretic counterpart, and this will serve as a stepping stone to defining the category-theoretic counterpart to the diagrams considered above.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Circuit diagrams}

Given that  boxes represent  processes, we can define two basic \em composition operations \em on processes with the following interpretations:
\begin{align*}
  \textrm{$f \otimes g$}
  & := 
  \textrm{`process $f$ takes place {\em while} process $g$ takes place'} \\  
  %
  \textrm{$f \circ g$\,}
  & :=
  \textrm{`process $f$ takes place {\em after} process $g$ takes place'}  
\end{align*}

The  \em parallel composition \em operation, written `$\otimes$', consists of placing a pair of diagrams side-by-side: 
\[
\left( \ \tikzfig{parallel-composition1} \right) \ \otimes \ \left( \ \tikzfig{parallel-composition2} \right) \ \ := \ \ \tikzfig{parallel-composition3}   
\] 
Any two diagrams can be composed in this manner, since placing diagrams side-by-side does not involve connecting anything.  This reflects the fact that both processes are happening independently of each other.   

This composition operation is associative: 
\beq\label{tensorassoc}
\left( \boxmap{f} \otimes  \boxmap{g} \right) \otimes  \boxmap{h}\ =\   \boxmap{f} \  \boxmap{g}  \ \boxmap{h}\ =\ \boxmap{f} \otimes \left( \boxmap{g} \otimes \boxmap{h} \right)
\eeq
and it has a unit, the empty diagram:
\beq\label{tensorunit}
\tikzfig{empty-diagram-unit}
\eeq

Parallel composition  is defined for system-types as well. That is, for types $A$ and $B$, we can form a new type $A \otimes B$, called the \textit{joint system-type}:
\ctikzfig{parallel-compose-wires}
There is also a special `empty' system-type, symbolically denoted $I$, which is used to represent `no inputs', `no ouputs' or both.

The \em sequential composition \em operation, written `$\circ$', consists of connecting the outputs of one diagram to the inputs of another diagram:
\[
\left(\ \tikzfig{sequential-composition1}\right)\ \circ \ \left(\ \tikzfig{sequential-composition2}\right)\ \ = \ \ \tikzfig{sequential-composition3}
\]
In other words, the process on the right  happens first,  followed by the process on the left,  taking the output of the first process as its input. Clearly not any pair of diagrams can be composed in this manner: the number and type of the inputs of the left process must match the number and type of the outputs of the right process.

The sequential composition operation is also associative: 
\beq\label{compassoc}
\left( \boxmap{h} \circ  \boxmap{g} \right) \circ  \boxmap{f}\   =     \ 
\tikzfig{threechain} \ 
=  \ \boxmap{h} \circ \left( \boxmap{g} \circ \boxmap{f} \right)
\eeq
and it also has a unit.  This time, it's a plain wire of appropriate type:
\beq\label{compunit}
\tikzfig{identity-diagram-unit}
\eeq

These two composition operations, due to their diagrammatic origin, also obey an \em interchange law\em.  Since we have:
\[
\left(\boxmap{g_1}\otimes \boxmap{g_2}\right)\circ\left(\boxmap{f_1}\otimes \boxmap{f_2}\right)
=
\left(\boxmap{g_1}\ \boxmap{g_2}\right)\circ\left(\boxmap{f_1}\ \boxmap{f_2}\right)
=\ 
\raisebox{0.6mm}{\tikzfig{twochain1}\  \tikzfig{twochain2}}
\]
\[
\left(\boxmap{g_1}\circ \boxmap{f_1}\right)\otimes\left(\boxmap{g_2}\circ \boxmap{f_2}\right)
=
\left(\,\raisebox{0.6mm}{\tikzfig{twochain1}}\right)  \otimes \left(\,\raisebox{0.6mm}{\tikzfig{twochain2}}\right)
\ =\ 
\raisebox{0.6mm}{\tikzfig{twochain1}\  \tikzfig{twochain2}}
\]
it follows that:
\beq\label{eq:bifunct}
\left(\boxmap{g_1}\otimes \boxmap{g_2}\right)\circ\left(\boxmap{f_1}\otimes \boxmap{f_2}\right)
=
\left(\boxmap{g_1}\circ \boxmap{f_1}\right)\otimes\left(\boxmap{g_2}\circ \boxmap{f_2}\right)
\eeq

Note that $\circ$ assumes there is some ordering on the input/output wires, and plugs them together `in order'. We can then express different orders by means of two wires crossing over each other:
\ctikzfig{specialbox2bisbis}
which as called a \textit{swap}.

\begin{definition} 
A diagram is a  \em circuit \em  if it  can be constructed  by composing boxes, including identities and swaps, by means of $\otimes$ and $\circ$.
\end{definition}

Every diagram that we have seen so far in this chapter is in fact a circuit.    Here is an example of the assembly of such a circuit:
\ctikzfig{circuitassembly} 
But not all diagrams are circuits. To understand  which ones are, we provide an equivalent characterisation that doesn't refer to the manner that one can build these diagrams, but in terms of a property that has to be satisfied.  

\begin{definition}
  A \textit{directed path} of wires is a list of wires $(w_1, w_2, \ldots, w_n)$ in a diagram such for all $i < n$, the wire $w_i$ is an input to some box for which 
  the wire $w_{i+1}$ is an output.   A \textit{directed cycle} is a directed path that starts and ends at the same box. 
\end{definition}

An example of a directed path is shown in bold here:
\ctikzfig{directed-path}
and an an example of a directed cycle is:
\ctikzfig{directed-cycle}
While diagrams only allow inputs to be connected to outputs, we indeed have done nothing (so far) to rule out the existence of directed cycles. This is precisely what the restricting to `circuit diagrams' does for us:  

\begin{theorem}\label{thm:circuit-acyclic}
The following are equivalent:
\bit
\item a diagram is a circuit, and, 
\item it contains no directed cycles.
\eit
\end{theorem}

\subsection{Category-theoretic counterpart}

We are now ready to provide a category-theoretic counterpart to diagrams.  A  \em symmetric monoidal category \em is essentially a process theory where all diagrams are circuit diagrams. Systems and processes are renamed, respectively as \em objects \em  and \em morphisms\em, and rather than diagrams being the main actor, the composition operations $\circ$ and $\otimes$ are taken as primitive. In order to guarantee that these operations behave as they did with diagrams, we have to require extra equations, namely equations (\ref{tensorassoc})--(\ref{eq:bifunct}) above.

\begin{definition}\label{def:strict-monoidal}
  A (strict) \textit{monoidal category} $\mathcal C$ consists of: 
  \begin{itemize}
    \item a collection $\textrm{ob}(\mathcal C)$ of \textit{objects},
    \item for every pair of objects $A, B$, a set $\mathcal C(A,B)$ of \textit{morphisms},
    \item for every object $A$, a special \em identity morphism \em $1_A \in \mathcal C(A,A)$,
    \item a \em sequential composition \em operation for morphisms:
    \[ (- \circ -) : \mathcal C(B,C) \times \mathcal C(A,B) \to \mathcal C(A,C) \]
    \item a \em parallel composition \em operation for objects: 
\[  
(- \otimes -) : \textrm{ob}(\mathcal C) \times \textrm{ob}(\mathcal C) \to \textrm{ob}(\mathcal C)
\]
    \item a \em unit object \em $I \in \textrm{ob}(\mathcal C)$, and
    \item a \em parallel composition \em operation for morphisms:
    \[ 
    (- \otimes -) : \mathcal C(A,B) \times \mathcal C(C,D) \to \mathcal C(A\otimes C,B \otimes D) 
    \]  
  \end{itemize}
  such that:
  \begin{itemize}
    \item $\otimes$ is associative and unital on objects:
    \[ (A \otimes B) \otimes C = A \otimes (B \otimes C) \qquad A \otimes I = A = I \otimes A \]
    \item $\otimes$ is associative and unital on morphisms:
    \[ \ \  (f \otimes g) \otimes h = f \otimes (g \otimes h) \ \   \qquad f \otimes 1_I = f = 1_I \otimes f \]
    \item $\circ$ is associative and unital on morphisms:
    \[ \ \ \ \   (h \circ g) \circ f = h \circ (g \circ f) \ \ \ \   \qquad 1_B \circ f = f = f \circ 1_A \]
    \item $\otimes$ and $\circ$ satisfy the \textit{interchange law}:  
    \[ 
    (g_1\otimes g_2)\circ(f_1\otimes f_2) = (g_1\circ f_1)\otimes(g_2\circ f_2)
    \]
  \end{itemize}
\end{definition}

Note we often write $f : A \to B$ as shorthand for $f \in \mathcal C(A, B)$, which indicates that we are thinking of morphisms as maps of some kind.

\begin{definition}
  A \textit{symmetric monoidal category} (SMC) is a monoidal category with a swap morphism:
  \[
  \sigma_{A,B} : A\otimes B \to B \otimes A
  \]
  defined for all objects $A, B$, satisfying:  
  \begin{itemize}
    \item $\sigma_{B,A} \circ \sigma_{A,B} = 1_{A\otimes B}$ 
    \item $(f \otimes g) \circ \sigma_{A,B} = \sigma_{B',A'} \circ (g \otimes f)$
    \item $\sigma_{A,I} = 1_A$
    \item $(1 \otimes \sigma_{A,C}) \circ (\sigma_{A,B} \otimes 1_C) = \sigma_{A,B\otimes C}$ 
  \end{itemize}
\end{definition} 

The diagrammatic counterparts to the first two of these equations are:
\ctikzfig{circuit_diagram_equiv_paper}
which are simply diagram deformations. The remaining two equations are again tautologies in terms of diagrams:
\ctikzfig{circuit_diagram_equiv_paper2}
  
It goes without saying that the category-theoretic definition is much more involved than its diagrammatic counterpart.  And in fact, it gets worse when we drop the `strict' from it, as explained in \cite{CatsII} \S  3.4.4. Simply stated, dropping strictness allows for some of the defining equations not to hold on-the-nose,  but are allowed some `wiggle room'. However, making this precise requires a number of \em natural isomorphisms\em, which express `how' one  `wiggles' from the LHS to the RHS, together with a bunch of \em coherence conditions \em which force all the natural isomorphisms to fit together well. The reason why it does make sense (and is in fact necessary) to consider this very involved definition is that  pretty much all set-theoretic structures which organise themselves into monoidal categories are in fact of the non-strict variety.  However, there is a standard procedure for turning every non-strict monoidal category into an equivalent strict one, so considering only strict monoidal categories (as we shall do throughout these papers) yields no real loss of generality.

\begin{example}
The category FHilb whose objects are finite-dimensional Hilbert spaces and whose morphisms are linear maps forms a (non-strict) SMC. Sequential composition is just the usual composition of linear maps, parallel composition is tensor product, and the unit object is the 1-dimensional Hilbert space $\mathbb C$.   The category Hilb of all Hilbert spaces and bounded linear maps also forms an SMC. However,  it does not form a compact closed category, which we'll define in the next section, so in categorical quantum mechanics, we typically focus on FHilb.
\end{example}

The precise connection between SMCs and circuit diagrams is the following:

\begin{theorem}\label{thm:circuit-smc}
  Any circuit diagram can be interpreted as a morphism in an SMC, and two morphisms are equal according to the axioms of an SMC if and only if their circuit diagrams are equal.
\end{theorem}

We won't say that much about the categories that correspond to arbitrary diagrams,  since they will be superseded by the notions introduced in the next section. The main point is that one has to adjoin an additional operation, called \em trace\em, for every triple $A, B, C$ of objects:
\[     
{\rm tr}_{B,C}^A : \mathcal C(A\otimes B, A\otimes C)  \to \mathcal C(B,C)
\]
This trace obeys a bunch of axioms that guarantee the following counterpart diagrammatic behaviour:
\[
{\rm tr}_{B,C}^A ::\ \ \raisebox{-0.6mm}{\tikzfig{partialtracepre_paper}}\ \ \mapsto \ \ \tikzfig{partialtrace_paper}  
\]
While such a trace  does play a role in quantum theory,  we will soon see that it  arises as a derived concept in a simpler type of category.

\subsection{Reference and further reading}  

The use of diagrams started with Penrose's diagrammatic calculus for abstract tensor systems \cite{Penrose}. The proof that abstract tensor systems characterise the free traced symmetric monoidal category was given in~\cite{KissingerATS}.

Monoidal categories are due to Benabou \cite{Benabou}, with their modern formulation---and the fact that any monoidal category is equivalent to a strict monoidal category---being worked out by Mac Lane \cite{MacLaneCoherence}.  The connection between circuit diagrams and symmetric monoidal categories was established  by Joyal and Street in \cite{JS}, where they are referred to as `progressive diagrams'.
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{String diagrams}  

\begin{quote}
\em When two systems, of which we know the states by their respective representatives, enter into temporary physical interaction due to known forces between them, and when after a time of mutual influence the systems separate again, then they can no longer be described in the same way as before, viz.~by endowing each of them with a representative of its own. I would not call that \textit{one} but rather \textit{the} characteristic trait of quantum mechanics, the one that enforces its entire departure from classical lines of thought.\par \em \hfill    --- Erwin Schr\"odinger,  1935.
\end{quote}

\noindent
By 1935, Schr\"odinger had already realised that the biggest gulf between quantum theory and our classical ways of thinking was really that, when it comes to quantum systems, the whole is more than the sum of its parts. In the classical world, for instance, it is possible to totally describe the state of two systems---say...two objects sitting on a table---by first totally describing the state of the first object then totally describing the state of the second object. This is a fundamental property one expects of a classical, or \textit{separable} (or, in category-theory lingo: \em Cartesian\em) universe. However, as Schr\"odinger points out, there exist states predicted by quantum theory (and observed in the lab!) which do not obey this `obvious' law about the physical world.  Schr\"odinger called this new, totally non-classical phenomenon \em verschr\"ankung\em, which later became translated to the dominant scientific language as \em entanglement\em. 

In contrast to this great insight, it took physicists many years to actually exploit this  property and reveal the features of the quantum world that are direct consequences of it.  Most strikingly, it took physicists some 60 years to discover what is probably the most direct consequence: \em quantum teleportation\em. 

\subsection{Non-separability}

\begin{definition}\label{def:stringdiagram} 
\em String diagrams \em  can be defined equivalently as: 
\bit
\item diagrams consisting of boxes and wires, where we additionally allow inputs to be connected to inputs and outputs  to be connected to outputs, for example:   
\[
\tikzfig{compound-process-capscups} 
\]
\eit
\bit
\item circuit diagrams that contain a special state and a special effect:
\[
\raisebox{0.2mm}{\tikzfig{CupStateType}}\! \qquad\quad {\rm and } \qquad\quad \raisebox{-0.2mm}{\tikzfig{CapEffectType}}
\]
for each type for which we have:
\begin{equation}\label{eq:cup-equations}
  \raisebox{2mm}{\tikzfig{CupCapNew}}\qquad\quad\qquad
\begin{array}{c}
\tikzfig{cap-box-swap} \, \ = \, \ \tikzfig{CapEffectType}\vspace{4mm}\\
\tikzfig{cup-box-swap}  \, \ = \, \ \tikzfig{CupStateType}
\end{array}
\end{equation}
\eit  
\end{definition}  

We can relate these two equivalent definitions by writing the cup state and cap effect from the second definition as cup- and cap-shaped pieces of wire:
\[
\raisebox{-1mm}{\tikzfig{cupType}} \ \ := \ \ \tikzfig{CupStateType} \qquad\qquad\raisebox{1mm} {\tikzfig{capType}}\ \  :=\ \  \tikzfig{CapEffectType}  
\]
so that the equations in~\eqref{eq:cup-equations} become:
\begin{equation}\label{eq:wire-yank-all}
  \tikzfig{wire_yank_all}
\end{equation}
Hence they are reduced to simple wire deformations:  
\begin{center}
\includegraphics[height=3.5cm]{yankwire.jpg}\qquad\  \includegraphics[height=3.5cm]{yankcup.jpg}
\end{center}

String diagrams capture what Schr\"odinger described as the characteristic trait of quantum mechanics: the existence of non-separable states. Visualising cups and caps as wires captures this intuition that the two systems involved cannot be separated from each other (since, of course, we are not allowed to cut wires). We can state this more formally as follows:

\begin{proposition}\label{prop:cupdiscrubbish}
If a theory is described by string diagrams, and all two-system states $\psi$ are $\otimes$-separable,  i.e.~there exist states $\psi_1$ and $\psi_2$ such that:    
\ctikzfig{State2split}
then every process $f$ is $\circ$-separable, i.e.~it can be written as:   
\[
\boxmap{f}\ \  = \ \ 
\begin{array}{c}
\raisebox{1.9mm}{\pointmap{\,\psi}}\vspace{0.5mm}\\
\raisebox{-1.9mm}{\copointmap{\,\pi\,}}
\end{array}
\]
for some effect $\pi$ and some state $\psi$.
\end{proposition}
\begin{proof}
By assumption, the cup-state  is $\otimes$-separable:      
\[
\tikzfig{cupX}\ \ =\ \point{\psi_1} \point{\psi_2}  
\]
So, for any process $f$ we have:
\ctikzfig{Separationproof_paper}
\end{proof}

What is this telling us? First, we should note that all processes being $\circ$-separable is a \textit{bad thing}. It is the same as saying all processes in the theory simply throw away the input and produce a constant output (possibly multiplied by some number depending on the input). In other words, nothing ever happens!  As this is an absurd condition for  any `reasonable' process theory, all bipartite (i.e.~two-system) states cannot be $\otimes$-separable. 

In such reasonable theories, string diagrams guarantee that the collection of two-system states is just as rich as the processes involving the same types:    

\begin{proposition}\label{prop:closurestring}
Any theory described by string diagrams has \em process-state duality\em. That is, for any two types $A$ and $B$ we have a 1-to-1 correspondence between processes and states of the following form:
\[
\tikzfig{notrans}\ \qquad\longleftrightarrow\qquad\  \tikzfig{paper1}
\]
which is realised by:
\[
\boxmap{f}\ \ \mapsto\ \  \tikzfig{CupActionpaper} \qquad\qquad\ \   \tikzfig{State2psi}\ \ \mapsto\ \ \tikzfig{CapActionpaper}
\]
\end{proposition}

\subsection{Traces and transposes}    

For a  process $f$ with one of its inputs having the same type as one of its outputs, the \em partial trace \em with respect to that input/output pair is: 
\[
{\rm tr}_{B,C}^A \left(\tikzfig{partialtracepre_paper}\right)\ \, := \  \tikzfig{partialtrace_paper}
\]
The total trace, or simply the \textit{trace}, is the special case where $B = C = I$. A typical property of the trace is \textit{cyclicity},  which now comes just from  the observation that---since only connectivity matters---the following two diagrams are the same: 
\ctikzfig{trace_f_g_paper}

The \em transpose \em of a  process $f$ is the  process:  
\[
\tikzfig{yestrans} 
\]
or equivalently, by \eqref{eq:wire-yank-all}:
\[
\tikzfig{yestrans-flip} 
\]
Then, clearly if we transpose twice, we get back where we started: 
\[  
\tikzfig{transtransmapyes}\ \  =\ \ \boxmap{f} 
\]
In other words, transposition is an \textit{involution}.  And now comes the really cool bit. First, we deform our boxes a bit:
\[ 
\boxmap{f} \ \ \ \leadsto\ \ \ \map{f} 
\]
Now, if we express the transpose of $f$ as a box labelled `$f$', but rotated 180${}^\circ$:    
\[
\tikzfig{smaptrans}\ \  :=\ \ \tikzfig{transmapyes}
\]
the definition of a transpose %, within the context of string diagrams,
gets built-in to this `180${}^\circ$ rotation'-notation: 
\begin{center}
\includegraphics[height=4.2cm]{yankmap.jpg}
\end{center}
From this, it also follows that:
\[
\tikzfig{slide1}\qquad\qquad\tikzfig{slide2}
\]
So we can slide boxes across cups and caps just like beads on a wire:
\[
\tikzfig{slide1steps}\qquad\quad \tikzfig{slide1steps2}
\]

Now, let's play a game. Here is the challenge: Aleks and Bob are far apart, Aleks possesses a system in a state $\psi$, and Bob needs this state.  Suppose they also share another state, namely the cup-state. So, we have this situation:  
\ctikzfig{telesum0NEWpre}
Starting from this arrangement, is there something Aleks and Bob can do in the `?'-marked regions indicated below,
that results in Bob obtaining $\psi$? 
\ctikzfig{telesum0NEW}
Here is a simple solution:
\ctikzfig{telesum00NEW}
If you the reader came up with this solution yourself, then you on your own did in a few seconds what all the physicists in the world failed to do between 1930 and 1990: discover quantum teleportation!  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Adjoints and unitarity}\label{sec:adjoints-and-unitarity} 

There is a slight caveat in the above discussion of teleportation.  While the cap is a process that Aleks can  attempt to `do', he'll need a bit of luck to succeed. This is because the cap process is not \textit{causal} (a concept we'll soon meet), so it can only be realised with some probability strictly less than 1.  As a consequence, Aleks might not get the effect he wants (the cap), but some other effect  $\phi_1, \phi_2, \ldots$ which, by process-state duality, we can represent as a cap with  some `unwanted' box:
\[ 
\tikzfig{ps-U-paper}\  \ :=\ \ \tikzfig{ps-phi-paper} 
\]
which we'll called the \textit{error}. This box obstructs Bob's direct access to the state he so much desires:
\beq\label{eq:tele-with-error}
\tikzfig{telesum1-2NEWpapera} \ \ =\ \ \tikzfig{telesum1-2NEWpaperb}
\eeq
So, all is lost?  Of course not! Bob  just needs to figure out how to `undo'  this error by means of some process.

Before going there, we need to enrich our language of string diagrams a bit.  In addition to rotating boxes 180${}^\circ$, we will now also reflect them vertically:
\[
\tikzfig{smapAB} \ \ \mapsto \ \ \tikzfig{smapdagAB}  
\]
and refer to this reflected box as the \em adjoint\em.  Like transposition, this is  an involution, and it can be applied to entire diagrams in the obvious way:
\[
\tikzfig{arbitrary_klein}
\ \  \mapsto \ \ 
\tikzfig{arbitrary_klein_flip}
\]

Rotating by 180${}^\circ$ degrees then reflecting vertically is the same as just reflecting horizontally:
\[ 
\map{f} \ \mapsto\ \maptrans{f}\ \mapsto\ \mapconj{f} 
\]
This horizontal reflection, obtained by composing the transpose and the adjoint, is called the \em conjugate\em.  So all together, boxes now come in quartets:
\beq\label{eq:smapALLFOURnew}
\tikzfig{smapALLFOURnew}
\eeq
Having adjoints around enables us to make the following definition:

\begin{definition}
A process $U$ an \em isometry \em if we have:     
\beq\label{eq:isometry}
\tikzfig{isometry-types} 
\eeq
and it is \em unitary \em if its adjoint is also an isometry.    
\end{definition}

Each of these names may sound familiar to  some readers, which is of course no coincidence: 

\begin{example}
  The conjugate, transpose, and adjoint of a linear map $f$ is a new linear map obtained by taking the conjugate, transpose, or adjoint (a.k.a.~conjugate-tranpose) of the matrix of $f$, respectively. Hence isometries and unitaries of linear maps are just the standard notions.
\end{example}

We now return to \eqref{eq:tele-with-error}, where Bob seeks to undo the error introduced by Aleks' process. In the case where $U$ is an isometry (or better yet, a unitary), Bob simply needs to apply its adjoint to undo it:
\ctikzfig{telesum1NEW} 

\subsection{Adjoints and connectedness} 

We haven't said much about adjoints, just that they have to preserve diagrams.  In fact, the ontology of the adjoint and corresponding postulates are still the subject of ongoing research.  Below we will make use of one particular additional condition  that one may want  adjoints to satisfy.  This extra condition comes from taking the notion that an adjoint really is a reflection seriously.

Suppose we have a $\circ$-non-separable process.  One could then imagine  that it has some internal structure, say a collection of tubes or machines connecting some inputs to outputs: 
\begin{center}
  \includegraphics[width=2.5cm]{structure.jpg}
\end{center}
If we now compose this process with its adjoint, i.e.~its vertical reflection, then these internal  connections match up:
\begin{center}
  \includegraphics[width=2.5cm]{structure-mirror.jpg}
\end{center}
so one expects the resulting process also to be $\circ$-non-separable, that is:
\beq\label{EQ:daggeraxiom}
\left( \exists \psi, \phi: \ \ \map{f} \ =\ \kpointketbra{\psi}{\phi} \right)
  \ \ \Longleftrightarrow\ \
 \left( \exists \psi', \phi':  \ \   \tikzfig{fdagf}\ \ =\ \kpointketbra{\psi'}{\phi'}\right)  
\eeq

Indeed this assumption holds for our main example:
\begin{example}
  For linear maps, $\circ$-separable means rank-1. It is a well-known fact from linear algebra that the rank of:
  \ctikzfig{fdagf}
  is the same as the rank of $f$. Hence \eqref{EQ:daggeraxiom} is satisfied.
\end{example}

While this assumption makes sense visually, it can fail in surprising places:
\begin{example}
  Consider a process theory whose processes are relations $R \subseteq A \times B$ where $\circ$ is the usual composition of relations, $\otimes$ is the Cartesian product, and $I$ is the 1-element set $\{ * \}$. The adjoint $R^\dagger$ of a relation $R$ is its converse. That is, $(b,a) \in R^\dagger$ if and only if $(a,b) \in R$. Then the following relation from the two element set $\{0,1\}$ to itself fails to satisfy \eqref{EQ:daggeraxiom}:
  \[ 
  \{ (0,0), (0,1), (1,1) \} \subseteq \{0,1\} \times \{0,1\} 
  \]
\end{example}

\subsection{Category-theoretic counterpart}

In Definition~\ref{def:stringdiagram} we gave two equivalent definitions 
of string diagram, the latter of which consisting of circuit diagrams with special processes called cups and caps. The category-theoretic counterpart for string diagrams proceeds in pretty much the same way:

\begin{definition}\label{def:compact-closed}
  A \textit{compact closed category} (with symmetric self-duality) is a symmetric monoidal category $\mathcal C$ such that for every object $A \in \textrm{ob}(\mathcal C)$, there exists morphisms $\epsilon_A \in \mathcal C(A \otimes A, I)$ and $\eta_A \in \mathcal C(I, A \otimes A)$ such that:  
\[ 
\begin{array}{ccc}
& &  \epsilon_A \circ \sigma_{A,A} = \epsilon_A\\
(\epsilon_A \otimes 1_A) \circ (1_A \otimes \eta_A) = 1_A & \qquad\quad & \\
& & \sigma_{A,A} \circ \eta_A = \eta_A
\end{array}
  \]
\end{definition}

Compact closed categories satisfy an analogue to Theorem~\ref{thm:circuit-smc}, but for string diagrams:

\begin{theorem}\label{thm:string-cmpcc}
  Any string diagram can be interpreted as a morphism in a compact closed category, and two morphisms are equal according to the axioms of a compact closed category if and only if their string diagrams are equal.
\end{theorem}

\begin{example}\label{ex:hilb-compact}
The category FHilb is compact closed. For a Hilbert space $A$, fix a basis $\{ e_i \}_i$ in $A$ then let:
\[ 
\eta_A : \mathbb C \to A \otimes A
   \qquad\qquad\textrm{and}\qquad\qquad 
   \epsilon_A : A \otimes A \to \mathbb C
\]
be linear maps defined as follows:
\[
   \eta_{A}(1) = \smallsum\ e_i \otimes e_i
   \qquad\qquad
   \epsilon_{A}(e_i \otimes e_j) = \begin{cases}
    1 & \textrm{ if } i = j \\
    0 & \textrm{ otherwise}
   \end{cases}   
   \]
Using Dirac's  `bra-ket' notation,  which is popular in the quantum computing literature, these maps can be written as:
\[ 
\eta_A = \smallsum\ \ket{i} \otimes \ket{i}
   \qquad\qquad
   \epsilon_A = \smallsum\ \bra{i} \otimes \bra{i} 
\]
\end{example}

In category theory, closure refers to the fact that one can represent sets of morphisms $\mathcal C(A,B)$ as the states of another object, which we could denote as $A\Rightarrow B$.  Compact closed categories have the very convenient feature that we can take: 
\[
A\Rightarrow B := A\otimes B
\]
We saw this feature in Proposition \ref{prop:closurestring},  under the name `process-state duality'.

Just as we simplified before by restricting to \textit{strict} monoidal categories, here we simplify from a more general notion of compact closed categories to symmetrically self-dual compact closed categories. The former only require that $\epsilon_A \in \mathcal C(A^* \otimes A, I)$ and $\eta_A \in \mathcal C(I, A \otimes A^*)$ exists for some object $A^*$ (called the \textit{dual} of $A$). Then, `self-duality' means we can choose $A^*$ to just be $A$ again, and `symmetric' means this choice gets along well with symmetries.  This of course makes sense from a diagrammatic point of view (cf.~the right-most equations in~\eqref{eq:wire-yank-all}),  and as pointed out in~\cite{SelingerSelfDual}, is necessary for interpreting string diagrams as morphisms without ambiguity. 

\begin{remark}
  The definition of $\eta_A$ and $\epsilon_A$ from Example~\ref{ex:hilb-compact} depend on the choice of basis. We can avoid this by dropping self-duality, in which case we take $A^*$ to be the dual space and let:
  \[ \epsilon_A(\xi \otimes a) = \xi(a) \]
  This uniquely fixes $\epsilon_A$ (and therefore $\eta_A$) without making reference to a basis.
\end{remark}

So to summarise, we have the following correspondences between  diagrams and categories: 
\begin{center}
\begin{tabular}{|c|c|c|}     
\hline
\em circuit diagram \em & \em %`intermediate'
diagram \em & \em string diagram \em \\
\tikzfig{leiden3x} & \tikzfig{leiden1xx} & \tikzfig{compound-process-capscups-book} \\
i.e.~admits causal structure & i.e.~outputs to inputs & i.e.~all to all \\
\hline
$\Rightarrow$ plain SMC  &  $\Rightarrow$ traced SMC & $\Rightarrow$ compact closed C \\    
\hline
\end{tabular}
\end{center}
Notably, the more sophisticated  (i.e.~restrictive) kinds of diagrams correspond to the simplest kinds of SMCs, and vice versa.

Unsurprisingly, the category-theoretic definition of  adjoints is again more involved than its diagrammatic counterpart, simply for the reason that we now have to say carefully what `preserving diagrams under reflection' means in terms of the language of SMCs.

\begin{definition}
For a strict SMC $\mathcal C$, a \textit{dagger functor} assigns to each morphism $f : A \to B$ a new morphism $f^\dagger : B \to A$ such that:
\[ 
  (f^\dagger)^\dagger = f \qquad
  (g \circ f)^\dagger = f^\dagger \circ g^\dagger \qquad
  (f \otimes g)^\dagger = f^\dagger \otimes g^\dagger \qquad
  \sigma_{AB}^\dagger = \sigma_{BA}
\]
\end{definition}

In category-theoretic parlance, this is therefore a `strict symmetric monoidal functor that is \textit{identity-on-objects} and \textit{involutive}'.

\begin{definition}
  A strict dagger-symmetric monoidal category ($\dagger$-SMC) is a strict SMC with a chosen dagger functor. For a \textit{dagger-compact closed category} (with symmetric self-duality), we additionally assume $\eta_A^\dagger = \epsilon_A$.
\end{definition}

\begin{example}
For FHilb, the dagger functor sends each linear map $f : A \to B$ to its linear-algebraic adjoint $f^\dagger : B \to A$, i.e.~the unique linear map such that:
\[ 
\braket{b}{f(a)} = \braket{f^\dagger(b)}{a} 
\]
for all $a \in A, b\in B$.
\end{example}

There is a tight connection between equations between linear maps and equations between string diagrams. Namely, any equation between string diagrams involving linear maps $f, g, h, \ldots$ (and their adjoints) holds generically---i.e.~for {\em all} linear maps $f, g, h, \ldots$---precisely when the diagrams themselves are equal. This is formally stated as a \textit{completeness} theorem:

\begin{theorem}\label{thm:Selinger}
  FHilb is complete for string diagrams.
\end{theorem}

In other words, if we don't know anything about the linear maps in a diagram (i.e.~we treat them as `black boxes'), diagrammatic reasoning is already the best we can do.

\subsection{Reference and further reading}

The quantum teleportation protocol first appeared in \cite{tele}. A diagrammatic derivation of teleportation first appeared in \cite{LE1}, and independently, also in \cite{Kauffman}.  The four variations of boxes as in (\ref{eq:smapALLFOURnew}) first appeared in \cite{SelingerCPM}. The use of caps and cups also already appeared in \cite{Penrose}. Proposition \ref{prop:closurestring} is known in quantum theory as the Choi-Jamio\l{}kowski isomorphism \cite{jamiolkowski, choi}.

The corresponding category-theoretic axiomatisation is due to Abramsky and Coecke \cite{AC1}, which was the first paper on categorical quantum mechanics, building further on Kelly's compact closed categories \cite{Kelly} by adjoining a dagger functor. Dagger compact categories had already appeared in \cite{BaezDolan} as a  special case of a more general construct in $n$-categories. Theorem \ref{thm:Selinger} is due to Selinger \cite{Selingercompleteness}. A comprehensive (at the time) survey of monoidal categories and their various graphical languages is given in~\cite{SelingerSurvey}.

\section{Quantum processes}

\begin{quote}
\em I would like to make a confession which may seem immoral: I do not believe   
absolutely in Hilbert space any more.\par \em \hfill    --- John von Neumann, letter to Garrett Birkhoff, 1935.         
\end{quote}

\noindent
Let us summarise what we have seen thus far.  In the first section we introduced a general formalism to reason about interacting processes based on diagrams.  In the following section we saw how the simple assumption that the diagrams are string diagrams allows a kindergartner to derive quantum teleportation. And then we bumped into a caveat, which we claimed came from something called \textit{causality}.

We claimed before that, rather than simply `doing' a cap effect, Aleks must perform a non-deterministic processes which might instead yield a cap-effect with some error. But that's just a bunch of words. None of the ingredients coming from string diagrams can actually help us derive this fact.

There's also a second issue here. Before Bob can correct the error, he must know which error $U_i$ happened. The only way this is possible is if Aleks picks up the phone and tells him. This requires distinguishing a phone call from a quantum system in our diagrams, i.e.~diagrams will need to involve two kinds of types: classical types and quantum types, and their distinct behaviour should also be evident in diagrammatic terms. In fact, it is the diagrammatic  formulation of quantum types that will allow us to  define this (in)famous causality postulate  which brought us here in the first place. Moreover, we will then be able to diagrammatically derive the fact that the cap-state cannot be invoked with certainty.

This section concerns specification of a  very general kind of quantum type.  Despite its generality, we will already be able to prove some highly non-trivial features of quantum systems, most notably, the no-broadcasting theorem.  This sets the stage for exploring alternative models  of quantum theory, which go beyond Hilbert spaces.

\subsection{Quantum types}

Back in Section~\ref{sec:procs-as-diagrams}, we interpreted a state meeting an effect as a probability, i.e.~a positive number:
\begin{equation}\label{eq:born-again}
  \tikzfig{state_test_paper}
\end{equation}
At that time, we didn't have a language rich enough to give a notion like `positivity', but thanks to reflection (i.e.~adjoints and conjugates) we now do. A complex number is positive precisely when it is the product of some number $\lambda$ and its conjugate $\overline{\lambda}$. Being the composition of a number and its conjugate thus gives us a generalisation of the condition of a number being positive:
\begin{equation}\label{eq:gen-positive}
  \tikzfig{gen-positive}
\end{equation}
So, we could use expressions like the one on the right to compute probabilities, and indeed this is how it is typically done in quantum theory. However, there is a way to have our cake and eat it too. Namely, we can retain the simplicity of~\eqref{eq:born-again} while secretly ensuring the result is always a positive number.

The trick is to double everything. By pairing two wires, we make a new thicker kind of wire:
\ctikzfig{doubled_wire}
which gives us a \textit{quantum} system type. We can then keep un-doubled types around for representing classical systems---something we'll use extensively in part II of this overview---obtaining this simple distinction:
\[
{\mbox{classical} \over\mbox{quantum}} = {\mbox{single wire} \over\mbox{double wires}}
\]

On these doubled wires, we can then build doubled boxes, which consist of the box itself, along with its conjugate:
\ctikzfig{double_process_1_to_1z}
When we apply this recipe to states and effects, we get a generalised positive number whenever the two meet:  
\ctikzfig{doubled_state_test}
Thus, the thing we called the generalised Born rule, applied to these new doubled processes, becomes what some will recognise as the  usual Born rule from quantum theory.

Doubling preserves string diagrams:
\[
\tikzfig{arbitrary_kleinx}\ \ \ \mapsto \ \ \ \tikzfig{double_arbitrary_klein}   
\]
as long as we are a bit careful about where the wires go for boxes with many inputs/outputs:
\ctikzfig{double_arbitrary}
In particular, this gives us the following expression for the doubled cap:
\[
\tikzfig{doubled_cup}\ \ :=\ \tikzfig{double_cup_derivation1}\vspace{-2mm}
\]
and similarly for the cup.

It also preserves all equations between string diagrams, so, for example, our derivation of teleportation carries over to the doubled world.  What about the  converse? Do equations in  doubled diagrams carry over to their un-doubled counterparts?  The answer turns out to be no,  but luckily this is a feature, not a bug.  

\begin{proposition}\label{prop:phases}
In a theory  described by string diagrams, if:
  \beq\label{eq:phaseelim1}
\dmap{\widehat f} \ =\ \dmap{\widehat g}
  \eeq
then there exist numbers $\lambda$ and $\mu$, with  $\widehat \lambda=\widehat \mu$, such that:
\begin{equation}\label{eq:phaseelim2}
  \scalar{\lambda} \, \map{f} \ =\ \scalar{\mu} \, \map{g}
\end{equation}
The converse also holds provided $\widehat \lambda=\widehat \mu$ is cancellable. 
\end{proposition}
\begin{proof}
Let $\lambda$ and $\mu$ be:  
\[
\scalar{\lambda} \ := \ \ \tikzfig{elim3bis}\qquad \quad\qquad\scalar{\mu} \ := \ \ \tikzfig{elim4bis}  
\]
Unfolding \eqref{eq:phaseelim1} yields:
\beq\label{eq:phaseelim3}
\mapconj{f}\ \map{f} \ =\ \mapconj{g}\ \map{g} 
\eeq
So:
\[
\dscalar{\widehat \lambda} \ \ \tikzfig{elim6_paper} \ \   \dscalar{\widehat \mu}
\]
and:
\[
\scalar{\lambda} \, \map{f}\ \, \tikzfig{elim5_paper}  \ \, \scalar{\mu} \, \map{g}  
\]
\end{proof}

Typically, `cancellable' means non-zero, and the condition that $\widehat\lambda = \widehat\mu$ means the absolute values of $\lambda$ and $\mu$ coincide. In that case, the condition \eqref{eq:phaseelim2} is more commonly referred to as `equal up to a (global) complex phase $\mu\over\lambda$'. One of the uglier aspects of the standard quantum formalism is indeed that it contains redundant numbers  of the form $\mu\over\lambda$, which have no physical significance.  Thus a nice side-effect of doubling is precisely removing this redundancy.

\subsection{Pure processes and discarding}

A state $\psi$ is called \textit{normalised} if composing with its adjoint yields  1, i.e.~the empty diagram:
\[ 
\kpointbraket{\psi}{\psi} \ =\ \emptydiag   
\]
When we pass to the doubled world, we therefore have a way to throw away states $\widehat\psi$ arising from normalised states $\psi$. Simply connect the two halves together:
\[
\tikzfig{discard_prop_proof_paper}\ \  = \ 
\kpointbraket{\psi}{\psi}\ =\ \ \emptydiag
\]
This new effect, which has no counterpart in the un-doubled underlying theory,  is called \textit{discarding}, and we denote it as follows:
\[
\discard\ \, := \ \ \tikzfig{trace_def}
\]
This then immediately gives rise to new boxes  as well: 
\beq\label{eq:quantummapx}
\tikzfig{quantummapx}
\eeq
which we call \textit{impure}, or \textit{mixed}, processes---for reasons that shall become clear in the follow-up paper to this one. These impure processes naturally occur, as the diagram indicates, when we are only considering part of a composite system, and ignoring  (i.e.~discarding) another part.  In other words, we are considering systems that are in interaction with their \textit{environment}. A \textit{pure} process is then one that doesn't involve discarding, i.e.~that doesn't have  a wire connecting its two halves. Impure processes will typically be denoted by $\Phi$, and and impure states by $\boldsymbol\rho$, in contrast to the pure ones which carry a `hat'.

Discarding multiple systems is the same as discarding one, bigger system. Hence we can put any process consisting of pure processes and discarding in the form of \eqref{eq:quantummapx} by grouping all of the discarding processes together into a single effect:
\[
  \tikzfig{arbitrary_w_discardbis}
  \quad\mapsto\quad
  \tikzfig{arbitrary_w_discardbisA}
\]
As a consequence:

\begin{proposition}\label{prop:q-boxclosedness}
Any string diagram consisting of processes of the form (\ref{eq:quantummapx}) is again of that form. Hence they form a process theory.
\end{proposition}

Another consequence is that any diagram of pure processes and discarding can be put into a standard form involving a pure process and a single discard. In other words, any (possibly impure) process $\Phi$ has a \textit{purification} $\widehat f$:
\beq\label{eq:purification}
\dmap{\Phi} \ =\ \ \tikzfig{purificationI}
\eeq

Condition (\ref{EQ:daggeraxiom}) on adjoints now allows us establish an important connection between $\otimes$-separability, and purity of the \textit{reduced state} of a composite system, i.e.~what remans if we discard part of it:
\ctikzfig{bipartite_disc_rho}
  
\begin{proposition}\label{prop:reduce-pure}   
Consider a theory that admits string diagrams and in which adjoints obey \eqref{EQ:daggeraxiom}. If the reduced state of a bipartite state $\boldsymbol\rho$ is pure:  
  \begin{equation}\label{eq:rho-disc-pure} 
    \tikzfig{bipartite_disc_rho}\  \ =\ \dkpoint{\,\widehat\phi\,}      
  \end{equation}
 then it $\otimes$-separates as follows:
\[ % \begin{equation}\label{eq:rho-disc-pure1}
 \dbistate{\boldsymbol\rho} \ =\
 \dkpoint{\,\boldsymbol\rho'}\, \dkpoint{\,\widehat\phi'\,}           
\] % \end{equation}
\end{proposition}
\begin{proof}
 Writing $\boldsymbol\rho$ in the form (\ref{eq:quantummapx}):
\begin{equation}\label{eq:unfold-form}
   \dbistate{\boldsymbol\rho}\, \ =\ \  \tikzfig{bistate-pfa-3} 
\end{equation}
and substituting this into (\ref{eq:rho-disc-pure}) we obtain: 
 \[
\tikzfig{bistate-disc-pfa-3} \ \  = 
\ \   \tikzfig{final1}   
\]
and hence:
\[
\tikzfig{bistate-disc-pfb-3} \ \ =\ \ \kpointconj{\phi}\kpoint{\phi}       
\]
Deforming this equation via process-state duality and transposition, we get:
\[
\tikzfig{final2NEW}
\]
Then, by (\ref{EQ:daggeraxiom}) there exist $\psi_1$ and $\psi_2$ such that:
\[
 \tikzfig{final3NEW-3} 
\]
hence:
\[
\tikzfig{final3NEW-3b}
\]
Plugging in to \eqref{eq:unfold-form} indeed yields a $\otimes$-separable state of the required form:
\[
\tikzfig{bistate-pfa-3-sep}\ \ =\ \ \tikzfig{bistate-pfa-3-sep2} 
\]
\end{proof}

%\COMMb{This is needed in part II and allows for a crisper no-broadcasting proof.}
By process-state duality this fact straightforwardly extend to processes:

\begin{proposition}\label{prop:discard-mix-pure-proc}   
Consider a theory  that admits string diagrams and in which adjoints obey \eqref{EQ:daggeraxiom}. If        
a  \em reduced process \em of a process $\Phi$ is pure:  
  \begin{equation}\label{eq:rho-disc-pure-proc}
\tikzfig{bekan7}\  \ =\ \dmap{\widehat f}  
  \end{equation}
 then it $\otimes$-separates as follows:
 \beq\label{eq:rho-disc-pure-proc2}
\tikzfig{bekan8}\  \ =\ \dkpoint{\,\boldsymbol\rho}\ \dmap{\widehat f}    
  \eeq
\end{proposition}
\begin{proof}
Bend the wire in (\ref{eq:rho-disc-pure-proc}):   
  \[
  \tikzfig{bekan9}\ \ = \ \ \tikzfig{bekan10}
\]
Treating the two rightmost wires above as a single system, this is the reduced state of a bipartite state. Since the reduced state is pure, by Proposition~\ref{prop:reduce-pure} it separates as follows:
\[
\tikzfig{bekan11}\ \ = \ \dkpoint{\,\boldsymbol\rho}\  \tikzfig{bekan10}
\]
Unbend the wire and we're done.
\end{proof}


\subsection{No-broadcasting}    

A \textit{cloning process} $\Delta$ is a process that takes any state as input and produces  two copies of that state as output:
\beq\label{eq:cloning}
\tikzfig{cloneboxstated} 
\eeq
It is often said that a key difference between quantum and classical processes is that the latter admits cloning. In fact, this is not entirely true if one includes probabilistic classical states into the mix, in which case there is no way to `clone' a probability distribution either.

However, what is possible classically is \textit{broadcasting}. That is, there exists a process $\Delta$  such that, when a state $\boldsymbol\rho$ is fed in and either output is discarded, we are left we $\boldsymbol\rho$:
\begin{equation}\label{eq:rho-broadcast} 
  \tikzfig{rho-broadcast-paper}
\end{equation}
It is easily seen diagrammatically that broadcasting is indeed a weaker notion than cloning:
\ctikzfig{cloneboxstatedproof-paper1}
and similarly for discarding the other output. Rather than making explicit reference to  the state  $\boldsymbol\rho$, we can also give the broadcasting equations (\ref{eq:rho-broadcast}) in a state-less (or, if you want, point-less) form:  
   \begin{equation}\label{eq:norho-broadcast}     
    \tikzfig{broadcast-paper}
  \end{equation}
  
\begin{theorem} 
 If in a theory  described by string diagrams adjoints obey (\ref{EQ:daggeraxiom}), then the theory obtained by doubling and adjoining discarding cannot have a broadcasting process.      
  \end{theorem}
\begin{proof}
By equation (\ref{eq:norho-broadcast}l) the reduced state of $\Delta$ is pure, namely a plain wire, so by Proposition \ref{prop:discard-mix-pure-proc} we have: 
  \beq\label{eq:broadcast-nopurify4}  
  \tikzfig{broadcast-nopurify4}
 \eeq 
for some state $\boldsymbol{\rho}$.  Hence it follows that:   
  \ctikzfig{broadcast-nopurify5}
  Since the identity is $\circ$-separable, so is every other process involving that type, and hence the system must be trivial for $\Delta$ to exist.
\end{proof}

\subsection{Category-theoretic counterpart}

Doubling and adding discarding has a categorical counterpart as well. Rather than building it up piecewise from doubled processes and discarding, the categorical construction just declares that all morphisms should be of the form \eqref{eq:quantummapx}:

\begin{definition}
  For a compact closed category $\mathcal C$, we can form a new compact closed category $\textrm{CPM}[\mathcal C]$ with objects $\widehat A$ for every $A \in \textrm{ob}(\mathcal C)$. The morphisms $f : \widehat A \to \widehat B$ are those morphisms $f \in \mathcal C(A \otimes A, B \otimes B)$ which are of the form:
  \ctikzfig{CPM-form}
  for some object $C$ and morphism $g : A \to C \otimes B$.
\end{definition}

One needs to do a bit of work to show that this is indeed a compact closed category. For instance, the parallel composition of $f : \widehat A \to \widehat B$ and $f' : \widehat A' \to \widehat B'$ should give something of the form:
\[ 
f \otimes f' \in \mathcal C((A \otimes A') \otimes (A \otimes A'), (B \otimes B') \otimes (B \otimes B'))
\]
which involves some reshuffling of wires. We refer to references in the next section for details.

The acronym CPM refers to `completely positive map', and indeed when you apply this construction to FHilb, you get the category whose morphisms are completely positive maps.

\subsection{Reference and further reading}  
  
The doubling construction was introduced in \cite{DeLL}, including the  proof of Proposition \ref{prop:phases}. Around the same time, the  generalisation to impure was introduced by Selinger \cite{SelingerCPM}. The idea that this can be done by adding the discarding process was put forward in \cite{SelingerAxiom}. 

The no-broadcasting theorem first appeared in \cite{Nobroadcast}, and our derivation from doubling and (\ref{EQ:daggeraxiom})   is novel. Another `generalised no-broadcasting theorem' is \cite{BBLW}, which rather than  process theories, concerns  generalised probabilistic theories.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  

\section{Causality}\label{sec:causality}
  
\begin{quote}
\em A new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die, and a new generation grows up that is familiar with it.  
\par \em \hfill    --- Max Planck, 1936.      
\end{quote}

\noindent
The beginning of the previous century saw two revolutions in physics: quantum theory and relativity. While the first one is a  theory which associates probabilities to non-deterministic processes (usually) involving microscopic systems, the second concerns the geometry of spacetime. Evidently, since there is only one reality, those two theories should not contradict each other. Amazingly, this compatibility can already be obtained within the generality of diagrams, provided there are discarding effects. If  these discarding  effects happen to arise from doubling as described above, then many more results follow.

\subsection{Causal processes}

Suppose we apply  a process to some inputs, but then discard all of its outputs.  Then the performance has gone to waste, and we could as well  have simply discarded its inputs.  In fact, this obvious assumption is quite vital for even being able to perform science.  It allows one to `discard'  (i.e.~ignore) everything that does not directly affect an experiment,  such as for example,  stuff happening in  some other galaxy. However innocent and/or obvious this principle sounds, it has many striking consequences,  warranting an important-sounding name:

\begin{definition}\label{def:eq:causqmaps}
In a process theory where each system  has a  distinguished discarding effect, a process ${\Phi}$ is called \textit{causal} if we have: 
\beq\label{eq:causqmaps}
\tikzfig{causal}\ \ = \ \, \discard
\eeq
We call a theory causal if all its processes are.
\end{definition}

Note that \eqref{eq:causqmaps} should be read as discarding {\em all} of the outputs on the LHS results in discarding {\em all} of the inputs on the RHS. As a special case, states have no inputs,  so nothing has to be discarded in the RHS:
\[
 \tikzfig{discard_prop} \ \  =\  \emptydiag  
\]
This is the usual condition for a (possibly impure) quantum state being normalised. Similarly, effects have no outputs, so nothing has to be discarded in the LHS:
\[
\dkpointadj{\boldsymbol\rho} \ =\ \discard 
\]
Clearly, this is bad news for those who like variety:

\begin{theorem}\label{thm:only-one-effect}
In a causal theory, each system-type  admits only one effect: discarding.
\end{theorem}

In the case of two systems this means that:
\[
\discard \, \discard 
\]
is the only available effect.  So now it should be clear that, if we restrict to causal effects, teleportation is  no longer possible:
\ctikzfig{telenoclass2dub}
The way around this problem is to avoid Theorem \ref{thm:only-one-effect} simply by having a classical output, corresponding to Aleks' outgoing phone call to Bob.  As we will see in the follow-up paper \cite{CQMII}, such a classical output is what enables one to accommodate the non-determinism alluded to in Section \ref{sec:adjoints-and-unitarity}.

\subsection{Evolution and Stinespring dilation}\label{sec:stinespring}

We now consider theories arising from doubling.  In our first result, we will actually derive something that is typically assumed \textit{a priori} in the standard formulation of quantum theory \cite{vN}.

\begin{theorem}\label{thm:purecausaliso}
In  a theory obtained by doubling and adjoining discarding, the following are equivalent  for any pure process $\widehat U$:    
 \ben
 \item $\widehat U$ is causal:    
\[
\ \ \tikzfig{smapUU}\, \ = \  \discard
\]
 \item $U$ is an isometry: 
\[
\tikzfig{isometry} 
\]
 \item and, $\widehat U$ is an isometry:   
\[
\tikzfig{isometrydub}
\]
\een 
\end{theorem}
\begin{proof}
Unfolding the causality equation, we have:
\[
  \tikzfig{isometryproof1}
\]
and we recover (\ref{eq:isometry}) simply  by un-bending, so $1 \Leftrightarrow 2$. $2 \Leftrightarrow 3$ follows by Proposition \ref{prop:phases}.
\end{proof}

\begin{corollary}\label{cor:purecausalisobis}
Under the assumptions of the previous theorem,  the following are equivalent for pure processes:
\ben
\item $\widehat U$ is causal and invertible, and
\item $\widehat U$ is unitary.
\een 
\end{corollary}

Dropping purity yields a standard result of quantum information theory:

\begin{theorem}[Stinespring dilation]
Under the assumptions of the previous theorem,  for every causal process $\Phi$ there exists an isometry $\widehat U$ such that:
\beq\label{eq:prestinespring}
 \dmap{\Phi} \ =\ \ \tikzfig{quantummapcaus}   
\eeq
\end{theorem}
\begin{proof} 
We have \eqref{eq:prestinespring} immediately if we let $\widehat U$ be the purification of $\Phi$, as in \eqref{eq:purification}. So, it suffices to prove that $\widehat U$ is an isometry in (\ref{eq:prestinespring}).  By causality of $\Phi$, it follows that $\widehat U$ must also be causal: 
\[
\tikzfig{quantummapcausproof-paper}
\]
which, by Theorem \ref{thm:purecausaliso} implies that $\widehat U$ is an isometry.    
\end{proof}

\subsection{No-signalling}  

In this section, we'll set doubling aside again and look at the general case of theories with discarding,  and how diagrams in such a theory relate to \textit{causal structures}. A causal structure is simply a directed graph (without cycles) that indicates some collection of events in spacetime, where an edge from $e_1$ to $e_2$ indicates that $e_1$ could have an influence on $e_2$, i.e. $e_2$ is in the \textit{causal future} of $e_1$. For example, the following causal structure:
\ctikzfig{Causalyab}
indicates that Aleks and Bob may have some shared history,  but now they have moved far away from each other, so that they can no longer directly communicate. More precisely, they are so far away that the speed of light prohibits Aleks sending any kind of message to Bob and vice versa.

A process theory is said to be \textit{non-signalling} if each process $\Phi$ in a diagram with a fixed causal structure can only have an influence on processes in the causal future of $\Phi$. We claim that  any causal process theory is non-signalling. 

First, we note that we can associate a causal structure to any circuit diagram by associating boxes to events, and declaring a box $\Phi$ to be in the causal future of another box $\Psi$ if an output of $\Psi$ is wired to an input of $\Phi$:
\ctikzfig{causal-ex-pre-paper}
Note that we can freely add some extra input/output wires to account for the fact that Aleks and Bob can interact with their own processes locally:
\ctikzfig{puricausalcomp1-pre}
However, in this situation, non-signalling dictates that, since Bob does not have access to the output of Aleks' process (as this would require Aleks sending a message faster than the speed of light), Aleks shouldn't be able to influence Bob via his input. To see this is the case, let's see things from Bob's perspective by discarding Aleks' output:
\[  
\tikzfig{puricausalcomp1-paper}
\]
and see if Bob can learn anything about Aleks' input from his own input-output pair. By causality we have:
\[
\tikzfig{rrr9}
\]
and hence it follows that:    
\[
\tikzfig{puricausalcomp2}
\]
So from Bob's perspective, his input-output pair is $\circ$-separated from Aleks' input. Thus no signalling from Aleks to Bob can take place. By symmetry it also follows that Bob cannot signal to Aleks. 

\begin{theorem}
 If a process theory has a discarding process for each type and it satisfies causality, then it is non-signalling. 
\end{theorem}

\subsection{Category-theoretic counterpart}   

In contrast to some of the previous definitions, one usually encounters the following definition in the first lesson of a course on category theory:    
  
\begin{definition} 
  An object $T$ is called \textit{terminal} if for every object $A$, there exists a unique morphism $! : A \to T$.  
\end{definition}

Its a quick exercise to show that, if a terminal object exists, it is unique (up to isomorphism). A monoidal category is called \textit{causal} if the monoidal unit $I$ is a terminal object, which is the same as saying that every morphism in the category satisfies the causality postulate.

\subsection{Reference and further reading}  
  
The causality postulate was only recently identified as a core principle of quantum theory, by Chiribella, D'Ariano and Perinotti \cite{chiri1}, as one of a series of axioms from which quantum theory was reconstructed.

Stinespring dilation first appeared within the context of C*-algebras \cite{Stinespring}. Our derivation of unitarity and Stinespring dilation from causality is new.  

The first proof of the non-signalling theorem for quantum theory can be found in \cite{Ghirardi}. The derivation of non-signalling from the causality principle  is taken from \cite{Cnonsig}. A similar result is also in \cite{FritzII}, but in those papers more structure is used in order to establish this fact.     

\section{What comes next}    

Simply by stating that a quantum type arises from doubling we derived many typical features of quantum theory.  The motivation for doubling arose from distinguishing quantum types from classical types.  However, we haven't said anything yet about classical types, nor how quantum and classical types interact. Having a grip on this is essential to understanding concepts such as mixing, measurement, and entanglement, and will enable us to give fully-comprehensive descriptions of several quantum protocols as diagrams.  This will be the content of the follow-up paper \cite{CQMII}.   

In the final paper \cite{CQMIII} we will discuss the important quantum theoretical notion of complementarity, as well as a strengthening thereof, which, among many other things, will enable us to derive quantum non-locality.  The corresponding category-theoretic  notions to classicality and complementarity  will involve certain  kinds of algebraic structures within a monoidal category, namely certain Frobenius algebras and Hopf-algebras.    

\bibliography{main}
\bibliographystyle{plain}  

\end{document}
