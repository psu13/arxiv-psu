\section{Experiment and evaluation}
\label{sec:xpmt}

This project was designed to collect evidence through an intervention trial to test whether (1) the diagrammatic formalism provides the most effective method to present quantum information theory (QIT) content, and (2) this formalism can significantly enhance young learners’ problem-solving ability after their training.


\subsection{Design and sampling}

This intervention trial is scheduled to be implemented between the 5th of June and the 11th of August, 2023.
It is designed to be delivered online through weekly one-hour sessions, each following a half an hour of self-study, spanning 10 weeks.
Through this trial, evidence has been 
 collected using a post-test design to evaluate the effectiveness of the QP approach.
A purposive sampling approach was employed to recruit 75 volunteer high-school students aged 16 to 19. The sample size was determined based on the number of available tutors. 

The project flyer was distributed to approximately 26 high schools across the UK and promoted on various social media platforms. Despite reaching out to a limited number of schools and teachers due to time constraints, we have received a more significant number of applications than anticipated $(N_0=734)$ within three weeks.
To ensure the quality of training, we  conducted an initial filtering process to exclude non-high-schoolers, respondents outside the target age range, and non-UK students as mandated by the obtained ethical approval.
We then asked for a study commitment of two hours weekly for 10 weeks, and sampled a random subset of positive respondents to reflect a balance of diversity criteria, re-sampling random subsets of respondents until all criteria were met within predetermined accuracy.
A total of 75 candidates were selected, with the goal of around 50 of them completing the course, taking into account potential attrition.

Participants have been provided with the experiment handbook that effectively communicates the objectives and requirements of the study; outlines the schedule; describes the evaluation methods to be used after the training; provides procedures for the tutorials; covers data protection and privacy policies; provides relevant contact details; and includes a handout which summarises the post-training procedures.
They have also been provided with a slimmed-down version of the QP book by Coecke and Gogioso~\cite{coecke2022quantum} to act as their tutorial book.
A similar and more substantive textbook by Coecke and Kissinger~\cite{CKbook} is actively  in use in various university-level courses, most notably at the University of Oxford.

All participants have been granted access, via a secure link, to weekly online recorded lectures (episodes) specifically designed to teach QP (a brief outline of the content is provided in Appendix A). They were also expected to engage in half-hour self-study sessions before the scheduled tutorials.
This was to help mitigate the effect of teacher and tutor variation on training outcomes, as each participant needed to have access to the same lectures during training via the project portal.

Participants have been provided with a link to book tutorials at their convenience. Each week's practice tutorials have been conducted by one of eight tutors, with a class size of 15 students maximum per tutorial.
 
To reduce the effect of tutor variation, the carousel technique was implemented: tutors rotated weekly, with a dedicated tutor being responsible for the week's material, enabling them to interact with each group at least once during the training period.
Consultation sessions with team members and tutors took place during the 1st, 3rd and 6th weeks to enable tutors to share their experiences and discuss the implementation of necessary measures.

Tutors underwent a Disclosure and Barring Service (DBS) check following UK regulations and completed a one-hour training session ahead of the trial. The training covered the study's objectives, effective interaction with students, conflict management, strategies for handling students with varying abilities, guidelines for taking observational notes for later qualitative data analyses, and techniques for encouraging students to progress towards the next steps.
It was made clear that the tutorials would primarily focus on practical exercises within interactive sessions.

Our tutors are highly qualified doctoral students, lecturers from the University of Oxford, and researchers from Quantinuum, all with substantial teaching experience.
Tutors were explicitly instructed to devise their own plans for implementing additional examples to reinforce the video lectures. These plans were supported by the Principal Investigators (PIs), who assisted in various aspects, including providing additional examples for each tutorial week. Their support ensured the curriculum remained up-to-date and incorporated research expertise and industry knowledge. 

\subsection{Data collection procedures}

Participants’ performance changes in learning outcomes (outlined in Appendix A) has been monitored via tutors' notes every week leading up to the post-tests. The weekly monitoring helped determine whether individuals exhibited observable improvement as a result of the training. For this, we utilised both directly related measures of performance and qualitative assessments of achievements. 
In addition to tutor notes, the exam and attitude questionnaires evaluated participants’ performance, providing comprehensive data to assess their progress and attitudes toward the training.  

\subsection {Assessment and evaluation}

The exam questionnaire used in this study is identical to the one previously implemented by the PIs in the quantum physics course for undergraduate students at the University of Oxford.
The questions were specified by the PIs for this project and subsequently reviewed by two project members to evaluate their applicability, appropriateness, language, presentation style, variability, and representativeness.

Questions were chosen to test the level of proficiency across target skills, ranging from calculation by diagrammatic manipulation to conceptual understanding of quantum information scenarios represented by the diagrams.

The selection process for each question involved careful consideration of various factors, including: 
\begin{itemize}
    \item objectives and aim of the study,
    \item desired outcomes,
    \item relevant literature,
    \item previous implementations with undergraduate students,
    \item the expertise of the PIs, and input from the research team, 
    \item a review process to assess the questions' clarity, relevance, and appropriateness for the study population. 
\end{itemize}

Upon completing the 8th week of training, participants were given a two-week period to complete and submit their answers to the exam questions.
The submitted work underwent a rigorous marking process managed by two experienced PIs, Coecke and Kissinger, who have been marking similar work for over a decade. They independently assessed students' work by following the provided criteria in Appendix B. This ensured fairness and accuracy, where each examiner independently assessed the submission without knowing the other's decision. In cases where a significant discrepancy of more than 9\% in the assigned grades occurs, another PI, Gogioso, was involved to review and facilitate further discussion until a consensus is reached.
This ensures consistency and transparency in the marking process, aims to provide participants with clear evaluation criteria and constructive feedback alongside their marks, and maintains consistency in the final grades.  

Participants' attitudes were assessed before the trial, focusing on three aspects: (1) their commitment, (2) interest in pursuing a STEM career, and (3) providing at least one specific reason for their interest in participating.
The post-intervention attitude assessment gathered feedback on the overall setup, satisfaction with the tutorials, any changes in their career plans, and their post-training/future expectations. Additionally, an optional question regarding their grades in STEM subjects was included to aid in analysing correlations between exam scores and attitude questions.
The attitude assessments generated qualitative data, which will be analyzed using qualitative analysis techniques in a follow-up study.

\subsection{Measured variables}

The outcome variables for the assessment, derived from the two questionnaires above (exam and attitude), focus on the number of problems students successfully solve using QP. 

The marking scheme prioritized comprehension rather than solely assessing the overall accuracy of answers. The evaluation process was guided by the following rubric, which is designed to align with the objectives, learning outcomes, and analysis scheme outlined in the breakdown marking criteria provided in Appendix A:

\begin{itemize}
\item Methodology: Assessing general problem-solving skills, including problem analysis, the ability to break down complex problems into smaller components, and logically organize the steps required to find a solution.
\item Correctness: Evaluating the accuracy of solutions and the validity of the reasoning provided in the answers.
\item Conciseness: Assessing the ability to present solutions concisely, considering factors such as the number of steps required to reach a solution.
\item Originality/Creativity: Considering the creativity and originality of the strategies employed by students in solving problems.
\item Evidence of understanding: Evaluating the correct application of relevant concepts and strategies taught during the course, such as the appropriate use of diagrammatic rewriting rules, and demonstrating a deep understanding of the physical meaning behind concepts like diagrammatic quantum teleportation.
\item Structuring, communication, presentation: Assessing the ability to organize, write, and draw solutions in a clear and unambiguous manner. This includes aspects such as the proper use of colors, distinguishing between ``quantum'' and ``ordinary'' diagrams, and using terminology consistent with the content presented in the tutorials (e.g., ``square-popping'', ``leg-chopping'', etc.).
\end{itemize}

Self-reports were also taken into account during the post-test period, in conjunction with the weekly observational data collected by tutors. Tutors received a feedback form they completed after each week's tutorial. This was to facilitate the assessment of each student's progress throughout the training and enable meaningful comparisons.

Further demographic factors, such as age, parental education, English language proficiency, and school type, were analysed as independent variables within the socio-economic and cultural impact on performance.

\subsection{Data exclusion rule}

Participants have been informed that they can withdraw from the study at any point.
Attendance during the training period was monitored, but only data from participants who attended tutorials and completed post-testing were included in the analysis.
As per the attendance rules agreed during the recruitment stage, participants had to register for one of five tutorial time options each week.
%Participants who were absent for more than one week of the online tutorials were excluded from the study.

To prevent the spillage  effect, participant interactions were discouraged during and after the training until they had submitted their exam answers. They were requested to keep their personal information private from each other to uphold the integrity of their training and ensure the validity of the analyses. With these precautions in place, no  unsupervised interaction or violation of research protocols between participants was observed  that would require us to exclude their data from the analyses, ensuring the study's validity. 

\subsection{Data Transformations}

For privacy reasons, raw subject data stored in a single/secure location accessible only to the project PI, Kissinger.
Students were then assigned a unique code to enable anonymised data to be shared and analysed independently by research team members. 
The researchers worked together throughout the data collection process, following the protocols for test administration. 
As a follow-up, frequency tables generated for each variable using SPSS / R to check that there are no out-of-range values and that any missing data points have been appropriately coded.
This strategy of creating single intermediate records, collating all raw data relating to each participant, has proved to be an essential facilitator of data checking and cleaning before entry for analysis, and tabulated data can be set up to allow for semi-automated entry once this process has been completed. 
Once data collection was ongoing, the researchers double-checked the processes involved, including coding and storing the raw data from the testing.
The coding schemes were modified where necessary.

\subsection{Analysis}

The impact of training was measured via post-tests.
Effects were assessed using analysis of variance. Differences in performance between the age groups were assessed using hierarchical regressions, path analyses, and multilevel modelling, also aiming to examine the influence of socioeconomic and demographic factors. 
Furthermore, underlying attitudinal factors examined using exploratory factor analysis. 

