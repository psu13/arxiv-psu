\documentclass[12pt]{article}

\usepackage[small]{titlesec}
\usepackage{cite}
\usepackage{tabularx}

%\usepackage{amsmath,amsthm,amscd,amssymb}
\usepackage[colorlinks=true,
breaklinks=true,
urlcolor=blue,
anchorcolor=blue,
citecolor=blue,
filecolor=blue,
linkcolor=blue,
menucolor=blue,linktocpage=true]{hyperref}
\hypersetup{bookmarksopen=true, bookmarksnumbered=true, bookmarksopenlevel=10}
\usepackage[noBBpl,sc]{mathpazo}
\linespread{1.05}
\usepackage[papersize={6.9in, 10in}, left=.5in, right=.5in, top=.7in, bottom=.9in]{geometry}
\sloppy
\raggedbottom
\pagestyle{plain}

\begin{document}

\title{\Large Thinking machines: Can there be? Are we?}
\author{\large Terry Winograd}
\date{\normalsize 1991 \\ {\footnotesize (Transcribed by psu 2024-08-13)}}

\maketitle

\section{Introduction}

Futurologists have proclaimed the birth of a new species, machina sapiens, that will share (perhaps usurp) our place as the intelligent sovereigns of our earthly domain . These ``thinking machines'' will take over our burdensome mental chores, just as their mechanical predecessors were intended to eliminate physical drudgery. Eventually they will apply their “ultra-intelligence” to solving all of our problems. Any thoughts of resisting this inevitable evolution is just a form of “speciesism,” born from a romantic and irrational attachment to the peculiarities of the human organism.

Critics have argued with equal fervor that “thinking machine” is an oxymoron - a contradiction in terms. Computers, with their foundations of cold logic, can never be creative or insightful or possess real judgment. No matter how competent they appear, they do not have the genuine intentionality that is at the heart of human understanding. The vain pretensions of those who seek to understand mind as computation can be dismissed as yet another demonstration of the arrogance of modern science.

Although my own understanding developed through active participation in artificial intelligence research, I have now come to recognize a larger grain of truth in the criticisms than in the enthusiastic predictions. But the story is more complex. The issues need not (perhaps cannot) be debated as fundamental questions concerning the place of humanity in the universe. Indeed, artificial intelligence has not achieved creativity, insight, and judgment. But its shortcomings are far more mundane: we have not yet been able to construct a machine with even a modicum of common sense or one that can converse on everyday topics in ordinary language.

The source of the difficulties will not be found in the details of silicon micro-circuits or of Boolean logic. The basic philosophy that has guided the research is shallow and inadequate, and has not received sufficient scrutiny. It is drawn from the traditions of rationalism and logical empiricism but has taken a novel turn away from its predecessors. This new ``patchwork rationalism'' will be our subject of examination.

First, we will review the guiding principles of artificial intelligence and see how they are embodied in current research. Then we will look at the fruits of that research. I will argue that ``artificial intelligence'' as now conceived is limited to a very particular kind of intelligence: one that can usefully be likened to bureaucracy in its rigidity, obtuseness, and inability to adapt to changing circumstances. The weakness comes not from insufficient development of the technology, but from the inadequacy of the basic tenets.

But, as with bureaucracy, weaknesses go hand in hand with unique strengths. Through a re-interpretation and re-formulation of the techniques that have been developed, we can anticipate and design appropriate and valuable uses. In conclusion I will briefly introduce an orientation I call hermeneutic constructivism and illustrate how it can lead down this alternative path of design.

\section{The mechanization of rationality}

In their quest for mechanical explanations of (or substitutes for) human reason, researchers in artificial intelligence are heirs to a long tradition. In his {\it Discourse on the method of properly guiding the reason in the search of truth in the sciences} (1637), Descartes initiated the quest for a systematic method of rationality. Although Descartes himself did not believe that reason could be achieved through mechanical devices, his understanding laid the groundwork for the symbol-processing machines of the modern age.

In 1651, Hobbes described reason as symbolic calculation:

\begin{quote}
When a man reasoneth, he does nothing else but conceive a sum total, from addition of parcels; or conceive a remainder ... These operations are not incident to numbers only, but to all manner of things that can be added together, and taken one out of another ... the logicians teach the same in consequences of words; adding together two names to make an affirmation, and two affirmations to make a syllogism; and many syllogisms to make a demonstration. ({\it Quoted in Haugeland}, 1985)
\end{quote}

\noindent
Leibniz\footnote{As described by Russell (1952) in {\it A History of Western Philosophy.}} cherished through his life the hope of discovering a kind of generalized mathematics, which he called Characteristica Universalis, by means of which thinking could be replaced by calculation. ``If we had it,'' he says ``we should be able to reason in metaphysics and morals in much the same way as in geometry and analysis. If controversies were to arise, there would be no more need of disputation between two philosophers than between two accountants. For it would suffice to take their pencils in their hands, to sit down to their slates, and to say to each other ... ‘Let us calculate’.''

The empiricists turned to physical experience and experiment as the true basis of knowledge. But in rejecting the a priori status of the propositions on which reasoning was based, they did not abandon the vision of rigorous (potentially mechanizable) logical procedures. For our purposes here, it will suffice to adopt a broader characterization, in which much of both rationalism and empiricism fall within a common ``rationalistic tradition.'' (Winograd and Flores, 1986). This label subsumes the varied (and at times hotly opposed) inheritors of Descartes’ legacy - those who seek to achieve rational reason through a precise method of symbolic calculation.

The electronic computer gave new embodiment to mechanical rationality, making it possible to derive the consequences of precisely specified rules, even when huge amounts of calculation are required. The first decades of computing emphasized the application of numerical techniques. Researchers in operations research and decision theory addressed policy questions by developing complex mathematical models of social and political systems and calculating the results of proposed alternatives.\footnote{2}
Although these techniques work well in specialized cases (such as scheduling delivery vehicles or controlling the operations in a refinery), they proved inadequate for the broader problems to which they were applied. The ``mathematization'' of experience required simplifications that made the computer results - accurate as they might be with respect to the models meaningless in the world.

Although there are still attempts to quantify matters of social import (for example in applying mathematical risk analysis to decisions about nuclear power), there is an overall disillusionment with the potential for adequately reducing human concerns to a precise set of numbers and equations (see for example, Davis and Hersh, 1986). The developers of artificial intelligence have rejected traditional mathematical modeling in favor of an emphasis on symbolic - rather than numerical - formalisms. Leibniz’s “Let us calculate” is taken in Hobbes’ broader sense to include not just numbers but also “affirmations” and “syllogisms.”

\section{The promise of artificial intelligence}

Attempts to duplicate formal non-numerical reasoning on a machine date back to the earliest computers, but the endeavor began in earnest with the AI projects of the mid 1950s (see Gardner, 1985, for an overview of the historical perspective). The goals were ambitious: to fully duplicate the human capacities of thought and language on a digital computer. Early claims that a complete theory of intelligence would be achieved within a few decades have long since been abandoned, but the research has not diminished. For example, a recent book by Minsky (one of the founders of AI) offers computational models for phenomena as diverse as conflict, pain and pleasure, the self, the soul, consciousness, confusion, genius, infant emotion, foreign accents, and freedom of will (these are among the section headings in Minsky, 1986).

In building models of mind, there are two distinct but complementary goals. On the one hand is the quest to explain human mental processes as thoroughly and unambiguously as physics explains the functioning of ordinary mechanical devices. On the other hand is the drive to create intelligent tools - machines that apply intelligence to serve some purpose, regardless of how closely they mimic the details of human intelligence. At times these two enterprises have gone hand in hand, at others they have led down separate paths.
\end{document}
