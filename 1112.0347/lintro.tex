\chapter{Applications to Functional Programming: 
The Lazy Lambda-Calculus}
\section{Introduction}
In this Chapter, we turn to our second case study, which concerns the 
foundations of functional programming. 
Once again, we aim not merely to exemplify our theory, 
but to use it in order to break some new ground.

The commonly accepted basis for functional programming is the 
$\lambda$-calculus; 
and it is folklore that the $\lambda$-calculus {\em is} the prototypical 
functional language in purified form. But what is the $\lambda$-calculus? 
The syntax is simple and classical; variables, abstraction and application 
in the pure calculus, with applied calculi obtained by adding constants. 
The further elaboration of the theory, covering conversion, reduction, 
theories and models, is laid out in Barendregt's already classical treatise 
\cite{Bar}. 
It is instructive to recall the following crux, which occurs rather early 
in that work (p.\  39):
\subsection*{Meaning of $\lambda$-terms: first attempt}
\begin{itemize}
\item The meaning of a $\lambda$-term is its normal form (if it exists).
\item All terms without normal forms are identified.
\end{itemize}
This proposal incorporates such a simple and natural interpretation of the 
$\lambda$-calculus as a programming language, that if it worked 
there would surely be no doubt that it was the right one. 
However, it gives rise to an inconsistent theory! (see the above reference).
\subsection*{Second attempt}
\begin{itemize}
\item The meaning of $\lambda$-terms is based on head normal forms 
via the notion of {\em Bohm tree}.
\item All unsolvable terms (no head normal form) are identified.
\end{itemize}
This second attempt forms the central theme of Barendregt's book, 
and gives rise to a very beautiful and successful theory 
(henceforth referred to as the ``standard theory''), as that work shows.

This, then, is the commonly accepted foundation for functional programming; 
more precisely, for the {\em lazy} functional languages, 
which represent the mainstream of current functional programming practice. 
Examples: MIRANDA \cite{Tur85}, LML \cite{Aug84}, LISPKIT \cite{Hen80}, 
ORWELL \cite {Wad85}, PONDER \cite{Fai85}, 
TALE \cite{BvL86}. 
But do these languages as defined and implemented actually evaluate terms 
to head normal form? 
To the best of my knowledge, {\em not a single one of them does so}. 
Instead, they evaluate to {\em weak head normal form}, i.e. they do not 
evaluate under abstractions. 
\subsection*{Example} 
$\lambda x. (\lambda y . y)M$ is in weak head normal form, but not in head normal form, since it contains the head redex $(\lambda y . y) M$.

So we have a mismatch between theory and practice. 
Since current practice is well-motivated by efficiency considerations and 
is unlikely to be abandoned readily, it makes sense to see if a good 
modified theory can be developed for it. 
To see that the theory really does need to be modified:
\subsection*{Example}
Let $\Omega \equiv (\lambda x . xx)(\lambda x . xx)$ be the standard 
unsolvable term. Then
\[ \lambda x . \Omega = \Omega \]
in the standard theory, since $\lambda x . \Omega$ is also unsolvable; 
but $\lambda x. \Omega$ is in weak head normal form, hence should be 
distinguished from $\Omega$ in our ``lazy'' theory.

We now turn to a second point in which the standard theory is not completely 
satisfactory.
\subsection*{Is the $\lambda$-calculus a programming language?}
In the standard theory, the $\lambda$-calculus may be regarded as being 
characterised by the type equation
\[ D = [D \rightarrow D] \]
(for justification of this in a general categorical framework, see e.g. 
\cite{Sco80a}, \cite{Koy82,LS86}).

It is one of the most remarkable features of the various categories of 
domains used in denotational semantics that they admit non-trivial 
solutions of this equation. 
However, there is no {\em canonical} solution in any of these categories 
(in particular, the initial solution is trivial -- the one-point domain).

I regard this as a symptom of the fact that the pure $\lambda$-calculus in 
the standard theory {\em is not a programming language}. 
Of course, this is to some extent a matter of terminology, but I feel that 
the expression ``programming language'' should be reserved for a formalism 
with a definite computational interpretation (an operational semantics). 
The pure $\lambda$-calculus as ordinarily conceived is too schematic to qualify.

A further indication of the same point is that studies such as Plotkin's 
``LCF Considered as a Programming Language'' \cite{Plo77} have not been 
carried over to the pure $\lambda$-calculus, for lack of any convincing way of 
doing do in the standard theory. 
This in turn impedes the development of a theory which integrates the 
$\lambda$-calculus with concurrency and other computational notions.

We shall see that by contrast with this situation, the lazy $\lambda$-calculus 
we shall develop does have a canonical model; that Plotkin's ideas can be 
carried over to it in a very natural way; 
and that the theory we shall develop will run quite strikingly in parallel 
with our treatment of concurrency in the previous Chapter.

The plan of the remainder of the Chapter is as follows. 
In the next section, we introduce the intuitions on which our theory is based, 
in the concrete setting of $\lambda$-terms. 
We then set up the axiomatic framework for our theory, 
based on the notion of {\em applicative transition systems}. 
This forms a bridge both to the standard theory, and to concurrency and other 
computational notions. 
Just as in Chapter 4, we introduce a domain equation for applicative 
transition systems, and the corresponding domain logic. 
We prove Duality, Characterisation, and Final Algebra theorems.

We then show how the ideas of \cite{Plo77} can be formulated in our setting. 
Two distinctive features of our approach are:
\begin{itemize}
\item the axiomatic treatment of concepts and results usually presented 
concretely in work on programming language semantics
\item the use of our domain logic as a tool in studying the equational theory 
over our ``programs'' ($\lambda$-terms).
\end{itemize}
Our results can also be interpreted as settling a number of questions and 
conjectures concerning the Domain Interpretation of Martin-Lof's 
Intuitionistic Type Theory raised at the 1983 Chalmers University Workshop on 
Semantics of Programming Languages \cite{Cha83}.

Finally, we consider some extensions and variations of the theory.
