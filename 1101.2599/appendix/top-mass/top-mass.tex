One of the important applications of Monte Carlo event generators is in
the experimental measurement of Standard Model parameters.  An example
where they are particularly heavily used is the top quark mass
determination.  As we will discuss in this Appendix, this application
warrants a deeper investigation of precisely how the top quark mass is
defined.  Our aim is not to review this entire field, but rather to give
just enough background information to set the scene for a discussion
of the mass definition used in event generators.  For more technical
details we refer to the literature and in particular
\cite{Hoang:2008yj,Fleming:2007qr,Fleming:2007xt,Jain:2008gb},
whose approach we largely follow.

Most of our discussion applies equally well to any coloured massive
object (\ie with mass in the perturbative regime, $m\gg\Lambda_{QCD}$):
the bottom quark and more marginally the charm quark, but also any new
coloured particles
that are discovered at the LHC, such as squarks, excited quarks or other
quark partners.  However, we will see that the width of the particle
plays an important role in our discussion and it seems likely that the
top quark is unique in this regard: its decay width (1.5~GeV) is above
the typical scale of confinement so the top decays before it can
hadronize and its production and decay should, in principle, be fully
calculable in perturbation theory.  At the same time, its width is not
so far above the confinement scale and is certainly a lot smaller than
its mass, so events containing top quarks are able to evolve
significantly between its production and decay and parton showers and
high-order perturbative effects are very important.  The bottom quark's
lifetime is much longer and in many, but not all, BSM scenarios those of
new coloured particles are much shorter.

We begin our discussion by recalling that in renormalized quantum field
theory, parameters that appear in the Lagrangian do not have a unique
physical interpretation, but rather are theoretical constructs that
serve as stepping stones to making physical predictions.  In particular,
for each parameter that we renormalize, we have to choose what quantity
to keep fixed, corresponding to the choice of
renormalization scheme.  In the case of particle masses, at one loop
order, we have to consider self-energy corrections that are divergent in
the ultraviolet,
\begin{equation}
  m_0 \to m_0 + \Sigma(m_0),
\end{equation}
where
\begin{equation}
  \Sigma(m) = \frac34C_F\,\frac{\alphaS}{\pi}\,m\left(\frac1\epsilon
  +\mbox{finite}\right)+\mathcal{O}(\alphaS^2)
\end{equation}
is the on-shell quark self-energy in $d=4-2\epsilon$ dimensions.  The
choice of scheme corresponds to a choice of mass parameter
$m^{\mathrm{scheme}}$,
\begin{equation}
  \label{eq:deltam}
  m^{\mathrm{scheme}}=m_0+\delta m
\end{equation}
and a reexpression of $\Sigma$ as a function of $m^{\mathrm{scheme}}$,
such that in
\begin{equation}
  m_0\to
  m^{\mathrm{scheme}}+\Sigma'(m^{\mathrm{scheme}}),
  \qquad \Sigma'(m)=\Sigma(m)-\delta m,
\end{equation}
$\Sigma'$ is finite.  The text-book wisdom is that the choice of scheme
is a purely technical issue, because at a given order of perturbative
theory the corresponding ambiguity is one order higher and therefore, if
calculated to sufficiently high order, the scheme-dependence becomes
irrelevant.  However, this means firstly that it remains a very
important practical issue, because one scheme may result in a
perturbative expansion that converges much more rapidly than another.
If we use the systematic rate of convergence as a criterion for our
preferred choice of scheme, and find that this rate is different for
different physical observables, we will conclude that the `best' choice
of scheme is an observable-dependent statement.  And secondly, the fact
that QCD perturbation theory is at best an asymptotic series means that
one is not able to calculate to infinite orders of perturbation theory
and one must seek a scheme that is well-defined also at the
non-perturbative level.

Before proceeding to discuss specific schemes that are in use, we
briefly mention that if one includes electroweak corrections in the
self-energy, then one obtains an imaginary part from the fact that the
top quark can decay to a quasi-on-shell W boson.  Including this in the
all-orders quark propagator, one obtains the imaginary part that gives
rise to the width term in the Breit-Wigner distribution.  Thus, from a
technical point of view, one can view the renormalized top quark mass as
a complex parameter whose imaginary part gives the top width.

Of the several top quark mass definitions on the market, we can divide
them into two categories: long-distance, which practically means the
pole mass scheme, and short-distance, for example the
$\overline{\mathrm{MS}}$ mass or jet mass schemes, which we define
briefly below.

The pole mass is defined by analogy with the mass definition used in
most QED calculations.  Conceptually, one imagines taking the particle
to infinity and measuring its classical mass in isolation.  Even though
this cannot be physically done for a quark in QCD, one can make it an
operational definition at any finite order of perturbation theory, with
the mass parameter defined to be the real part of the position of the
pole in the complex momentum space.  At the one-loop level, this amounts
to defining $\delta m=\Sigma(m)$ in \EqRef{eq:deltam}.

The archetypal short-distance scheme is the $\overline{\mathrm{MS}}$
one\footnote{Note that the choice of renormalization scheme used for
  particle masses is totally independent of the choice of
  renormalization scheme used for coupling constants. In particular,
  using $\overline{\mathrm{MS}}$ for $\alphaS$ does not require us to
  use the $\overline{\mathrm{MS}}$ scheme also for the top mass. In
  fact, the two schemes are unrelated to each other, except
  operationally: in both one subtracts only the epsilon pole and
  associated universal constants.}.  There, one defines
\begin{equation}
  \delta m(\mu) = \frac34C_F\,\frac{\alphaS}{\pi}\,m
  \,\frac{(4\pi)^{\epsilon}}{\Gamma(1-\epsilon)}\,\frac1\epsilon\,.
\end{equation}
That is, one subtracts only the divergent term itself and associated
universal $\epsilon$-dependent constants.

The difference between the masses in any two schemes can be calculated
as a perturbative series in $\alphaS$.  In particular, the difference
between the pole and $\overline{\mathrm{MS}}$ masses is simply the
ultraviolet-regular part of the self-energy.  Crucial
information about the mass schemes can be obtained by examining the
infrared behaviour of this difference.  At one-loop level, it contains
the integral over gluon loop momenta, weighted by the running coupling
evaluated at the scale of the loop momentum,
\begin{equation}
  \label{eq:C6}
  m^{\mathrm{pole}}-m^{\overline{\mathrm{MS}}}
  \;\stackrel{q\ll m}\sim\;
  C_F\int \frac{\dthree q}{2(2\pi)^3}\,\frac{\alphaS(q)}{q^2}
  \;\sim\; C_F\int \done q\,\alphaS(q).
\end{equation}
This integral is ill-defined in all-order perturbation theory, since it
involves an integral over the region where $\alphaS$ becomes large.
In a perturbative
expansion in powers of $\alphaS(\mu)$, this shows up as a set of
factorially-growing terms, such that perturbation theory does not
converge.  Technically, this gives rise to an ambiguity in the all-order
result, known as the renormalon ambiguity, of
order $\Lambda_{QCD}$: the bottom line is that one cannot,
perturbatively, relate $m^{\mathrm{pole}}$ and
$m^{\overline{\mathrm{MS}}}$ to each other with an accuracy of better
than $\Lambda_{QCD}$.  This indicates that one (or possibly both) of
these definitions is unsuitable for making perturbative calculations
with an accuracy better than this.

Further insight can be gained by calculating simple physical quantities
in the two schemes.  For example, one can calculate the static
interquark potential and show that it has exactly the same renormalon
ambiguity as the self-energy correction.  Therefore a prediction of the
total energy of a static quark-antiquark system in the pole mass scheme,
which absorbs all of the self-energy into the mass definition, leaves a
renormalon ambiguity in the prediction of this physical quantity.  On
the other hand, short-distance mass schemes do not subtract it,
allowing it to cancel between the self-energy and the potential, leaving
a perturbatively-calculable physical prediction.  This argument shows
that, for this observable, a short-distance mass is preferable.  In
fact, for every
observable that has been analysed in sufficient detail to make this
comparison, the same conclusion has been reached.  The practical results
also bear it out: the perturbative series for total top production
cross sections, the top quark decay width and electroweak corrections
such as the $\rho$ parameter, all converge significantly faster if
expressed in terms of the $\overline{\mathrm{MS}}$ mass rather than the
pole mass.  But is this what is measured experimentally?

It is possible to extract a value of the top mass from a measurement of
the $t\bar{t}$ cross section \cite{Abazov:2009ae,Langenfeld:2009wd},
which is unambiguously the $\overline{\mathrm{MS}}$ mass, but this is
considerably less precise than direct measurements from the final-state
properties.
These direct measurements are highly non-trivial conceptually,
precisely because the top quark is not isolated, but rather is produced
as part of a system, evolves by the emission of gluons, decays to a
$b$~quark, which evolves further and then hadronizes to form a jet.  While
there are many refinements in the experimental techniques, they are all
based in one way or another on the measurement of this jet momentum, and
of the decay products of the W that accompanies it (either a lepton and
neutrino or two jets).  Our goal is therefore to understand the
connection between the properties of this jet and the mass of the top
quark that contributed to it.  However, it also contains hadrons
produced by radiation from other partons in the event, including the
initial-state partons, and by the underlying event.  In the absence of a
first-principles understanding of these effects, the experiments model
them with event generators, so that the experimental measurement can
effectively be thought of as a measurement of the top mass parameter of
the particular event generator used.  We assume that this measurement
itself is well understood, and concentrate on the final step of the
analysis: the relation of this parameter to some quantity that can be
defined perturbatively and related to other mass schemes, for example
the $\overline{\mathrm{MS}}$ one.

As a point of principle, it is not possible to make this connection.
Parton shower algorithms are based on leading logarithmic perturbation
theory and as such are not accurate enough to fix the scheme~--
different schemes will only differ by next-to-leading logarithmic
corrections.  Nevertheless, by speculating about how an ideal all-order
algorithm would work, we can obtain an order-of-magnitude result for the
mass parameter that appears in parton shower algorithms.

This argument is facilitated by the approach developed
in~\cite{Hoang:2008yj}.  This showed that all short-distance mass
schemes in use can be defined perturbatively with reference to the pole
mass, an auxiliary mass scale, $R$, and the scale used to renormalize
$\alphaS$, $\mu$,
\begin{equation}
  \label{eq:Revolution}
  m^{\mathrm{pole}} = m(R,\mu)+R\left[\sum_{n=1}^\infty
    \alphaS^n(\mu)\,C_n\!\left(\frac{\mu}R\right)\right],
\end{equation}
where the series in square brackets does not depend explicitly on $m$,
only implicitly through $R$. Renormalization group arguments can then be
used to derive the joint dependence of $m$ on $R$ and $\mu$, which has a
leading logarithm at the $n^{\rm th}$ order $\ln^n\!R/\mu$.  Moreover,
since the perturbation theory in which $m$ is used must also be $\mu$
dependent, large logarithms may arise at all orders of the perturbative
expansion of the observable being calculated, or the expression for $m$,
or both, unless $\mu$ and $R$ are chosen to be of order the physical
scale for the observable being calculated.  One also observes in
calculating the terms in \EqRef{eq:Revolution} that the renormalon
ambiguity arising from the square brackets is equal to that in
$m^{\mathrm{pole}}$, showing that the short-distance mass $m$ does not
contain a renormalon ambiguity.

Different
schemes fall into different classes, with the $\overline{\mathrm{MS}}$
scheme having $R\sim m$, threshold mass schemes such as the 1S, PS and
kinetic mass schemes typically used in B~physics having $R\sim\alphaS m$
and the jet mass scheme discussed below having $R\sim\Gamma_t$, the top
quark decay width.  Using the insight from this renormalization group
approach, one can view $R$ as a new factorization scale above which
physics is integrated out into the mass definition.
Since the infrared contribution to the self-energy (the right-hand side
of \EqRef{eq:C6}) is positive definite, one expects in this picture that
the series in brackets will be positive in general, which it is for all
of the mass definitions in practical use.

With this physical picture in mind, we can describe the action of an
idealized parton shower event generator.  It would describe the
production and evolution of the system containing a top quark using a
properly-matched combination of fixed-order matrix elements and parton
showers to sufficient
accuracy (at least next-to-leading order and next-to-leading logarithmic
respectively).  This evolution would describe the state of the system
down to scales of order the top decay width, whereupon the top quark
would decay.  It would also describe the evolution of the partons
involved in the decay from the scale of the energy release ($\sim m$)
down to the top width.  Finally, for the evolution of the system at
scales from $\Gamma_t$ down to the parton shower's infrared cutoff, the
system of partons produced by the previous steps should be considered
the external partons that emit, including the $b$ quark but not the $t$
quark.  Consideration of this evolution shows that the jet distributions
are affected by physics at all scales, but that only the physics at
scales above $\Gamma_t$ is sensitive to the value of the top quark mass.
Therefore the mass that is reconstructed from such a measurement has, in
principle, all logarithmic physics at scales above $\Gamma_t$ integrated
into it.  We can conclude that perturbation theory will converge
quickest with a mass definition defined at a reference scale
$R\sim\Gamma_t$.  This was illustrated in
\cite{Fleming:2007xt,Jain:2008gb} for the
simpler case of $e^+e^-\to t\bar{t}$, where it was explicitly shown that
a suitably-defined jet mass scheme indeed gave quicker convergence, with
much smaller order-to-order changes in the shape of the top hemisphere
mass distribution than in the $\overline{\mathrm{MS}}$ scheme, for
example.  The final step of the argument is to state that, if the
idealized all-orders calculation converges quickest with such a scheme,
then the scheme-independent leading-order leading-log results will be
most similar to them if their mass parameter is chosen to be of order
the jet mass.

In practice, current parton shower algorithms do not interrupt the
evolution at scale $\Gamma_t\sim1.5$~GeV, although an implementation was
attempted in \pythiasix and some effects of it studied for $e^+e^-\to
t\bar{t}$ \cite{Khoze:1994fu}.  They rather continue it down to
their infrared cutoffs $Q_0\sim1$~GeV.  That is, they shower the events
as if $\Gamma_t<Q_0$.  Despite the small difference between these two
scales, it means that in principle one can repeat the argument above and
state that the parton shower results are most similar to an all-orders
calculation in a scheme in which $R\sim Q_0$.  That is, we can state as
the final result for the likely relation between the top quark mass
measured using a given Monte Carlo event generator (``MC'') and the pole
mass as~\cite{Hoang:2008xm}
\begin{equation}
  m^{\mathrm{pole}} = m^{\mathrm{MC}}+Q_0\Bigl[\alphaS(Q_0)\,c_1+\ldots\Bigr],
\end{equation}
where $Q_0\sim1$~GeV and $c_1$ is unknown, but presumed to be of
order~1 and, according to the argument above, presumed to be positive.
Given that $\alphaS(\mbox{1~GeV})$ is also of order~1, this
states that $m^{\mathrm{pole}}$ could be of order 1~GeV higher than the
value measured by the Tevatron experiments (and hence that
$m^{\overline{\mathrm{MS}}}$ could be of order 1~GeV higher than the
value obtained by assuming that the measured value is actually
$m^{\mathrm{pole}}$).  Since the current experimental uncertainty is
$\pm1.1$~GeV~\cite{:1900yx},
clarifying this relation clearly demands more attention.

% Local Variables: 
% mode: LaTeX
% TeX-master: "../mcreview"
% End: 
