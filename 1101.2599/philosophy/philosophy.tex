As discussed in \SecRef{sec:general-introduction}, Monte Carlo simulations are used in
various ways when performing measurements in particle physics experiments that require
the comparison of theoretical predictions with data.  Similarly, measurements of SM
processes in data provide important input to Monte Carlo tools. They provide validation
of theoretical predictions and allow free parameters to be tuned.

There are some basic philosophies that experimentalists using Monte Carlo tools
and making experimental measurements potentially useful for their
validation should be aware of.  These are discussed in this section.

\input{philosophy/mc-truth.tex}

\mcsubsection{Making generator-friendly experimental measurements}
\label{sec:mcfriendlyobs}

For a measurement to be useful in the context of the development and
improvement of Monte Carlo models, it must be well-defined in terms of
the observed initial- and final-state particles, rather than in terms of
intermediate unstable particles or a particular type of process.
This is also a desirable attribute for any physical measurement to have
meaning beyond a particular theoretical framework. Indeed, quantities
not defined in terms of physical observables run the risk of not being
quantum-mechanically meaningful.


The philosophy advocated here is that the data are ``golden'', and any
dependence on current theoretical tools should be minimized to ensure
the longevity and usefulness of the experimental result. Therefore
corrections and extrapolations to different regions of phase-space using
a Monte Carlo or other theoretical prediction should be minimized. This
should not be confused with correcting for detector effects. In fact it
is required that the effects of the detector (resolutions, efficiencies)
are removed to within some stated systematic uncertainty, or at least
quantified in terms of systematic uncertainties.

The initial state is generally the colliding beams, which are well
known, although in some cases, for example almost-on-shell photons, they
may be treated as a quasi-real initial state.  The final state can be
more problematic. In general the best approach is to define all
particles with proper lifetimes beyond some cut~\cite{Buttar:2008jx}
(typically 30~ps) as being the ``stable'' final state of the event, and
derive all event properties, cross section fiducial regions and so on
from these. The result should be stated in terms of final-state
particles within the acceptance of the detectors, without extrapolations
into regions that are not measured. Statistics allowing, it is even
better to split up the observed phase space into a few complementary
regions, and quote the result for each separately, which can provide a
non-trivial cross check on the ability of the models to interpolate
among those regions.

If any theory-based corrections are applied (for example QED radiative
corrections) they need to be clearly stated and quantified and the
result without the correction should also be stated, since in principle
these corrections would be included in the ``ideal'' Monte Carlo.


These guidelines are best illustrated with different examples of common
measurements at collider experiments.

\paragraph{Measurements of charged-particle distributions (``minimum bias")}

Typically distributions of charged particles, such as charged particle
multiplicity, transverse momentum \pt\ and pseudo-rapidity $\eta$ distributions are made. These measurements
are often referred to as ``minimum bias'', because the idea is usually
to be as inclusive as possible and include the distributions of events
in which it is known that an inelastic collision occurred.  This is
inferred from the detection of final-state particles (other than the
incoming ones). Following the philosophy previously described, such a
measurement should be made within a well-defined region of phase space.
For example if a detector can reconstruct tracks from charged particles
in the region $|\eta| < 2.5$ and \pt\ $>$ 100~MeV, then the result
should be expressed in terms of charged particles with the same
(or tighter) kinematic cuts.  Furthermore, if the distributions are
normalized to the total number of events in the sample (as is often the
case) it should be well defined what is meant by an event. For example
an event could be defined as ``any event with at least one charged
particle with $|\eta| < 2.5$ and \pt\ $>$ 100~MeV''. This is a
definition that can easily be reproduced at the generator level.
Normalizing to all events from a $pp$ collision is not well defined
experimentally, as some minimal experimental criterion is required to
detect a collision. The only way to correct distributions for events
with no particles within the acceptance of the detector is to use a
theoretical model or ad hoc extrapolation, which does not give any extra
information from the data, and in fact contaminates the result with the
model that is used to perform the correction.

Another important point for this type of analysis is the definition of
the final state. As previously stressed, the result should be given in
terms of final-state particles only. No claims should be made about the
type of process that produced this final state, as it is not possible to
state unambiguously what the process was.  Historically many such
measurements have been made for non-single-diffractive events.  The reasoning is usually the use of
a double-armed trigger, which selects events based on the presence of
forward particles on both sides of the detector. These triggers are
typically inefficient for single-diffractive events, where one of the
colliding hadrons remains intact, resulting in a void of activity on one
side of the detector.  The distributions are often corrected for the
remaining single-diffractive contribution, using a given Monte Carlo model. These
models are very poorly constrained and unreliable, resulting in model
dependent corrections with systematic uncertainties that are very
difficult to quantify. A preferable approach is to leave the
distributions uncorrected for a certain type of process.

To further suppress diffraction, one would instead add more requirements
(more ``bias'') on the final state, such as the presence of more than
one track in the fiducial region or the absence of large rapidity
gaps in the event.

This particular example raises a more subtle issue, which is correcting
for detector effects such as the trigger described previously. It is
preferable to use a trigger that is as inclusive as possible, and highly
efficient with respect to the event sample definition. It is also highly
desirable to correct for the trigger efficiency using a data-driven
approach. Relying on a model to correct for a trigger that does not
overlap in phase-space with the particles being measured can also lead
to unreliable results, as the prediction of the particle distributions
in the region outside the measurement acceptance is model dependent.
Again, the systematic uncertainties on these corrections can be large
and very difficult to quantify. Alternatively the trigger signal should
be corrected for detector effects and converted into a hadron-level
definition to be included in the event definition discussed above (\eg
at least one charged particle in the region  $3.0 < |\eta| < 5.0$ with
\pt\ $>$ 50 MeV).


\paragraph{Measurement of the $\ell^+\ell^-$ transverse momentum
distribution in $Z^0/\gamma* \rightarrow \ell^+\ell^-$ events}

An interesting measurement for constraining QCD initial-state radiation
predictions is the \pt\ of the $Z^0$ boson.  There are features of such a
measurement that illustrate many of the issues introduced above. The measurement that is actually made is of the di-lepton
($\ell^+\ell^-$) \pt, not the $Z^0$ \pt, as it is the final-state leptons
that are detected. Correcting back to the $Z^0$ \pt\ traditionally
involves two steps, both of which should be avoided. Firstly, QED
radiation of photons from the final-state leptons would have to be
corrected for, as the photons will carry off some fraction of the lepton
and hence the  $Z^0$ \pt. This involves using a model of QED radiation
that is likely to have uncertainties and may neglect interference
between photons emitted in the initial and final states. It may be
argued that the experimental measurement should be comparable to a
theoretical prediction that does not itself include the effects of QED
radiation. Of course the ideal prediction should include all effects,
but in reality this is not always practical. In this case the result
should be given both with and without the QED corrections. Only
presenting results corrected for QED effects implies that the best Monte Carlo
generators must switch off part of the true process in order to compare
to the data that has been corrected with another (potentially less
accurate)  model -- which is an unnecessarily complicated procedure and
in fact reduces the accuracy of the experimental result.


The correction of QED radiation is a subtle issue and
should be treated with some caution.  In the case of final-state
electrons, the energy and hence \pt\ measurement is typically made in a
calorimeter. Any final-state photons that are emitted in a direction
collinear to the electrons may, if they do not convert into $e^+e^-$
pairs, end up in the same calorimeter cell(s) and hence can be
indistinguishable from the electrons. Thus their energy will be
automatically ``clustered'' back into the energy of the electron. Wide-angle
radiation will of course not be included in the energy
measurement.  Depending upon
the detector, it may therefore be preferable to define the electron in
terms of a cone of electromagnetic particles, analogous to a hadronic jet. The size
of this cone might be experiment specific, but it would be well defined
and easily reproducible at the final-state particle level in a
generator.
See the contribution of Buckley et al.\ in \cite{Butterworth:2010ym}
for a detailed discussion of this issue.
Defining the final state in this way is also theoretically more reliable as
the required corrections are smaller.

In the case of final-state muons the momentum is typically measured by a
tracker that measures the curvature of charged particle tracks in a magnetic
field. In this case the photons do not contribute to the particle
momenta and only the di-muon momentum is measured.
However, it should be noted that the effect of enhanced collinear radiation from muons is much less than that from electrons due to their larger mass.

The second correction required to ``measure'' the $Z^0$ \pt\ is for the
contribution from the virtual photon propagator and for $Z^0/\gamma^*$
interference terms. It is not possible to experimentally distinguish
these contributions, although the $Z^0$ contribution can be greatly
enhanced by making a cut on the invariant mass of the lepton pair in a
window around the $Z^0$ boson mass, \eg 66 $< M_{\ell\ell} <$
116~GeV. Again, this definition is unambiguous and reproducible by any
Monte Carlo generator and should therefore be preferred over claims of a process
involving a particular propagator.

Another important issue that can be demonstrated in this example is the
correction for the acceptance of the final-state leptons.  The
measurement can only be performed on leptons that fall within the
acceptance; the result should therefore be presented in terms of leptons
that pass certain kinematic cuts, \eg \pt\ $>$ 25~GeV and $|\eta| <
2.0$. An attempt to correct for the regions of phase space not measured
can result in large extrapolations, using a certain prediction with
its associated limitations and uncertainties. Again, this adds no
information to the measurement and in fact reduces its
accuracy, reliability and usefulness for validation and tuning.


\paragraph{Jet cross sections}

Jets are designed to reflect and be sensitive to short-distance physics,
but they are composed of hadrons.  An example of poor practice which is
fortunately by now almost extinct in current experimental measurements
is the correction of jets to some ``parton-level final state''. While
hadronization and other soft corrections do need to be evaluated in
order to compare to perturbative QCD calculations, they are now
typically applied to the theory rather than data, and in any case the
data are almost invariably presented first in terms of final-state
particles, even if later corrected in such comparisons. The soft QCD
physics used in such corrections is typically the least theoretically
constrained aspect of a given Monte Carlo program. Cases where, for example, the
underlying event is corrected for at the same time as pile-up, or where
even, bizarrely, the data are corrected directly from a detector level
distribution to some ``leading order'' partonic state, are essentially
useless for any theory comparison except possibly to the particular
version of the particular Monte Carlo generator used to make the correction. Note that there are
methods of correcting for, or reducing the effects of, underlying event which
are well defined and model-independent, see for example~\cite{Cacciari:2009dp}.



\mcsubsection{Evaluation of MC-dependent systematic errors}

Even if a measurement is defined in a model-independent way, as
described above, there will still in general be model dependence in the
corrections applied to remove or quantify detector effects, since
detector response is often evaluated using Monte Carlo tools.  In addition it is
often necessary to use Monte Carlo predictions of signal and background rates
or kinematic distributions in order to extract the significance of a
signal or place limits in the absence of a signal.

As a general rule, experimentalists should use all Monte Carlo generators that
simulate the process of interest and potential backgrounds. While it is
not always sufficient to take the difference between the result of two
different generators or tunes as a systematic uncertainty, it is useful
for getting an idea of the limitations of and differences between the
predictions.

Often it is necessary to unfold a distribution, both for detector
inefficiencies and resolutions.  In some cases, such as a low detector
efficiency that is localized in $\phi$, the azimuthal angle around the
beam-pipe, using a Monte Carlo to model the inefficiency will be very reliable.
There is no physical significance to this region, so if the detector is
well modelled and if the generator models the physics well in other
$\phi$ regions, the modelling of the inefficiency will be robust.  In
other cases the underlying physics of the model used to do the
unfolding can have a significant effect on the result.  There are many
different possible techniques for unfolding, which depend to varying
degrees on the underlying model. The dependence on the model can be
reduced by \eg reweighting the Monte Carlo events to match the data for relevant
kinematic distributions.
Note that it is not necessarily only the distribution that is being
unfolded that is relevant for the unfolding and sometimes unfolding in
two dimensions, with a second distribution that is chosen because it
is strongly correlated with the size of the correction, can be useful.

 Residual uncertainties can be determined by
comparing different Monte Carlo models or tunes, as long as the differences
between the tunes are sufficiently large to cover the difference
between Monte Carlo and data in relevant distributions.

A common Monte Carlo systematic is the modelling of a detector response to QCD
jets. In general this depends upon the details of the detector and upon
the fragmentation of the jets (charge-to-neutral ratio, energy
partition, etc). The model dependence of a calibration may be tightly
constrained by requiring that the simulation describes quantities such
as the number of charged particles near jets, or the energy flow around
jets, satisfactorily.

Finally, there are often MC-dependent systematic uncertainties
associated with the modelling of the background and/or signal rates and
kinematic distributions.  Such uncertainties can be evaluated and
minimized in the manner described above, with the constraining
requirements coming from comparisons between data and Monte Carlo in control
regions. In addition, if any relevant measurements from the same or other
experiments provide constraints on the Monte Carlo predictions used to extract
the signal, these should be used in the assessment of the systematic
uncertainties.

In general how to assess MC-dependent systematic uncertainties depends
on the specific analysis. However, it is good practice to consider all
possible constraints from data, whether it be control regions in the
same measurement or different results. In addition the limitations of
the Monte Carlo generator used should be understood, and different generators and tools
should be considered.

% Local Variables:
% mode: LaTeX
% TeX-master: "../mcreview"
% End:
