%!TEX root = huet-1986-pal.tex
%\usepackage[dotinlabels]{titletoc}
%\titlelabel{{\thetitle}.\quad}
%\input{../helpers/psu-plain-titles.tex}
%\input{../helpers/psu-sc-headers.tex}
%\input{../helpers/fix-revtex-12.tex}
%\DeclareSymbolFont{CMlargesymbols}{OMX}{cmex}{m}{n}
%\DeclareMathSymbol{\sum}{\mathop}{CMlargesymbols}{"50}

\usepackage[papersize={6.6in, 10.0in}, left=.5in, right=.5in, top=.6in, bottom=.9in]{geometry}
\linespread{1.05}
\sloppy
\raggedbottom

\pagestyle{plain}
\usepackage{mathpartir}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{tikz-cd}
\usepackage{microtype}
\usepackage{enumitem}
\usepackage{nccmath}
\usetikzlibrary {arrows.meta,bending,positioning}
\usepackage{bussproofs}

\newcommand{\mprime}{\ensuremath{^\prime}}

%\usepackage{fdsymbol}

% these include amsmath and that can cause trouble in older docs.
\input{../helpers/cmrsum}
\input{../helpers/fix-underbrace.tex}

% some nicer symbols
\input{../helpers/matha-symbols.tex}

\usepackage[tiny]{titlesec}
\titleformat{\section}
  {\normalfont\bfseries}
  {\thesection.}
  {.5em}
  {}

\usepackage{cite}

% make sure there is enough TOC for reasonable pdf bookmarks.
\setcounter{tocdepth}{3}
\usepackage{amsthm}

\theoremstyle{definition}


\usepackage[colorlinks=true
,breaklinks=true
,urlcolor=blue
,anchorcolor=blue
,citecolor=blue
,filecolor=blue
,linkcolor=blue
,menucolor=blue
,linktocpage=true]{hyperref}
\hypersetup{
bookmarksopen=true,
bookmarksnumbered=true,
bookmarksopenlevel=10,
pdfencoding=auto, psdextra
}

\date{}
\def\deqd{\mathrel{\cdot\!\!=\!\!\cdot}}
\def\trans{\Phi}
\def\mm{\Vdash}
\def\kxa{\kappa_{x \in A}}
\def\prAB{\pi_{A,B}}
\def\prpAB{\pi'_{A,B}}
\def\pr#1{\pi_{#1}}
\def\prp#1{\pi'_{#1}}
\def\to{\longrightarrow}
\def\xto#1{\xrightarrow{\kern.6em #1 \kern.6em}}
\def\sxto#1{\xrightarrow{\kern.3em #1 \kern.3em}}
\def\ent{\vdash}
\def\eent{\Vdash}
\def\entt{\models}
\def\imp{\shortrightarrow}
\def\iff{\leftrightarrow}
\def\from{\Leftarrow}
\def\impl{\Rightarrow}
\def\union{\cup}
\def\fexp#1#2{#1^{#2}}
\def\fexpBA{\fexp{B}{A}}
\def\inc{\subseteq}
\def\Sub{\mathop{\rm sub}}
\def\dom{\mathop{\rm dom}}
\def\cod{\mathop{\rm cod}}
\def\ker{\mathop{\rm ker}}
\def\Ker{\mathop{\rm Ker}}
\def\cha{\mathop{\rm char}}
\def\id{{\mathrm 1}}
\def\res{\!\upharpoonleft\!}
\def\ffam{\varphi}
\def\comp{\circ}
\def\bbone{\mathbb 1}
\def\one{1}
\def\zeromap{0}
\def\bbzero{{\mathbb O}}
\def\ccc{{c.c.c.}}
\def\ev{\varepsilon}
\def\ebc{\varepsilon_{BC}}
\def\evBA{\varepsilon_{B,A}}
\def\L{\Lambda}
\def\OM{\Omega}
\def\nat{\text{\it nat}}

\def\l{\lambda}
\def\lamC{\l\text{-{\bf{\kern 0.2pt}calc}}}
\def\lx{\lambda_x}
\def\ly{\lambda_y}
\def\lu{\lambda_u}
\def\lv{\lambda_v}
\def\lz{\lambda_z}
\def\lxa{\l_{x \in A}}
\def\subX{\ensuremath{_\text{X}}}
\def\lm#1.#2{\lambda#1.\, #2}
\def\br#1{[\, #1 \, ]}
\def\V{V}
\def\U{U}
\def\D{D}
\def\cart{\text{\bf Cart}}
\def\C{\mathcal C}
\def\S{\mathcal S}
\def\lxy{\l x\, \l y . \,}
\def\lmm#1#2.#3{\l #1\, \l #2 . \, #3}
\def\sss{(*\!*\!*)}
\def\ss{(**)}
\def\ssn{(**_n)}
\def\scop{\S^{\C^{op}}}
\def\sland{\wedge}
\def\PU{\mathcal P U}
\def\P{\mathcal P}
\def\R{\mathcal R}
\def\UU{(U\to U)}
\def\BA{B \to A}
\def\AB{A \to B}
\def\calA{{\cal A}}
\def\calB{{\cal B}}
\def\cI{{I}}
\def\cS{{S}}
\def\cK{{K}}
\def\cIA{\cI_{A}}
\def\cKAB{\cK_{A,B}}
\def\cSABC{\cS_{A,B,C}}
\def\la{\langle}
\def\ra{\rangle}
\def\bracket#1{\la #1 \ra}
\def\app{\mathop{{}^\wr}\kern-.8pt}
\def\schon{Sch\"onfinkel}
\def\nat{\mathbb N}
\def\pf{\varphi}
\def\abs{\mathop{\text{\small[\,]}}}
\def\App{\mathop{\text{\it App}}}
\def\sigmaN{\Sigma^n_N}
\def\comptr{\triangleright}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bes}{\begin{equation*}}
\newcommand{\ees}{\end{equation*}}

\newcommand{\fcat}[1]{{\mathbf {#1}}} 
\newcommand{\Cat}{\fcat{Cat}}
\newcommand{\Prod}{\fcat{Prod}}
\newcommand{\Lang}{\fcat{Lang}}
\newcommand{\grph}{\fcat{Grph}}
\newcommand{\AC}{\fcat{A}}
\newcommand{\CC}{\fcat{Categ}}
\newcommand{\ZC}{\fcat{Z}}
\def\LC{\fcat{L}}
\def\MC{\fcat{M}}
\def\TC{\fcat{T}}
\def\FC{\fcat{F}}
\DeclareMathOperator{\Hom}{{Hom}}
\def\compseq#1#2{#1 \mathbin{;} #2}
\def\Id{\text{\it Id}}
\def\Idl{\text{\it Idl}}
\def\Idr{\text{\it Idr}}
\def\Nil{\text{\it Nil}}
\def\Uni{\text{\it Uni}}
\def\Nill{\text{\it Nil}1}
\def\Unii{\text{\it Uni}1}
\def\Assoc{\text{\it Assoc}}
\def\fst{\mathop{\text{\it fst}}}
\def\snd{\mathop{\text{\it snd}}}
\def\pair#1#2{\la  #1, #2 \ra}
\def\emptypair{\la  \_\,, \_ \ra}

\newcommand{\iso}{\cong}                % Isomorphism
\newcommand{\eqv}{\simeq}               % Equivalence
\newcommand{\sub}{\subseteq}            % Subset (possibly not proper)

\usepackage{amsmath,amsthm}

\theoremstyle{definition}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{defn}[thm]{Definition}
\newtheorem{example}[thm]{Example}
\newtheorem{remark}[thm]{Remark}
\newtheorem{note}[thm]{Note}

% makes "=" with "x" under it
\makeatletter
\DeclareRobustCommand{\eqx}{\mathrel{\mathpalette\eq@{X}}}
\DeclareRobustCommand{\eqlx}{\mathrel{\mathpalette\eq@{x}}}
\DeclareRobustCommand{\eqy}{\mathrel{\mathpalette\eq@{Y}}}
\DeclareRobustCommand{\eqxx}{\mathrel{\mathpalette\eq@{X \union \{x\}}}}
\DeclareRobustCommand{\eqtx}{\mathrel{\mathpalette\eq@{\trans(X)}}}
\newcommand{\eq@}[2]{%
  \vtop{\offinterlineskip
    \ialign{\hfil##\hfil\cr
      $\m@th#1=$\cr % top
      \noalign{\sbox\z@{$\m@th#1\mkern0mu$}\kern-\wd\z@}
      $\m@th\alexey@demote{#1}#2$\cr
    }%
  }%
}
\DeclareRobustCommand{\eqdX}{\mathrel{\mathpalette\eqd@{X}}}
\DeclareRobustCommand{\eqdx}{\mathrel{\mathpalette\eqd@{x}}}
\newcommand{\eqd@}[2]{%
  \vtop{\offinterlineskip
    \ialign{\hfil##\hfil\cr
      $\m@th#1\deqd$\cr % top
      \noalign{\sbox\z@{$\m@th#1\mkern0mu$}\kern-\wd\z@}
      $\m@th\alexey@demote{#1}#2$\cr
    }%
  }%
}
\newcommand{\alexey@demote}[1]{%
  \ifx#1\displaystyle\scriptstyle\else
  \ifx#1\textstyle\scriptstyle\else
  \scriptscriptstyle\fi\fi
}

\makeatother

% footnote tricks
\usepackage{footmisc}
%\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\makeatletter
\let\original@footnotemark\footnotemark
\newcommand{\align@footnotemark}{%
  \ifmeasuring@
    \chardef\@tempfn=\value{footnote}%
    \original@footnotemark
    \setcounter{footnote}{\@tempfn}%
  \else
    \iffirstchoice@
      \original@footnotemark
    \fi
  \fi}
\pretocmd{\start@align}{\let\footnotemark\align@footnotemark}{}{}
\makeatother

\makeatletter
\newcommand*\dotop{\mathpalette\bigcdot@{.6}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\begin{document}

\title{\large Cartesian Closed Categories and Lambda Calculus}
\author{\normalsize G\'erad Huet%
\footnote{This is a remake of the paper {\em Cartesian Closed Categories and Lambda Calculus}
originally published 1986. This version of the paper was typed out in 2025/26 by Pete Su.} 
\\ \\ \small INRIA}


\maketitle

\noindent
The purpose of these notes is to propose an equational framework for the formalization, and
ultimately the mechanization, of categorical reasoning. This framework is explained by way of
example in the axiomatization of cartesian closed categories. The relationship with intuitionistic
sequent calculus and lambda calculus is explained.

\section{The Equational Nature of Category Theory}%

Category theory reasoning proves equality of arrow compositions, as determined by diagrams. The
corresponding equality is given in the model, i.e. in the category under consideration. But the
proofs do not appeal to any particular property of the equality relation, such as extensionality. All
we assume is that equality is a congruence with respect to the arrow operators.

However we are not dealing with simple homogeneous equational theories, but with typed
theories. For instance, every arrow is equipped with its type $f : A \to B$. Here $A$ and $B$ are
expressions denoting objects. These expressions are formed in turn by functorial operations and
constants representing distinguished objects. The object terms can be considered untyped only
within the context of one category. As soon as several categories are concerned, we must type
the objects as well, with sorts representing categories. We thus have implicitly two levels of type
structure.

The main difference between typed theories and untyped ones is that in untyped (homogeneous)
theories one usually assume the domain of discourse to be non-empty. For instance, a first-order
model has a non-empty carrier. Thus a variable always denotes something. In typed theories one
does not usually make this restriction. Thus we do not want to impose the $\Hom$-set $A\to B$ to be
always non-empty for every $A$ and $B$ in the category, in the same way that we want to consider
partial orderings.

This has an unfortunate consequence: the law of substitution of equals for equals does not hold
whenever one substitutes an expression containing a variable universally quantified over an empty
domain by an expression not containing this variable, since we replace something that does not
denote by something which may denote. For instance, 
consider the signature $H : A \to B$, with $T:B$, $F:B$,
and the equations $H(x) = T$ and $H(x) = F$. These equations are valid in the model
where $A$ is the empty set, $H$ is the empty function,
and $B$ is a set of two elements $\{0,1\}$, with $T$
interpreted as $\one$ and $F$ interpreted as $0$. 
In this model we do not have $T= F$. We shall have to
keep this problem in mind in the following.

\subsection{The General Formalism}

We have thus a formalism with four levels. At the first level, we have the alphabet of categories
$\Cat= \{\AC,...,\ZC\}$. At the second level, we have the alphabet of object operators. Every category
is defined over an object alphabet $\Phi$ of operators given with an arity. $\Phi$ is where the (internal)
functors live. We then form sequents by pairs of terms $ M \imp N$, with $M,N \in \TC(\Phi,V)$. $V$ is a set
of variables denoting arbitrary objects of the category. At the third level we have the alphabet $\Sigma$
of arrow operators. An operator from $\Sigma$ is given as an inference rule of the form:
\[
S_1,\dots,S_n \ent S
\]
where the $S_i$’s and $S$ are sequents. Such an operator is polymorphic over the free variables of the
$S_i$’s and $S$, which are supposed to be universally quantified over the inference rule. Such operators
are familiar from logic, either as schematic inference rules, or as (definite) Horn clauses. Of course
the arrows with domain $M$ and codomain $N$ are represented as terms over $\TC(\Sigma,F)$ of type $M \imp N$.
Here $F$ is a set of arrow variables, indexed by sequents $A\imp B$. Finally, at the fourth level we have
the proofs of arrow equalities. The alphabet consists of a set $\cal R$ of conditional rules of the form:
\[
f_{1} =_{S_{1}} g_{1}, \dots, f_{n} =_{S_{n}} g_{n}\, \entt \, f =_{S} g
\]
Here the $f$’s and $g$ are arrow expressions of type $S$, and similarly for the $f_i$’s and $g_i$’s. 
All object and arrow variables appearing in the rule are supposed to be universally 
quantified in front of the rule.

\subsection{A Simplified Formalism}
From now on, we shall assume that we are in one category of discourse which is left implicit. We shall therefore deal only with the last three levels. Furthermore, we shall assume that the only proof rules are:
\begin{align*}
\text {{\it Refl}:}\, f&=_{A \rightarrow B} f \\
\text {{\it Trans}:}\, f&=_{A \rightarrow B} g, \, g=_{A \rightarrow B} h\, 
\models\, f=_{A \rightarrow B} h \\
\text {{\it Sym}:}\, f&=_{A \rightarrow B} g \, \models\, g=_{A \rightarrow B} f
\end{align*}
together with the rules stating that $=$ is a congruence with respect to the operators in $\Sigma$, all other rules being given by simple identities, i.e. by rules with an empty set of premisses ($n=0$).

The further simplification comes from the realization that we are not really obliged to completely specify the types of all variable arrows and equalities, since there is a lot of redundancy. This fact exploits unification, and the following:

\subsubsection*{Meta-theorem}

Let $\Sigma$ be an arbitrary arrow signature, and $E$ be an arbitrary term formed by operators from $\Sigma$ and untyped variables. If there is an assignment of types to the variables of $E$ that makes $E$ well-typed with respect to $\Sigma$, there is a most general such assignment, independent in each variable, and furthermore the resulting type of $E$ is most general. Here ``more general'' means ``has as substitution instance''. We call this assignment, together with the resulting type of $E$, the principal typing of $E$. More generally, for every type sequent $S$, if there is an assignment of types which makes $E$ of a type some instance of $S$, there is a principal such assignment.

The meta-theorem above is most useful. It permits to omit most of the types. When we write
an equation $E= E'$, we shall implicitly refer to the principal typing giving $E$ and $E'$ 
the same type $A\to B$. So from now on, all equations in $\R$ 
are written without type, the types being implicit
from the principality assumption.

\subsection{The initial theory Categ}

We are now ready to start Category Theory. The initial theory $\CC$ has $\Phi = \emptyset$,
and $\Sigma = \{\Id,\compseq{\_}{\_} \}$, given with respective signatures:
\begin{align*}
\Id &: A \to A\\
\compseq{\_}{\_}&: A \to B, B \to C \ent A \to C
\end{align*}
The notation ``$\compseq{\_}{\_}$'' means that we use the infix notation $\compseq{f}{g}$
for the composition of arrows $f$ and $g$. We can read ``$\!f$ then $g$'',
and follow arrow composition along diagrams with semi-colon as
concatenation of the labels. But since more people are accustomed to the standard set-theoretic
composition notation, we shall below use $g\comp f$ as an abbreviation for $\compseq{f}{g}$.

The equations $\R$ of $\CC$ are simply the laws of a monoıd:
\begin{align*}
\Assoc &: (f \comp g) \comp h = f \comp (g \comp h)\\
\Idl &: \Id \comp f = f\\
\Idr &: f \comp \Id = f
\end{align*}

It is to be noted that the identification of the Hom-set symbol $\to$ with the sequent entailment
arrow is not fortuitious. Actually $\Id$ and $\compseq{\_}{\_}$
are well-known inference rules of intuitionistic propositional calculus.
However, the logic is quite poor at this stage: we have no propositional connective
whatsoever, just the basic mechanism for sequent composition, 
stating that entailment is reflexive
and transitive. The rules of $\R$, considered as a left-to-right
rewriting system, define a normal form
on the sequent calculus proofs, i.e. on the arrow expressions

Before we embark on more complicated theories, let us give a recipe on how to cook an equational
presentation from a categorical statement.

\subsection{What the Category Theorists Don’t Say}


Open a standard book on category theory, and consider a typical categorical definition.
It usually reads: ``Mumble, such that the following diagram commutes.''
Similarly, a typical categorical result states: 
``If $\,\text{\it diagram}_1$ and ... and $\text{\it diagram}_n$ commute, then {\it diagram}
commutes.''
The first step in understanding such statements is to determine exactly their universality:
what is exactly quantified, universally or existentially, what depends on what,
what are exactly the parameters of the (frequent) unicity condition.
The next step is to realize that the diagram states conditional
equalities on arrows, and that it is enough to state the equalities
of the inside diagrams in order to get all equalities.

A uniform compilation of such statements as an equational theory proceeds as follows.
First write completely explicitly the quantification prefix of the statement, in two
lines, one for the objects and one for the arrows. Then Skolemize the statement
independently in the first and the second line. That is, for every existentially
quantified variable $x$ following the universally quantified $y_1, \ldots y_n$, introduce
a new $n$-ary operator $X$ and substitute throughout $x$ by $X\left(y_1, \ldots
y_n\right)$. The Skolemization of the object variables determines $\Phi$. The
Skolemization of the second line, together with the types implicit from the diagram
determine $\Sigma$. Finally, following arrows around the inner diagrams determines
$\R$. This concerns the existential part. For the unicity part, proceed as
follows. Let $f$ be the arrow whose unicity is asserted. The existence part provided by
Skolemization an $F\left(g_1, \ldots, g_k\right)$ in place of $f$. Write a supplementary
arrow $h$ on the diagram parallel to $f$, and use the commutation conditions to eliminate
all the $g_i$'s as $G_i(h)$. Add an extra equation $F\left(G_1(h), \ldots,
G_k(h)\right)=h$.

Once we have convinced ourselves that the category theoretic statements and proofs are of
an equational nature, we may ask: why do the category theorists use diagrams at all? The
reason is that diagram chasing is a sophisticated way of doing complex equality reasoning,
using several equations simultaneously, on a shared data structure (the graph underlying
the diagram). So diagrammatic reasoning may be considered a good tool for high level
equational reasoning. On the other hand, equality reasoning techniques such as rewrite
rules analysis is good for mechanical implementation, and this is why we stress here the
equational theories hidden behind the diagrams. 

\bigskip\noindent
{\bf Remark}. Let us finally remark that more
general categorical concepts than the simple universal statements that we shall now
consider may force us to generalize the basic formalism. For instance, more complicated
limit constructions such as pullbacks force the dependence of objects on arrows. The
Skolemization cannot be eﬀected separately on the object and the arrow variables, and we
shall have to place ourselves in a more complicated type theory with dependent types.

\section{Products}

\subsection{The Theory Prod}

We shall apply the recipe above to the definition of product in a category. We recall that a category
possesses a product if for all objects $A$,$B$ there exists an object $C$ and there exist arrows
$\fst$, $\snd$ such that for every object $D$ and all arrows $f$, $g$ 
there exists a unique arrow $h$ such that the
following diagram commutes:

\tikzcdset{arrow style=tikz, diagrams={>=latex}}
\begin{center}
\begin{tikzcd}[column sep=huge, row sep=5.5em]
A \arrow[thick, r, "\fst"] & C  \arrow[thick, r, "\snd"]& B \\
 & \arrow[thick, ul, "f" {xshift=2pt}] D \arrow[thick, u, "h" {right}] 
 \arrow[thick, ur, "g" {below, yshift = -3pt} ] &
\end{tikzcd}
\end{center}
We now get the theory $\Prod$ by enriching $\CC$ as follows. The Skolemization of $C$ gives the
binary functor $\times$, and we write with the infix notation 
$A \times B$ in place of $C$. So now $\Phi$ = $\{\times\}$.
Similarly, we add to $\Sigma$ the following operators,
issued respectively from $\fst$, $\snd$ and $h$:
\begin{align*}
\fst &: A \times B \to A\\
\snd &: A \times B \to B\\
\emptypair &: D\to A \text{ , } D \to B \,\ent\, D \to A \times B
\end{align*}
and we now have the usual diagram:
\tikzcdset{arrow style=tikz, diagrams={>=latex}}
\begin{center}
\begin{tikzcd}[column sep=huge, row sep=5.5em]
A \arrow[thick, r, "\fst"] & A \times B  \arrow[thick, r, "\snd"]& B \\
 & \arrow[thick, ul, "f" {xshift=2pt}] D \arrow[thick, u, "\pair{f}{g}" {right,yshift=8pt}] 
 \arrow[thick, ur, "g" {below, yshift = -3pt} ] &
\end{tikzcd}
\end{center}
The existence of $h$, that is the commutation of the two triangles,
gives two new equations in $\R$:
\begin{align*}
\pi_1 &: \fst \comp\, \pair{f}{g} = f\\
\pi_2 &: \snd \comp\, \pair{f}{g} = g
\end{align*}
Unicity of $h$ gives one last equation:
\[
\text{\it Unipair} : \pair{\,\fst \comp h}{\,\snd \comp h} = h
\]
The arrow part of the functor $\times$ may be defined as a derived operator as follows:
\begin{align*}
\_ \times \_  &: A\to B , \, C \to D \, \ent \, A\times C \to B \times D\\
\text{\it Def } \times &: f \times g = \pair{\,\fst \comp f}{g\comp \, \snd}
\end{align*}

\bigskip\noindent
{\bf Remark}. There is a possible source of confusion in our terminology. We talked about the elements
of $\Phi$ as functors. Actually these are just function symbols denoting object constructors. 
Skolemization of a diagram will determine certain such function symbols,
but there is no guarantee that
there will be a corresponding functor. For instance,
for product, we had to define the arrow part
of $\times$ above, and to verify that indeed it obeys the functorality laws.

\subsection{The Logical Point of View}

From the logical point of view, specifying a product amounts to defining conjunction. 
Read $A \times B$ as $A \sland B$, and recognize $\fst$, $\snd$ and $\pair{-}{-}$ as respectively 
$\sland$-elim-left, $\sland$-elim-right, and $\sland$-intro respectively [7,15,24].

The rules of $\R$ have a computational meaning: they specify how to reduce a proof to its normal form.
Here we may apply known results from the theory of term rewriting systems,
in order to complete $\R$ to a canonical system [17,9].

The Knuth-Bendix completion procedure, when applied to theory {\bf Prod}, generates two additional rewrite rules:

\begin{align*}
\Id &: \pair{\fst}{\snd} = \Id \\
\text{\it DistrPair} &: \pair{f}{g}\comp h = \pair{f \comp h}{g \comp h}
\end{align*}
The resulting system $\R$ is canonical, and can be used to decide the equality
of arrows in the theory {\bf Prod}. Of course, the equations above do not
modify the theory, since they have been obtained by equational reasoning.

Finally, let us note that other presentations of the same theory is possible.
For instance, we could have obtained product as the right adjoint of the
diagonal functor. The unit of this adjunction is the 
{\it duplicator}, which may be defined here as:
$$
D = \pair{\Id}{\Id}
$$
Note that type-checking imposes that the two identities are the same, so that $D_A: A \to A \times A$.
As its name suggests, the duplicator duplicates, in the sense that we can
prove $D \comp f = \pair{f}{f}$.
The co-unit of the adjunction is the pair of projections $(\fst, \snd)$.

\subsection{Finite products}

We say that a category admits all finite products if it admits products and a terminal object.
Equationally, this amounts to enrich the theory {\bf Prod} to a theory {\bf Prods} by adding
a constant $1$ to $\Phi$, a polymorphic constant $\Nil : A \to 1$ to $\Sigma$,
and a unicity equation $\Unii$ to $\R$:
$$
\Unii : h = \Nil.
$$
Note that this does not make the equational theory inconsistent: 
the variable $h$ above is principally typed to $A\to 1$.
However this equation brings up two problems. The first one is the one mentioned
in the beginning of these notes, since variable $h$ appears on the left but not on the right of $\Unii$.
The second problem is that $\Unii$ cannot be considered as a term rewriting rule in the usual sense,
since it would rewrite $\Nil$ to itself and therefore does not satisfy the finite termination criterion.
Note that $\Unii$ entails with the other equations two consequences:

\begin{align*}
\text{\it Zero} &: f \comp \Nil = \Nil\\
\text{{\it Id}1} &: \Id = \Nil
\end{align*}
Again, ${\Id}1$ does not identify every $\Id$ with every $\Nil$,
but only (restoring explicit types) $\Id_1$
with $\Nil_1$. Now it may be checked that $\Unii$ is actually a
consequence of $\text{\it Zero}$
and ${\Id}1$. The rule $\text{\it Zero}$ is a bona fide rewrite rule, 
which leaves the special equality $\text{{\it Id}1}$ to be dealt with in an ad hoc
fashion.

Using operators $\times$ and $1$ we may now construct $n$-tuples of objects, which we shall call contexts.
$1$ is the empty context, and if $E$ is a context of length $n$ and $A$ an object term, 
$E \times A$ is a context of length $n+ 1$. 
We write $|E|$ for the length of a context.
If $C$ is the current set of (representable)
objects, i.e. $T(\Phi,V)$, we denote by $C^*$ be the set of contexts.

If $1 \leq i \leq |E|$, we define the $i^{th}$ component $E_i$ of $E$ recursively, as:
\[
\begin{array}{lcll}
(E \times A)_i  & = &
E_{i-1} &\text{ if } i > 1\\
&& A &\text{ if } i = 1
\end{array}
\]
If $E$ and $E'$ are contexts, we define their concatenation $E@E'$ as a context recursively:
\begin{align*}
E@1 & = E \\
E@(E' \times A) & = (E@E') \times A.
\end{align*}
Similarly, using operators $\la$ , $\ra$ and $\Nil$ we may construct lists, or $n$-tuples of arrows of
some domain $D$. The empty arrow list is $\Nil$, of length $0$ and if $L : D \to E$ is an arrow list of
length $n$ then $\pair{L}{f} : D \to E \times A$ is an arrow list of length $n+ 1$,
for every $f : D\to A$. Finally,
for every object list and every $n$, with $1 \leq n \leq |E|$ we define recursively the projection arrow
$\pi_{E} (n) : E \to E_n$, as:
\[
\begin{array}{lcll}
\pi_{E} (n) & =&  
\pi_{E'}(n)\comp \fst & \text { if } n > 1 \text{ and } E = E' \times A\\
&& \snd & \text{ if } n= 1
\end{array}
\]

\section{CCC}

\subsection{The Theory Exp}

We obtain the theory {\bf Exp} by enriching the theory {\bf Prods} as follows. First, we add a binary
operator $\impl$ to $\Phi$. Next we add two operators to $\Sigma$, the constant ${\App}$
(application) and the unary operator $\abs$ (abstraction):
\begin{align*}
{\App} & : (B \impl C) \times B \to C\\
\abs &: A \times B \to C \ent A\to (B \impl C)
\end{align*}
Finally, we add the following equations to $\R$:
\begin{align*}
{\text{\it ExAbs}} & :\, \App \comp (\abs f \times \Id) = f\\
{\text{\it UniAbs}} &:\, \abs(\App \comp (f \times \Id)) = f
\end{align*}
As before, this equational theory may be mechanically generated from the following diagram:
\begin{center}
\begin{tikzcd}[column sep=large,row sep=7em]
 B \impl C \times B  \arrow[thick, r, "\App"]& C \\
 A  \arrow[thick, u, shift left=7.5, "\abs f" {right}]  \times B \qquad \arrow[thick, u, "\Id" {right}] 
 \arrow[thick, ur, "f" {below, yshift = -3pt} ] &
\end{tikzcd}
\end{center}
The logical point of view is here that $\impl$ is the (intuitionistic) implication. The operator $\App$
is $\impl$-introduction. It plays the role of the Modus Ponens inference rule (although here it is a
constant, and not a binary operator). Abstraction is $\impl$-elimination, and plays somewhat the role
of the deduction theorem.

Let us give a few equational consequences of the theory {\bf Exp}:
\begin{align*}
{\text{\it IdExp}} & : \abs \App = \Id\\
{\text{\it Red}}_1 & : \App \comp \la \abs f \comp y, x\ra = f\comp\la y, x\ra \\
{\text{\it Red}} & : \App \comp \la\abs f, x \ra = f\comp\la \Id , x\ra \\
{\text{\it DistrAbs}} & : \abs f \comp g = \abs(f \comp (g \times \Id ))
\end{align*}
We can also show that abstraction is a bijection between the arrows of A×B →C and those
of $A \to B \impl C$, with inverse:
$$
{\abs}^{-1}\, f = \App \comp \la f \times \Id \ra
$$
Thus we could have presented {\bf Exp} in terms of $\abs$ and ${\abs}^{-1}$, and defined $\App$
as ${\abs}^{-1}\Id$. This corresponds to the fact that we could have rather axiomatized 
exponentiation by an adjunction to the product, whose co-unit is $\App$ (the unit being $\abs \Id$ ).

Finally, we define the arrow part of the functor $\impl$ (which is contravariant in its first argument)
as:
$$
f \impl g = \abs(g\comp \App \comp (\Id \times f)).
$$

\section{Lambda-calculus}

Sometimes $\abs$ is called ``Curryfication'', in honor of Curry. In fact there is an important relation
between combinatory logic and CCC’s, which we shall exhibit on $\l$-calculus.

\subsection{The $\l$-terms}

We assume that the current theory is an extension of {\bf Exp}.
We define recursively a relation $E \ent M : A$, read ``$M$ is a term of type $A$ in the context $E$'',
where $A \in \C$ and $E \in \C^*$, as follows:
\begin{align*}
\text{\bf Variable} &: \text{If } 1 \leq n \leq |E| \text{ then } E\ent n: E_n\\
\text{\bf Abstraction} &: \text{If } E \times A \ent M : B \text{ then } E \ent [A]M : A \impl B\\
\text{\bf Application} &: \text{If } E \ent M: A \impl B \text{ and } E \ent N
\text{ then } E \ent (M N) : B
\end{align*}
Thus a term may be a natural number, or may be of the form $[A]M$ with $A$ an object and $M$
a term, or may be of the form $(M N)$ with $M, N$ two terms.

We thus obtain $\l$-terms typed with objects of the CCC currently axiomatized. Variables are
coded as de Bruijn's indexes [2]. i.e. as integers denoting their reference depth (distance in the
tree to their binder). This representation avoids all the renaming problems associated with actual
names ($\alpha$ conversion), but we shall use such names whenever we give examples of terms. For
instance, the term $[A] (1 [B] (1 2))$ shall be presented under a concrete representation such as
$[x : A] (x [y : B] (y x))$. In Church's original notation, the left bracket was a $\l$ and the right
bracket a dot, and typing was indicated by superscripting, like: $\l x^A\cdot (x \l y^B \cdot (y x))$.

Note that the relation $E \ent M : A$ is functional, in that $A$ is uniquely determined from $E$ and $M$.
Thus the definition above may be interpreted as the recursive definition of a function $A = \tau_E(M)$.

\subsection{A Translation From $\l$-terms to CCC Arrows}

We shall now show how to translate $\l$-terms to CCC arrows. More precisely, to every term $M$ such
that $E \ent M : A$ we associate an arrow $F_E(M) : E \to A$ as follows:
\begin{align*}
F_E (n) &= \pi_E (n)\\
F_E ([A]M) &= \abs F_{E \times A}(M)\\
F_E ((M\, N)) &= \App \comp \la F_E (M) , F_E (N) \ra
\end{align*}
It can be easily proved by induction that $F_E(M)$ is a well-typed arrow expression.

\medskip
\noindent
{\bf Example}. The closed term $M = [f : \nat \impl \nat ][x : \nat](f\, (f\, x))$ of type $A = (\nat \impl
\nat) \impl (\nat\impl \nat)$ in the empty context $E = 1$, gets translated to:
$$
F_E (M) = \abs \abs (\App\comp \la \snd \comp \fst, \App \comp \la \snd \comp \fst, \snd\ra \ra) : 1 \to A.
$$

\subsection{The syntactic theory of terms}

The advantage of the name-free terms is that we have no name conflict. The disadvantage is that
we have to explicate relocation operations for terms containing free variables. For instance, let
us define for every term $M$ the term $M^{+n}$ obtained in incrementing its free variables by $n$. Let
$M^{+n} = R^0_{n}(M)$, with:
\[
\begin{array}{rcll}
R^i_n(k) & = & k & \text{ if } k \leq i\nonumber\\
&& k + n & \text{ if } k > i\nonumber\\
R^i_n([A]M) &=& [A]R^{i+1}_n (M)\nonumber\\
R^i_n((M N)) &=& (R^i_n(M) R^i_n(N)).\nonumber
\end{array}
\]
The reader will check that $E\ent M : A$ if and only if $E@E' \ent M^{+n} : A$, where $E'$
is an arbitrary context of length $n$.

We now define substitution to free variables. Let $E\times A \ent M : B$, and $E\ent N : A$. We shall
define a term $M\{N\}$, and show that $E \ent M\{N\}: B$. First we define recursively:
\[
\begin{array}{rcll}
\sigmaN & = & k + 1 & \text{ if } k < n \\
 &  & N^{+n} & \text{ if } k = n \\
 &  & k  & \text{ if } k > n \\
\sigmaN([A]M) & = & [A]\Sigma^{n}_{n+1} (M)\\
\sigmaN(M\, M') &=& (\sigmaN(M) \, \sigmaN(M') )
\end{array}
\]
It is easy to show that substitution preserves the types,
in the sense that $(E \times A)@E' \ent M : B$
and $E \ent N : A$ implies $E@E' \ent \sigmaN(M) : B$ with
$n = |E'|$.

Now we define $M{N} = \Sigma^0_N(M)$
and we get that $\tau_E (M\{N\}) = \tau_{E \times A}(M)$,
with $A= \tau_E (N)$.

We are now ready to define the computation relation $\comptr$ as follows:
\begin{align*}
([A]M\, N) & \comptr M\{N\}\\
M \comptr M' & \impl [A]M \comptr [A]M'
\end{align*}




















