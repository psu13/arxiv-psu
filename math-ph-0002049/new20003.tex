\section{Kolmogorov and Ito}
A {\em stochastic process} over a set $T$ is a family $\{X_t,t\in T\}$
of random variables on a measure space $(\Omega,{\cal B},\mu)$.
We might have $T=\{0,1,2\ldots\}$, or $T={\bf R}^+$, when we interpret
$t$ as time. From the frequentist point of view, we can observe
$X_{t_1},X_{t_2},\ldots X_{t_N}$ at finitely many points of time.
In this way, we can test any a model as to what the joint distribution
of these r.v. is.

Kolmogorov's existence theorem says that a family of joint (cumulative)
distributions
$F_{1,2\ldots n}(x_1,\ldots,x_n)$, given for all finite subsets of $T$, is
the set of joint distributions of a stochastic process over $T$ if and only
if the {\em consistency conditions} hold. Thus, (the hatted variable is omitted):
\begin{enumerate}
\item For any permutation $\pi$ of $(1,2,\ldots,n)$, we have
\[F_{1,\ldots n}(x_1,\ldots,x_n)=F_{\pi(1),\ldots,\pi(n)}(x_{\pi(1)},
\ldots,x_{\pi(n)})\]
\item For any $j$, we have
\[ F_{1,\ldots,n}(x_1,\ldots,x_j=\infty,x_{j+1},\ldots,x_n)=F_{1,\ldots,
\hat{j},\ldots,n}(x_1,\ldots,\hat{x_j},\ldots,x_n).\]
\end{enumerate}

If these hold, he shows that the sample space $\Omega$ may be taken to
be ${\bf R}^T$, an enormous space (of all functions $\omega$ of $t$); the
r. v. $X_t$ is then the function $X_t(\omega)=\omega(t)$.
He proved the existence of
a measure $\mu$, which reproduces the given joint distributions; the
$\sigma$-tribe ${\cal B}$ has the following structure. 
Let ${\cal B}_t$ be the smallest $\sigma$-tribe such that all $X_s$, for
$s\leq t$, are measurable; then this is an increasing family of
$\sigma$-tribes, called a filtration. Then ${\cal B}$ is the smallest
$\sigma$-tribe containing all the ${\cal B}_t$.

Apply this to the Brownian paths, and the
measures defined by a finite set of gates as in the last section;
this proves
that there is a probability theory underlying the finite joint
distributions. However, it does not prove Wiener's theorem, in that the
sample space obtained by the Kolmogorov construction is the huge set of all
functions of time. It is then a hard problem to show that the subset
of continuous functions has measure 1. This fact is very important
for specialists in Brownian motion, but is not a general feature of
processes covered by Kolmogorov's theorem, and is not needed to construct
the usual $L^p$ spaces of functional analysis.
Without Wiener's version
we lose the power of the path-wise methods, and also lots of intuition.
The modern method is to get the cow off the ice using Kolmogorov, and
supplement it with further estimates, on tightness and radonifying maps,
if we need to find smaller carrier spaces for the measure
\cite{Gross,Schwartz}.
After Kolmogorov's treatise, the subject could develop ``in the usual
professional mathematical way'', to use Segal's phrase. That is, theorems
could be stated and proved, and then sharpened. The most important of these
were the laws of large numbers, the zero-one laws, the central limit
theorems,
the theory of large deviations, the classification of all processes with
independent increments, martingales, and stochastic integration.


The conditional
expectation $E_t:=E[\bullet|{\cal B}_t]$ takes a random variable in
$L^2(\Omega,{\cal B},\mu)$ into one in $L^2(\Omega,{\cal B}_t,\mu)$;
since it is the identity on the latter space, and is Hermitian,
it must be the orthogonal projection onto $L^2(\Omega,{\cal B}_t,\mu)$.
None of these ideas depends on which version of the sample space we have.


The concept of conditional expectation can be extended to integrable
r.v., thus:
\begin{definition}
Let $(\Omega,{\cal B},\mu)$ be a probability space, and let ${\cal B}_0$ be
a sub-$\sigma$-tribe of ${\cal B}$. Let $X$ be a random variable with
$E[X]<\infty$. Then there exists a ${\cal B}_0$-measurable r.v. $Y$,
written $E[X|{\cal B}_0]$, such that for each set $B\in{\cal B}_0$ we have
\begin{equation}
\int_BY\,d\mu=\int_BX\,d\mu
\end{equation}
Further, if $\hat{Y}$ is another r.v. with these properties, then
$\hat{Y}=Y$ almost everywhere.
\end{definition}
See \cite{Williams} for a proof, and other things.

A martingale is a stochastic process $X_t$ on $(\Omega,{\cal B}_{t\geq 0}
,\mu)$ such that $X_t$ is integrable, and
\begin{equation}
E[X_t|X_s]=E[X_s]\mbox{ for all }t\geq s.
\label{martingale}
\end{equation}

A martingale is a fair game.
For example, consider the independent tosses of a fair coin,
and let $X_n=H_n-T_n$, where $H_n$ is the number of heads and $T_n$ is
the number of tails at the $n^{\rm th}$ toss. Let $S_N=\sum_{j=1}^NX_j$.
Then $S_N$ is a martingale \cite{Grimmett}, p 202.

There are four concepts of convergence of a sequence $\{X_n\}$
to $X$ in the space of random variables on a probability space $(\Omega,
{\cal B},\mu)$.
\begin{enumerate}
\item We say $X_n\rightarrow X$ {\em almost surely} (or, almost
everywhere) if
\[\mu\{\omega:X_n(\omega)\rightarrow X(\omega)\}=1.\]
\item We say $X_n\rightarrow X\mbox{ in }\|\bullet\|_r$ if
\[\|X_n-X\|_r\rightarrow0\mbox{ as }n\rightarrow\infty.\]
\item We say that $X_n\rightarrow X$ in probability if
\[\mu\{\omega:|X_n(\omega)-X(\omega)|>\epsilon\}\rightarrow0 \mbox{ as }
n\rightarrow\infty\;\;\mbox{for all }\epsilon>0.\]
\item We say $X_n\rightarrow X$ in law if
\[\mu\{\omega:X_n\leq x\}\rightarrow\mu\{\omega:X\leq x\}\mbox{ for all }
x\mbox{ at which }F_X(x):=\mu\{X\leq x\}\]
is continuous.
\end{enumerate}
These concepts are not equivalent; (1) and (2) are not comparable, but
(1) or (2) imply (3), which
implies (4) \cite{Grimmett}. Convergence in law can be
related to convergence of the characteristic functions of $X_n$ to that of
$X$; we see that if $X_n$ converges to $X$ in law implies that $X_n$
also converges to $Y$ in law if $Y$ has the same distribution as $X$.
This shows that convergence in law in a very feeble concept.
The four concepts of convergence do not depend
on the version of sample space adopted, and so are the same whether we use
Wiener space or Kolmogorov's abstract construction. 

For a given $\mu$, we can complete the $\sigma$-tribe ${\cal B}$ to include
all subsets of sets of $\mu$-measure zero; then the events that can happen
are described by the quotient $\sigma$-tribe, in which events which differ
by a set of measure zero are identified. This idea is not wise when we are
interested in measures with different sets of zero measure, as happens when
we condition a Wiener path to pass through a given point. The Dirac measure
on ${\bf R}$ is a simple example of the trouble we get into. If two
measures $\mu_1,\mu_2$ have the same sets of zero measure in $(\Omega,{\cal
B})$, we say that they are equivalent. If $\mu_1(B)=0$ whenever $\mu_2(B)=0$
we say that $\mu_1$ is absolutely continuous relative to $\mu_2$; in that
case there exists a function $w\in L^1(\Omega,{\cal B},\mu_2)$ such that
$\mu_1(B)=\int_B\rho(\omega)d\mu_2$ for all $B\in{\cal B}$. We write
$w=d\mu_1/d\mu_2$, the Radon-Nikodym derivative. This is the abstract
version of eq.~(\ref{change}). We shall be interested in other measures,
singular relative to a given one. Then the best formalism is to start with
an abelian $C^*$-algebra ${\cal A}$ and consider its states.

Estimation is assisted by the law of large numbers.
Let $X$ be a random variable on a probability space, whose mean $\eta$ we
wish to find, making use of a random experiment which is believed to be
well modelled by $X$. We set up a sequence of independent copies $X_n$
of $X$, and
consider the stochastic process $\{X_n\}$ on e.g. the probability space
constructed by the theorem of Kolmogorov. The {\em strong law of
large numbers} says that if $E(X)=\eta$ and $E(X^2)<\infty$, then putting
$S_n=\sum_{j=1}^N S_j$ we have
\[S_N/N\rightarrow \eta I \mbox{ in }\|\bullet
\|_2.\]
If $E|X|<\infty$, we get almost sure convergence. These are necessary and
sufficient conditions.
Weaker conditions ensure that the sum converges in probability
\cite{Grimmett}. This is called the weak law.
Note that the meaning of convergence uses the measure on the Kolmogorov space,
so for almost all sequences, randomly chosen, we get convergence to the mean.
It does not say how fast the convergence is.
For example if $X_n$ is the number of heads minus the number of tails,
at the $n^{\rm th}$ toss of a fair coin, then $S_N$ is the number of heads in $N$
tosses minus the number of tails, and $S_N/N$ converges almost surely to
zero. If we know that $S_m\neq 0$ after $m$ results, the law does not say
that the bias evens out in the long run.
$S_n$ is a martingale, and its expected value for $N>m$ is its present
value $S_m$. It is $S_N/N$, which converges; the bias at time
$m$ gets divided by $N$, and so goes away for large $N$.


Another famous limit law is the central limit theorem; if the standard
deviation $X$ is 1 and the mean is zero, then one can show that
\[S_n/(\surd n)\rightarrow N(0,1)\mbox{ in law}.\]
Versions of this were known to Bernouilli and Gauss, if we assume that the
moment-generating function exists. It explains the ubiquity of the normal
distribution; many random processes are the sums of small and independent
random things, and so tend to be Gaussian.
The theory of large deviations tells us something about the rate of
convergence of $S_n$; this stuff is deeper \cite{Varadhan,Donsker,Lewis,Stroock2}.
There is also a large body of work on sums of nearly independent random
variables, and also on the cases where the variances are not all equal.

Doob proved that martingales often converge; e. g.,
\begin{theorem}
If $\{S_n\}$ is a martingale with $E(S_n^2)<M<\infty$ for some $M$ and all
$n$, then there exists a random variable $S$ such that $S_n\rightarrow S$
almost surely.
\end{theorem}

Consider now a process $(X_t,\Omega,{\cal B}_{t\geq 0},\mu)$ in continuous
time with independent increments; that is, $X_t-X_s$ is independent of
$X_r$ for $r<s<t$. Since we can write $X_t-X_s$ as the sum of more and more
independent differences, we might expect that $X_t-X_s$ must be Gaussian,
by the central limit theorem. However, this is not the case since
the distributions of the difference $X_t-X_s$ might change as the interval
is made smaller.
This question led Levy to characterise all processes that are
stationary and have independent increments. This can be done by showing
that the characteristic function
\[ C(\lambda):=E[\exp{i(X_t-X_s)\lambda}]\]
should not only be of positive type, but so should any fractional power.
Such a function is called {\em infinitely divisible}, and so is the
corresponding random variable. The necessity is easy to see; we can write
$X_t-X_s$ as the sum of $N$ identical and independent random
variables, namely, the increments for time intervals $(t-s)/N$; then the
characteristic function of this sum is the product of the $N$
characteristic functions (which are all equal, by stationarity) of
these increments, and so C has an $N^{\rm th}$ root that is of positive type.
This condition is also sufficient, to which we shall return.
The characteristic function of the Gaussian is infinitely divisible, and
so is that for the Poisson distribution. This means that Gaussian and Poisson
processes with independent increments exist. Levy found that by mixing these
he got some new processes (Levy processes), and he found
the most general form of the characteristic function, which is
\begin{equation}
\log C(\lambda)=-a\lambda^2+ib\lambda+\int d\sigma(\alpha)
[e^{i\alpha\lambda}-(1+i\alpha\lambda)Z(\alpha)]
\label{Levy}
\end{equation}
where $a\geq0$, $b$ is real, $d\sigma(\alpha)\geq0$ obeys $\int_{-1}^1
\alpha^2d\sigma(\alpha)<\infty$. There are some
further conditions on the weight $d\sigma$ at
infinity \cite{GelfandV}. If $\sigma=0$ we get the Gaussian, and if
$\sigma$ has a discontinuity, we get a Poisson process. These can be
understood in terms of Hilbert space cohomology of ${\bf R}$, as in
\S(5).

During this period, physicists and engineers studied stochastic differential
equations, similar to the Langevin equation. Often the random force was
chosen to be the derivative of Brownian motion, called white noise. Since
$B_t$ is at best continuous, this work lacked rigour, and remained
poorly defined even after appeal to Dirac's generalised concept of
function. This sorry state of affairs was cleared up by Ito.

Let $W(t)$ be Brownian motion starting at zero. At first sight, an equation
for an unknown $X(t)$ similar to the Langevin equation, of the form
eq.~(\ref{Langevin})
\[\frac{dX_t}{dt}=a(t)+b\frac{dW_t}{dt}, \mbox{ for almost all }\omega\]
makes no sense, since for almost all $\omega\in\Omega$, $W(t)$ is not
differentiable. The equation does make sense if written in the form:
find a family of random variables, $\{X(t)\}$, such that
for a given initial random variable $X(0)$, the r. v.
$X(t)-X(0)-\int_0^ta(s)ds$ 
is the known r.v. $W_t$ for almost all $\omega$. This does not prove that
there is such a process, but it is does make sense. For the more general
case when $a,b$ depend on the unknown $X(t)$, the integral form is
\begin{equation}
X(t)-X(0)=\int_0^ta(s,X(s))ds+\int_0^tb(s,X(s))dW(s).
\label{Itoequation}
\end{equation}
The last expression, called a stochastic integral, looks like a Stieltjes
integral, but the needed condition of bounded variation on $W(s)$ do not
hold.
Solve the equation by iteration (Picard's method); we see that
at each stage, the approximation to $X(t)$ is a function of $W(s)$ only for
$s\leq t$. So it would appear that we need only
give a meaning to the stochastic integral for the cases where $X(t)$
is a function of $W(s)$ for $s\leq t$, and so the same holds for $b(t,X(t))$.
This can be neatly put in terms of the filtration ${\cal B}_t$ generated by
the Wiener process: for all $t\geq 0$, $X(t)$ and so $b(t,X(t))$
is measurable relative to the $\sigma$-tribe
${\cal B}_t$. This makes sense physically; it says that
we can know the present configuration $X(t)$ if we know the initial
configuration $X(0)$ and the outcomes of all the randomness, $W_s,\;s\leq
t$, so far. A random function of time, $f$ is said to be {\em adapted to
the filtration} ${\cal B}_t$ if $f(t)$ is ${\cal B}_t$-measurable for all
$t\geq0$. 

Let $f(t)$ be an adapted process in the time interval $0\leq t\leq T$,
which is {\em simple}: that is there is a finite partition $0=t_0,t_1,
\ldots<t_n=T$ such that $f(t)=f_j$ for $t_{j-1}\leq t<t_j$ for all
integers $j\in(1,\ldots,N)$. Here, $f_j$ is a random variable independent
of time, and equality of random variables means almost everywhere.
Following Ito, we can define the stochastic integral of an adapted simple
function $f$ to be the random variable
\begin{equation}
\int_0^Tf(t)dW_t:=\sum_jf_j(W_{t_{j+1}}-W_{t_j}).
\end{equation}
Note that the increment $dW$ is in the future of the random variable
$f_j$ that multiplies it. The mapping, $f\mapsto\int_0^Tf(t)dW_t$ takes
the linear space of simple adapted functions into the space
of random variables, and is clearly a linear map. The brilliant
remark of Ito is then that the following identity, called Ito's isometry,
holds:
\begin{equation}
E[|\int_0^Tf(t)dW_t|^2]=\int_0^TE[|f(t)|^2]dt
\label{Ito}
\end{equation}
Proof:
\begin{eqnarray*}
E[|\int_0^Tf(t)dW_t|^2]&=&\sum_i\sum_jE[f_i(W_{t_{i+1}}-W_{t_i})f_j(W_{t_{
j+1}}-W_{t_j})]\\
&=&\sum_iE[|f_i|^2(W_{t_{i+1}}-W_{t_i})^2\\
&+&2\sum_{i<j}f_if_j(W_{t_{i+1}}-
W_{t_i})(W_{t_{j+1}}-W_{t_j})].
\end{eqnarray*}
Now, the future increment $W_{t_{i+1}}-W_{t_i}$ is independent of $f_i$,
which is adapted, i.e. a function of earlier $W(s)$. So the expectation
value in the first term factorises:
\begin{eqnarray*}
E[|f_i|^2(W_{t_{i+1}}-W_{t_i})^2]&=&E[|f_i|^2]E[(W_{t{i+1}}-W_{t_i})^2]\\
&=&E[f_i|^2](t_{i+1}-t_i),
\end{eqnarray*}
by the property of Brownian motion. This gives the desired term in
eq.~(\ref{Ito}). It remains to show that the remaining double sum vanishes.
This is true, because the factor $(W_{t_{j+1}}-W_{t_j})$ for $j>i$ is
independent of the remaining factors $f_if_j(W_{t_{i+1}}-W_{t_i})$ and so
the expectation of the product is the product of the expectations;
but the expectation of the future increment of $W_t$
is zero.\hspace{\fill}$\Box$

Ito's isometry is a mapping from the set of simple adapted processes
to random variables; by a simple theorem of normed spaces, it
can be extended by continuity to a linear isometry
(unitary transformation) between the completions of both sides in the
norms given. The completion of simple functions in the norm
\begin{equation}
\|f\|^2=\int_0^TE[|f(t)|^2]dt
\end{equation}
is the space of processes such that $E[|f|^2]$ is Lebesgue integrable; so
Ito can define the stochastic, or Ito integral, of all processes with this
property; it is the limit in this norm of simple adapted processes
approximating it. Naturally, we must prove that the adapted simple processes
are $L^2$-dense in the square-integrable adapted processes; this is not
difficult, since the projection $E_t$ is a bounded operator and maps onto
the space of ${\cal B}_t$-adapted square-integrable processes.

We can now give a meaning to the question, do there exist solutions to the
stochastic differential equation
\begin{equation}
\frac{dX_t}{dt}=a(X_t,t)+b(X_t,t)\frac{dW_t}{dt}?
\label{sde}
\end{equation}
We say the a process $X_t$ satisfies this equation if, on substituting
$X_s$ in the integrals in eq.~(\ref{Itoequation}) we get back $X_t-X_0$.
 
For a wide class of functions $a$ and $b$ of two variables we can then
get a convergent iterated approximation, the Picard series, which converges
to a process $X_t$ obeying the (integral form of) the stochastic
differential equation. This holds for example if $a(x,y)$ is
uniformly Lipschitz in $y$ in a region, and $b(x,y)$ is uniformly elliptic
in $y$ and measurable in $x,y$.
This result can be improved and generalised, so
that vector-valued stochastic processes can be studied, and the noise
can be of a much more general martingale than $W_t$.
This can be reworded as a ``martingale problem'' \cite{Stroock}.


The converse to Ito integration should be a form of differentiation:
it is called (Ito) stochastic differentiation; we may say that the process
$f(W_t,t)$ is the stochastic derivative of $\int_0^t f(W_s,s)\,dW_s$.
The Ito integral is always a martingale, and every martingale is
a stochastic integral, and so has a stochastic derivative, namely the
integrand in its representation as an Ito integral. One can show that
this is unique. It is interesting to form the repeated stochastic integrals
\begin{eqnarray*}
W_t&=&\int_0^tdW_s\\
:W_t^2:=W_t^2-t&=&2\int_0^tW_sdW_s\\
:W_t^3:&=&3\int_0^t:W_s^2:dW_s\\
\ldots& &\ldots
\end{eqnarray*}
in which the Wick ordered (Hermite polynomials) occurring in the Wiener chaos
are the successive stochastic integrals. They are all contained
in the exponential martingale $e^{\lambda X_t-\frac{1}{2}\lambda^2t}$.
The second one illustrates the Doob-Meyer decomposition: $W_t^2$
is a submartingale, and is written as the sum of a martingale, $:W_t^2:$,
and an increasing function, $t$ of bounded variation.

Manipulation of stochastic integration can be summarised
by the Ito multiplication table: keep all differentials in $dt$
up to first order, using $dt.dW=0$ and $dW.dW=dt$. From this, we can get
the important relation between a certain parabolic partial differential
equations known as Kolmogorov's forward equation, and the corresponding 
stochastic differential equation. Suppose that
$X_t$ satisfies the stochastic differential equation eq.~(\ref{sde}),
with initial r.v. equal to $X_0$, which has law $p(x)$.
Let $p(x,t)$ be the law of $X_t$; then it can be shown that
$p(x,t)$ is smooth and satisfies the parabolic equation
\begin{equation}
\frac{\partial p}{\partial t}=\frac{1}{2}\frac{\partial}{\partial x}\left
(b(x,t)^2\frac{\partial p}{\partial x}\right)+\frac{\partial}{\partial x}
(a(x,t)p),
\label{63}
\end{equation}
with initial condition $p(x,0)=p(x)$.
To see why this is, we note that if $f(x)$ is any smooth function,
we can apply Ito's lemma to the random process $f(X_t)$. We
recover $\int p(x,t)f(x)\,dx$ as $E[f(X_t)|X_t=x]$.
We now expand $f(X_{t+dt})$ in a Taylor series about $X_t$ up to
second order in $dW$:
\begin{equation}
f(X_{t+dt})=f(X_t)+\frac{\partial f}{\partial x}dX+\frac{1}{2}
\frac{\partial^2f}{\partial x^2}(dX)^2.
\label{eq}
\end{equation}
Eq.~(\ref{sde}) tells us that $(dX_t)^2=b^2\,dt$ and $dX=a\,dt +b\,dW$.
Here, $dW$ is the forward difference. Then
the expectation  vanishes: $E[f^\prime b\,dW|X_t-x]=E[f^\prime b|X_t=x]
E[dW|X_t=x]=0$,
since $dW$ is independent of $f^\prime b$ at time $t$,
and has zero expectation. So, taking the conditional
expectation of eq.~(\ref{eq}),
\begin{equation}
E[f(X_{t+dt}-f(X_t)|X_t=x]=E[\frac{\partial f}{\partial x}a]\,dt+
\frac{1}{2}E[b^2f^{\prime\prime}|X_t=x]\,dt.
\end{equation}
Since $a,b,f,f^\prime,f^{\prime\prime}$ are functions of $X_t,t$
they become sure functions, evaluated at $x$
under the conditioning; thus we get the equation for the increment
$f(x,t+dt):=E[f(X_{t+dt}|X_t=x]$:
\[(f(x,t+dt)-f(x))/dt:={\cal L}f=
(1/2)b(x,t)^2f^{\prime\prime}+a(x,t)f^\prime.\]
This is Kolmogorov's {\em backward} equation, which applies to the
dynamics of the process. To get the dynamics of the probability density,
we take the dual operator ${\cal L}^*$, defined by 
\[ \int p(x,t){\cal L}f(x,t)\,dx=\int{\cal L}^*p(x,t)f(x,t)dx\]
which on integration by parts, and discarding the boundary term at $\infty$
gives
\[{\cal L}^*f:=\frac{1}{2}\frac{\partial}{\partial x}\left(b(x,t)^2\frac
{\partial}{\partial x}f\right)+\frac{\partial}{\partial x}\left(a(x,t)f
\right).\]
Since $f$ was arbitrary, we see that $p(x,t)$ satisfies the forward
equation in the weak sense (after smoothing with a test-function $f$).
It is known from the theory of elliptic regularity, that any weak
solution is a strong solution. If $a$ and $b$ are constants, we arrive at
the Smoluchowski equation, and the continuum version of (\ref{KBE}):
\[p(x,t)=E[p(X_t,0)|X(0)=x].\]
This representation for the solution of the pde gives an immediate proof
that the solution remains non-negative if the initial condition is
non-negative, since $p(X_t,0)\geq 0$; also, one sees that the time-evolution must be a contraction
in the $L^\infty$-norm, and the $L^2$-norm as the conditional expectation
is a projection.

Sometimes, we can rewrite the solution $X_t$ in terms of time-translation
$\omega\mapsto\omega T_t$ if we modify the measure \cite{Williams2}.
Suppose $\mu^\prime$
is absolutely continuous relative to $\mu$. Then there exists an adapted
process $u(t)$ in $(\Omega,{\cal B},\mu)$ such that
\begin{equation}
dX_t=dW_t+u(t)dt,\hspace{.3in}X_0=0,
\label{CM}
\end{equation}
has a weak solution $X_t$ whose law is the same as $Y_t(\omega):=\omega(t)$
as a r. v. on $(\Omega,{\cal B},\mu^\prime)$. Then the Radon-Nikodym
derivative is
\begin{equation}
d\mu^\prime/d\mu^=\exp\left[\int_0^tu(s)dX_s-(1/2)\int_0^t\|u(s)\|^2ds\right].
\label{Girsanov}
\end{equation}
Conversely, if $u$ is such that the r. h. s. of (\ref{Girsanov}) has Wiener
expectation 1, (as will happen if $u$ is bounded), then there exists
an absolutely continuous measure $\mu^\prime$ given by (\ref{Girsanov}),
such that $T^*_t$ on $(\Omega,{\cal B},\mu^\prime)$ produces a weak solution
to (\ref{CM}).
This is the Girsanov-Cameron-Martin theorem.

This change of measure is closely linked to the change of
ground state in the corresponding quantum theory, when an interaction is
introduced. We see this in the Feynman-Kac formula, below.

One can, using similar methods, integrate adapted functions relative to
$dM$, where $M$ is any martingale. The stochastic integral has other
variants, such as the Stratonovitch
version \cite{Wiener2,Nelson4}; one can also integrate non-adapted
processes, subject to
other conditions (Skorokhod), or use another noise which is not quite
a martingale \cite{McShane,Barnett3}.
The Ito version has an interesting interpretation in mathematical finance.
Suppose that the price of an asset is a random process $S_t$, and it
obeys the Ito equation
\[dS_t=a(S_t,t)dt+b(S_t,t)dW_t.\]
If we choose to hold $\varphi(t)$ units of this asset, our portfolio at time
$t$ is worth $\varphi(t)S_t$. The change in the value of our portfolio
in time $dt$ is $d(\varphi(t)S_t)$, and we evaluate this as $\varphi(t)dS_t$,
because we do not change our holding $\varphi(t)$ until after we have seen
the change in the asset price. Here $dS_t=S_{t+dt}-S_t$, so the total
change in the asset over the time-interval $[0,T]$ is the Ito integral
$\int_0^T\varphi(s)dS_s$, in which $\varphi$ is adapted and the stochastic
increment is the forward difference.

We now give a brief account of the Feynman-Kac formula \cite{Kac}.
Feynman related the quantum transition amplitude $\langle\psi,e^{-iHt}\phi
\rangle$ to the integral over histories of $\langle\psi,e^{i\int L(s)\,ds}\phi
\rangle$ where $L$ is the Lagrangian \cite{Feynman}. The trouble is,
the Feynman ``integral'' over histories is not based on measures, but on
oscillatory integrals, and these rarely converge. In quantum
physics, the spectrum of the energy is bounded below (at least
at zero temperature). This expresses the
stability of the theory. It follows that the unitary time-evolution group
$e^{-iHt}$ has an analytic continuation to complex times with negative
imaginary part. In particular this is true of all the matrix elements
of this operator. This is the underlying fact used in Euclidean
quantum field theory, but also holds for quantum systems without any large
symmetry group; only invariance under time-evolution is needed. In
particular, we can consider the group for negative imaginary times,
giving a semigroup $e^{-Ht}$. The
large-time behaviour of this is very good. This was used by Nelson
\cite{Nelson} to study certain perturbations of the free Hamiltonian: it is
easier to study perturbations of a contraction
semigroup than a unitary group.

\begin{theorem}
Let $H_0=-\frac{1}{2}\frac{\partial ^2}{\partial x^2}$ and $V$ be a
real-valued $C^\infty$-function of $x\in{\bf R}$, vanishing at $\infty$.
Then $H_0+V$ is self-adjoint on Dom$\,H_0$ and
\begin{equation}
\langle\psi,e^{-(H_0+V)t}\varphi\rangle=\int\overline{\psi(\omega(0))}
\varphi(\omega(t))\exp\left(-\int_0^tV(\omega(s))\,ds\right)d\mu.
\end{equation}
\end{theorem}
For the proof, see \cite{Nelson} or \cite{Simon}. For a version within
quantum probability, see \cite{HIK}. In this way, we construct an
interacting theory in terms of a path integral using the Wiener measure
$\mu$, weighted with an exponential function. The similarity with
the Gibbs state of a system of paths in a potential $V$ is noteworthy.
Suppose that $V=0$ outside a region $\Lambda$, and converges to
$+\infty$ inside $\Lambda$. Then we see from Feynman-Kac formula
that the measure vanishes on all paths that enter the region
$\Lambda$. After a normalisation, the weighted measure thus becomes
the conditional Wiener measure, $\mu(\;.\;|\omega(t)\notin\Lambda
\mbox{ for all }t)$. The formula then solves the heat equation
subject to the condition of no-flow through the boundary $\partial
\Lambda$. We do not need to find this conditioned measure to use
the formula; we can, for example, use the Monte Carlo method, and
sample paths by computer, rejecting any that enter $\Lambda$; we
can also use the conditioned measure to get results on monotonicity,
since e. g. if the region $\Lambda$ is enlarged, obviously more
paths are allowed, and so the integral of a positive integrand
is increased. This relation with pde's has developed into the subject
called {\em potential theory} \cite{Grimmett}, and is one of the
tools used in constructive quantum field theory
\cite{Glimm,Glimm2,Frohlich,Guerra}. 

Dyson saw the usefulness of using
imaginary time in quantum field theory \cite{Dyson}.
Schwinger \cite{Schwinger} had introduced
the idea of the Euclidean quantum field as a way
of avoiding the difficulties of Lorentz invariance; these are replaced by
invariance under $O(4)$, the orthogonal group; since we analytically
continue all the time-ordered functions to imaginary time, time $t$ gets
replaced by $it$, often attributed to Minkowski. In fact, Minkowski did not
know
about the consequences of positive energy; he did not analytically continue
anything, but simply replaced time by $-ix_4$, where $x_4=it$. This means
that he considered the complex $O(4)$, and the invariance group was
a particular subgroup $L$ of it
consisting of matrices some of whose entries were complex. In fact, $L$ is
isomorphic to the real Lorentz group, and is thus non-compact. Nothing has
been gained by Minkowski's trick. Indeed, lots of confusion arose in
electromagnetic texts up until recently, where other four-vectors such as
$A^\mu$ were regarded as having a complex zero$^{\rm th}$ component.
Schwinger's programme of Euclidean field theory is a special case of a theory
developed by Wightman \cite{Jost,SW}, in which the expectation values of the
field are
proved to have an analytic continuation in all the space-time components,
into a domain that includes real position variables and purely imaginary time.

Symanzik \cite{Symanzik} started the mathematical programme of Euclidean
quantum field theory. Glimm and Jaffe developed constructive quantum
field theory using their theory of the perturbation of contraction
semigroups. This is almost a Euclidean point of view. A beautiful
probabilistic version of the subject resulted from Nelson's rewrite of
Symanzik's programme. Let us outline this for the quantum mechanics
of an oscillator.

We start with the self-adjoint Hamiltonian
\begin{equation}
H=H_0+V=\frac{1}{2}(-\frac{\partial^2}{\partial q_j^2}+q^2-1)
\end{equation}
Then the lowest eigenvalue, say $0$, is simple; let $U(t)=e^{-iHt}$
and let $\psi_0$ be the eigenfunction of the eigenvalue $0$. Then $\psi_0>0$
holds. That is, there are no nodes in the ground state, a kind of
Perron-Frobenius
theorem. It is then convenient to replace the Hilbert space of the theory,
${\cal H}=L^2({\bf R},dq)$ by the unitarily equivalent space ${\cal
H}^\prime=L^2({\bf R},|\psi_0(q)|^2 dq)$. The unitary map $W:{\cal H}
\rightarrow{\cal H}^\prime$ is given by $(W\psi)(q)=\psi(q)/\psi_0(q)$.
This is obviously organised so that $W\psi_0=1$, the unit constant function
in ${\cal H}^\prime$.
An observable $A$, acting on ${\cal H}$, is converted to $A^\prime=
WAW^{-1}$. The operator $q$ commutes with $W$, so is
unchanged; but its canonical conjugate, $p$ does
not commute with $W$, and neither does $q(t):=U(t)qU(-t)$, so
these operators do not take the usual Schr\"{o}dinger form on ${\cal
H}^\prime$.

The positivity of the energy ensures that the Wightman function
$\langle 1,q(t_1)\ldots q(t_n)1\rangle$
 has an analytic continuation to purely imaginary times, 
\begin{equation}
t_j=is_j,\;\mbox{ such that }s_j-s_{j+1}>0, s_j\in{\bf R},\;j=1,\ldots n-1.
\label{spoints}
\end{equation}
Define the {\em Schwinger function}
\begin{equation}
S_n(s_1,\ldots,s_n)=W_n(is_1,\ldots,is_n)
\end{equation}
at points given by eq.~(\ref{spoints}); we take $S_n$ to be defined
by symmetry in the other regions; since the $w_n$ are symmetric at
real points, the $n!$ analytic functions coincide at a common boundary
of real dimension $n$. So by the edge-of-the-wedge theorem \cite{SW}
there is one common analytic function coinciding with these
Schwinger functions. Obviously, $S_n$ determines $W_n$, by the
uniqueness of analytic continuation.

Then two properties hold: there is a stochastic process $X(t)$
such that $S_n$ is the $n^{\rm th}$ moment:
\[S_n(s_1,\ldots,s_n)=E[X(s_1)\ldots X(s_n)];\]
Moreover, the process is stationary and Markovian; that is
\begin{equation}
E[X_t|{\cal B}_{\leq s}]=E[X_t|{\cal B}_s],\;\mbox{ for }t\geq s.
\end{equation}
Here, ${\cal B}_{\leq s}$ is the $\sigma$-tribe generated by $X_r,\;r\leq
s$, and ${\cal B}_s$ that generated by $X_s$.
Neither of these properties is true for a general Hamiltonian theory, so
they reflect somehow the Lagrangian origins of the theory.

We can recover the physical Hilbert space as the initial space, $L^2(\Omega,
{\cal B}_0,\mu)$ generated by powers $X(0)$ acting on the vacuum, $\psi_0$
which is the function 1. Also $q$ is then multiplication
by $X(0)$. The Hamiltonian can be recovered by the identity
({\em c.f.} (\ref{KBE}))
\begin{equation}
e^{-Ht}P(q)\psi_0=E[P(X(t))|{\cal B}_0]
\end{equation}
for any polynomial $P$.
This is the continuous version of the fact that the transition matrix of
a Markov chain can be recovered as the conditional probability of one
time-step.
We find
\begin{equation}
\langle\psi_0,q(t_1)q(t_2)\psi_0\rangle=(1/2)\exp\{i(t_1-t_2)\}.
\end{equation}
This leads by analytic continuation to
\begin{equation}
S(s_1,s_2)=(1/2)\exp\{-|s_1-s_2|\}=E[X(s_1)X(s_2)]
\end{equation}
where $X(t)$ is the Ornstein-Uhlenbeck process.

Nelson was able to follow this programme for the free quantised field,
and so rewrite the problem of finding solutions to relativistic
quantum fields in terms of generalised random fields. A selection of
good reading on this subject is \cite{Minlos,Wong,Nelson2,Simon2,Gross2}.
\input new20005
