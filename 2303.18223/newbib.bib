@article{Yu-arxiv-2023-mmvet,
  author       = {Weihao Yu and
                  Zhengyuan Yang and
                  Linjie Li and
                  Jianfeng Wang and
                  Kevin Lin and
                  Zicheng Liu and
                  Xinchao Wang and
                  Lijuan Wang},
  title        = {MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities},
  journal      = {CoRR},
  volume       = {abs/2308.02490},
  year         = {2023}
}

@article{Zhang-arxiv-2023-siren,
  author       = {Yue Zhang and
                  Yafu Li and
                  Leyang Cui and
                  Deng Cai and
                  Lemao Liu and
                  Tingchen Fu and
                  Xinting Huang and
                  Enbo Zhao and
                  Yu Zhang and
                  Yulong Chen and
                  Longyue Wang and
                  Anh Tuan Luu and
                  Wei Bi and
                  Freda Shi and
                  Shuming Shi},
  title        = {Siren's Song in the {AI} Ocean: {A} Survey on Hallucination in Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.01219},
  year         = {2023}
}

@article{Liu-arxiv-2023-hallusionbench,
  author       = {Fuxiao Liu and
                  Tianrui Guan and
                  Zongxia Li and
                  Lichang Chen and
                  Yaser Yacoob and
                  Dinesh Manocha and
                  Tianyi Zhou},
  title        = {HallusionBench: You See What You Think? Or You Think What You See?
                  An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision),
                  LLaVA-1.5, and Other Multi-modality Models},
  journal      = {CoRR},
  volume       = {abs/2310.14566},
  year         = {2023}
}

@article{Lu-arxiv-2023-evaluation,
  author       = {Jiaying Lu and
                  Jinmeng Rao and
                  Kezhen Chen and
                  Xiaoyuan Guo and
                  Yawen Zhang and
                  Baochen Sun and
                  Carl Yang and
                  Jie Yang},
  title        = {Evaluation and Mitigation of Agnosia in Multimodal Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2309.04041},
  year         = {2023}
}

@article{Li-arxiv-2023-FLM,
  title={Flm-101b: An open llm and how to train it with \$100 k budget},
  author={Li, Xiang and Yao, Yiqun and Jiang, Xin and Fang, Xuezhi and Meng, Xuying and Fan, Siqi and Han, Peng and Li, Jing and Du, Li and Qin, Bowen and others},
  journal={arXiv preprint arXiv:2309.03852},
  year={2023}
}

@article{Gunjal-arxiv-2023-detecting,
  author       = {Anisha Gunjal and
                  Jihan Yin and
                  Erhan Bas},
  title        = {Detecting and Preventing Hallucinations in Large Vision Language Models},
  journal      = {CoRR},
  volume       = {abs/2308.06394},
  year         = {2023}
}

@article{Liu-arxiv-2023-aligning,
  author       = {Fuxiao Liu and
                  Kevin Lin and
                  Linjie Li and
                  Jianfeng Wang and
                  Yaser Yacoob and
                  Lijuan Wang},
  title        = {Aligning Large Multi-Modal Model with Robust Instruction Tuning},
  journal      = {CoRR},
  volume       = {abs/2306.14565},
  year         = {2023}
}

@article{Zhao-arxiv-2023-slichf,
  author       = {Yao Zhao and
                  Rishabh Joshi and
                  Tianqi Liu and
                  Misha Khalman and
                  Mohammad Saleh and
                  Peter J. Liu},
  title        = {SLiC-HF: Sequence Likelihood Calibration with Human Feedback},
  journal      = {CoRR},
  volume       = {abs/2305.10425},
  year         = {2023}
}

@article{Azerbayev-arxiv-2023-llemma,
  title={Llemma: An open language model for mathematics},
  author={Azerbayev, Zhangir and Schoelkopf, Hailey and Paster, Keiran and Santos, Marco Dos and McAleer, Stephen and Jiang, Albert Q and Deng, Jia and Biderman, Stella and Welleck, Sean},
  journal={arXiv preprint arXiv:2310.10631},
  year={2023}
}

@article{Scheurer-arxiv-2023-ILF,
  author       = {J{\'{e}}r{\'{e}}my Scheurer and
                  Jon Ander Campos and
                  Tomasz Korbak and
                  Jun Shern Chan and
                  Angelica Chen and
                  Kyunghyun Cho and
                  Ethan Perez},
  title        = {Training Language Models with Language Feedback at Scale},
  journal      = {CoRR},
  volume       = {abs/2303.16755},
  year         = {2023}
}

@inproceedings{Mishra-cvpr-2012-top,
  author       = {Anand Mishra and
                  Karteek Alahari and
                  C. V. Jawahar},
  title        = {Top-down and bottom-up cues for scene text recognition},
  booktitle    = {{CVPR}},
  pages        = {2687--2694},
  publisher    = {{IEEE} Computer Society},
  year         = {2012}
}

@InProceedings{Joulin-2017-EACL-fasttext,
  title={Bag of Tricks for Efficient Text Classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  booktitle={{EACL}},
  year={2017},
  pages={427--431},
}

@article{chen-2023-arXiv-DataJuicer,
  title={Data-Juicer: A One-Stop Data Processing System for Large Language Models},
  author={Chen, Daoyuan and Huang, Yilun and Ma, Zhijian and Chen, Hesen and Pan, Xuchen and Ge, Ce and Gao, Dawei and Xie, Yuexiang and Liu, Zhaoyang and Gao, Jinyang and others},
  journal={arXiv preprint arXiv:2309.02033},
  year={2023}
}

@inproceedings{Wenzek-2020-LREC-CCNet,
  title={CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data},
  author={Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzm{\'a}n, Francisco and Joulin, Armand and Grave, {\'E}douard},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={4003--4012},
  year={2020}
}

@inproceedings{Gurari-cvpr-2018-vizwiz,
  author       = {Danna Gurari and
                  Qing Li and
                  Abigale J. Stangl and
                  Anhong Guo and
                  Chi Lin and
                  Kristen Grauman and
                  Jiebo Luo and
                  Jeffrey P. Bigham},
  title        = {VizWiz Grand Challenge: Answering Visual Questions From Blind People},
  booktitle    = {{CVPR}},
  pages        = {3608--3617},
  publisher    = {Computer Vision Foundation / {IEEE} Computer Society},
  year         = {2018}
}

@inproceedings{Deng-cvpr-2009-imagenet,
  author       = {Jia Deng and
                  Wei Dong and
                  Richard Socher and
                  Li{-}Jia Li and
                  Kai Li and
                  Li Fei{-}Fei},
  title        = {ImageNet: {A} large-scale hierarchical image database},
  booktitle    = {{CVPR}},
  pages        = {248--255},
  publisher    = {{IEEE} Computer Society},
  year         = {2009}
}

@inproceedings{Lin-eccv-2014-coco,
  author       = {Tsung{-}Yi Lin and
                  Michael Maire and
                  Serge J. Belongie and
                  James Hays and
                  Pietro Perona and
                  Deva Ramanan and
                  Piotr Doll{\'{a}}r and
                  C. Lawrence Zitnick},
  title        = {Microsoft {COCO:} Common Objects in Context},
  booktitle    = {{ECCV} {(5)}},
  series       = {Lecture Notes in Computer Science},
  volume       = {8693},
  pages        = {740--755},
  publisher    = {Springer},
  year         = {2014}
}

@inproceedings{Sharma-acl-2018-cc3m,
  author       = {Piyush Sharma and
                  Nan Ding and
                  Sebastian Goodman and
                  Radu Soricut},
  title        = {Conceptual Captions: {A} Cleaned, Hypernymed, Image Alt-text Dataset
                  For Automatic Image Captioning},
  booktitle    = {{ACL} {(1)}},
  pages        = {2556--2565},
  publisher    = {Association for Computational Linguistics},
  year         = {2018}
}

@article{Li-arxiv-2023-seed,
  author       = {Bohao Li and
                  Rui Wang and
                  Guangzhi Wang and
                  Yuying Ge and
                  Yixiao Ge and
                  Ying Shan},
  title        = {SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension},
  journal      = {CoRR},
  volume       = {abs/2307.16125},
  year         = {2023}
}

@article{Li-arxiv-2023-reform,
  author       = {Zejun Li and
                  Ye Wang and
                  Mengfei Du and
                  Qingwen Liu and
                  Binhao Wu and
                  Jiwen Zhang and
                  Chengxing Zhou and
                  Zhihao Fan and
                  Jie Fu and
                  Jingjing Chen and
                  Xuanjing Huang and
                  Zhongyu Wei},
  title        = {ReForm-Eval: Evaluating Large Vision Language Models via Unified Re-Formulation
                  of Task-Oriented Benchmarks},
  journal      = {CoRR},
  volume       = {abs/2310.02569},
  year         = {2023}
}

@article{Xu-arxiv-2023-lvlm,
  author       = {Peng Xu and
                  Wenqi Shao and
                  Kaipeng Zhang and
                  Peng Gao and
                  Shuo Liu and
                  Meng Lei and
                  Fanqing Meng and
                  Siyuan Huang and
                  Yu Qiao and
                  Ping Luo},
  title        = {LVLM-eHub: {A} Comprehensive Evaluation Benchmark for Large Vision-Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2306.09265},
  year         = {2023}
}

@inproceedings{Amanpreet-cvpr-2019-textvqa,
    title={Towards VQA Models That Can Read},
    author={Singh, Amanpreet and Natarjan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Parikh, Devi and Rohrbach, Marcus},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages={8317-8326},
    year={2019}
}

@inproceedings{Lu-nips-2022-learn,
  author       = {Pan Lu and
                  Swaroop Mishra and
                  Tanglin Xia and
                  Liang Qiu and
                  Kai{-}Wei Chang and
                  Song{-}Chun Zhu and
                  Oyvind Tafjord and
                  Peter Clark and
                  Ashwin Kalyan},
  title        = {Learn to Explain: Multimodal Reasoning via Thought Chains for Science
                  Question Answering},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@inproceedings{Hudson-cvpr-2019-gqa,
  author       = {Drew A. Hudson and
                  Christopher D. Manning},
  title        = {{GQA:} {A} New Dataset for Real-World Visual Reasoning and Compositional
                  Question Answering},
  booktitle    = {{CVPR}},
  pages        = {6700--6709},
  publisher    = {Computer Vision Foundation / {IEEE}},
  year         = {2019}
}

@article{Li-arxiv-2023-llava-med,
  author       = {Chunyuan Li and
                  Cliff Wong and
                  Sheng Zhang and
                  Naoto Usuyama and
                  Haotian Liu and
                  Jianwei Yang and
                  Tristan Naumann and
                  Hoifung Poon and
                  Jianfeng Gao},
  title        = {LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine
                  in One Day},
  journal      = {CoRR},
  volume       = {abs/2306.00890},
  year         = {2023}
}

@inproceedings{Vedantam-cvpr-2015-cider,
  author       = {Ramakrishna Vedantam and
                  C. Lawrence Zitnick and
                  Devi Parikh},
  title        = {CIDEr: Consensus-based image description evaluation},
  booktitle    = {{CVPR}},
  pages        = {4566--4575},
  publisher    = {{IEEE} Computer Society},
  year         = {2015}
}

@inproceedings{Antol-iccv-2015-vqa,
  author       = {Stanislaw Antol and
                  Aishwarya Agrawal and
                  Jiasen Lu and
                  Margaret Mitchell and
                  Dhruv Batra and
                  C. Lawrence Zitnick and
                  Devi Parikh},
  title        = {{VQA:} Visual Question Answering},
  booktitle    = {{ICCV}},
  pages        = {2425--2433},
  publisher    = {{IEEE} Computer Society},
  year         = {2015}
}

@inproceedings{Li-emnlp-2023-evaluating,
  title={Evaluating Object Hallucination in Large Vision-Language Models},
  author={Yifan Li and Yifan Du and Kun Zhou and Jinpeng Wang and Wayne Xin Zhao and Ji-Rong Wen},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023},
  url={https://openreview.net/forum?id=xozJw0kZXF}
}

@inproceedings{Rohrbach-emnlp-2018-object,
  author       = {Anna Rohrbach and
                  Lisa Anne Hendricks and
                  Kaylee Burns and
                  Trevor Darrell and
                  Kate Saenko},
  title        = {Object Hallucination in Image Captioning},
  booktitle    = {{EMNLP}},
  pages        = {4035--4045},
  publisher    = {Association for Computational Linguistics},
  year         = {2018}
}

@article{Fu-arxiv-2023-mme,
  author       = {Chaoyou Fu and
                  Peixian Chen and
                  Yunhang Shen and
                  Yulei Qin and
                  Mengdan Zhang and
                  Xu Lin and
                  Zhenyu Qiu and
                  Wei Lin and
                  Jinrui Yang and
                  Xiawu Zheng and
                  Ke Li and
                  Xing Sun and
                  Rongrong Ji},
  title        = {{MME:} {A} Comprehensive Evaluation Benchmark for Multimodal Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2306.13394},
  year         = {2023}
}

@article{Liu-arxiv-2023-mmbench,
  author       = {Yuan Liu and
                  Haodong Duan and
                  Yuanhan Zhang and
                  Bo Li and
                  Songyang Zhang and
                  Wangbo Zhao and
                  Yike Yuan and
                  Jiaqi Wang and
                  Conghui He and
                  Ziwei Liu and
                  Kai Chen and
                  Dahua Lin},
  title        = {MMBench: Is Your Multi-modal Model an All-around Player?},
  journal      = {CoRR},
  volume       = {abs/2307.06281},
  year         = {2023}
}

@article{Liu-arxiv-2023-training,
  author       = {Ruibo Liu and
                  Ruixin Yang and
                  Chenyan Jia and
                  Ge Zhang and
                  Denny Zhou and
                  Andrew M. Dai and
                  Diyi Yang and
                  Soroush Vosoughi},
  title        = {Training Socially Aligned Language Models in Simulated Human Society},
  journal      = {CoRR},
  volume       = {abs/2305.16960},
  year         = {2023}
}

@inproceedings{Lu-nips-2022-quark,
  author       = {Ximing Lu and
                  Sean Welleck and
                  Jack Hessel and
                  Liwei Jiang and
                  Lianhui Qin and
                  Peter West and
                  Prithviraj Ammanabrolu and
                  Yejin Choi},
  title        = {{QUARK:} Controllable Text Generation with Reinforced Unlearning},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@inproceedings{Prasad-EACL-2023-GrIPS,
  author       = {Archiki Prasad and
                  Peter Hase and
                  Xiang Zhou and
                  Mohit Bansal},
  editor       = {Andreas Vlachos and
                  Isabelle Augenstein},
  title        = {GrIPS: Gradient-free, Edit-based Instruction Search for Prompting
                  Large Language Models},
  booktitle    = {Proceedings of the 17th Conference of the European Chapter of the
                  Association for Computational Linguistics, {EACL} 2023, Dubrovnik,
                  Croatia, May 2-6, 2023},
  pages        = {3827--3846},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{Wang-CoRR-2023-PromptAgent,
  author       = {Xinyuan Wang and
                  Chenxi Li and
                  Zhen Wang and
                  Fan Bai and
                  Haotian Luo and
                  Jiayou Zhang and
                  Nebojsa Jojic and
                  Eric P. Xing and
                  Zhiting Hu},
  title        = {PromptAgent: Strategic Planning with Language Models Enables Expert-level
                  Prompt Optimization},
  journal      = {CoRR},
  volume       = {abs/2310.16427},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.16427},
  doi          = {10.48550/ARXIV.2310.16427},
  eprinttype    = {arXiv},
  eprint       = {2310.16427}
}

@article{Yang-CoRR-2023-Large,
  author       = {Chengrun Yang and
                  Xuezhi Wang and
                  Yifeng Lu and
                  Hanxiao Liu and
                  Quoc V. Le and
                  Denny Zhou and
                  Xinyun Chen},
  title        = {Large Language Models as Optimizers},
  journal      = {CoRR},
  volume       = {abs/2309.03409},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.03409},
  doi          = {10.48550/ARXIV.2309.03409},
  eprinttype    = {arXiv},
  eprint       = {2309.03409}
}

@article{Pryzant-CoRR-2023-Automatic,
  author       = {Reid Pryzant and
                  Dan Iter and
                  Jerry Li and
                  Yin Tat Lee and
                  Chenguang Zhu and
                  Michael Zeng},
  title        = {Automatic Prompt Optimization with "Gradient Descent" and Beam Search},
  journal      = {CoRR},
  volume       = {abs/2305.03495},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.03495},
  doi          = {10.48550/ARXIV.2305.03495},
  eprinttype    = {arXiv},
  eprint       = {2305.03495}
}

@inproceedings{Zhou-ICLR-2023-Large,
  author       = {Yongchao Zhou and
                  Andrei Ioan Muresanu and
                  Ziwen Han and
                  Keiran Paster and
                  Silviu Pitis and
                  Harris Chan and
                  Jimmy Ba},
  title        = {Large Language Models are Human-Level Prompt Engineers},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@inproceedings{Xu-EMNLP-2022-GPS,
  author       = {Hanwei Xu and
                  Yujun Chen and
                  Yulun Du and
                  Nan Shao and
                  Yanggang Wang and
                  Haiyu Li and
                  Zhilin Yang},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {{GPS:} Genetic Prompt Search for Efficient Few-Shot Learning},
  booktitle    = {Proceedings of the 2022 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
                  December 7-11, 2022},
  pages        = {8162--8171},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@article{Dong-arxiv-2023-RAFT,
  author       = {Hanze Dong and
                  Wei Xiong and
                  Deepanshu Goyal and
                  Rui Pan and
                  Shizhe Diao and
                  Jipeng Zhang and
                  Kashun Shum and
                  Tong Zhang},
  title        = {{RAFT:} Reward rAnked FineTuning for Generative Foundation Model Alignment},
  journal      = {CoRR},
  volume       = {abs/2304.06767},
  year         = {2023}
}

@article{Zhang-arxiv-2023-The,
  author       = {Tianjun Zhang and
                  Fangchen Liu and
                  Justin Wong and
                  Pieter Abbeel and
                  Joseph E. Gonzalez},
  title        = {The Wisdom of Hindsight Makes Language Models Better Instruction Followers},
  journal      = {CoRR},
  volume       = {abs/2302.05206},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2302.05206},
  doi          = {10.48550/arXiv.2302.05206},
  eprinttype    = {arXiv},
  eprint       = {2302.05206}
}

@inproceedings{Liu-NeurIPS-2022-Second,
  author       = {Ruibo Liu and
                  Chenyan Jia and
                  Ge Zhang and
                  Ziyu Zhuang and
                  Tony X. Liu and
                  Soroush Vosoughi},
  title        = {Second Thoughts are Best: Learning to Re-Align With Human Values from
                  Text Edits},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@article{Rafailov-arxiv-2023-Direct,
  author       = {Rafael Rafailov and
                  Archit Sharma and
                  Eric Mitchell and
                  Stefano Ermon and
                  Christopher D. Manning and
                  Chelsea Finn},
  title        = {Direct Preference Optimization: Your Language Model is Secretly a
                  Reward Model},
  journal      = {CoRR},
  volume       = {abs/2305.18290},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.18290},
  doi          = {10.48550/arXiv.2305.18290},
  eprinttype    = {arXiv},
  eprint       = {2305.18290}
}

@article{Liu-arxiv-2023-Chain,
  author       = {Hao Liu and
                  Carmelo Sferrazza and
                  Pieter Abbeel},
  title        = {Chain of Hindsight Aligns Language Models with Feedback},
  journal      = {CoRR},
  volume       = {abs/2302.02676},
  year         = {2023}
}

@misc{Tan-arxiv-2023-towards,
      title={Towards Applying Powerful Large AI Models in Classroom Teaching: Opportunities, Challenges and Prospects}, 
      author={Kehui Tan and Tianqi Pang and Chenyou Fan},
      year={2023},
      eprint={2305.03433},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{Zan-WMT-2022-Vega-MT,
  author       = {Changtong Zan and
                  Keqin Peng and
                  Liang Ding and
                  Baopu Qiu and
                  Boan Liu and
                  Shwai He and
                  Qingyu Lu and
                  Zheng Zhang and
                  Chuang Liu and
                  Weifeng Liu and
                  Yibing Zhan and
                  Dacheng Tao},
  editor       = {Philipp Koehn and
                  Lo{\"{\i}}c Barrault and
                  Ondrej Bojar and
                  Fethi Bougares and
                  Rajen Chatterjee and
                  Marta R. Costa{-}juss{\`{a}} and
                  Christian Federmann and
                  Mark Fishel and
                  Alexander Fraser and
                  Markus Freitag and
                  Yvette Graham and
                  Roman Grundkiewicz and
                  Paco Guzman and
                  Barry Haddow and
                  Matthias Huck and
                  Antonio Jimeno{-}Yepes and
                  Tom Kocmi and
                  Andr{\'{e}} Martins and
                  Makoto Morishita and
                  Christof Monz and
                  Masaaki Nagata and
                  Toshiaki Nakazawa and
                  Matteo Negri and
                  Aur{\'{e}}lie N{\'{e}}v{\'{e}}ol and
                  Mariana Neves and
                  Martin Popel and
                  Marco Turchi and
                  Marcos Zampieri},
  title        = {Vega-MT: The {JD} Explore Academy Machine Translation System for {WMT22}},
  booktitle    = {Proceedings of the Seventh Conference on Machine Translation, {WMT}
                  2022, Abu Dhabi, United Arab Emirates (Hybrid), December 7-8, 2022},
  pages        = {411--422},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@article{Yuan-RRHF-2023-arxiv,
  author       = {Zheng Yuan and
                  Hongyi Yuan and
                  Chuanqi Tan and
                  Wei Wang and
                  Songfang Huang and
                  Fei Huang},
  title        = {{RRHF:} Rank Responses to Align Language Models with Human Feedback
                  without tears},
  journal      = {CoRR},
  volume       = {abs/2304.05302},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.05302},
  doi          = {10.48550/arXiv.2304.05302},
  eprinttype    = {arXiv},
  eprint       = {2304.05302}
}

@article{Kasneci-learning-2023-chatgpt,
  title={ChatGPT for good? On opportunities and challenges of large language models for education},
  author={Kasneci, Enkelejda and Se{\ss}ler, Kathrin and K{\"u}chemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and G{\"u}nnemann, Stephan and H{\"u}llermeier, Eyke and others},
  journal={Learning and Individual Differences},
  volume={103},
  pages={102274},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{Naryan-EMNLP-2018-XSUM,
  author    = {Shashi Narayan and
               Shay B. Cohen and
               Mirella Lapata},
  title     = {Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional
               Neural Networks for Extreme Summarization},
  booktitle = {{EMNLP}},
  pages     = {1797--1807},
  publisher = {Association for Computational Linguistics},
  year      = {2018}
}

@article{Saier-arxiv-2023-unarXive,
  title={unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including Structured Full-Text and Citation Network},
  author={Saier, Tarek and Krause, Johan and F{\"a}rber, Michael},
  journal={arXiv preprint arXiv:2303.14957},
  year={2023}
}

@article{Bawden-journal-2021-DiaBLa,
  author    = {Rachel Bawden and
               Eric Bilinski and
               Thomas Lavergne and
               Sophie Rosset},
  title     = {DiaBLa: a corpus of bilingual spontaneous written dialogues for machine
               translation},
  journal   = {Lang. Resour. Evaluation},
  volume    = {55},
  number    = {3},
  pages     = {635--660},
  year      = {2021}
}

@article{OpenAI-blog-2023-plugins,
  title   = "ChatGPT plugins",
  author  = "Sandhini Agarwal and Ilge Akkaya and Valerie Balcom and Mo Bavarian and Gabriel Bernadett-Shapiro and Greg Brockman and Miles Brundage and Jeff Chan and Fotis Chantzis and Noah Deutsch and Brydon Eastman and Atty Eleti and Niko Felix and Simón Posada Fishman and Isa Fulford and Christian Gibson and Joshua Gross and Mike Heaton and Jacob Hilton and Xin Hu and Shawn Jain and Haozhun Jin and Logan Kilpatrick and Christina Kim and Michael Kolhede and Andrew Mayne and Paul McMillan and David Medina and Jacob Menick and Andrey Mishchenko and Ashvin Nair and Rajeev Nayak and Arvind Neelakantan and Rohan Nuttall and Joel Parish and Alex Tachard Passos and Adam Perelman and Filipe de Avila Belbute Peres and Vitchyr Pong and John Schulman and Eric Sigler and Natalie Staudacher and Nicholas Turley and Jerry Tworek and Ryan Greene and Arun Vijayvergiya and Chelsea Voss and Jiayi Weng and Matt Wiethoff and Sarah Yoo and Kevin Yu and Wojciech Zaremba and Shengjia Zhao and Will Zhuk and Barret Zoph",
  journal = "OpenAI Blog",
  year    = "2023",
  month   = "March",
}


@article{Huberman-AI-1987-phase,
  title={Phase transitions in artificial intelligence systems},
  author={Huberman, Bernardo A and Hogg, Tad},
  journal={Artificial Intelligence},
  volume={33},
  number={2},
  pages={155--171},
  year={1987},
  publisher={Elsevier}
}

@inproceedings{Yang-EMNLP-2022-Re3,
  author    = {Kevin Yang and
               Yuandong Tian and
               Nanyun Peng and
               Dan Klein},
  editor    = {Yoav Goldberg and
               Zornitsa Kozareva and
               Yue Zhang},
  title     = {Re3: Generating Longer Stories With Recursive Reprompting and Revision},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {4393--4479},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@inproceedings{Sheng-WISA-2019-CLMed,
  author    = {Ming Sheng and
               Han Zhang and
               Yong Zhang and
               Chao Li and
               Chunxiao Xing and
               Jingwen Wang and
               Yuyao Shao and
               Fei Gao},
  editor    = {Weiwei Ni and
               Xin Wang and
               Wei Song and
               Yukun Li},
  title     = {CLMed: {A} Cross-lingual Knowledge Graph Framework for Cardiovascular
               Diseases},
  booktitle = {Web Information Systems and Applications - 16th International Conference,
               {WISA} 2019, Qingdao, China, September 20-22, 2019, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {11817},
  pages     = {512--517},
  publisher = {Springer},
  year      = {2019}
}

@article{Peng-arxiv-2023-Check,
  author    = {Baolin Peng and
               Michel Galley and
               Pengcheng He and
               Hao Cheng and
               Yujia Xie and
               Yu Hu and
               Qiuyuan Huang and
               Lars Liden and
               Zhou Yu and
               Weizhu Chen and
               Jianfeng Gao},
  title     = {Check Your Facts and Try Again: Improving Large Language Models with
               External Knowledge and Automated Feedback},
  journal   = {CoRR},
  volume    = {abs/2302.12813},
  year      = {2023}
}

@article{Lazaridou-arxiv-2022-Internet,
  author    = {Angeliki Lazaridou and
               Elena Gribovskaya and
               Wojciech Stokowiec and
               Nikolai Grigorev},
  title     = {Internet-augmented language models through few-shot prompting for
               open-domain question answering},
  journal   = {CoRR},
  volume    = {abs/2203.05115},
  year      = {2022}
}

@article{Gehrmann-arxiv-2021-GEM,
  author    = {Sebastian Gehrmann and
               Tosin P. Adewumi and
               Karmanya Aggarwal and
               Pawan Sasanka Ammanamanchi and
               Aremu Anuoluwapo and
               Antoine Bosselut and
               Khyathi Raghavi Chandu and
               Miruna{-}Adriana Clinciu and
               Dipanjan Das and
               Kaustubh D. Dhole and
               Wanyu Du and
               Esin Durmus and
               Ondrej Dusek and
               Chris Emezue and
               Varun Gangal and
               Cristina Garbacea and
               Tatsunori Hashimoto and
               Yufang Hou and
               Yacine Jernite and
               Harsh Jhamtani and
               Yangfeng Ji and
               Shailza Jolly and
               Dhruv Kumar and
               Faisal Ladhak and
               Aman Madaan and
               Mounica Maddela and
               Khyati Mahajan and
               Saad Mahamood and
               Bodhisattwa Prasad Majumder and
               Pedro Henrique Martins and
               Angelina McMillan{-}Major and
               Simon Mille and
               Emiel van Miltenburg and
               Moin Nadeem and
               Shashi Narayan and
               Vitaly Nikolaev and
               Rubungo Andre Niyongabo and
               Salomey Osei and
               Ankur P. Parikh and
               Laura Perez{-}Beltrachini and
               Niranjan Ramesh Rao and
               Vikas Raunak and
               Juan Diego Rodriguez and
               Sashank Santhanam and
               Jo{\~{a}}o Sedoc and
               Thibault Sellam and
               Samira Shaikh and
               Anastasia Shimorina and
               Marco Antonio Sobrevilla Cabezudo and
               Hendrik Strobelt and
               Nishant Subramani and
               Wei Xu and
               Diyi Yang and
               Akhila Yerukola and
               Jiawei Zhou},
  title     = {The {GEM} Benchmark: Natural Language Generation, its Evaluation and
               Metrics},
  journal   = {CoRR},
  volume    = {abs/2102.01672},
  year      = {2021}
}

@inproceedings{Liu-ACL-2021-GLGE,
  author    = {Dayiheng Liu and
               Yu Yan and
               Yeyun Gong and
               Weizhen Qi and
               Hang Zhang and
               Jian Jiao and
               Weizhu Chen and
               Jie Fu and
               Linjun Shou and
               Ming Gong and
               Pengcheng Wang and
               Jiusheng Chen and
               Daxin Jiang and
               Jiancheng Lv and
               Ruofei Zhang and
               Winnie Wu and
               Ming Zhou and
               Nan Duan},
  title     = {{GLGE:} {A} New General Language Generation Evaluation Benchmark},
  booktitle = {{ACL/IJCNLP} (Findings)},
  series    = {Findings of {ACL}},
  volume    = {{ACL/IJCNLP} 2021},
  pages     = {408--420},
  publisher = {Association for Computational Linguistics},
  year      = {2021}
}

@inproceedings{Bojar-WMT-2016-Findings,
  author    = {Ondrej Bojar and
               Rajen Chatterjee and
               Christian Federmann and
               Yvette Graham and
               Barry Haddow and
               Matthias Huck and
               Antonio Jimeno{-}Yepes and
               Philipp Koehn and
               Varvara Logacheva and
               Christof Monz and
               Matteo Negri and
               Aur{\'{e}}lie N{\'{e}}v{\'{e}}ol and
               Mariana L. Neves and
               Martin Popel and
               Matt Post and
               Raphael Rubino and
               Carolina Scarton and
               Lucia Specia and
               Marco Turchi and
               Karin Verspoor and
               Marcos Zampieri},
  title     = {Findings of the 2016 Conference on Machine Translation},
  booktitle = {{WMT}},
  pages     = {131--198},
  publisher = {The Association for Computer Linguistics},
  year      = {2016}
}

@article{Cu-arxiv-2021-FewCLUE,
  author    = {Liang Xu and
               Xiaojing Lu and
               Chenyang Yuan and
               Xuanwei Zhang and
               Hu Yuan and
               Huilin Xu and
               Guoao Wei and
               Xiang Pan and
               Hai Hu},
  title     = {FewCLUE: {A} Chinese Few-shot Learning Evaluation Benchmark},
  journal   = {CoRR},
  volume    = {abs/2107.07498},
  year      = {2021}
}

@inproceedings{Xu-COLING-2020-CLUE,
  author    = {Liang Xu and
               Hai Hu and
               Xuanwei Zhang and
               Lu Li and
               Chenjie Cao and
               Yudong Li and
               Yechen Xu and
               Kai Sun and
               Dian Yu and
               Cong Yu and
               Yin Tian and
               Qianqian Dong and
               Weitang Liu and
               Bo Shi and
               Yiming Cui and
               Junyi Li and
               Jun Zeng and
               Rongzhao Wang and
               Weijian Xie and
               Yanting Li and
               Yina Patterson and
               Zuoyu Tian and
               Yiwen Zhang and
               He Zhou and
               Shaoweihua Liu and
               Zhe Zhao and
               Qipeng Zhao and
               Cong Yue and
               Xinrui Zhang and
               Zhengliang Yang and
               Kyle Richardson and
               Zhenzhong Lan},
  title     = {{CLUE:} {A} Chinese Language Understanding Evaluation Benchmark},
  booktitle = {{COLING}},
  pages     = {4762--4772},
  publisher = {International Committee on Computational Linguistics},
  year      = {2020}
}

@inproceedings{Lai-EMNLP-2017-RACE,
  author    = {Guokun Lai and
               Qizhe Xie and
               Hanxiao Liu and
               Yiming Yang and
               Eduard H. Hovy},
  title     = {{RACE:} Large-scale ReAding Comprehension Dataset From Examinations},
  booktitle = {{EMNLP}},
  pages     = {785--794},
  publisher = {Association for Computational Linguistics},
  year      = {2017}
}

@inproceedings{McCoy-ACL-2019-Right,
  author    = {Tom McCoy and
               Ellie Pavlick and
               Tal Linzen},
  title     = {Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural
               Language Inference},
  booktitle = {{ACL} {(1)}},
  pages     = {3428--3448},
  publisher = {Association for Computational Linguistics},
  year      = {2019}
}

@inproceedings{Nie-ACL-2020-Adversarial,
  author    = {Yixin Nie and
               Adina Williams and
               Emily Dinan and
               Mohit Bansal and
               Jason Weston and
               Douwe Kiela},
  title     = {Adversarial {NLI:} {A} New Benchmark for Natural Language Understanding},
  booktitle = {{ACL}},
  pages     = {4885--4901},
  publisher = {Association for Computational Linguistics},
  year      = {2020}
}

@inproceedings{Sakaguchi-AAAI-2020-WinoGrande,
  author    = {Keisuke Sakaguchi and
               Ronan Le Bras and
               Chandra Bhagavatula and
               Yejin Choi},
  title     = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
  booktitle = {{AAAI}},
  pages     = {8732--8740},
  publisher = {{AAAI} Press},
  year      = {2020}
}

@inproceedings{Ladhak-EMNLP-2020-WikiLingua,
  title={WikiLingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization},
  author={Ladhak, Faisal and Durmus, Esin and Cardie, Claire and Mckeown, Kathleen},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={4034--4048},
  year={2020}
}

@article{Goyal-TACL-2022-The,
  author    = {Naman Goyal and
               Cynthia Gao and
               Vishrav Chaudhary and
               Peng{-}Jen Chen and
               Guillaume Wenzek and
               Da Ju and
               Sanjana Krishnan and
               Marc'Aurelio Ranzato and
               Francisco Guzm{\'{a}}n and
               Angela Fan},
  title     = {The Flores-101 Evaluation Benchmark for Low-Resource and Multilingual
               Machine Translation},
  journal   = {Trans. Assoc. Comput. Linguistics},
  volume    = {10},
  pages     = {522--538},
  year      = {2022}
}

@inproceedings{Bojar-WMT-2014-Findings,
  author    = {Ondrej Bojar and
               Christian Buck and
               Christian Federmann and
               Barry Haddow and
               Philipp Koehn and
               Johannes Leveling and
               Christof Monz and
               Pavel Pecina and
               Matt Post and
               Herve Saint{-}Amand and
               Radu Soricut and
               Lucia Specia and
               Ales Tamchyna},
  title     = {Findings of the 2014 Workshop on Statistical Machine Translation},
  booktitle = {WMT@ACL},
  pages     = {12--58},
  publisher = {The Association for Computer Linguistics},
  year      = {2014}
}

@article{Liang-arxiv-2022-Code,
  author    = {Jacky Liang and
               Wenlong Huang and
               Fei Xia and
               Peng Xu and
               Karol Hausman and
               Brian Ichter and
               Pete Florence and
               Andy Zeng},
  title     = {Code as Policies: Language Model Programs for Embodied Control},
  journal   = {CoRR},
  volume    = {abs/2209.07753},
  year      = {2022}
}

@inproceedings{Srivastava-CoRL-2021-BEHAVIOR,
  author    = {Sanjana Srivastava and
               Chengshu Li and
               Michael Lingelbach and
               Roberto Mart{\'{\i}}n{-}Mart{\'{\i}}n and
               Fei Xia and
               Kent Elliott Vainio and
               Zheng Lian and
               Cem Gokmen and
               Shyamal Buch and
               C. Karen Liu and
               Silvio Savarese and
               Hyowon Gweon and
               Jiajun Wu and
               Li Fei{-}Fei},
  title     = {{BEHAVIOR:} Benchmark for Everyday Household Activities in Virtual,
               Interactive, and Ecological Environments},
  booktitle = {CoRL},
  series    = {Proceedings of Machine Learning Research},
  volume    = {164},
  pages     = {477--490},
  publisher = {{PMLR}},
  year      = {2021}
}

@inproceedings{Shridhar-CVPR-2020-ALFRED,
  author    = {Mohit Shridhar and
               Jesse Thomason and
               Daniel Gordon and
               Yonatan Bisk and
               Winson Han and
               Roozbeh Mottaghi and
               Luke Zettlemoyer and
               Dieter Fox},
  title     = {{ALFRED:} {A} Benchmark for Interpreting Grounded Instructions for
               Everyday Tasks},
  booktitle = {{CVPR}},
  pages     = {10737--10746},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2020}
}




@article{hauser-science-2002-faculty,
  title={The faculty of language: what is it, who has it, and how did it evolve?},
  author={Hauser, Marc D and Chomsky, Noam and Fitch, W Tecumseh},
  journal={science},
  volume={298},
  number={5598},
  pages={1569--1579},
  year={2002},
  publisher={American Association for the Advancement of Science}
}


@article{FU-blog-2022-how,
  title   = "How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources",
  author  = "Fu, Yao and Peng, Hao and Khot, Tushar",
  journal = "Yao Fu’s Notion",
  year    = "2022",
  month   = "Dec",
}



@inproceedings{Maynez-ACL-2020-On,
  author    = {Joshua Maynez and
               Shashi Narayan and
               Bernd Bohnet and
               Ryan T. McDonald},
  editor    = {Dan Jurafsky and
               Joyce Chai and
               Natalie Schluter and
               Joel R. Tetreault},
  title     = {On Faithfulness and Factuality in Abstractive Summarization},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages     = {1906--1919},
  publisher = {Association for Computational Linguistics},
  year      = {2020}
}

@article{Ganguli-arxiv-2022-Red,
  author    = {Deep Ganguli and
               Liane Lovitt and
               Jackson Kernion and
               Amanda Askell and
               Yuntao Bai and
               Saurav Kadavath and
               Ben Mann and
               Ethan Perez and
               Nicholas Schiefer and
               Kamal Ndousse and
               Andy Jones and
               Sam Bowman and
               Anna Chen and
               Tom Conerly and
               Nova DasSarma and
               Dawn Drain and
               Nelson Elhage and
               Sheer El Showk and
               Stanislav Fort and
               Zac Hatfield{-}Dodds and
               Tom Henighan and
               Danny Hernandez and
               Tristan Hume and
               Josh Jacobson and
               Scott Johnston and
               Shauna Kravec and
               Catherine Olsson and
               Sam Ringer and
               Eli Tran{-}Johnson and
               Dario Amodei and
               Tom Brown and
               Nicholas Joseph and
               Sam McCandlish and
               Chris Olah and
               Jared Kaplan and
               Jack Clark},
  title     = {Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors,
               and Lessons Learned},
  journal   = {CoRR},
  volume    = {abs/2209.07858},
  year      = {2022},
}

@inproceedings{Perez-EMNLP-2022-Red,
  author    = {Ethan Perez and
               Saffron Huang and
               H. Francis Song and
               Trevor Cai and
               Roman Ring and
               John Aslanides and
               Amelia Glaese and
               Nat McAleese and
               Geoffrey Irving},
  editor    = {Yoav Goldberg and
               Zornitsa Kozareva and
               Yue Zhang},
  title     = {Red Teaming Language Models with Language Models},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {3419--3448},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@article{OpenAI-blog-2023-Planning,
  title   = "Planning for AGI and beyond",
  author  = "Altman, Sam",
  journal = "OpenAI Blog",
  year    = "2023",
  month   = "February",
}

@article{Wang-arxiv-2022-Execution,
  author    = {Zhiruo Wang and
               Shuyan Zhou and
               Daniel Fried and
               Graham Neubig},
  title     = {Execution-Based Evaluation for Open-Domain Code Generation},
  journal   = {CoRR},
  volume    = {abs/2212.10481},
  year      = {2022}
}

@article{Clark-trans-2020-TyDi,
  author    = {Jonathan H. Clark and
               Jennimaria Palomaki and
               Vitaly Nikolaev and
               Eunsol Choi and
               Dan Garrette and
               Michael Collins and
               Tom Kwiatkowski},
  title     = {TyDi {QA:} {A} Benchmark for Information-Seeking Question Answering
               in Typologically Diverse Languages},
  journal   = {Trans. Assoc. Comput. Linguistics},
  volume    = {8},
  pages     = {454--470},
  year      = {2020}
}

@article{Lai-arxiv-2022-DS,
  author    = {Yuhang Lai and
               Chengxi Li and
               Yiming Wang and
               Tianyi Zhang and
               Ruiqi Zhong and
               Luke Zettlemoyer and
               Scott Wen{-}tau Yih and
               Daniel Fried and
               Sida I. Wang and
               Tao Yu},
  title     = {{DS-1000:} {A} Natural and Reliable Benchmark for Data Science Code
               Generation},
  journal   = {CoRR},
  volume    = {abs/2211.11501},
  year      = {2022}
}

@article{Gulwani-Found-2017-Program,
  author    = {Sumit Gulwani and
               Oleksandr Polozov and
               Rishabh Singh},
  title     = {Program Synthesis},
  journal   = {Found. Trends Program. Lang.},
  volume    = {4},
  number    = {1-2},
  pages     = {1--119},
  year      = {2017}
}

@article{Welsh-ACM-2023-The,
  author    = {Matt Welsh},
  title     = {The End of Programming},
  journal   = {Commun. {ACM}},
  volume    = {66},
  number    = {1},
  pages     = {34--35},
  year      = {2023}
}

@inproceedings{Puig-CVPR-2018-VirtualHome,
  author    = {Xavier Puig and
               Kevin Ra and
               Marko Boben and
               Jiaman Li and
               Tingwu Wang and
               Sanja Fidler and
               Antonio Torralba},
  title     = {VirtualHome: Simulating Household Activities via Programs},
  booktitle = {{CVPR}},
  pages     = {8494--8502},
  publisher = {Computer Vision Foundation / {IEEE} Computer Society},
  year      = {2018}
}

@article{Garg-arxiv-2022-What,
  author    = {Shivam Garg and
               Dimitris Tsipras and
               Percy Liang and
               Gregory Valiant},
  title     = {What Can Transformers Learn In-Context? {A} Case Study of Simple Function
               Classes},
  journal   = {CoRR},
  volume    = {abs/2208.01066},
  year      = {2022}
}

@inproceedings{Shin-NAACL-2022-On,
  author    = {Seongjin Shin and
               Sang{-}Woo Lee and
               Hwijeen Ahn and
               Sungdong Kim and
               HyoungSeok Kim and
               Boseop Kim and
               Kyunghyun Cho and
               Gichang Lee and
               Woo{-}Myoung Park and
               Jung{-}Woo Ha and
               Nako Sung},
  title     = {On the Effect of Pretraining Corpora on In-context Learning by a Large-scale
               Language Model},
  booktitle = {{NAACL-HLT}},
  pages     = {5168--5186},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@inproceedings{Patel-NAACL-2021-Are,
  author    = {Arkil Patel and
               Satwik Bhattamishra and
               Navin Goyal},
  title     = {Are {NLP} Models really able to Solve Simple Math Word Problems?},
  booktitle = {{NAACL-HLT}},
  pages     = {2080--2094},
  publisher = {Association for Computational Linguistics},
  year      = {2021}
}

@inproceedings{Rush-EMNLP-2015-A,
  author    = {Alexander M. Rush and
               Sumit Chopra and
               Jason Weston},
  title     = {A Neural Attention Model for Abstractive Sentence Summarization},
  booktitle = {{EMNLP}},
  pages     = {379--389},
  publisher = {The Association for Computational Linguistics},
  year      = {2015}
}

@inproceedings{Chen-ACL-2017-Reading,
  author    = {Danqi Chen and
               Adam Fisch and
               Jason Weston and
               Antoine Bordes},
  title     = {Reading Wikipedia to Answer Open-Domain Questions},
  booktitle = {{ACL} {(1)}},
  pages     = {1870--1879},
  publisher = {Association for Computational Linguistics},
  year      = {2017}
}

@inproceedings{Wang-NIPS-2019-SuperGLUE,
  author    = {Alex Wang and
               Yada Pruksachatkun and
               Nikita Nangia and
               Amanpreet Singh and
               Julian Michael and
               Felix Hill and
               Omer Levy and
               Samuel R. Bowman},
  title     = {SuperGLUE: {A} Stickier Benchmark for General-Purpose Language Understanding
               Systems},
  booktitle = {NeurIPS},
  pages     = {3261--3275},
  year      = {2019}
}

@article{Dong-RAFT-2023-arxiv,
  author       = {Hanze Dong and
                  Wei Xiong and
                  Deepanshu Goyal and
                  Rui Pan and
                  Shizhe Diao and
                  Jipeng Zhang and
                  Kashun Shum and
                  Tong Zhang},
  title        = {{RAFT:} Reward rAnked FineTuning for Generative Foundation Model Alignment},
  journal      = {CoRR},
  volume       = {abs/2304.06767},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.06767},
  doi          = {10.48550/arXiv.2304.06767},
  eprinttype    = {arXiv},
  eprint       = {2304.06767}
}

@article{Suzgun-arxiv-2022-Challenging,
  author    = {Mirac Suzgun and
               Nathan Scales and
               Nathanael Sch{\"{a}}rli and
               Sebastian Gehrmann and
               Yi Tay and
               Hyung Won Chung and
               Aakanksha Chowdhery and
               Quoc V. Le and
               Ed H. Chi and
               Denny Zhou and
               Jason Wei},
  title     = {Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve
               Them},
  journal   = {CoRR},
  volume    = {abs/2210.09261},
  year      = {2022}
}

@inproceedings{Moon-ACL-2019-OpenDialKG,
  author    = {Seungwhan Moon and
               Pararth Shah and
               Anuj Kumar and
               Rajen Subba},
  title     = {OpenDialKG: Explainable Conversational Reasoning with Attention-based
               Walks over Knowledge Graphs},
  booktitle = {{ACL} {(1)}},
  pages     = {845--854},
  publisher = {Association for Computational Linguistics},
  year      = {2019}
}

@article{Bang-arxiv-2023-A,
  author    = {Yejin Bang and
               Samuel Cahyawijaya and
               Nayeon Lee and
               Wenliang Dai and
               Dan Su and
               Bryan Wilie and
               Holy Lovenia and
               Ziwei Ji and
               Tiezheng Yu and
               Willy Chung and
               Quyet V. Do and
               Yan Xu and
               Pascale Fung},
  title     = {A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning,
               Hallucination, and Interactivity},
  journal   = {CoRR},
  volume    = {abs/2302.04023},
  year      = {2023}
}

@article{Shi-arxiv-2022-Language,
  author    = {Freda Shi and
               Mirac Suzgun and
               Markus Freitag and
               Xuezhi Wang and
               Suraj Srivats and
               Soroush Vosoughi and
               Hyung Won Chung and
               Yi Tay and
               Sebastian Ruder and
               Denny Zhou and
               Dipanjan Das and
               Jason Wei},
  title     = {Language Models are Multilingual Chain-of-Thought Reasoners},
  journal   = {CoRR},
  volume    = {abs/2210.03057},
  year      = {2022}
}

@inproceedings{Alex-NIPS-2021-RAFT,
  author    = {Neel Alex and
               Eli Lifland and
               Lewis Tunstall and
               Abhishek Thakur and
               Pegah Maham and
               C. Jess Riedel and
               Emmie Hine and
               Carolyn Ashurst and
               Paul Sedille and
               Alexis Carlier and
               Michael Noetel and
               Andreas Stuhlm{\"{u}}ller},
  title     = {{RAFT:} {A} Real-World Few-Shot Text Classification Benchmark},
  booktitle = {NeurIPS Datasets and Benchmarks},
  year      = {2021}
}

@article{Srivastava-arxiv-2022-Beyond,
  author    = {Aarohi Srivastava and
               Abhinav Rastogi and
               Abhishek Rao and
               Abu Awal Md Shoeb and
               Abubakar Abid and
               Adam Fisch and
               Adam R. Brown and
               Adam Santoro and
               Aditya Gupta and
               Adri{\`{a}} Garriga{-}Alonso and
               Agnieszka Kluska and
               Aitor Lewkowycz and
               Akshat Agarwal and
               Alethea Power and
               Alex Ray and
               Alex Warstadt and
               Alexander W. Kocurek and
               Ali Safaya and
               Ali Tazarv and
               Alice Xiang and
               Alicia Parrish and
               Allen Nie and
               Aman Hussain and
               Amanda Askell and
               Amanda Dsouza and
               Ameet Rahane and
               Anantharaman S. Iyer and
               Anders Andreassen and
               Andrea Santilli and
               Andreas Stuhlm{\"{u}}ller and
               Andrew M. Dai and
               Andrew La and
               Andrew K. Lampinen and
               Andy Zou and
               Angela Jiang and
               Angelica Chen and
               Anh Vuong and
               Animesh Gupta and
               Anna Gottardi and
               Antonio Norelli and
               Anu Venkatesh and
               Arash Gholamidavoodi and
               Arfa Tabassum and
               Arul Menezes and
               Arun Kirubarajan and
               Asher Mullokandov and
               Ashish Sabharwal and
               Austin Herrick and
               Avia Efrat and
               Aykut Erdem and
               Ayla Karakas and
               et al.},
  title     = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities
               of language models},
  journal   = {CoRR},
  volume    = {abs/2206.04615},
  year      = {2022}
}

@inproceedings{Hendrycks-ICLR-2021-Measuring,
  author    = {Dan Hendrycks and
               Collin Burns and
               Steven Basart and
               Andy Zou and
               Mantas Mazeika and
               Dawn Song and
               Jacob Steinhardt},
  title     = {Measuring Massive Multitask Language Understanding},
  booktitle = {{ICLR}},
  publisher = {OpenReview.net},
  year      = {2021}
}

@article{Tay-arxiv-2022-Unifying,
  author    = {Yi Tay and
               Mostafa Dehghani and
               Vinh Q. Tran and
               Xavier Garcia and
               Dara Bahri and
               Tal Schuster and
               Huaixiu Steven Zheng and
               Neil Houlsby and
               Donald Metzler},
  title     = {Unifying Language Learning Paradigms},
  journal   = {CoRR},
  volume    = {abs/2205.05131},
  year      = {2022}
}


@book{instinct-book,
  title={The Language Instinct: How the Mind Creates Language},
  author={Steven Pinker},
  year={2014},
  publisher={Brilliance Audio; Unabridged edition}
}


@book{NLP-Speech-book,
  title={Statistical Methods for Speech Recognition},
  author={Frederick Jelinek},
  year={1998},
  publisher={MIT Press}
}



@article{turing-test,
  author    = {Alan M. Turing},
  title     = {Computing machinery and intelligence},
  journal   = {Mind},
  volume    = {{LIX}},
  number    = {236},
  pages     = {433--460},
  year      = {1950},
}

@article{SLM-2004,
  author    = {Jianfeng Gao and
               Chin{-}Yew Lin},
  title     = {Introduction to the special issue on statistical language modeling},
  journal   = {{ACM} Trans. Asian Lang. Inf. Process.},
  volume    = {3},
  number    = {2},
  pages     = {87--93},
  year      = {2004},
}


@article{SLM-IR1,
  author    = {Xiaoyong Liu and
               W. Bruce Croft},
  title     = {Statistical language modeling for information retrieval},
  journal   = {Annu. Rev. Inf. Sci. Technol.},
  volume    = {39},
  number    = {1},
  pages     = {1--31},
  year      = {2005},
}


@book{SLM-IR2,
  author    = {ChengXiang Zhai},
  title     = {Statistical Language Models for Information Retrieval},
  series    = {Synthesis Lectures on Human Language Technologies},
  publisher = {Morgan {\&} Claypool Publishers},
  year      = {2008},
}


@article{Katz-IEEE-1987-estimation,
  author    = {Slava M. Katz},
  title     = {Estimation of probabilities from sparse data for the language model
               component of a speech recognizer},
  journal   = {{IEEE} Trans. Acoust. Speech Signal Process.},
  volume    = {35},
  number    = {3},
  pages     = {400--401},
  year      = {1987},
}


@article{Gale-JQL-1995-good,
  author    = {William A. Gale and
               Geoffrey Sampson},
  title     = {Good-Turing Frequency Estimation Without Tears},
  journal   = {J. Quant. Linguistics},
  volume    = {2},
  number    = {3},
  pages     = {217--237},
  year      = {1995},
}



@inproceedings{Thede-acl-1999-a,
  author    = {Scott M. Thede and
               Mary P. Harper},
  editor    = {Robert Dale and
               Kenneth Ward Church},
  title     = {A Second-Order Hidden Markov Model for Part-of-Speech Tagging},
  booktitle = {27th Annual Meeting of the Association for Computational Linguistics,
               University of Maryland, College Park, Maryland, USA, 20-26 June 1999},
  pages     = {175--182},
  publisher = {{ACL}},
  year      = {1999},
}



@article{rosenfeld2000two,
  title={Two decades of statistical language modeling: Where do we go from here?},
  author={Rosenfeld, Ronald},
  journal={Proceedings of the IEEE},
  volume={88},
  number={8},
  pages={1270--1278},
  year={2000},
  publisher={IEEE}
}


@article{bahl1989tree,
  title={A tree-based statistical language model for natural language speech recognition},
  author={Bahl, Lalit R and Brown, Peter F and de Souza, Peter V and Mercer, Robert L},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume={37},
  number={7},
  pages={1001--1008},
  year={1989},
  publisher={IEEE}
}


@inproceedings{stolcke2002srilm,
  title={SRILM-an extensible language modeling toolkit},
  author={Stolcke, Andreas},
  booktitle={Seventh international conference on spoken language processing},
  year={2002}
}


@inproceedings{Brants-emnlp-2007-large,
  author    = {Thorsten Brants and
               Ashok C. Popat and
               Peng Xu and
               Franz Josef Och and
               Jeffrey Dean},
  editor    = {Jason Eisner},
  title     = {Large Language Models in Machine Translation},
  booktitle = {EMNLP-CoNLL 2007, Proceedings of the 2007 Joint Conference on Empirical
               Methods in Natural Language Processing and Computational Natural Language
               Learning, June 28-30, 2007, Prague, Czech Republic},
  pages     = {858--867},
  publisher = {{ACL}},
  year      = {2007},
}


@inproceedings{Mikolov-INTERSPEECH-2010,
  author    = {Tom{\'{a}}s Mikolov and
               Martin Karafi{\'{a}}t and
               Luk{\'{a}}s Burget and
               Jan Cernock{\'{y}} and
               Sanjeev Khudanpur},
  editor    = {Takao Kobayashi and
               Keikichi Hirose and
               Satoshi Nakamura},
  title     = {Recurrent neural network based language model},
  booktitle = {{INTERSPEECH} 2010, 11th Annual Conference of the International Speech
               Communication Association, Makuhari, Chiba, Japan, September 26-30,
               2010},
  pages     = {1045--1048},
  publisher = {{ISCA}},
  year      = {2010},
}


@inproceedings{Kombrink-INTERSPEECH-2011,
  author    = {Stefan Kombrink and
               Tom{\'{a}}s Mikolov and
               Martin Karafi{\'{a}}t and
               Luk{\'{a}}s Burget},
  title     = {Recurrent Neural Network Based Language Modeling in Meeting Recognition},
  booktitle = {{INTERSPEECH} 2011, 12th Annual Conference of the International Speech
               Communication Association, Florence, Italy, August 27-31, 2011},
  pages     = {2877--2880},
  publisher = {{ISCA}},
  year      = {2011},
}


@inproceedings{Mikolov-NIPS-2013,
  author    = {Tom{\'{a}}s Mikolov and
               Ilya Sutskever and
               Kai Chen and
               Gregory S. Corrado and
               Jeffrey Dean},
  editor    = {Christopher J. C. Burges and
               L{\'{e}}on Bottou and
               Zoubin Ghahramani and
               Kilian Q. Weinberger},
  title     = {Distributed Representations of Words and Phrases and their Compositionality},
  booktitle = {Advances in Neural Information Processing Systems 26: 27th Annual
               Conference on Neural Information Processing Systems 2013. Proceedings
               of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
  pages     = {3111--3119},
  year      = {2013},
}


@inproceedings{Mikolov-ICLR-2013,
  author    = {Tom{\'{a}}s Mikolov and
               Kai Chen and
               Greg Corrado and
               Jeffrey Dean},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  booktitle = {1st International Conference on Learning Representations, {ICLR} 2013,
               Scottsdale, Arizona, USA, May 2-4, 2013, Workshop Track Proceedings},
  year      = {2013},
}


@inproceedings{Peters-NAACL-2018,
  author    = {Matthew E. Peters and
               Mark Neumann and
               Mohit Iyyer and
               Matt Gardner and
               Christopher Clark and
               Kenton Lee and
               Luke Zettlemoyer},
  editor    = {Marilyn A. Walker and
               Heng Ji and
               Amanda Stent},
  title     = {Deep Contextualized Word Representations},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume
               1 (Long Papers)},
  pages     = {2227--2237},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
}


@article{Liu-CoRR-2019-RoBERTa,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
}


@article{Han-AIopen-2021-PTM,
  author    = {Xu Han and
               Zhengyan Zhang and
               Ning Ding and
               Yuxian Gu and
               Xiao Liu and
               Yuqi Huo and
               Jiezhong Qiu and
               Yuan Yao and
               Ao Zhang and
               Liang Zhang and
               Wentao Han and
               Minlie Huang and
               Qin Jin and
               Yanyan Lan and
               Yang Liu and
               Zhiyuan Liu and
               Zhiwu Lu and
               Xipeng Qiu and
               Ruihua Song and
               Jie Tang and
               Ji{-}Rong Wen and
               Jinhui Yuan and
               Wayne Xin Zhao and
               Jun Zhu},
  title     = {Pre-trained models: Past, present and future},
  journal   = {{AI} Open},
  volume    = {2},
  pages     = {225--250},
  year      = {2021},
}

@inproceedings{Li-IJCAI-2021-Pretrained,
  author    = {Junyi Li and
               Tianyi Tang and
               Wayne Xin Zhao and
               Ji{-}Rong Wen},
  editor    = {Zhi{-}Hua Zhou},
  title     = {Pretrained Language Model for Text Generation: {A} Survey},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial
               Intelligence, {IJCAI} 2021, Virtual Event / Montreal, Canada, 19-27
               August 2021},
  pages     = {4492--4499},
  publisher = {ijcai.org},
  year      = {2021},
}

@article{qiu-CoRR-2020-PTM,
  author    = {Xipeng Qiu and
               Tianxiang Sun and
               Yige Xu and
               Yunfan Shao and
               Ning Dai and
               Xuanjing Huang},
  title     = {Pre-trained Models for Natural Language Processing: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2003.08271},
  year      = {2020},
}


@article{Huang-CoRR-2023,
  author    = {Shaohan Huang and
               Li Dong and
               Wenhui Wang and
               Yaru Hao and
               Saksham Singhal and
               Shuming Ma and
               Tengchao Lv and
               Lei Cui and
               Owais Khan Mohammed and
               Barun Patra and
               Qiang Liu and
               Kriti Aggarwal and
               Zewen Chi and
               Johan Bjorck and
               Vishrav Chaudhary and
               Subhojit Som and
               Xia Song and
               Furu Wei},
  title     = {Language Is Not All You Need: Aligning Perception with Language Models},
  journal   = {CoRR},
  volume    = {abs/2302.14045},
  year      = {2023},
}

@inproceedings{Bahdanau-ICLR-2015-Neural,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {{ICLR}},
  year      = {2015}
}

@inproceedings{Kang-ICDM-2018-Self,
  author       = {Wang{-}Cheng Kang and
                  Julian J. McAuley},
  title        = {Self-Attentive Sequential Recommendation},
  booktitle    = {{IEEE} International Conference on Data Mining, {ICDM} 2018, Singapore,
                  November 17-20, 2018},
  pages        = {197--206},
  publisher    = {{IEEE} Computer Society},
  year         = {2018}
}

@article{Zhao-arxiv-2022-Calibrating,
  author       = {Yao Zhao and
                  Misha Khalman and
                  Rishabh Joshi and
                  Shashi Narayan and
                  Mohammad Saleh and
                  Peter J. Liu},
  title        = {Calibrating Sequence likelihood Improves Conditional Language Generation},
  journal      = {CoRR},
  volume       = {abs/2210.00045},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2210.00045},
  doi          = {10.48550/arXiv.2210.00045},
  eprinttype    = {arXiv},
  eprint       = {2210.00045}
}

@inproceedings{Yang-NAACL-2022-Improving,
  author       = {Bowen Yang and
                  Cong Han and
                  Yu Li and
                  Lei Zuo and
                  Zhou Yu},
  editor       = {Marine Carpuat and
                  Marie{-}Catherine de Marneffe and
                  Iv{\'{a}}n Vladimir Meza Ru{\'{\i}}z},
  title        = {Improving Conversational Recommendation Systems' Quality with Context-Aware
                  Item Meta-Information},
  booktitle    = {Findings of the Association for Computational Linguistics: {NAACL}
                  2022, Seattle, WA, United States, July 10-15, 2022},
  pages        = {38--48},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}


@inproceedings{Paperno-ACL-2016-LAMBADA,
  author    = {Denis Paperno and
               Germ{\'{a}}n Kruszewski and
               Angeliki Lazaridou and
               Quan Ngoc Pham and
               Raffaella Bernardi and
               Sandro Pezzelle and
               Marco Baroni and
               Gemma Boleda and
               Raquel Fern{\'{a}}ndez},
  title     = {The {LAMBADA} dataset: Word prediction requiring a broad discourse
               context},
  booktitle = {{ACL} {(1)}},
  publisher = {The Association for Computer Linguistics},
  year      = {2016}
}

@article{Gao-arxiv-2021-Pile,
  author    = {Leo Gao and
               Stella Biderman and
               Sid Black and
               Laurence Golding and
               Travis Hoppe and
               Charles Foster and
               Jason Phang and
               Horace He and
               Anish Thite and
               Noa Nabeshima and
               Shawn Presser and
               Connor Leahy},
  title     = {The Pile: An 800GB Dataset of Diverse Text for Language Modeling},
  journal   = {CoRR},
  volume    = {abs/2101.00027},
  year      = {2021}
}

@inproceedings{Merity-ICLR-2017-Pointer, 
  author    = {Stephen Merity and
               Caiming Xiong and
               James Bradbury and
               Richard Socher},
  title     = {Pointer Sentinel Mixture Models},
  booktitle = {{ICLR} (Poster)},
  publisher = {OpenReview.net},
  year      = {2017}
}

@article{Marcus-CL-1993-Building,
  author    = {Mitchell P. Marcus and
               Beatrice Santorini and
               Mary Ann Marcinkiewicz},
  title     = {Building a Large Annotated Corpus of English: The Penn Treebank},
  journal   = {Comput. Linguistics},
  volume    = {19},
  number    = {2},
  pages     = {313--330},
  year      = {1993}
}

@article{Bengio-JMLR-2003-A,
  author    = {Yoshua Bengio and
               R{\'{e}}jean Ducharme and
               Pascal Vincent and
               Christian Janvin},
  title     = {A Neural Probabilistic Language Model},
  journal   = {J. Mach. Learn. Res.},
  volume    = {3},
  pages     = {1137--1155},
  year      = {2003}
}

@article{Wang-arxiv-2023-Describe,
  author    = {Zihao Wang and
               Shaofei Cai and
               Anji Liu and
               Xiaojian Ma and
               Yitao Liang},
  title     = {Describe, Explain, Plan and Select: Interactive Planning with Large
               Language Models Enables Open-World Multi-Task Agents},
  journal   = {CoRR},
  volume    = {abs/2302.01560},
  year      = {2023}
}

@article{Ahn-arxiv-2022-Do,
  author    = {Michael Ahn and
               Anthony Brohan and
               Noah Brown and
               Yevgen Chebotar and
               Omar Cortes and
               Byron David and
               Chelsea Finn and
               Keerthana Gopalakrishnan and
               Karol Hausman and
               Alexander Herzog and
               Daniel Ho and
               Jasmine Hsu and
               Julian Ibarz and
               Brian Ichter and
               Alex Irpan and
               Eric Jang and
               Rosario Jauregui Ruano and
               Kyle Jeffrey and
               Sally Jesmonth and
               Nikhil J. Joshi and
               Ryan Julian and
               Dmitry Kalashnikov and
               Yuheng Kuang and
               Kuang{-}Huei Lee and
               Sergey Levine and
               Yao Lu and
               Linda Luu and
               Carolina Parada and
               Peter Pastor and
               Jornell Quiambao and
               Kanishka Rao and
               Jarek Rettinghouse and
               Diego Reyes and
               Pierre Sermanet and
               Nicolas Sievers and
               Clayton Tan and
               Alexander Toshev and
               Vincent Vanhoucke and
               Fei Xia and
               Ted Xiao and
               Peng Xu and
               Sichun Xu and
               Mengyuan Yan},
  title     = {Do As {I} Can, Not As {I} Say: Grounding Language in Robotic Affordances},
  journal   = {CoRR},
  volume    = {abs/2204.01691},
  year      = {2022}
}

@article{Singh-arxiv-2022-ProgPrompt,
  author    = {Ishika Singh and
               Valts Blukis and
               Arsalan Mousavian and
               Ankit Goyal and
               Danfei Xu and
               Jonathan Tremblay and
               Dieter Fox and
               Jesse Thomason and
               Animesh Garg},
  title     = {ProgPrompt: Generating Situated Robot Task Plans using Large Language
               Models},
  journal   = {CoRR},
  volume    = {abs/2209.11302},
  year      = {2022}
}

@article{Carta-arxiv-2023-Grounding,
  author    = {Thomas Carta and
               Cl{\'{e}}ment Romac and
               Thomas Wolf and
               Sylvain Lamprier and
               Olivier Sigaud and
               Pierre{-}Yves Oudeyer},
  title     = {Grounding Large Language Models in Interactive Environments with Online
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2302.02662},
  year      = {2023}
}

@inproceedings{Huang-ICML-2022-Language,
  author    = {Wenlong Huang and
               Pieter Abbeel and
               Deepak Pathak and
               Igor Mordatch},
  title     = {Language Models as Zero-Shot Planners: Extracting Actionable Knowledge
               for Embodied Agents},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {162},
  pages     = {9118--9147},
  publisher = {{PMLR}},
  year      = {2022}
}

@article{radford-blog-2019-language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  pages={9},
  year={2019}
}

@article{Chen-arxiv-2021-evaluating,
  author    = {Mark Chen and
               Jerry Tworek and
               Heewoo Jun and
               Qiming Yuan and
               Henrique Pond{\'{e}} de Oliveira Pinto and
               Jared Kaplan and
               Harrison Edwards and
               Yuri Burda and
               Nicholas Joseph and
               Greg Brockman and
               Alex Ray and
               Raul Puri and
               Gretchen Krueger and
               Michael Petrov and
               Heidy Khlaaf and
               Girish Sastry and
               Pamela Mishkin and
               Brooke Chan and
               Scott Gray and
               Nick Ryder and
               Mikhail Pavlov and
               Alethea Power and
               Lukasz Kaiser and
               Mohammad Bavarian and
               Clemens Winter and
               Philippe Tillet and
               Felipe Petroski Such and
               Dave Cummings and
               Matthias Plappert and
               Fotios Chantzis and
               Elizabeth Barnes and
               Ariel Herbert{-}Voss and
               William Hebgen Guss and
               Alex Nichol and
               Alex Paino and
               Nikolas Tezak and
               Jie Tang and
               Igor Babuschkin and
               Suchir Balaji and
               Shantanu Jain and
               William Saunders and
               Christopher Hesse and
               Andrew N. Carr and
               Jan Leike and
               Joshua Achiam and
               Vedant Misra and
               Evan Morikawa and
               Alec Radford and
               Matthew Knight and
               Miles Brundage and
               Mira Murati and
               Katie Mayer and
               Peter Welinder and
               Bob McGrew and
               Dario Amodei and
               Sam McCandlish and
               Ilya Sutskever and
               Wojciech Zaremba},
  title     = {Evaluating Large Language Models Trained on Code},
  journal   = {CoRR},
  volume    = {abs/2107.03374},
  year      = {2021}
}

@article{nijkamp-arxiv-2022-Codegen,
  title={Codegen: An open large language model for code with mtulti-turn program synthesis},
  author={Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming},
  journal={arXiv preprint arXiv:2203.13474},
  year={2022}
}

@article{Austin-arxiv-2021-Program,
  author    = {Jacob Austin and
               Augustus Odena and
               Maxwell I. Nye and
               Maarten Bosma and
               Henryk Michalewski and
               David Dohan and
               Ellen Jiang and
               Carrie J. Cai and
               Michael Terry and
               Quoc V. Le and
               Charles Sutton},
  title     = {Program Synthesis with Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2108.07732},
  year      = {2021}
}

@article{OpenAI-OpenAI-2023-GPT-4,
  author    = {OpenAI},
  title     = {GPT-4 Technical Report},
  journal   = {OpenAI},
  year      = {2023}
}

@article{OpenAI-OpenAI-2023-PromptGuide,
  author    = {OpenAI},
  title     = {GPT best practices},
  journal   = {OpenAI},
  url       = {https://platform.openai.com/docs/guides/gpt-best-practices},
  year      = {2023}
}

@article{Contributors-Github-2023-Awesome,
  author    = {Contributors},
  title     = {Awesome ChatGPT Prompts},
  journal   = {Github},
  url       = {https://github.com/f/awesome-chatgpt-prompts/},
  year      = {2023}
}

@article{Contributors-AIShort-2023-AIShort,
  author    = {Contributors},
  title     = {AI Short},
  url       = {https://www.aishort.top/},
  year      = {2023}
}

@inproceedings{Fried-ICLR-2023-InCoder,
  author    = {Daniel Fried and
               Armen Aghajanyan and
               Jessy Lin and
               Sida Wang and
               Eric Wallace and
               Freda Shi and
               Ruiqi Zhong and
               Wen{-}tau Yih and
               Luke Zettlemoyer and
               Mike Lewis},
  title     = {InCoder: {A} Generative Model for Code Infilling and Synthesis},
  booktitle   = {{ICLR}},
  year      = {2023}
}

@software{Black-GitHub-2021-GPT-Neo,
  author       = {Black, Sid and
                  Gao, Leo and
                  Wang, Phil and
                  Leahy, Connor and
                  Biderman, Stella},
  title        = {{GPT-Neo: Large Scale Autoregressive Language 
                   Modeling with Mesh-Tensorflow}},
  year         = 2021,
}


@misc{Zhipu-GitHub-2023-ChatGLM2-6B,
  title = {{ChatGLM2-6B
}},
  howpublished = {\url{https://github.com/THUDM/ChatGLM2-6B}},
  year = 2023
}


@misc{TII-Web-2023-Falcon,
  title = {{Introducing
Falcon LLM
}},
  howpublished = {\url{https://falconllm.tii.ae}},
  year = 2023
}

@misc{Wang-GitHub-2021-GPT-J,
  author = {Wang, Ben and Komatsuzaki, Aran},
  title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year = 2021
}

@article{Li-Science-2022-AlphaCode,
  author    = {Yujia Li and
               David H. Choi and
               Junyoung Chung and
               Nate Kushman and
               Julian Schrittwieser and
               R{\'{e}}mi Leblond and
               Tom Eccles and
               James Keeling and
               Felix Gimeno and
               Agustin Dal Lago and
               Thomas Hubert and
               Peter Choy and
               Cyprien de Masson d'Autume and
               Igor Babuschkin and
               Xinyun Chen and
               Po{-}Sen Huang and
               Johannes Welbl and
               Sven Gowal and
               Alexey Cherepanov and
               James Molloy and
               Daniel J. Mankowitz and
               Esme Sutherland Robson and
               Pushmeet Kohli and
               Nando de Freitas and
               Koray Kavukcuoglu and
               Oriol Vinyals},
  title     = {Competition-Level Code Generation with AlphaCode},
  journal   = {Science},
  year      = {2022}
}

@inproceedings{Feng-EMNLPFindings-2020-CodeBERT,
  author    = {Zhangyin Feng and
               Daya Guo and
               Duyu Tang and
               Nan Duan and
               Xiaocheng Feng and
               Ming Gong and
               Linjun Shou and
               Bing Qin and
               Ting Liu and
               Daxin Jiang and
               Ming Zhou},
  title     = {CodeBERT: {A} Pre-Trained Model for Programming and Natural Languages},
  booktitle = {Findings of {EMNLP}},
  year      = {2020}
}

@article{Manna-CommunACM-1971-Toward,
  author    = {Zohar Manna and
               Richard J. Waldinger},
  title     = {Toward Automatic Program Synthesis},
  journal   = {Commun. {ACM}},
  volume    = {14},
  number    = {3},
  pages     = {151--165},
  year      = {1971}
}

@article{Simon-JACM-1963-Experiments,
  author    = {Herbert A. Simon},
  title     = {Experiments with a Heuristic Compiler},
  journal   = {J. {ACM}},
  volume    = {10},
  number    = {4},
  pages     = {493--506},
  year      = {1963}
}

@article{Bai-arXiv-2022-Constitutional,
  author       = {Yuntao Bai and
                  Saurav Kadavath and
                  Sandipan Kundu and
                  Amanda Askell and
                  Jackson Kernion and
                  Andy Jones and
                  Anna Chen and
                  Anna Goldie and
                  Azalia Mirhoseini and
                  Cameron McKinnon and
                  Carol Chen and
                  Catherine Olsson and
                  Christopher Olah and
                  Danny Hernandez and
                  Dawn Drain and
                  Deep Ganguli and
                  Dustin Li and
                  Eli Tran{-}Johnson and
                  Ethan Perez and
                  Jamie Kerr and
                  Jared Mueller and
                  Jeffrey Ladish and
                  Joshua Landau and
                  Kamal Ndousse and
                  Kamile Lukosiute and
                  Liane Lovitt and
                  Michael Sellitto and
                  Nelson Elhage and
                  Nicholas Schiefer and
                  Noem{\'{\i}} Mercado and
                  Nova DasSarma and
                  Robert Lasenby and
                  Robin Larson and
                  Sam Ringer and
                  Scott Johnston and
                  Shauna Kravec and
                  Sheer El Showk and
                  Stanislav Fort and
                  Tamera Lanham and
                  Timothy Telleen{-}Lawton and
                  Tom Conerly and
                  Tom Henighan and
                  Tristan Hume and
                  Samuel R. Bowman and
                  Zac Hatfield{-}Dodds and
                  Ben Mann and
                  Dario Amodei and
                  Nicholas Joseph and
                  Sam McCandlish and
                  Tom Brown and
                  Jared Kaplan},
  title        = {Constitutional {AI:} Harmlessness from {AI} Feedback},
  journal      = {CoRR},
  volume       = {abs/2212.08073},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2212.08073},
  doi          = {10.48550/arXiv.2212.08073},
  eprinttype    = {arXiv},
  eprint       = {2212.08073},
  timestamp    = {Mon, 02 Jan 2023 15:09:55 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2212-08073.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Xu-SIGPLAN-2022-Systematic,
  author    = {Frank F. Xu and
               Uri Alon and
               Graham Neubig and
               Vincent Josua Hellendoorn},
  title     = {A systematic evaluation of large language models of code},
  booktitle = {{MAPS@PLDI}},
  year      = {2022}
}

@inproceedings{Hendrycks-nips-2021-Measuring,
  author    = {Dan Hendrycks and
               Steven Basart and
               Saurav Kadavath and
               Mantas Mazeika and
               Akul Arora and
               Ethan Guo and
               Collin Burns and
               Samir Puranik and
               Horace He and
               Dawn Song and
               Jacob Steinhardt},
  title     = {Measuring Coding Challenge Competence With {APPS}},
  booktitle = {NeurIPS Datasets and Benchmarks},
  year      = {2021}
}

@article{Askell-arxiv-2021-A,
  author    = {Amanda Askell and
               Yuntao Bai and
               Anna Chen and
               Dawn Drain and
               Deep Ganguli and
               Tom Henighan and
               Andy Jones and
               Nicholas Joseph and
               Benjamin Mann and
               Nova DasSarma and
               Nelson Elhage and
               Zac Hatfield{-}Dodds and
               Danny Hernandez and
               Jackson Kernion and
               Kamal Ndousse and
               Catherine Olsson and
               Dario Amodei and
               Tom B. Brown and
               Jack Clark and
               Sam McCandlish and
               Chris Olah and
               Jared Kaplan},
  title     = {A General Language Assistant as a Laboratory for Alignment},
  journal   = {CoRR},
  volume    = {abs/2112.00861},
  year      = {2021},
}


@article{Glaese-arxiv-2022-Improving,
  author    = {Amelia Glaese and
               Nat McAleese and
               Maja Trebacz and
               John Aslanides and
               Vlad Firoiu and
               Timo Ewalds and
               Maribeth Rauh and
               Laura Weidinger and
               Martin Chadwick and
               Phoebe Thacker and
               Lucy Campbell{-}Gillingham and
               Jonathan Uesato and
               Po{-}Sen Huang and
               Ramona Comanescu and
               Fan Yang and
               Abigail See and
               Sumanth Dathathri and
               Rory Greig and
               Charlie Chen and
               Doug Fritz and
               Jaume Sanchez Elias and
               Richard Green and
               Sona Mokr{\'{a}} and
               Nicholas Fernando and
               Boxi Wu and
               Rachel Foley and
               Susannah Young and
               Iason Gabriel and
               William Isaac and
               John Mellor and
               Demis Hassabis and
               Koray Kavukcuoglu and
               Lisa Anne Hendricks and
               Geoffrey Irving},
  title     = {Improving alignment of dialogue agents via targeted human judgements},
  journal   = {CoRR},
  volume    = {abs/2209.14375},
  year      = {2022}
}

@article{Wei-arxiv-2022-Emergent,
  author    = {Jason Wei and
               Yi Tay and
               Rishi Bommasani and
               Colin Raffel and
               Barret Zoph and
               Sebastian Borgeaud and
               Dani Yogatama and
               Maarten Bosma and
               Denny Zhou and
               Donald Metzler and
               Ed H. Chi and
               Tatsunori Hashimoto and
               Oriol Vinyals and
               Percy Liang and
               Jeff Dean and
               William Fedus},
  title     = {Emergent Abilities of Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2206.07682},
  year      = {2022},
}


@inproceedings{Sanh-ICLR-2022-Multitask,
  author    = {Victor Sanh and
               Albert Webson and
               Colin Raffel and
               Stephen H. Bach and
               Lintang Sutawika and
               Zaid Alyafeai and
               Antoine Chaffin and
               Arnaud Stiegler and
               Arun Raja and
               Manan Dey and
               M Saiful Bari and
               Canwen Xu and
               Urmish Thakker and
               Shanya Sharma Sharma and
               Eliza Szczechla and
               Taewoon Kim and
               Gunjan Chhablani and
               Nihal V. Nayak and
               Debajyoti Datta and
               Jonathan Chang and
               Mike Tian{-}Jian Jiang and
               Han Wang and
               Matteo Manica and
               Sheng Shen and
               Zheng Xin Yong and
               Harshit Pandey and
               Rachel Bawden and
               Thomas Wang and
               Trishala Neeraj and
               Jos Rozen and
               Abheesht Sharma and
               Andrea Santilli and
               Thibault F{\'{e}}vry and
               Jason Alan Fries and
               Ryan Teehan and
               Teven Le Scao and
               Stella Biderman and
               Leo Gao and
               Thomas Wolf and
               Alexander M. Rush},
  title     = {Multitask Prompted Training Enables Zero-Shot Task Generalization},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022}
}

@inproceedings{Christiano-NeurIPS-2017-Deep,
  author    = {Paul F. Christiano and
               Jan Leike and
               Tom B. Brown and
               Miljan Martic and
               Shane Legg and
               Dario Amodei},
  editor    = {Isabelle Guyon and
               Ulrike von Luxburg and
               Samy Bengio and
               Hanna M. Wallach and
               Rob Fergus and
               S. V. N. Vishwanathan and
               Roman Garnett},
  title     = {Deep Reinforcement Learning from Human Preferences},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems 2017, December 4-9, 2017,
               Long Beach, CA, {USA}},
  pages     = {4299--4307},
  year      = {2017}
}

@article{Ouyang-arxiv-2022-Training,
  author    = {Long Ouyang and
               Jeff Wu and
               Xu Jiang and
               Diogo Almeida and
               Carroll L. Wainwright and
               Pamela Mishkin and
               Chong Zhang and
               Sandhini Agarwal and
               Katarina Slama and
               Alex Ray and
               John Schulman and
               Jacob Hilton and
               Fraser Kelton and
               Luke Miller and
               Maddie Simens and
               Amanda Askell and
               Peter Welinder and
               Paul F. Christiano and
               Jan Leike and
               Ryan Lowe},
  title     = {Training language models to follow instructions with human feedback},
  journal   = {CoRR},
  volume    = {abs/2203.02155},
  year      = {2022}
}

@article{Kenton-arxiv-2021-Alignment,
  author    = {Zachary Kenton and
               Tom Everitt and
               Laura Weidinger and
               Iason Gabriel and
               Vladimir Mikulik and
               Geoffrey Irving},
  title     = {Alignment of Language Agents},
  journal   = {CoRR},
  volume    = {abs/2103.14659},
  year      = {2021}
}

@inproceedings{Wei-ICLR-2022-Finetuned,
  author    = {Jason Wei and
               Maarten Bosma and
               Vincent Y. Zhao and
               Kelvin Guu and
               Adams Wei Yu and
               Brian Lester and
               Nan Du and
               Andrew M. Dai and
               Quoc V. Le},
  title     = {Finetuned Language Models are Zero-Shot Learners},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022}
}

@article{Zhang-arxiv-2022-OPT,
  author    = {Susan Zhang and
               Stephen Roller and
               Naman Goyal and
               Mikel Artetxe and
               Moya Chen and
               Shuohui Chen and
               Christopher Dewan and
               Mona T. Diab and
               Xian Li and
               Xi Victoria Lin and
               Todor Mihaylov and
               Myle Ott and
               Sam Shleifer and
               Kurt Shuster and
               Daniel Simig and
               Punit Singh Koura and
               Anjali Sridhar and
               Tianlu Wang and
               Luke Zettlemoyer},
  title     = {{OPT:} Open Pre-trained Transformer Language Models},
  journal   = {CoRR},
  volume    = {abs/2205.01068},
  year      = {2022}
}

@inproceedings{Brown-NeurIPS-2020-Language,
  author    = {Tom B. Brown and
               Benjamin Mann and
               Nick Ryder and
               Melanie Subbiah and
               Jared Kaplan and
               Prafulla Dhariwal and
               Arvind Neelakantan and
               Pranav Shyam and
               Girish Sastry and
               Amanda Askell and
               Sandhini Agarwal and
               Ariel Herbert{-}Voss and
               Gretchen Krueger and
               Tom Henighan and
               Rewon Child and
               Aditya Ramesh and
               Daniel M. Ziegler and
               Jeffrey Wu and
               Clemens Winter and
               Christopher Hesse and
               Mark Chen and
               Eric Sigler and
               Mateusz Litwin and
               Scott Gray and
               Benjamin Chess and
               Jack Clark and
               Christopher Berner and
               Sam McCandlish and
               Alec Radford and
               Ilya Sutskever and
               Dario Amodei},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Language Models are Few-Shot Learners},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020}
}

@article{Chowdhery-arxiv-2022-PaLM,
  author    = {Aakanksha Chowdhery and
               Sharan Narang and
               Jacob Devlin and
               Maarten Bosma and
               Gaurav Mishra and
               Adam Roberts and
               Paul Barham and
               Hyung Won Chung and
               Charles Sutton and
               Sebastian Gehrmann and
               Parker Schuh and
               Kensen Shi and
               Sasha Tsvyashchenko and
               Joshua Maynez and
               Abhishek Rao and
               Parker Barnes and
               Yi Tay and
               Noam Shazeer and
               Vinodkumar Prabhakaran and
               Emily Reif and
               Nan Du and
               Ben Hutchinson and
               Reiner Pope and
               James Bradbury and
               Jacob Austin and
               Michael Isard and
               Guy Gur{-}Ari and
               Pengcheng Yin and
               Toju Duke and
               Anselm Levskaya and
               Sanjay Ghemawat and
               Sunipa Dev and
               Henryk Michalewski and
               Xavier Garcia and
               Vedant Misra and
               Kevin Robinson and
               Liam Fedus and
               Denny Zhou and
               Daphne Ippolito and
               David Luan and
               Hyeontaek Lim and
               Barret Zoph and
               Alexander Spiridonov and
               Ryan Sepassi and
               David Dohan and
               Shivani Agrawal and
               Mark Omernick and
               Andrew M. Dai and
               Thanumalayan Sankaranarayana Pillai and
               Marie Pellat and
               Aitor Lewkowycz and
               Erica Moreira and
               Rewon Child and
               Oleksandr Polozov and
               Katherine Lee and
               Zongwei Zhou and
               Xuezhi Wang and
               Brennan Saeta and
               Mark Diaz and
               Orhan Firat and
               Michele Catasta and
               Jason Wei and
               Kathy Meier{-}Hellstern and
               Douglas Eck and
               Jeff Dean and
               Slav Petrov and
               Noah Fiedel},
  title     = {PaLM: Scaling Language Modeling with Pathways},
  journal   = {CoRR},
  volume    = {abs/2204.02311},
  year      = {2022}
}

@article{Anil-arxiv-2023-palm2,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@article{Rae-arxiv-2021-Scaling,
  author    = {Jack W. Rae and
               Sebastian Borgeaud and
               Trevor Cai and
               Katie Millican and
               Jordan Hoffmann and
               H. Francis Song and
               John Aslanides and
               Sarah Henderson and
               Roman Ring and
               Susannah Young and
               Eliza Rutherford and
               Tom Hennigan and
               Jacob Menick and
               Albin Cassirer and
               Richard Powell and
               George van den Driessche and
               Lisa Anne Hendricks and
               Maribeth Rauh and
               Po{-}Sen Huang and
               Amelia Glaese and
               Johannes Welbl and
               Sumanth Dathathri and
               Saffron Huang and
               Jonathan Uesato and
               John Mellor and
               Irina Higgins and
               Antonia Creswell and
               Nat McAleese and
               Amy Wu and
               Erich Elsen and
               Siddhant M. Jayakumar and
               Elena Buchatskaya and
               David Budden and
               Esme Sutherland and
               Karen Simonyan and
               Michela Paganini and
               Laurent Sifre and
               Lena Martens and
               Xiang Lorraine Li and
               Adhiguna Kuncoro and
               Aida Nematzadeh and
               Elena Gribovskaya and
               Domenic Donato and
               Angeliki Lazaridou and
               Arthur Mensch and
               Jean{-}Baptiste Lespiau and
               Maria Tsimpoukelli and
               Nikolai Grigorev and
               Doug Fritz and
               Thibault Sottiaux and
               Mantas Pajarskas and
               Toby Pohlen and
               Zhitao Gong and
               Daniel Toyama and
               Cyprien de Masson d'Autume and
               Yujia Li and
               Tayfun Terzi and
               Vladimir Mikulik and
               Igor Babuschkin and
               Aidan Clark and
               Diego de Las Casas and
               Aurelia Guy and
               Chris Jones and
               James Bradbury and
               Matthew J. Johnson and
               Blake A. Hechtman and
               Laura Weidinger and
               Iason Gabriel and
               William S. Isaac and
               Edward Lockhart and
               Simon Osindero and
               Laura Rimell and
               Chris Dyer and
               Oriol Vinyals and
               Kareem Ayoub and
               Jeff Stanway and
               Lorrayne Bennett and
               Demis Hassabis and
               Koray Kavukcuoglu and
               Geoffrey Irving},
  title     = {Scaling Language Models: Methods, Analysis {\&} Insights from
               Training Gopher},
  journal   = {CoRR},
  volume    = {abs/2112.11446},
  year      = {2021},
}


@inproceedings{Devlin-NAACL-2019-BERT,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {4171--4186},
  publisher = {Association for Computational Linguistics},
  year      = {2019}
}

@article{Kaplan-arxiv-2020-Scaling,
  author    = {Jared Kaplan and
               Sam McCandlish and
               Tom Henighan and
               Tom B. Brown and
               Benjamin Chess and
               Rewon Child and
               Scott Gray and
               Alec Radford and
               Jeffrey Wu and
               Dario Amodei},
  title     = {Scaling Laws for Neural Language Models},
  journal   = {CoRR},
  volume    = {abs/2001.08361},
  year      = {2020},
}

@article{Taylor-arxiv-2022-Galactica,
  author    = {Ross Taylor and
               Marcin Kardas and
               Guillem Cucurull and
               Thomas Scialom and
               Anthony Hartshorn and
               Elvis Saravia and
               Andrew Poulton and
               Viktor Kerkez and
               Robert Stojnic},
  title     = {Galactica: {A} Large Language Model for Science},
  journal   = {CoRR},
  volume    = {abs/2211.09085},
  year      = {2022},
}

@article{Zhou-arxiv-2023-A,
  author    = {Ce Zhou and
               Qian Li and
               Chen Li and
               Jun Yu and
               Yixin Liu and
               Guangjing Wang and
               Kai Zhang and
               Cheng Ji and
               Qiben Yan and
               Lifang He and
               Hao Peng and
               Jianxin Li and
               Jia Wu and
               Ziwei Liu and
               Pengtao Xie and
               Caiming Xiong and
               Jian Pei and
               Philip S. Yu and
               Lichao Sun},
  title     = {A Comprehensive Survey on Pretrained Foundation Models: {A} History
               from {BERT} to ChatGPT},
  journal   = {CoRR},
  volume    = {abs/2302.09419},
  year      = {2023},
}

@inproceedings{Tang-COLING-2022-Context,
  author       = {Tianyi Tang and
                  Junyi Li and
                  Wayne Xin Zhao and
                  Ji{-}Rong Wen},
  editor       = {Nicoletta Calzolari and
                  Chu{-}Ren Huang and
                  Hansaem Kim and
                  James Pustejovsky and
                  Leo Wanner and
                  Key{-}Sun Choi and
                  Pum{-}Mo Ryu and
                  Hsin{-}Hsi Chen and
                  Lucia Donatelli and
                  Heng Ji and
                  Sadao Kurohashi and
                  Patrizia Paggio and
                  Nianwen Xue and
                  Seokhwan Kim and
                  Younggyun Hahm and
                  Zhong He and
                  Tony Kyungil Lee and
                  Enrico Santus and
                  Francis Bond and
                  Seung{-}Hoon Na},
  title        = {Context-Tuning: Learning Contextualized Prompts for Natural Language
                  Generation},
  booktitle    = {Proceedings of the 29th International Conference on Computational
                  Linguistics, {COLING} 2022, Gyeongju, Republic of Korea, October 12-17,
                  2022},
  pages        = {6340--6354},
  publisher    = {International Committee on Computational Linguistics},
  year         = {2022}
}

@article{hao2022structured,
  title={Structured Prompting: Scaling In-Context Learning to 1,000 Examples},
  author={Hao, Yaru and Sun, Yutao and Dong, Li and Han, Zhixiong and Gu, Yuxian and Wei, Furu},
  journal={arXiv preprint arXiv:2212.06713},
  year={2022}
}

@article{Fedus-JMLR-2021-Switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={J. Mach. Learn. Res},
  pages={1--40},
  year={2021}
}

@article{Tay-ACM-2023-Efficient,
  author    = {Yi Tay and
               Mostafa Dehghani and
               Dara Bahri and
               Donald Metzler},
  title     = {Efficient Transformers: {A} Survey},
  journal   = {{ACM} Comput. Surv.},
  volume    = {55},
  number    = {6},
  pages     = {109:1--109:28},
  year      = {2023}
}

@inproceedings{Du-ICML-2022-GLaM,
  author    = {Nan Du and
               Yanping Huang and
               Andrew M. Dai and
               Simon Tong and
               Dmitry Lepikhin and
               Yuanzhong Xu and
               Maxim Krikun and
               Yanqi Zhou and
               Adams Wei Yu and
               Orhan Firat and
               Barret Zoph and
               Liam Fedus and
               Maarten P. Bosma and
               Zongwei Zhou and
               Tao Wang and
               Yu Emma Wang and
               Kellie Webster and
               Marie Pellat and
               Kevin Robinson and
               Kathleen S. Meier{-}Hellstern and
               Toju Duke and
               Lucas Dixon and
               Kun Zhang and
               Quoc V. Le and
               Yonghui Wu and
               Zhifeng Chen and
               Claire Cui},
  title     = {GLaM: Efficient Scaling of Language Models with Mixture-of-Experts},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  pages     = {5547--5569},
  year      = {2022},
}
@inproceedings{Clark-ICML-2022-Unified,
  author    = {Aidan Clark and
               Diego de Las Casas and
               Aurelia Guy and
               Arthur Mensch and
               Michela Paganini and
               Jordan Hoffmann and
               Bogdan Damoc and
               Blake A. Hechtman and
               Trevor Cai and
               Sebastian Borgeaud and
               George van den Driessche and
               Eliza Rutherford and
               Tom Hennigan and
               Matthew J. Johnson and
               Albin Cassirer and
               Chris Jones and
               Elena Buchatskaya and
               David Budden and
               Laurent Sifre and
               Simon Osindero and
               Oriol Vinyals and
               Marc'Aurelio Ranzato and
               Jack W. Rae and
               Erich Elsen and
               Koray Kavukcuoglu and
               Karen Simonyan},
  title     = {Unified Scaling Laws for Routed Language Models},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  pages     = {4057--4086},
  year      = {2022}
}

@inproceedings{Vaswani-NIPS-2017-Attention,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention is All you Need},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems 2017, December 4-9, 2017,
               Long Beach, CA, {USA}},
  pages     = {5998--6008},
  year      = {2017},
}

@article{Raffel-JMLR-2020-Exploring,
  author    = {Colin Raffel and
               Noam Shazeer and
               Adam Roberts and
               Katherine Lee and
               Sharan Narang and
               Michael Matena and
               Yanqi Zhou and
               Wei Li and
               Peter J. Liu},
  title     = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text
               Transformer},
  journal   = {J. Mach. Learn. Res.},
  pages     = {140:1--140:67},
  year      = {2020},
}

@inproceedings{Lewis-ACL-2020-BART,
  author    = {Mike Lewis and
               Yinhan Liu and
               Naman Goyal and
               Marjan Ghazvininejad and
               Abdelrahman Mohamed and
               Omer Levy and
               Veselin Stoyanov and
               Luke Zettlemoyer},
  title     = {{BART:} Denoising Sequence-to-Sequence Pre-training for Natural Language
               Generation, Translation, and Comprehension},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages     = {7871--7880},
  year      = {2020},
}

@inproceedings{Zhang-ICML-2022-Examining,
  author    = {Biao Zhang and
               Behrooz Ghorbani and
               Ankur Bapna and
               Yong Cheng and
               Xavier Garcia and
               Jonathan Shen and
               Orhan Firat},
  title     = {Examining Scaling and Transfer of Language Model Architectures for
               Machine Translation},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  pages     = {26176--26192},
  year      = {2022},
}

@article{Tay-arxiv-2022-Transcending,
  author    = {Yi Tay and
               Jason Wei and
               Hyung Won Chung and
               Vinh Q. Tran and
               David R. So and
               Siamak Shakeri and
               Xavier Garcia and
               Huaixiu Steven Zheng and
               Jinfeng Rao and
               Aakanksha Chowdhery and
               Denny Zhou and
               Donald Metzler and
               Slav Petrov and
               Neil Houlsby and
               Quoc V. Le and
               Mostafa Dehghani},
  title     = {Transcending Scaling Laws with 0.1{\%} Extra Compute},
  journal   = {CoRR},
  volume    = {abs/2210.11399},
  year      = {2022},
}


@inproceedings{Wang-ICML-2022-What,
  author    = {Thomas Wang and
               Adam Roberts and
               Daniel Hesslow and
               Teven Le Scao and
               Hyung Won Chung and
               Iz Beltagy and
               Julien Launay and
               Colin Raffel},

  title     = {What Language Model Architecture and Pretraining Objective Works Best
               for Zero-Shot Generalization?},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {162},
  pages     = {22964--22984},
  year      = {2022}
}

@inproceedings{Dong-NIPS-2019-Unified,
  author    = {Li Dong and
               Nan Yang and
               Wenhui Wang and
               Furu Wei and
               Xiaodong Liu and
               Yu Wang and
               Jianfeng Gao and
               Ming Zhou and
               Hsiao{-}Wuen Hon},
  title     = {Unified Language Model Pre-training for Natural Language Understanding
               and Generation},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {13042--13054},
  year      = {2019},
}


@article{Scao-arxiv-2022-BLOOM,
  author    = {Teven Le Scao and
               Angela Fan and
               Christopher Akiki and
               Ellie Pavlick and
               Suzana Ilic and
               Daniel Hesslow and
               Roman Castagn{\'{e}} and
               Alexandra Sasha Luccioni and
               Fran{\c{c}}ois Yvon and
               Matthias Gall{\'{e}} and
               Jonathan Tow and
               Alexander M. Rush and
               Stella Biderman and
               Albert Webson and
               Pawan Sasanka Ammanamanchi and
               Thomas Wang and
               Beno{\^{\i}}t Sagot and
               Niklas Muennighoff and
               Albert Villanova del Moral and
               Olatunji Ruwase and
               Rachel Bawden and
               Stas Bekman and
               Angelina McMillan{-}Major and
               Iz Beltagy and
               Huu Nguyen and
               Lucile Saulnier and
               Samson Tan and
               Pedro Ortiz Suarez and
               Victor Sanh and
               Hugo Lauren{\c{c}}on and
               Yacine Jernite and
               Julien Launay and
               Margaret Mitchell and
               Colin Raffel and
               Aaron Gokaslan and
               Adi Simhi and
               Aitor Soroa and
               Alham Fikri Aji and
               Amit Alfassy and
               Anna Rogers and
               Ariel Kreisberg Nitzav and
               Canwen Xu and
               Chenghao Mou and
               Chris Emezue and
               Christopher Klamm and
               Colin Leong and
               Daniel van Strien and
               David Ifeoluwa Adelani and
               et al.},
  title     = {{BLOOM:} {A} 176B-Parameter Open-Access Multilingual Language Model},
  journal   = {CoRR},
  volume    = {abs/2211.05100},
  year      = {2022}
}

@article{Liang-arxiv-2022-Holistic,
  author    = {Percy Liang and
               Rishi Bommasani and
               Tony Lee and
               Dimitris Tsipras and
               Dilara Soylu and
               Michihiro Yasunaga and
               Yian Zhang and
               Deepak Narayanan and
               Yuhuai Wu and
               Ananya Kumar and
               Benjamin Newman and
               Binhang Yuan and
               Bobby Yan and
               Ce Zhang and
               Christian Cosgrove and
               Christopher D. Manning and
               Christopher R{\'{e}} and
               Diana Acosta{-}Navas and
               Drew A. Hudson and
               Eric Zelikman and
               Esin Durmus and
               Faisal Ladhak and
               Frieda Rong and
               Hongyu Ren and
               Huaxiu Yao and
               Jue Wang and
               Keshav Santhanam and
               Laurel J. Orr and
               Lucia Zheng and
               Mert Y{\"{u}}ksekg{\"{o}}n{\"{u}}l and
               Mirac Suzgun and
               Nathan Kim and
               Neel Guha and
               Niladri S. Chatterji and
               Omar Khattab and
               Peter Henderson and
               Qian Huang and
               Ryan Chi and
               Sang Michael Xie and
               Shibani Santurkar and
               Surya Ganguli and
               Tatsunori Hashimoto and
               Thomas Icard and
               Tianyi Zhang and
               Vishrav Chaudhary and
               William Wang and
               Xuechen Li and
               Yifan Mai and
               Yuhui Zhang and
               Yuta Koreeda},
  title     = {Holistic Evaluation of Language Models},
  volume    = {abs/2211.09110},
  journal   = {CoRR},
  year      = {2022},
}

@inproceedings{Joshi-ACL-2017-TriviaQA,
  author    = {Mandar Joshi and
               Eunsol Choi and
               Daniel S. Weld and
               Luke Zettlemoyer},
  title     = {TriviaQA: {A} Large Scale Distantly Supervised Challenge Dataset for
               Reading Comprehension},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2017, Vancouver, Canada, July 30 - August 4, Volume
               1: Long Papers},
  pages     = {1601--1611},
  year      = {2017},
}

@article{Izacard-arxiv-2022-Few,
  author    = {Gautier Izacard and
               Patrick S. H. Lewis and
               Maria Lomeli and
               Lucas Hosseini and
               Fabio Petroni and
               Timo Schick and
               Jane Dwivedi{-}Yu and
               Armand Joulin and
               Sebastian Riedel and
               Edouard Grave},
  title     = {Few-shot Learning with Retrieval Augmented Language Models},
  journal   = {CoRR},
  volume    = {abs/2208.03299},
  year      = {2022},
}

@inproceedings{Roberts-EMNLP-2020-How,
  author    = {Adam Roberts and
               Colin Raffel and
               Noam Shazeer},
  title     = {How Much Knowledge Can You Pack Into the Parameters of a Language
               Model?},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages     = {5418--5426},
  year      = {2020},
}

@article{Nakano-arxiv-2021-WebGPT,
  author    = {Reiichiro Nakano and
               Jacob Hilton and
               Suchir Balaji and
               Jeff Wu and
               Long Ouyang and
               Christina Kim and
               Christopher Hesse and
               Shantanu Jain and
               Vineet Kosaraju and
               William Saunders and
               Xu Jiang and
               Karl Cobbe and
               Tyna Eloundou and
               Gretchen Krueger and
               Kevin Button and
               Matthew Knight and
               Benjamin Chess and
               John Schulman},
  title     = {WebGPT: Browser-assisted question-answering with human feedback},
  journal   = {CoRR},
  volume    = {abs/2112.09332},
  year      = {2021},
}

@inproceedings{Berant-EMNLP-2013-Semantic,
  author    = {Jonathan Berant and
               Andrew Chou and
               Roy Frostig and
               Percy Liang},
  title     = {Semantic Parsing on Freebase from Question-Answer Pairs},
  booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2013, 18-21 October 2013, Grand Hyatt
               Seattle, Seattle, Washington, USA, {A} meeting of SIGDAT, a Special
               Interest Group of the {ACL}},
  pages     = {1533--1544},
  year      = {2013},
}

@article{Kwiatkowski-ACL-2019-Natural,
  author    = {Tom Kwiatkowski and
               Jennimaria Palomaki and
               Olivia Redfield and
               Michael Collins and
               Ankur P. Parikh and
               Chris Alberti and
               Danielle Epstein and
               Illia Polosukhin and
               Jacob Devlin and
               Kenton Lee and
               Kristina Toutanova and
               Llion Jones and
               Matthew Kelcey and
               Ming{-}Wei Chang and
               Andrew M. Dai and
               Jakob Uszkoreit and
               Quoc Le and
               Slav Petrov},
  title     = {Natural Questions: a Benchmark for Question Answering Research},
  journal   = {Trans. Assoc. Comput. Linguistics},
  pages     = {452--466},
  year      = {2019},
}

@inproceedings{Guu-ICML-2020-Retrieval,
  author    = {Kelvin Guu and
               Kenton Lee and
               Zora Tung and
               Panupong Pasupat and
               Ming{-}Wei Chang},
  title     = {Retrieval Augmented Language Model Pre-Training},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  pages     = {3929--3938},
  year      = {2020},
}

@inproceedings{Lewis-NeurIPS-2020-Retrieval,
  author    = {Patrick S. H. Lewis and
               Ethan Perez and
               Aleksandra Piktus and
               Fabio Petroni and
               Vladimir Karpukhin and
               Naman Goyal and
               Heinrich K{\"{u}}ttler and
               Mike Lewis and
               Wen{-}tau Yih and
               Tim Rockt{\"{a}}schel and
               Sebastian Riedel and
               Douwe Kiela},
  title     = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
}

@inproceedings{Goodrich-KDD-2019-Assessing,
  author    = {Ben Goodrich and
               Vinay Rao and
               Peter J. Liu and
               Mohammad Saleh},
  title     = {Assessing The Factual Accuracy of Generated Text},
  booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on
               Knowledge Discovery {\&} Data Mining, {KDD} 2019, Anchorage, AK,
               USA, August 4-8, 2019},
  pages     = {166--175},
  year      = {2019},
}

@inproceedings{Dettmers-AAAI-2018-Convolutional,
  author    = {Tim Dettmers and
               Pasquale Minervini and
               Pontus Stenetorp and
               Sebastian Riedel},
  title     = {Convolutional 2D Knowledge Graph Embeddings},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence,
               (AAAI-18), the 30th innovative Applications of Artificial Intelligence
               (IAAI-18), and the 8th {AAAI} Symposium on Educational Advances in
               Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
               2-7, 2018},
  pages     = {1811--1818},
  year      = {2018},
}

@inproceedings{Toutanova-CVSC-2015-Observed,
  author    = {Kristina Toutanova and
               Danqi Chen},
  title     = {Observed versus latent features for knowledge base and text inference},
  booktitle = {Proceedings of the 3rd Workshop on Continuous Vector Space Models
               and their Compositionality, {CVSC} 2015, Beijing, China, July 26-31,
               2015},
  pages     = {57--66},
  year      = {2015},
}

@article{Shanahan-arxiv-2022-Talking,
  author    = {Murray Shanahan},
  title     = {Talking About Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2212.03551},
  year      = {2022},
}

@article{Wei-arxiv-2022-chain,
  author    = {Jason Wei and
               Xuezhi Wang and
               Dale Schuurmans and
               Maarten Bosma and
               Ed H. Chi and
               Quoc Le and
               Denny Zhou},
  title     = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2201.11903},
  year      = {2022},
}

@article{Cobbe-arxiv-2021-Training,
  author    = {Karl Cobbe and
               Vineet Kosaraju and
               Mohammad Bavarian and
               Jacob Hilton and
               Reiichiro Nakano and
               Christopher Hesse and
               John Schulman},
  title     = {Training Verifiers to Solve Math Word Problems},
  journal   = {CoRR},
  volume    = {abs/2110.14168},
  year      = {2021}
}

@inproceedings{Talmor-naacl-2019-CommonsenseQA,
  author    = {Alon Talmor and
               Jonathan Herzig and
               Nicholas Lourie and
               Jonathan Berant},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {CommonsenseQA: {A} Question Answering Challenge Targeting Commonsense
               Knowledge},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {4149--4158},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
}

@inproceedings{Liu-ACL-2022-What,
  author    = {Jiachang Liu and
               Dinghan Shen and
               Yizhe Zhang and
               Bill Dolan and
               Lawrence Carin and
               Weizhu Chen},
  title     = {What Makes Good In-Context Examples for GPT-3?},
  booktitle = {Proceedings of Deep Learning Inside Out: The 3rd Workshop on Knowledge
               Extraction and Integration for Deep Learning Architectures, DeeLIO@ACL
               2022, Dublin, Ireland and Online, May 27, 2022},
  pages     = {100--114},
  year      = {2022},
}

@article{Dong-arxiv-2023-A,
  author    = {Qingxiu Dong and
               Lei Li and
               Damai Dai and
               Ce Zheng and
               Zhiyong Wu and
               Baobao Chang and
               Xu Sun and
               Jingjing Xu and
               Lei Li and
               Zhifang Sui},
  title     = {A Survey for In-context Learning},
  journal   = {CoRR},
  volume    = {abs/2301.00234},
  year      = {2023},
}

@article{Levy-arxiv-2022-Diverse,
  author    = {Itay Levy and
               Ben Bogin and
               Jonathan Berant},
  title     = {Diverse Demonstrations Improve In-context Compositional Generalization},
  journal   = {CoRR},
  volume    = {abs/2212.06800},
  year      = {2022},
}

@article{liu-arxiv-2023-goat,
  title={Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks},
  author={Liu, Tiedong and Low, Bryan Kian Hsiang},
  journal={arXiv preprint arXiv:2305.14201},
  year={2023}
}

@article{zhou-arxiv-2023-controlled,
  title={Controlled text generation with natural language instructions},
  author={Zhou, Wangchunshu and Jiang, Yuchen Eleanor and Wilcox, Ethan and Cotterell, Ryan and Sachan, Mrinmaya},
  journal={arXiv preprint arXiv:2304.14293},
  year={2023}
}

@inproceedings{Sorensen-ACL-2022-An,
  author    = {Taylor Sorensen and
               Joshua Robinson and
               Christopher Michael Rytting and
               Alexander Glenn Shaw and
               Kyle Jeffrey Rogers and
               Alexia Pauline Delorey and
               Mahmoud Khalil and
               Nancy Fulda and
               David Wingate},
  title     = {An Information-theoretic Approach to Prompt Engineering Without Ground
               Truth Labels},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {819--862},
  year      = {2022},
}

@article{White-arxiv-2023-Prompt,
  title={A prompt pattern catalog to enhance prompt engineering with chatgpt},
  author={White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C},
  journal={arXiv preprint arXiv:2302.11382},
  year={2023}
}

@inproceedings{Liu-arxiv-2022-Design,
  title={Design guidelines for prompt engineering text-to-image generative models},
  author={Liu, Vivian and Chilton, Lydia B},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--23},
  year={2022}
}

@article{Gonen-arxiv-2022-Demystifying,
  author    = {Hila Gonen and
               Srini Iyer and
               Terra Blevins and
               Noah A. Smith and
               Luke Zettlemoyer},
  title     = {Demystifying Prompts in Language Models via Perplexity Estimation},
  journal   = {CoRR},
  volume    = {abs/2212.04037},
  year      = {2022},
}

@article{Kim-arxiv-2022-Self-Generated,
  author    = {Hyuhng Joon Kim and
               Hyunsoo Cho and
               Junyeob Kim and
               Taeuk Kim and
               Kang Min Yoo and
               Sang{-}goo Lee},
  title     = {Self-Generated In-Context Learning: Leveraging Auto-regressive Language
               Models as a Demonstration Generator},
  journal   = {CoRR},
  volume    = {abs/2206.08082},
  year      = {2022},
}

@article{Ganguli-arxiv-2023-The,
  author       = {Deep Ganguli and
                  Amanda Askell and
                  Nicholas Schiefer and
                  Thomas I. Liao and
                  Kamile Lukosiute and
                  Anna Chen and
                  Anna Goldie and
                  Azalia Mirhoseini and
                  Catherine Olsson and
                  Danny Hernandez and
                  Dawn Drain and
                  Dustin Li and
                  Eli Tran{-}Johnson and
                  Ethan Perez and
                  Jackson Kernion and
                  Jamie Kerr and
                  Jared Mueller and
                  Joshua Landau and
                  Kamal Ndousse and
                  Karina Nguyen and
                  Liane Lovitt and
                  Michael Sellitto and
                  Nelson Elhage and
                  Noem{\'{\i}} Mercado and
                  Nova DasSarma and
                  Oliver Rausch and
                  Robert Lasenby and
                  Robin Larson and
                  Sam Ringer and
                  Sandipan Kundu and
                  Saurav Kadavath and
                  Scott Johnston and
                  Shauna Kravec and
                  Sheer El Showk and
                  Tamera Lanham and
                  Timothy Telleen{-}Lawton and
                  Tom Henighan and
                  Tristan Hume and
                  Yuntao Bai and
                  Zac Hatfield{-}Dodds and
                  Ben Mann and
                  Dario Amodei and
                  Nicholas Joseph and
                  Sam McCandlish and
                  Tom Brown and
                  Christopher Olah and
                  Jack Clark and
                  Samuel R. Bowman and
                  Jared Kaplan},
  title        = {The Capacity for Moral Self-Correction in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2302.07459},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2302.07459},
  doi          = {10.48550/arXiv.2302.07459},
  eprinttype    = {arXiv},
  eprint       = {2302.07459}
}

@article{Krishna-PNAS-2022-Socially,
  title={Socially situated artificial intelligence enables learning from human interaction},
  author={Ranjay Krishna and Donsuk Lee and Li Fei-Fei and Michael S. Bernstein},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  year={2022},
  volume={119},
  url={https://api.semanticscholar.org/CorpusID:252381954}
}

@article{Ziegler-arxiv-2019-Fine-Tuning,
  author    = {Daniel M. Ziegler and
               Nisan Stiennon and
               Jeffrey Wu and
               Tom B. Brown and
               Alec Radford and
               Dario Amodei and
               Paul F. Christiano and
               Geoffrey Irving},
  title     = {Fine-Tuning Language Models from Human Preferences},
  journal   = {CoRR},
  volume    = {abs/1909.08593},
  year      = {2019},
}


@article{Stiennon-arxiv-2020-learning,
  author    = {Nisan Stiennon and
               Long Ouyang and
               Jeff Wu and
               Daniel M. Ziegler and
               Ryan Lowe and
               Chelsea Voss and
               Alec Radford and
               Dario Amodei and
               Paul F. Christiano},
  title     = {Learning to summarize from human feedback},
  journal   = {CoRR},
  volume    = {abs/2009.01325},
  year      = {2020},
}

@article{Longpre-arxiv-2023-pretrainer,
  title={A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, \& Toxicity},
  author={Longpre, Shayne and Yauney, Gregory and Reif, Emily and Lee, Katherine and Roberts, Adam and Zoph, Barret and Zhou, Denny and Wei, Jason and Robinson, Kevin and Mimno, David and others},
  journal={arXiv preprint arXiv:2305.13169},
  year={2023}
}

@article{Xie-arxiv-2023-doremi,
  title={DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining},
  author={Xie, Sang Michael and Pham, Hieu and Dong, Xuanyi and Du, Nan and Liu, Hanxiao and Lu, Yifeng and Liang, Percy and Le, Quoc V and Ma, Tengyu and Yu, Adams Wei},
  journal={arXiv preprint arXiv:2305.10429},
  year={2023}
}

@article{Xie-arxiv-2023-DSIR,
  title={Data selection for language models via importance resampling},
  author={Xie, Sang Michael and Santurkar, Shibani and Ma, Tengyu and Liang, Percy},
  journal={arXiv preprint arXiv:2302.03169},
  year={2023}
}

@misc{Rose-arxiv-2023-Personalisation,
  author = {Kirk, Hannah Rose and Vidgen, Bertie and Röttger, Paul and Hale, Scott A.},
  title = {Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback},
  publisher = {arXiv},
  year = {2023},
}


@article{Menick-arxiv-2022-teaching,
  author    = {Jacob Menick and
               Maja Trebacz and
               Vladimir Mikulik and
               John Aslanides and
               H. Francis Song and
               Martin Chadwick and
               Mia Glaese and
               Susannah Young and
               Lucy Campbell{-}Gillingham and
               Geoffrey Irving and
               Nat McAleese},
  title     = {Teaching language models to support answers with verified quotes},
  journal   = {CoRR},
  volume    = {abs/2203.11147},
  year      = {2022},
}

@article{wu-arxiv-2021-recursively,
  author    = {Jeff Wu and
               Long Ouyang and
               Daniel M. Ziegler and
               Nisan Stiennon and
               Ryan Lowe and
               Jan Leike and
               Paul F. Christiano},
  title     = {Recursively Summarizing Books with Human Feedback},
  journal   = {CoRR},
  volume    = {abs/2109.10862},
  year      = {2021},
}

@article{Wang-arxiv-2023-Large,
  author    = {Xinyi Wang and
               Wanrong Zhu and
               William Yang Wang},
  title     = {Large Language Models Are Implicitly Topic Models: Explaining and
               Finding Good Demonstrations for In-Context Learning},
  journal   = {CoRR},
  volume    = {abs/2301.11916},
  year      = {2023},
}

@inproceedings{Zhang-EMNLP-2022-Active,
  author    = {Yiming Zhang and
               Shi Feng and
               Chenhao Tan},
  title     = {Active Example Selection for In-Context Learning},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {9134--9148},
  year      = {2022},
}

@inproceedings{Rubin-NAACL-2022-Learning,
  author    = {Ohad Rubin and
               Jonathan Herzig and
               Jonathan Berant},
  title     = {Learning To Retrieve Prompts for In-Context Learning},
  booktitle = {Proceedings of the 2022 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL} 2022, Seattle, WA, United States, July 10-15, 2022},
  pages     = {2655--2671},
  year      = {2022},
}

@inproceedings{Mishra-ACL-2022-Cross,
  author    = {Swaroop Mishra and
               Daniel Khashabi and
               Chitta Baral and
               Hannaneh Hajishirzi},
  editor    = {Smaranda Muresan and
               Preslav Nakov and
               Aline Villavicencio},
  title     = {Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {3470--3487},
  year      = {2022}
}

@misc{Chen-2023-arxiv-Data,
      title={Data-Juicer: A One-Stop Data Processing System for Large Language Models}, 
      author={Daoyuan Chen and Yilun Huang and Zhijian Ma and Hesen Chen and Xuchen Pan and Ce Ge and Dawei Gao and Yuexiang Xie and Zhaoyang Liu and Jinyang Gao and Yaliang Li and Bolin Ding and Jingren Zhou},
      year={2023},
      eprint={2309.02033},
      archivePrefix={arXiv}
}

@article{Efrat-arXiv-20-The,
  author    = {Avia Efrat and
               Omer Levy},
  title     = {The Turking Test: Can Language Models Understand Instructions?},
  journal   = {CoRR},
  volume    = {abs/2010.11982},
  year      = {2020},
}

@misc{Kuang-2023-arxiv-FederatedScope,
      title={FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning}, 
      author={Weirui Kuang and Bingchen Qian and Zitao Li and Daoyuan Chen and Dawei Gao and Xuchen Pan and Yuexiang Xie and Yaliang Li and Bolin Ding and Jingren Zhou},
      year={2023},
      eprint={2309.00363},
      archivePrefix={arXiv}
}

@article{schulman-arxiv-2017-proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{Jimmy-arxiv-2016-Layer,
  author    = {Lei Jimmy Ba and
               Jamie Ryan Kiros and
               Geoffrey E. Hinton},
  title     = {Layer Normalization},
  volume    = {abs/1607.06450},
  year      = {2016},
}

@inproceedings{Zhang-NIPS-2019-Root,
  author    = {Biao Zhang and
               Rico Sennrich},
  title     = {Root Mean Square Layer Normalization},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {12360--12371},
  year      = {2019}
}

@article{Wang-arxiv-2022-DeepNet,
  author    = {Hongyu Wang and
               Shuming Ma and
               Li Dong and
               Shaohan Huang and
               Dongdong Zhang and
               Furu Wei},
  title     = {DeepNet: Scaling Transformers to 1, 000 Layers},
  volume    = {abs/2203.00555},
  year      = {2022},
}


@article{Hoffmann-arxiv-2022-Training,
  author    = {Jordan Hoffmann and
               Sebastian Borgeaud and
               Arthur Mensch and
               Elena Buchatskaya and
               Trevor Cai and
               Eliza Rutherford and
               Diego de Las Casas and
               Lisa Anne Hendricks and
               Johannes Welbl and
               Aidan Clark and
               Tom Hennigan and
               Eric Noland and
               Katie Millican and
               George van den Driessche and
               Bogdan Damoc and
               Aurelia Guy and
               Simon Osindero and
               Karen Simonyan and
               Erich Elsen and
               Jack W. Rae and
               Oriol Vinyals and
               Laurent Sifre},
  title     = {Training Compute-Optimal Large Language Models},
  volume    = {abs/2203.15556},
  year      = {2022},

}

@inproceedings{Narang-EMNLP-2021-Do,
  author    = {Sharan Narang and
               Hyung Won Chung and
               Yi Tay and
               Liam Fedus and
               Thibault F{\'{e}}vry and
               Michael Matena and
               Karishma Malkan and
               Noah Fiedel and
               Noam Shazeer and
               Zhenzhong Lan and
               Yanqi Zhou and
               Wei Li and
               Nan Ding and
               Jake Marcus and
               Adam Roberts and
               Colin Raffel},
  title     = {Do Transformer Modifications Transfer Across Implementations and Applications?},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
               Republic, 7-11 November, 2021},
  pages     = {5758--5773},
  year      = {2021},
}

@inproceedings{Le-EMNLP-2022-What,
  author    = {Teven Le Scao and
               Thomas Wang and
               Daniel Hesslow and
               Stas Bekman and
               M. Saiful Bari and
               Stella Biderman and
               Hady Elsahar and
               Niklas Muennighoff and
               Jason Phang and
               Ofir Press and
               Colin Raffel and
               Victor Sanh and
               Sheng Shen and
               Lintang Sutawika and
               Jaesung Tae and
               Zheng Xin Yong and
               Julien Launay and
               Iz Beltagy},
  title     = {What Language Model to Train if You Have One Million {GPU} Hours?},
  booktitle = {Findings of the Association for Computational Linguistics: {EMNLP}
               2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages     = {765--782},
  year      = {2022},
}

@article{Yang-NeurIPS-2019-xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{Dubois-arxiv-2023-AlpacaFarm,
  author       = {Yann Dubois and
                  Xuechen Li and
                  Rohan Taori and
                  Tianyi Zhang and
                  Ishaan Gulrajani and
                  Jimmy Ba and
                  Carlos Guestrin and
                  Percy Liang and
                  Tatsunori B. Hashimoto},
  title        = {AlpacaFarm: {A} Simulation Framework for Methods that Learn from Human
                  Feedback},
  journal      = {CoRR},
  volume       = {abs/2305.14387},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.14387},
  doi          = {10.48550/arXiv.2305.14387},
  eprinttype    = {arXiv},
  eprint       = {2305.14387}
}

@article{Ebtesam-arxiv-2023-Falcon,
  title={{Falcon-40B}: an open large language model with state-of-the-art performance},
  author={Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme},
  year={2023}
}

@article{Zeng-arxiv-2022-GLM,
  author    = {Aohan Zeng and
               Xiao Liu and
               Zhengxiao Du and
               Zihan Wang and
               Hanyu Lai and
               Ming Ding and
               Zhuoyi Yang and
               Yifan Xu and
               Wendi Zheng and
               Xiao Xia and
               Weng Lam Tam and
               Zixuan Ma and
               Yufei Xue and
               Jidong Zhai and
               Wenguang Chen and
               Peng Zhang and
               Yuxiao Dong and
               Jie Tang},
  title     = {{GLM-130B:} An Open Bilingual Pre-trained Model},
  volume    = {abs/2210.02414},
  year      = {2022},
}

@inproceedings{Press-ICLR-2022-Train,
  author    = {Ofir Press and
               Noah A. Smith and
               Mike Lewis},
  title     = {Train Short, Test Long: Attention with Linear Biases Enables Input
               Length Extrapolation},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  year      = {2022},
}
@article{Su-arxiv-2021-Roformer,
  author    = {Jianlin Su and
               Yu Lu and
               Shengfeng Pan and
               Bo Wen and
               Yunfeng Liu},
  title     = {RoFormer: Enhanced Transformer with Rotary Position Embedding},

  volume    = {abs/2104.09864},
  year      = {2021},

}

@article{Dan-arxiv-2016-Gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{Shazeer-arxiv-2020-GLU,
  author    = {Noam Shazeer},
  title     = {{GLU} Variants Improve Transformer},
  volume    = {abs/2002.05202},
  year      = {2020},
}

@inproceedings{Dauphin-ICML-2017-Language,
  author    = {Yann N. Dauphin and
               Angela Fan and
               Michael Auli and
               David Grangier},
  title     = {Language Modeling with Gated Convolutional Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  pages     = {933--941},
  year      = {2017}
}

@article{Fu-arxiv-2022-Complexity,
  author    = {Yao Fu and
               Hao Peng and
               Ashish Sabharwal and
               Peter Clark and
               Tushar Khot},
  title     = {Complexity-Based Prompting for Multi-Step Reasoning},
  journal   = {CoRR},
  volume    = {abs/2210.00720},
  year      = {2022},
}

@article{Zhang-arxiv-2022-Automatic,
  author    = {Zhuosheng Zhang and
               Aston Zhang and
               Mu Li and
               Alex Smola},
  title     = {Automatic Chain of Thought Prompting in Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2210.03493},
  year      = {2022},
}

@inproceedings{Aghajanyan-EMNLP-2021-Muppet,
  author    = {Armen Aghajanyan and
               Anchit Gupta and
               Akshat Shrivastava and
               Xilun Chen and
               Luke Zettlemoyer and
               Sonal Gupta},
  title     = {Muppet: Massive Multi-task Representations with Pre-Finetuning},
  booktitle = {{EMNLP} {(1)}},
  pages     = {5799--5811},
  publisher = {Association for Computational Linguistics},
  year      = {2021}
}

@inproceedings{Aribandi-ICLR-2022-ExT5,
  author    = {Vamsi Aribandi and
               Yi Tay and
               Tal Schuster and
               Jinfeng Rao and
               Huaixiu Steven Zheng and
               Sanket Vaibhav Mehta and
               Honglei Zhuang and
               Vinh Q. Tran and
               Dara Bahri and
               Jianmo Ni and
               Jai Prakash Gupta and
               Kai Hui and
               Sebastian Ruder and
               Donald Metzler},
  title     = {ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning},
  booktitle = {{ICLR}},
  publisher = {OpenReview.net},
  year      = {2022}
}

@article{Tang-arxiv-2022-MVP,
  author    = {Tianyi Tang and
               Junyi Li and
               Wayne Xin Zhao and
               Ji{-}Rong Wen},
  title     = {{MVP:} Multi-task Supervised Pre-training for Natural Language Generation},
  journal   = {CoRR},
  volume    = {abs/2206.12131},
  year      = {2022}
}

@inproceedings{Liu-ACL-2019-Multi,
  author    = {Xiaodong Liu and
               Pengcheng He and
               Weizhu Chen and
               Jianfeng Gao},
  title     = {Multi-Task Deep Neural Networks for Natural Language Understanding},
  booktitle = {{ACL} {(1)}},
  pages     = {4487--4496},
  publisher = {Association for Computational Linguistics},
  year      = {2019}
}

@inproceedings{Khashabi-EMNLP-2020-UnifiedQA,
  author    = {Daniel Khashabi and
               Sewon Min and
               Tushar Khot and
               Ashish Sabharwal and
               Oyvind Tafjord and
               Peter Clark and
               Hannaneh Hajishirzi},
  title     = {UnifiedQA: Crossing Format Boundaries With a Single {QA} System},
  booktitle = {{EMNLP} (Findings)},
  series    = {Findings of {ACL}},
  volume    = {{EMNLP} 2020},
  pages     = {1896--1907},
  publisher = {Association for Computational Linguistics},
  year      = {2020}
}

@article{Kojima-arxiv-2022-Large,
  author    = {Takeshi Kojima and
               Shixiang Shane Gu and
               Machel Reid and
               Yutaka Matsuo and
               Yusuke Iwasawa},
  title     = {Large Language Models are Zero-Shot Reasoners},
  journal   = {CoRR},
  volume    = {abs/2205.11916},
  year      = {2022},
  
}

@article{Wang-arxiv-2022-Self-Consistency,
  author    = {Xuezhi Wang and
               Jason Wei and
               Dale Schuurmans and
               Quoc V. Le and
               Ed H. Chi and
               Denny Zhou},
  title     = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  journal   = {CoRR},
  volume    = {abs/2203.11171},
  year      = {2022},
  
}

@article{Wang-arxiv-2022-Rationale,
  author    = {Xuezhi Wang and
               Jason Wei and
               Dale Schuurmans and
               Quoc V. Le and
               Ed H. Chi and
               Denny Zhou},
  title     = {Rationale-Augmented Ensembles in Language Models},
  journal   = {CoRR},
  year      = {2022},
}

@article{Muennighoff-2022-arxiv-Crosslingual,
  author    = {Niklas Muennighoff and
               Thomas Wang and
               Lintang Sutawika and
               Adam Roberts and
               Stella Biderman and
               Teven Le Scao and
               M. Saiful Bari and
               Sheng Shen and
               Zheng Xin Yong and
               Hailey Schoelkopf and
               Xiangru Tang and
               Dragomir Radev and
               Alham Fikri Aji and
               Khalid Almubarak and
               Samuel Albanie and
               Zaid Alyafeai and
               Albert Webson and
               Edward Raff and
               Colin Raffel},
  title     = {Crosslingual Generalization through Multitask Finetuning},
  journal   = {CoRR},
  volume    = {abs/2211.01786},
  year      = {2022},
}

@inproceedings{Holtzman-2019-ICLR-The,
  author    = {Ari Holtzman and
               Jan Buys and
               Li Du and
               Maxwell Forbes and
               Yejin Choi},
  title     = {The Curious Case of Neural Text Degeneration},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  
}

@article{Li-arxiv-2022-On,
  author    = {Yifei Li and
               Zeqi Lin and
               Shizhuo Zhang and
               Qiang Fu and
               Bei Chen and
               Jian{-}Guang Lou and
               Weizhu Chen},
  title     = {On the Advance of Making Language Models Better Reasoners},
  journal   = {CoRR},
  volume    = {abs/2206.02336},
  year      = {2022},

}


@article{Zelikman-arxiv-2022-Star,
  title={Star: Self-taught reasoner bootstrapping reasoning with reasoning},
  author={Zelikman, Eric and Mu, Jesse and Goodman, Noah D and Wu, Yuhuai Tony},
  year={2022}
}

@inproceedings{Carlini-USENIX-2021-Extracting,
  author    = {Nicholas Carlini and
               Florian Tram{\`{e}}r and
               Eric Wallace and
               Matthew Jagielski and
               Ariel Herbert{-}Voss and
               Katherine Lee and
               Adam Roberts and
               Tom B. Brown and
               Dawn Song and
               {\'{U}}lfar Erlingsson and
               Alina Oprea and
               Colin Raffel},
  title     = {Extracting Training Data from Large Language Models},
  booktitle = {30th {USENIX} Security Symposium, {USENIX} Security 2021, August 11-13,
               2021},
  pages     = {2633--2650},
  year      = {2021},
}

@inproceedings{Laurencon-NIPS-2022-The,
  title={The bigscience roots corpus: A 1.6 tb composite multilingual dataset},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Wang, Thomas and Akiki, Christopher and del Moral, Albert Villanova and Le Scao, Teven and Von Werra, Leandro and Mou, Chenghao and Ponferrada, Eduardo Gonz{\'a}lez and Nguyen, Huu and others},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022}
}

@inproceedings{Kandpal-ICML-2022-Deduplicating,
  author    = {Nikhil Kandpal and
               Eric Wallace and
               Colin Raffel},
  title     = {Deduplicating Training Data Mitigates Privacy Risks in Language Models},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  pages     = {10697--10707},
  publisher = {{PMLR}},
  year      = {2022},
}

@inproceedings{Ding-ACL-2021-ERNIE,
  author    = {Siyu Ding and
               Junyuan Shang and
               Shuohuan Wang and
               Yu Sun and
               Hao Tian and
               Hua Wu and
               Haifeng Wang},
  editor    = {Chengqing Zong and
               Fei Xia and
               Wenjie Li and
               Roberto Navigli},
  title     = {ERNIE-Doc: {A} Retrospective Long-Document Modeling Transformer},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational
               Linguistics and the 11th International Joint Conference on Natural
               Language Processing, {ACL/IJCNLP} 2021, (Volume 1: Long Papers), Virtual
               Event, August 1-6, 2021},
  pages     = {2914--2927},
  year      = {2021},
}

@inproceedings{Clark-ICLR-2020-ELECTRA,
  author    = {Kevin Clark and
               Minh{-}Thang Luong and
               Quoc V. Le and
               Christopher D. Manning},
  title     = {{ELECTRA:} Pre-training Text Encoders as Discriminators Rather Than
               Generators},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  year      = {2020},
}



@inproceedings{Wang-EMNLP-2018-GLUE,
  author    = {Alex Wang and
               Amanpreet Singh and
               Julian Michael and
               Felix Hill and
               Omer Levy and
               Samuel R. Bowman},
  editor    = {Tal Linzen and
               Grzegorz Chrupala and
               Afra Alishahi},
  title     = {{GLUE:} {A} Multi-Task Benchmark and Analysis Platform for Natural
               Language Understanding},
  booktitle = {Proceedings of the Workshop: Analyzing and Interpreting Neural Networks
               for NLP, BlackboxNLP@EMNLP 2018, Brussels, Belgium, November 1, 2018},
  pages     = {353--355},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
}

@article{Cho-arxiv-2022-Prompt,
  author    = {Hyunsoo Cho and
               Hyuhng Joon Kim and
               Junyeob Kim and
               Sang{-}Woo Lee and
               Sang{-}goo Lee and
               Kang Min Yoo and
               Taeuk Kim},
  title     = {Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot
               In-Context Learners},
  journal   = {CoRR},
  volume    = {abs/2212.10873},
  year      = {2022},
}

@article{Xi-arxiv-2022-The,
  title={The unreliability of explanations in few-shot prompting for textual reasoning},
  author={Ye, Xi and Durrett, Greg},
  journal={Advances in neural information processing systems},
  year={2022}
}

@inproceedings{Zhao-ICML-2021-Calibrate,
  author    = {Zihao Zhao and
               Eric Wallace and
               Shi Feng and
               Dan Klein and
               Sameer Singh},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Calibrate Before Use: Improving Few-shot Performance of Language Models},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  pages     = {12697--12706},
  year      = {2021}
}

@article{Wu-arxiv-2022-Self,
  author    = {Zhiyong Wu and
               Yaoxiang Wang and
               Jiacheng Ye and
               Lingpeng Kong},
  title     = {Self-adaptive In-context Learning},
  journal   = {CoRR},
  volume    = {abs/2212.10375},
  year      = {2022},
}

@inproceedings{Michael-ICLR-2022-An,
  author    = {Sang Michael Xie and
               Aditi Raghunathan and
               Percy Liang and
               Tengyu Ma},
  title     = {An Explanation of In-context Learning as Implicit Bayesian Inference},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  year      = {2022}
}

@inproceedings{Lu-ACL-2022-Fantasically,
  author    = {Yao Lu and
               Max Bartolo and
               Alastair Moore and
               Sebastian Riedel and
               Pontus Stenetorp},
  editor    = {Smaranda Muresan and
               Preslav Nakov and
               Aline Villavicencio},
  title     = {Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot
               Prompt Order Sensitivity},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {8086--8098},
  year      = {2022}
}

@article{Chung-arxiv-2022-Scaling,
  author    = {Hyung Won Chung and
               Le Hou and
               Shayne Longpre and
               Barret Zoph and
               Yi Tay and
               William Fedus and
               Eric Li and
               Xuezhi Wang and
               Mostafa Dehghani and
               Siddhartha Brahma and
               Albert Webson and
               Shixiang Shane Gu and
               Zhuyun Dai and
               Mirac Suzgun and
               Xinyun Chen and
               Aakanksha Chowdhery and
               Sharan Narang and
               Gaurav Mishra and
               Adams Yu and
               Vincent Y. Zhao and
               Yanping Huang and
               Andrew M. Dai and
               Hongkun Yu and
               Slav Petrov and
               Ed H. Chi and
               Jeff Dean and
               Jacob Devlin and
               Adam Roberts and
               Denny Zhou and
               Quoc V. Le and
               Jason Wei},
  title     = {Scaling Instruction-Finetuned Language Models},
  journal   = {CoRR},
  volume    = {abs/2210.11416},
  year      = {2022},
}

@article{Chan-arxiv-2022-Data,
  author    = {Stephanie C. Y. Chan and
               Adam Santoro and
               Andrew K. Lampinen and
               Jane X. Wang and
               Aaditya Singh and
               Pierre H. Richemond and
               Jay McClelland and
               Felix Hill},
  title     = {Data Distributional Properties Drive Emergent In-Context Learning
               in Transformers},
  journal   = {CoRR},
  volume    = {abs/2205.05055},
  year      = {2022}
}

@inproceedings{Houlsby-ICML-2019-Parameter,
  author    = {Neil Houlsby and
               Andrei Giurgiu and
               Stanislaw Jastrzebski and
               Bruna Morrone and
               Quentin de Laroussilhe and
               Andrea Gesmundo and
               Mona Attariyan and
               Sylvain Gelly},
  title     = {Parameter-Efficient Transfer Learning for {NLP}},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning,
               {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}},
  pages     = {2790--2799},
  year      = {2019},
}

@article{Liu-survey-2023-Pre-train,
  author    = {Pengfei Liu and
               Weizhe Yuan and
               Jinlan Fu and
               Zhengbao Jiang and
               Hiroaki Hayashi and
               Graham Neubig},
  title     = {Pre-train, Prompt, and Predict: {A} Systematic Survey of Prompting
               Methods in Natural Language Processing},
  journal   = {{ACM} Comput. Surv.},
  pages     = {195:1--195:35},
  year      = {2023},
}

@article{Longpre-arxiv-2023-The,
  author    = {Shayne Longpre and
               Le Hou and
               Tu Vu and
               Albert Webson and
               Hyung Won Chung and
               Yi Tay and
               Denny Zhou and
               Quoc V. Le and
               Barret Zoph and
               Jason Wei and
               Adam Roberts},
  title     = {The Flan Collection: Designing Data and Methods for Effective Instruction
               Tuning},
  journal   = {CoRR},
  volume    = {abs/2301.13688},
  year      = {2023},
}

@inproceedings{Min-NAACL-2022-MetaICL,
  author    = {Sewon Min and
               Mike Lewis and
               Luke Zettlemoyer and
               Hannaneh Hajishirzi},
  editor    = {Marine Carpuat and
               Marie{-}Catherine de Marneffe and
               Iv{\'{a}}n Vladimir Meza Ru{\'{\i}}z},
  title     = {MetaICL: Learning to Learn In Context},
  booktitle = {Proceedings of the 2022 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL} 2022, Seattle, WA, United States, July 10-15, 2022},
  pages     = {2791--2809},
  year      = {2022}
}

@article{Oswald-arxiv-2022-Transformers,
  author    = {Johannes von Oswald and
               Eyvind Niklasson and
               Ettore Randazzo and
               Jo{\~{a}}o Sacramento and
               Alexander Mordvintsev and
               Andrey Zhmoginov and
               Max Vladymyrov},
  title     = {Transformers learn in-context by gradient descent},
  journal   = {CoRR},
  volume    = {abs/2212.07677},
  year      = {2022},
}

@article{Dai-arxiv-2022-Why,
  author    = {Damai Dai and
               Yutao Sun and
               Li Dong and
               Yaru Hao and
               Zhifang Sui and
               Furu Wei},
  title     = {Why Can {GPT} Learn In-Context? Language Models Secretly Perform Gradient
               Descent as Meta-Optimizers},
  journal   = {CoRR},
  volume    = {abs/2212.10559},
  year      = {2022}
}

@article{Olsson-arxiv-2022-In,
  author    = {Catherine Olsson and
               Nelson Elhage and
               Neel Nanda and
               Nicholas Joseph and
               Nova DasSarma and
               Tom Henighan and
               Ben Mann and
               Amanda Askell and
               Yuntao Bai and
               Anna Chen and
               Tom Conerly and
               Dawn Drain and
               Deep Ganguli and
               Zac Hatfield{-}Dodds and
               Danny Hernandez and
               Scott Johnston and
               Andy Jones and
               Jackson Kernion and
               Liane Lovitt and
               Kamal Ndousse and
               Dario Amodei and
               Tom Brown and
               Jack Clark and
               Jared Kaplan and
               Sam McCandlish and
               Chris Olah},
  title     = {In-context Learning and Induction Heads},
  journal   = {CoRR},
  volume    = {abs/2209.11895},
  year      = {2022}
}

@article{Bansal-arxiv-2022-Rethinking,
  author    = {Hritik Bansal and
               Karthik Gopalakrishnan and
               Saket Dingliwal and
               Sravan Bodapati and
               Katrin Kirchhoff and
               Dan Roth},
  title     = {Rethinking the Role of Scale for In-Context Learning: An Interpretability-based
               Case Study at 66 Billion Scale},
  journal   = {CoRR},
  volume    = {abs/2212.09095},
  year      = {2022},
}

@article{Li-arxiv-2023-Transformers,
  author    = {Yingcong Li and
               M. Emrullah Ildiz and
               Dimitris S. Papailiopoulos and
               Samet Oymak},
  title     = {Transformers as Algorithms: Generalization and Implicit Model Selection
               in In-context Learning},
  journal   = {CoRR},
  volume    = {abs/2301.07067},
  year      = {2023}
}

@article{Madaan-arxiv-2022-Text,
  author    = {Aman Madaan and
               Amir Yazdanbakhsh},
  title     = {Text and Patterns: For Effective Chain of Thought, It Takes Two to
               Tango},
  journal   = {CoRR},
  volume    = {abs/2209.07686},
  year      = {2022},
  
}

@article{rek-arxiv-2022-what,
  author    = {Ekin Aky{\"{u}}rek and
               Dale Schuurmans and
               Jacob Andreas and
               Tengyu Ma and
               Denny Zhou},
  title     = {What learning algorithm is in-context learning? Investigations with
               linear models},
  journal   = {CoRR},
  volume    = {abs/2211.15661},
  year      = {2022}
}


@article{Iyer-arxiv-2022-OPT,
  author    = {Srinivasan Iyer and
               Xi Victoria Lin and
               Ramakanth Pasunuru and
               Todor Mihaylov and
               Daniel Simig and
               Ping Yu and
               Kurt Shuster and
               Tianlu Wang and
               Qing Liu and
               Punit Singh Koura and
               Xian Li and
               Brian O'Horo and
               Gabriel Pereyra and
               Jeff Wang and
               Christopher Dewan and
               Asli Celikyilmaz and
               Luke Zettlemoyer and
               Ves Stoyanov},
  title     = {{OPT-IML:} Scaling Language Model Instruction Meta Learning through
               the Lens of Generalization},
  journal   = {CoRR},
  volume    = {abs/2212.12017},
  year      = {2022}
}

@article{Wang-arxiv-2022-Towards,
  author    = {Boshi Wang and
               Sewon Min and
               Xiang Deng and
               Jiaming Shen and
               You Wu and
               Luke Zettlemoyer and
               Huan Sun},
  title     = {Towards Understanding Chain-of-Thought Prompting: An Empirical Study
               of What Matters},
  journal   = {CoRR},
  volume    = {abs/2212.10001},
  year      = {2022},
  
}

@article{Zhang-arxiv-2022-Multimodal,
  author    = {Zhuosheng Zhang and
               Aston Zhang and
               Mu Li and
               Hai Zhao and
               George Karypis and
               Alex Smola},
  title     = {Multimodal Chain-of-Thought Reasoning in Language Models},
  journal   = {CoRR},
  volume    = {abs/2302.00923},
  year      = {2023},
  
}



@article{Schick-arxiv-2023-Toolformer,
  author    = {Timo Schick and
               Jane Dwivedi{-}Yu and
               Roberto Dess{\`{\i}} and
               Roberta Raileanu and
               Maria Lomeli and
               Luke Zettlemoyer and
               Nicola Cancedda and
               Thomas Scialom},
  title     = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  journal   = {CoRR},
  volume    = {abs/2302.04761},
  year      = {2023},
}

@article{Khattab-arxiv-2022-Demonstrate,
  author    = {Omar Khattab and
               Keshav Santhanam and
               Xiang Lisa Li and
               David Hall and
               Percy Liang and
               Christopher Potts and
               Matei Zaharia},
  title     = {Demonstrate-Search-Predict: Composing retrieval and language models
               for knowledge-intensive {NLP}},
  journal   = {CoRR},
  volume    = {abs/2212.14024},
  year      = {2022},
}

@article{Trivedi-arxiv-2022-Interleaving,
  author    = {Harsh Trivedi and
               Niranjan Balasubramanian and
               Tushar Khot and
               Ashish Sabharwal},
  title     = {Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive
               Multi-Step Questions},
  journal   = {CoRR},
  volume    = {abs/2212.10509},
  year      = {2022},
}

@article{Yao-arxiv-2022-ReAct,
  author    = {Shunyu Yao and
               Jeffrey Zhao and
               Dian Yu and
               Nan Du and
               Izhak Shafran and
               Karthik Narasimhan and
               Yuan Cao},
  title     = {ReAct: Synergizing Reasoning and Acting in Language Models},
  journal   = {CoRR},
  volume    = {abs/2210.03629},
  year      = {2022},
}

@article{Huang-arxiv-2022-Towards,
  author    = {Jie Huang and
               Kevin Chen{-}Chuan Chang},
  title     = {Towards Reasoning in Large Language Models: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2212.10403},
  year      = {2022},
}
@article{Anil-arxiv-2022-Exploring,
  author    = {Cem Anil and
               Yuhuai Wu and
               Anders Andreassen and
               Aitor Lewkowycz and
               Vedant Misra and
               Vinay V. Ramasesh and
               Ambrose Slone and
               Guy Gur{-}Ari and
               Ethan Dyer and
               Behnam Neyshabur},
  title     = {Exploring Length Generalization in Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2207.04901},
  year      = {2022},
}
@article{Nye-arxiv-2021-Show,
  author    = {Maxwell I. Nye and
               Anders Johan Andreassen and
               Guy Gur{-}Ari and
               Henryk Michalewski and
               Jacob Austin and
               David Bieber and
               David Dohan and
               Aitor Lewkowycz and
               Maarten Bosma and
               David Luan and
               Charles Sutton and
               Augustus Odena},
  title     = {Show Your Work: Scratchpads for Intermediate Computation with Language
               Models},
  journal   = {CoRR},
  volume    = {abs/2112.00114},
  year      = {2021},
}
@article{Qian-arxiv-2022-Limitations,
  author    = {Jing Qian and
               Hong Wang and
               Zekun Li and
               Shiyang Li and
               Xifeng Yan},
  title     = {Limitations of Language Models in Arithmetic and Symbolic Induction},
  journal   = {CoRR},
  volume    = {abs/2208.05051},
  year      = {2022},
}
@article{Saikh-IJDL-2022-ScienceQA,
  author    = {Tanik Saikh and
               Tirthankar Ghosal and
               Amish Mittal and
               Asif Ekbal and
               Pushpak Bhattacharyya},
  title     = {ScienceQA: a novel resource for question answering on scholarly articles},
  journal   = {Int. J. Digit. Libr.},
  volume    = {23},
  number    = {3},
  pages     = {289--301},
  year      = {2022},
}

@inproceedings{Madaan-emnlp-2022-Language,
  author    = {Aman Madaan and
               Shuyan Zhou and
               Uri Alon and
               Yiming Yang and
               Graham Neubig},
  editor    = {Yoav Goldberg and
               Zornitsa Kozareva and
               Yue Zhang},
  title     = {Language Models of Code are Few-Shot Commonsense Learners},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {1384--1403},
  publisher = {Association for Computational Linguistics},
  year      = {2022},
}
@inproceedings{Tay-arxiv-2022-UL2,
  title={UL2: Unifying Language Learning Paradigms},
  author={Yi Tay and Mostafa Dehghani and Vinh Quang Tran and Xavier Garc{\'i}a and Jason Wei and Xuezhi Wang and Hyung Won Chung and Dara Bahri and Tal Schuster and Huaixiu Zheng and Denny Zhou and Neil Houlsby and Donald Metzler},
  year={2022}
}
@article{Qin-arxiv-2023-Is,
  author    = {Chengwei Qin and
               Aston Zhang and
               Zhuosheng Zhang and
               Jiaao Chen and
               Michihiro Yasunaga and
               Diyi Yang},
  title     = {Is ChatGPT a General-Purpose Natural Language Processing Task Solver?},
  journal   = {CoRR},
  volume    = {abs/2302.06476},
  year      = {2023},
}

@article{Lu-arxiv-2022-Survey,
  author    = {Pan Lu and
               Liang Qiu and
               Wenhao Yu and
               Sean Welleck and
               Kai{-}Wei Chang},
  title     = {A Survey of Deep Learning for Mathematical Reasoning},
  journal   = {CoRR},
  volume    = {abs/2212.10535},
  year      = {2022},
}

@article{Lyu-arxiv-2023-Faithful,
  author    = {Qing Lyu and
               Shreya Havaldar and
               Adam Stein and
               Li Zhang and
               Delip Rao and
               Eric Wong and
               Marianna Apidianaki and
               Chris Callison{-}Burch},
  title     = {Faithful Chain-of-Thought Reasoning},
  journal   = {CoRR},
  volume    = {abs/2301.13379},
  year      = {2023},
}


@article{Sun-arxiv-2023-Principle,
  title={Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision},
  author={Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal={arXiv preprint arXiv:2305.03047},
  year={2023}
}


@article{Xu-arxiv-2023-WizardLM,
  author       = {Can Xu and
                  Qingfeng Sun and
                  Kai Zheng and
                  Xiubo Geng and
                  Pu Zhao and
                  Jiazhan Feng and
                  Chongyang Tao and
                  Daxin Jiang},
  title        = {WizardLM: Empowering Large Language Models to Follow Complex Instructions},
  journal      = {CoRR},
  volume       = {abs/2304.12244},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.12244},
  doi          = {10.48550/arXiv.2304.12244},
  eprinttype    = {arXiv},
  eprint       = {2304.12244}
}

@article{Santu-arxiv-2023-TELeR,
  author       = {Shubhra Kanti Karmaker Santu and
                  Dongji Feng},
  title        = {TELeR: {A} General Taxonomy of {LLM} Prompts for Benchmarking Complex
                  Tasks},
  journal      = {CoRR},
  volume       = {abs/2305.11430},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.11430},
  doi          = {10.48550/arXiv.2305.11430},
  eprinttype    = {arXiv},
  eprint       = {2305.11430}
}

@article{Chang-arxiv-2023-How,
  author       = {Shuaichen Chang and
                  Eric Fosler{-}Lussier},
  title        = {How to Prompt LLMs for Text-to-SQL: {A} Study in Zero-shot, Single-domain,
                  and Cross-domain Settings},
  journal      = {CoRR},
  volume       = {abs/2305.11853},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.11853},
  doi          = {10.48550/arXiv.2305.11853},
  eprinttype    = {arXiv},
  eprint       = {2305.11853}
}

@misc{YuLan-Chat,
  author = {YuLan-Chat-Team},
  title = {YuLan-Chat: An Open-Source Bilingual Chatbot},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/RUC-GSAI/YuLan-Chat}},
}

@inproceedings{Wang-CICM-2018-First,
  author    = {Qingxiang Wang and
               Cezary Kaliszyk and
               Josef Urban},
  editor    = {Florian Rabe and
               William M. Farmer and
               Grant O. Passmore and
               Abdou Youssef},
  title     = {First Experiments with Neural Translation of Informal to Formal Mathematics},
  booktitle = {Intelligent Computer Mathematics - 11th International Conference,
               {CICM} 2018, Hagenberg, Austria, August 13-17, 2018, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {11006},
  pages     = {255--270},
  publisher = {Springer},
  year      = {2018},
}
@inproceedings{Welleck-NIPS-2021-NaturalProofs,
  author    = {Sean Welleck and
               Jiacheng Liu and
               Ronan Le Bras and
               Hanna Hajishirzi and
               Yejin Choi and
               Kyunghyun Cho},
  editor    = {Joaquin Vanschoren and
               Sai{-}Kit Yeung},
  title     = {NaturalProofs: Mathematical Theorem Proving in Natural Language},
  booktitle = {Proceedings of the Neural Information Processing Systems Track on
               Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December
               2021, virtual},
  year      = {2021},
}
@article{Wu-arxiv-2022-Autoformalization,
  author    = {Yuhuai Wu and
               Albert Q. Jiang and
               Wenda Li and
               Markus N. Rabe and
               Charles Staats and
               Mateja Jamnik and
               Christian Szegedy},
  title     = {Autoformalization with Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2205.12615},
  year      = {2022},
}


@article{Jiang-arxiv-2022-Draft,
  author    = {Albert Q. Jiang and
               Sean Welleck and
               Jin Peng Zhou and
               Wenda Li and
               Jiacheng Liu and
               Mateja Jamnik and
               Timoth{\'{e}}e Lacroix and
               Yuhuai Wu and
               Guillaume Lample},
  title     = {Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal
               Proofs},
  journal   = {CoRR},
  volume    = {abs/2210.12283},
  year      = {2022},
}
@inproceedings{Zheng-ICLR-2022-miniF2F,
  author    = {Kunhao Zheng and
               Jesse Michael Han and
               Stanislas Polu},
  title     = {miniF2F: a cross-system benchmark for formal Olympiad-level mathematics},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
}

@article{Jiang-arxiv-2022-Thor,
  author    = {Albert Q. Jiang and
               Wenda Li and
               Szymon Tworkowski and
               Konrad Czechowski and
               Tomasz Odrzyg{\'{o}}zdz and
               Piotr Milos and
               Yuhuai Wu and
               Mateja Jamnik},
  title     = {Thor: Wielding Hammers to Integrate Language Models and Automated
               Theorem Provers},
  journal   = {CoRR},
  volume    = {abs/2205.10893},
  year      = {2022},
}
@article{Polu-arxiv-2022-Formal,
  author    = {Stanislas Polu and
               Jesse Michael Han and
               Kunhao Zheng and
               Mantas Baksys and
               Igor Babuschkin and
               Ilya Sutskever},
  title     = {Formal Mathematics Statement Curriculum Learning},
  journal   = {CoRR},
  volume    = {abs/2202.01344},
  year      = {2022},
}

@article{Lewkowycz-arxiv-2022-Solving,
  author    = {Aitor Lewkowycz and
               Anders Andreassen and
               David Dohan and
               Ethan Dyer and
               Henryk Michalewski and
               Vinay V. Ramasesh and
               Ambrose Slone and
               Cem Anil and
               Imanol Schlag and
               Theo Gutman{-}Solo and
               Yuhuai Wu and
               Behnam Neyshabur and
               Guy Gur{-}Ari and
               Vedant Misra},
  title     = {Solving Quantitative Reasoning Problems with Language Models},
  journal   = {CoRR},
  volume    = {abs/2206.14858},
  year      = {2022},
}

@article{Gao-arxiv-2022-PAL,
  author    = {Luyu Gao and
               Aman Madaan and
               Shuyan Zhou and
               Uri Alon and
               Pengfei Liu and
               Yiming Yang and
               Jamie Callan and
               Graham Neubig},
  title     = {{PAL:} Program-aided Language Models},
  journal   = {CoRR},
  volume    = {abs/2211.10435},
  year      = {2022},
}
@article{Zhou-arxiv-2022-Least,
  author    = {Denny Zhou and
               Nathanael Sch{\"{a}}rli and
               Le Hou and
               Jason Wei and
               Nathan Scales and
               Xuezhi Wang and
               Dale Schuurmans and
               Olivier Bousquet and
               Quoc Le and
               Ed H. Chi},
  title     = {Least-to-Most Prompting Enables Complex Reasoning in Large Language
               Models},
  journal   = {CoRR},
  volume    = {abs/2205.10625},
  year      = {2022}
}
@article{Fu-arxiv-2023-Specializing,
  author    = {Yao Fu and
               Hao Peng and
               Litu Ou and
               Ashish Sabharwal and
               Tushar Khot},
  title     = {Specializing Smaller Language Models towards Multi-Step Reasoning},
  journal   = {CoRR},
  volume    = {abs/2301.12726},
  year      = {2023},
}
@article{Huang-arxiv-2022-Large,
  author    = {Jiaxin Huang and
               Shixiang Shane Gu and
               Le Hou and
               Yuexin Wu and
               Xuezhi Wang and
               Hongkun Yu and
               Jiawei Han},
  title     = {Large Language Models Can Self-Improve},
  journal   = {CoRR},
  volume    = {abs/2210.11610},
  year      = {2022},
}

@article{Ho-2022-arxiv-Large,
  author    = {Namgyu Ho and
               Laura Schmid and
               Se{-}Young Yun},
  title     = {Large Language Models Are Reasoning Teachers},
  journal   = {CoRR},
  volume    = {abs/2212.10071},
  year      = {2022},
  
}
@article{Magister-arxiv-2022-Teaching,
  author    = {Lucie Charlotte Magister and
               Jonathan Mallinson and
               Jakub Ad{\'{a}}mek and
               Eric Malmi and
               Aliaksei Severyn},
  title     = {Teaching Small Language Models to Reason},
  journal   = {CoRR},
  volume    = {abs/2212.08410},
  year      = {2022},
}
@article{Shridhar-arxiv-2022-Distilling,
  title={Distilling Multi-Step Reasoning Capabilities of Large Language Models into Smaller Models via Semantic Decompositions},
  author={Kumar Shridhar and Alessandro Stolfo and Mrinmaya Sachan},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.00193}
}
@article{Li-arxiv-2022-Explanations,
  author    = {Shiyang Li and
               Jianshu Chen and
               Yelong Shen and
               Zhiyu Chen and
               Xinlu Zhang and
               Zekun Li and
               Hong Wang and
               Jing Qian and
               Baolin Peng and
               Yi Mao and
               Wenhu Chen and
               Xifeng Yan},
  title     = {Explanations from Large Language Models Make Small Reasoners Better},
  journal   = {CoRR},
  volume    = {abs/2210.06726},
  year      = {2022},
}
@article{Qiao-arxiv-2022-Reasoning,
  author    = {Shuofei Qiao and
               Yixin Ou and
               Ningyu Zhang and
               Xiang Chen and
               Yunzhi Yao and
               Shumin Deng and
               Chuanqi Tan and
               Fei Huang and
               Huajun Chen},
  title     = {Reasoning with Language Model Prompting: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2212.09597},
  year      = {2022},
}
@inproceedings{Tafjord-acl-2021-ProofWriter,
  author    = {Oyvind Tafjord and
               Bhavana Dalvi and
               Peter Clark},
  editor    = {Chengqing Zong and
               Fei Xia and
               Wenjie Li and
               Roberto Navigli},
  title     = {ProofWriter: Generating Implications, Proofs, and Abductive Statements
               over Natural Language},
  booktitle = {Findings of the Association for Computational Linguistics: {ACL/IJCNLP}
               2021, Online Event, August 1-6, 2021},
  series    = {Findings of {ACL}},
  volume    = {{ACL/IJCNLP} 2021},
  pages     = {3621--3634},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
}
@article{Saparov-arxiv-2022-Language,
  author    = {Abulhair Saparov and
               He He},
  title     = {Language Models Are Greedy Reasoners: {A} Systematic Formal Analysis
               of Chain-of-Thought},
  journal   = {CoRR},
  volume    = {abs/2210.01240},
  year      = {2022},
}


@inproceedings{Mihaylov-EMNLP-2018-Can,
  author    = {Todor Mihaylov and
               Peter Clark and
               Tushar Khot and
               Ashish Sabharwal},
  title     = {Can a Suit of Armor Conduct Electricity? {A} New Dataset for Open
               Book Question Answering},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural
               Language Processing, Brussels, Belgium, October 31 - November 4, 2018},
  pages     = {2381--2391},
  year      = {2018},
}

@article{Carlini-arxiv-2022-Quantifying,
  author    = {Nicholas Carlini and
               Daphne Ippolito and
               Matthew Jagielski and
               Katherine Lee and
               Florian Tram{\`{e}}r and
               Chiyuan Zhang},
  title     = {Quantifying Memorization Across Neural Language Models},
  journal   = {CoRR},
  year      = {2022},
  eprinttype = {arXiv},
  eprint    = {2202.07646},
}

@article{Shoeybi-arXiv-2019-Megatron,
  author    = {Mohammad Shoeybi and
               Mostofa Patwary and
               Raul Puri and
               Patrick LeGresley and
               Jared Casper and
               Bryan Catanzaro},
  title     = {Megatron-LM: Training Multi-Billion Parameter Language Models Using
               Model Parallelism},
  journal   = {CoRR},
  volume    = {abs/1909.08053},
  year      = {2019},
}

@article{Xu-arXiv-2021-An,
  author    = {Qifan Xu and
               Shenggui Li and
               Chaoyu Gong and
               Yang You},
  title     = {An Efficient 2D Method for Training Super-Large Deep Learning Models},
  journal   = {CoRR},
  volume    = {abs/2104.05343},
  year      = {2021},
}

@inproceedings{Wang-ICPP-2022-Tesseract,
  author    = {Boxiang Wang and
               Qifan Xu and
               Zhengda Bian and
               Yang You},
  title     = {Tesseract: Parallelize the Tensor Parallelism Efficiently},
  booktitle = {Proceedings of the 51st International Conference on Parallel Processing,
               {ICPP} 2022, Bordeaux, France, 29 August 2022 - 1 September 2022},
  publisher = {{ACM}},
  year      = {2022},
  
}

@article{Bian-arXiv-2021-Maximizing,
  author    = {Zhengda Bian and
               Qifan Xu and
               Boxiang Wang and
               Yang You},
  title     = {Maximizing Parallelism in Distributed Training for Huge Neural Networks},
  journal   = {CoRR},
  volume    = {abs/2105.14450},
  year      = {2021},
}

@article{Li-arXiv-2021-Sequence,
  title={Sequence Parallelism: Long Sequence Training from System Perspective},
  author={Li, Shenggui and Xue, Fuzhao and Baranwal, Chaitanya and Li, Yongbin and You, Yang},
  journal={arXiv e-prints},
  pages={arXiv--2105},
  year={2021}
}

@inproceedings{Huang-NeurIPS-2019-GPipe,
  author    = {Yanping Huang and
               Youlong Cheng and
               Ankur Bapna and
               Orhan Firat and
               Dehao Chen and
               Mia Xu Chen and
               HyoukJoong Lee and
               Jiquan Ngiam and
               Quoc V. Le and
               Yonghui Wu and
               Zhifeng Chen},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {GPipe: Efficient Training of Giant Neural Networks using Pipeline
               Parallelism},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {103--112},
  year      = {2019},
}

@article{Harlap-arXiv-2018-PipeDream,
  author    = {Aaron Harlap and
               Deepak Narayanan and
               Amar Phanishayee and
               Vivek Seshadri and
               Nikhil R. Devanur and
               Gregory R. Ganger and
               Phillip B. Gibbons},
  title     = {PipeDream: Fast and Efficient Pipeline Parallel {DNN} Training},
  journal   = {CoRR},
  volume    = {abs/1806.03377},
  year      = {2018},
}

@inproceedings{Rajbhandari-IEEE-2020-ZeRO,
  author    = {Samyam Rajbhandari and
               Jeff Rasley and
               Olatunji Ruwase and
               Yuxiong He},
  editor    = {Christine Cuicchi and
               Irene Qualters and
               William T. Kramer},
  title     = {ZeRO: memory optimizations toward training trillion parameter models},
  booktitle = {Proceedings of the International Conference for High Performance Computing,
               Networking, Storage and Analysis, {SC} 2020, Virtual Event / Atlanta,
               Georgia, USA, November 9-19, 2020},
  pages     = {20},
  publisher = {{IEEE/ACM}},
  year      = {2020},
  
}

@inproceedings{Ren-USENIX-2021-ZeRO,
  author    = {Jie Ren and
               Samyam Rajbhandari and
               Reza Yazdani Aminabadi and
               Olatunji Ruwase and
               Shuangyan Yang and
               Minjia Zhang and
               Dong Li and
               Yuxiong He},
  editor    = {Irina Calciu and
               Geoff Kuenning},
  title     = {ZeRO-Offload: Democratizing Billion-Scale Model Training},
  booktitle = {2021 {USENIX} Annual Technical Conference, {USENIX} {ATC} 2021, July
               14-16, 2021},
  pages     = {551--564},
  publisher = {{USENIX} Association},
  year      = {2021},
}

@article{Micikevicius-arXiv-2017-Mixed,
  author    = {Paulius Micikevicius and
               Sharan Narang and
               Jonah Alben and
               Gregory F. Diamos and
               Erich Elsen and
               David Garc{\'{\i}}a and
               Boris Ginsburg and
               Michael Houston and
               Oleksii Kuchaiev and
               Ganesh Venkatesh and
               Hao Wu},
  title     = {Mixed Precision Training},
  journal   = {CoRR},
  volume    = {abs/1710.03740},
  year      = {2017},
}

@inproceedings{Miao-ACL-2020-A,
  author    = {Shen{-}Yun Miao and
               Chao{-}Chun Liang and
               Keh{-}Yih Su},
  editor    = {Dan Jurafsky and
               Joyce Chai and
               Natalie Schluter and
               Joel R. Tetreault},
  title     = {A Diverse Corpus for Evaluating and Developing English Math Word Problem
               Solvers},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages     = {975--984},
  publisher = {Association for Computational Linguistics},
  year      = {2020},
 
}

@inproceedings{Wang-EMNLP-2022-Super,
  author    = {Yizhong Wang and
               Swaroop Mishra and
               Pegah Alipoormolabashi and
               Yeganeh Kordi and
               Amirreza Mirzaei and
               Atharva Naik and
               Arjun Ashok and
               Arut Selvan Dhanasekaran and
               Anjana Arunkumar and
               David Stap and
               Eshaan Pathak and
               Giannis Karamanolakis and
               Haizhi Gary Lai and
               Ishan Purohit and
               Ishani Mondal and
               Jacob Anderson and
               Kirby Kuznia and
               Krima Doshi and
               Kuntal Kumar Pal and
               Maitreya Patel and
               Mehrad Moradshahi and
               Mihir Parmar and
               Mirali Purohit and
               Neeraj Varshney and
               Phani Rohitha Kaza and
               Pulkit Verma and
               Ravsehaj Singh Puri and
               Rushang Karia and
               Savan Doshi and
               Shailaja Keyur Sampat and
               Siddhartha Mishra and
               Sujan Reddy A and
               Sumanta Patro and
               Tanay Dixit and
               Xudong Shen},
  title     = {Super-NaturalInstructions: Generalization via Declarative Instructions
               on 1600+ {NLP} Tasks},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {5085--5109},
  year      = {2022},
}

@article{Parisi-arxiv-2022-TALM,
  author    = {Aaron Parisi and
               Yao Zhao and
               Noah Fiedel},
  title     = {{TALM:} Tool Augmented Language Models},
  journal   = {CoRR},
  volume    = {abs/2205.12255},
  year      = {2022},
}


@inproceedings{Roller-ACL-2021-Recipes,
  author    = {Stephen Roller and
               Emily Dinan and
               Naman Goyal and
               Da Ju and
               Mary Williamson and
               Yinhan Liu and
               Jing Xu and
               Myle Ott and
               Eric Michael Smith and
               Y{-}Lan Boureau and
               Jason Weston},
  title     = {Recipes for Building an Open-Domain Chatbot},
  booktitle = {Proceedings of the 16th Conference of the European Chapter of the
               Association for Computational Linguistics: Main Volume, {EACL} 2021,
               Online, April 19 - 23, 2021},
  pages     = {300--325},
  year      = {2021},
}

@inproceedings{Baumgartner-AAAI-2020-The,
  author    = {Jason Baumgartner and
               Savvas Zannettou and
               Brian Keegan and
               Megan Squire and
               Jeremy Blackburn},
  title     = {The Pushshift Reddit Dataset},
  booktitle = {Proceedings of the Fourteenth International {AAAI} Conference on Web
               and Social Media, {ICWSM} 2020, Held Virtually, Original Venue: Atlanta,
               Georgia, USA, June 8-11, 2020},
  pages     = {830--839},
  publisher = {{AAAI} Press},
  year      = {2020},
}

@inproceedings{Chen-ACL-2022-Improving,
  author    = {Mingda Chen and
               Jingfei Du and
               Ramakanth Pasunuru and
               Todor Mihaylov and
               Srini Iyer and
               Veselin Stoyanov and
               Zornitsa Kozareva},
  title     = {Improving In-Context Few-Shot Learning via Self-Supervised Training},
  booktitle = {Proceedings of the 2022 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL} 2022, Seattle, WA, United States, July 10-15, 2022},
  pages     = {3558--3573},
  year      = {2022},
}

@article{Touvron-arxiv-2023-LLaMA,
  author    = {Hugo Touvron and
               Thibaut Lavril and
               Gautier Izacard and
               Xavier Martinet and
               Marie{-}Anne Lachaux and
               Timoth{\'{e}}e Lacroix and
               Baptiste Rozi{\`{e}}re and
               Naman Goyal and
               Eric Hambro and
               Faisal Azhar and
               Aur{\'{e}}lien Rodriguez and
               Armand Joulin and
               Edouard Grave and
               Guillaume Lample},
  title     = {LLaMA: Open and Efficient Foundation Language Models},
  journal   = {CoRR},
  year      = {2023},
}

@article{toma-arxiv-2023-clinical,
  title={Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding},
  author={Toma, Augustin and Lawler, Patrick R and Ba, Jimmy and Krishnan, Rahul G and Rubin, Barry B and Wang, Bo},
  journal={arXiv preprint arXiv:2305.12031},
  year={2023}
}

@article{wang-arxiv-2023-huatuo,
  title={Huatuo: Tuning llama model with chinese medical knowledge},
  author={Wang, Haochun and Liu, Chi and Xi, Nuwa and Qiang, Zewen and Zhao, Sendong and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:2304.06975},
  year={2023}
}

@article{yunxiang-arxiv-2023-chatdoctor,
  title={Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge},
  author={Yunxiang, Li and Zihan, Li and Kai, Zhang and Ruilong, Dan and You, Zhang},
  journal={arXiv preprint arXiv:2303.14070},
  year={2023}
}

@article{huang-arxiv-2023-lawyer,
  title={Lawyer LLaMA Technical Report},
  author={Huang, Quzhe and Tao, Mingxu and An, Zhenwei and Zhang, Chen and Jiang, Cong and Chen, Zhibin and Wu, Zirui and Feng, Yansong},
  journal={arXiv preprint arXiv:2305.15062},
  year={2023}
}

@article{zhang-arxiv-2023-xuanyuan,
  title={XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters},
  author={Zhang, Xuanyu and Yang, Qing and Xu, Dongliang},
  journal={arXiv preprint arXiv:2305.12002},
  year={2023}
}

@article{wu-arxiv-2023-bloomberggpt,
  title={Bloomberggpt: A large language model for finance},
  author={Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
  journal={arXiv preprint arXiv:2303.17564},
  year={2023}
}


@article{radford-openai-2018-improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@inproceedings{Bach-ACL-2022-PromptSource,
  author    = {Stephen H. Bach and
               Victor Sanh and
               Zheng Xin Yong and
               Albert Webson and
               Colin Raffel and
               Nihal V. Nayak and
               Abheesht Sharma and
               Taewoon Kim and
               M. Saiful Bari and
               Thibault F{\'{e}}vry and
               Zaid Alyafeai and
               Manan Dey and
               Andrea Santilli and
               Zhiqing Sun and
               Srulik Ben{-}David and
               Canwen Xu and
               Gunjan Chhablani and
               Han Wang and
               Jason Alan Fries and
               Maged Saeed AlShaibani and
               Shanya Sharma and
               Urmish Thakker and
               Khalid Almubarak and
               Xiangru Tang and
               Dragomir R. Radev and
               Mike Tian{-}Jian Jiang and
               Alexander M. Rush},
  title     = {PromptSource: An Integrated Development Environment and Repository
               for Natural Language Prompts},
  booktitle = {{ACL} (demo)},
  pages     = {93--104},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}


@inproceedings{Lee-ACL-2022-Deduplicating,
  author    = {Katherine Lee and
               Daphne Ippolito and
               Andrew Nystrom and
               Chiyuan Zhang and
               Douglas Eck and
               Chris Callison{-}Burch and
               Nicholas Carlini},
  title     = {Deduplicating Training Data Makes Language Models Better},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {8424--8445},
  year      = {2022},
}

@article{Hernandez-arxiv-2022-Scaling,
  author    = {Danny Hernandez and
               Tom B. Brown and
               Tom Conerly and
               Nova DasSarma and
               Dawn Drain and
               Sheer El Showk and
               Nelson Elhage and
               Zac Hatfield{-}Dodds and
               Tom Henighan and
               Tristan Hume and
               Scott Johnston and
               Benjamin Mann and
               Chris Olah and
               Catherine Olsson and
               Dario Amodei and
               Nicholas Joseph and
               Jared Kaplan and
               Sam McCandlish},
  title     = {Scaling Laws and Interpretability of Learning from Repeated Data},
  journal   = {CoRR},
  volume    = {abs/2205.10487},
  year      = {2022},
}

@inproceedings{Nakkiran-ICLR-2020-Deep,
  author    = {Preetum Nakkiran and
               Gal Kaplun and
               Yamini Bansal and
               Tristan Yang and
               Boaz Barak and
               Ilya Sutskever},
  title     = {Deep Double Descent: Where Bigger Models and More Data Hurt},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  
}

@article{Honovich-arxiv-2022-Unnatural,
  author    = {Or Honovich and
               Thomas Scialom and
               Omer Levy and
               Timo Schick},
  title     = {Unnatural Instructions: Tuning Language Models with (Almost) No Human
               Labor},
  journal   = {CoRR},
  volume    = {abs/2212.09689},
  year      = {2022}
}

@inproceedings{Gu-EMNLP-2022-Learning,
  author    = {Yuxian Gu and
               Pei Ke and
               Xiaoyan Zhu and
               Minlie Huang},
  title     = {Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task
               Generalization},
  booktitle = {{EMNLP}},
  pages     = {1617--1634},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@inproceedings{Kingma-arXiv-2015-Adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  
}

@inproceedings{Shazeer-ICML-2018-Adafactor,
  author    = {Noam Shazeer and
               Mitchell Stern},
  editor    = {Jennifer G. Dy and
               Andreas Krause},
  title     = {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {4603--4611},
  publisher = {{PMLR}},
  year      = {2018},
}
@article{Sap-arxiv-2019-SocialIQA,
  author    = {Maarten Sap and
               Hannah Rashkin and
               Derek Chen and
               Ronan Le Bras and
               Yejin Choi},
  title     = {SocialIQA: Commonsense Reasoning about Social Interactions},
  journal   = {CoRR},
  volume    = {abs/1904.09728},
  year      = {2019},
}
@inproceedings{Zellers-acl-2019-HellaSwag,
  author    = {Rowan Zellers and
               Ari Holtzman and
               Yonatan Bisk and
               Ali Farhadi and
               Yejin Choi},
  editor    = {Anna Korhonen and
               David R. Traum and
               Llu{\'{\i}}s M{\`{a}}rquez},
  title     = {HellaSwag: Can a Machine Really Finish Your Sentence?},
  booktitle = {Proceedings of the 57th Conference of the Association for Computational
               Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
               Volume 1: Long Papers},
  pages     = {4791--4800},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
}

@inproceedings{Roemmele-aaai-2011-Choice,
  author    = {Melissa Roemmele and
               Cosmin Adrian Bejan and
               Andrew S. Gordon},
  title     = {Choice of Plausible Alternatives: An Evaluation of Commonsense Causal
               Reasoning},
  booktitle = {Logical Formalizations of Commonsense Reasoning, Papers from the 2011
               {AAAI} Spring Symposium, Technical Report SS-11-06, Stanford, California,
               USA, March 21-23, 2011},
  publisher = {{AAAI}},
  year      = {2011},
}
@inproceedings{Clark-naacl-2019-BoolQ,
  author    = {Christopher Clark and
               Kenton Lee and
               Ming{-}Wei Chang and
               Tom Kwiatkowski and
               Michael Collins and
               Kristina Toutanova},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {2924--2936},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
}
@inproceedings{Bisk-aaai-2020-PIQA,
  author    = {Yonatan Bisk and
               Rowan Zellers and
               Ronan Le Bras and
               Jianfeng Gao and
               Yejin Choi},
  title     = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
               February 7-12, 2020},
  pages     = {7432--7439},
  year      = {2020},
}
@inproceedings{Sakaguchi-acl-2021-proScript,
  author    = {Keisuke Sakaguchi and
               Chandra Bhagavatula and
               Ronan Le Bras and
               Niket Tandon and
               Peter Clark and
               Yejin Choi},
  editor    = {Marie{-}Francine Moens and
               Xuanjing Huang and
               Lucia Specia and
               Scott Wen{-}tau Yih},
  title     = {proScript: Partially Ordered Scripts Generation},
  booktitle = {Findings of the Association for Computational Linguistics: {EMNLP}
               2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November,
               2021},
  pages     = {2138--2149},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
}
@inproceedings{Dalvi-acl-2018-Tracking,
  author    = {Bhavana Dalvi and
               Lifu Huang and
               Niket Tandon and
               Wen{-}tau Yih and
               Peter Clark},
  editor    = {Marilyn A. Walker and
               Heng Ji and
               Amanda Stent},
  title     = {Tracking State Changes in Procedural Text: a Challenge Dataset and
               Models for Process Paragraph Comprehension},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume
               1 (Long Papers)},
  pages     = {1595--1604},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
}
@inproceedings{Saha-acl-2021-ExplaGraphs,
  author    = {Swarnadeep Saha and
               Prateek Yadav and
               Lisa Bauer and
               Mohit Bansal},
  editor    = {Marie{-}Francine Moens and
               Xuanjing Huang and
               Lucia Specia and
               Scott Wen{-}tau Yih},
  title     = {ExplaGraphs: An Explanation Graph Generation Task for Structured Commonsense
               Reasoning},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
               Republic, 7-11 November, 2021},
  pages     = {7716--7740},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
}
@article{Azerbayev-arxiv-2023-ProofNet,
  author    = {Zhangir Azerbayev and
               Bartosz Piotrowski and
               Hailey Schoelkopf and
               Edward W. Ayers and
               Dragomir Radev and
               Jeremy Avigad},
  title     = {ProofNet: Autoformalizing and Formally Proving Undergraduate-Level
               Mathematics},
  journal   = {CoRR},
  volume    = {abs/2302.12433},
  year      = {2023},
}
@inproceedings{Roy-acl-2015-Solving,
  author    = {Subhro Roy and
               Dan Roth},
  editor    = {Llu{\'{\i}}s M{\`{a}}rquez and
               Chris Callison{-}Burch and
               Jian Su and
               Daniele Pighin and
               Yuval Marton},
  title     = {Solving General Arithmetic Word Problems},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2015, Lisbon, Portugal, September 17-21,
               2015},
  pages     = {1743--1752},
  publisher = {The Association for Computational Linguistics},
  year      = {2015},
}

@inproceedings{Ling-acl-2017-Program,
  author    = {Wang Ling and
               Dani Yogatama and
               Chris Dyer and
               Phil Blunsom},
  editor    = {Regina Barzilay and
               Min{-}Yen Kan},
  title     = {Program Induction by Rationale Generation: Learning to Solve and Explain
               Algebraic Word Problems},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2017, Vancouver, Canada, July 30 - August 4, Volume
               1: Long Papers},
  pages     = {158--167},
  publisher = {Association for Computational Linguistics},
  year      = {2017},
}
@inproceedings{Amini-acl-2019-MathQA,
  author    = {Aida Amini and
               Saadia Gabriel and
               Shanchuan Lin and
               Rik Koncel{-}Kedziorski and
               Yejin Choi and
               Hannaneh Hajishirzi},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based
               Formalisms},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {2357--2367},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
}
@inproceedings{Dalvi-acl-2021-Explaining,
  author    = {Bhavana Dalvi and
               Peter Jansen and
               Oyvind Tafjord and
               Zhengnan Xie and
               Hannah Smith and
               Leighanna Pipatanangkura and
               Peter Clark},
  editor    = {Marie{-}Francine Moens and
               Xuanjing Huang and
               Lucia Specia and
               Scott Wen{-}tau Yih},
  title     = {Explaining Answers with Entailment Trees},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
               Republic, 7-11 November, 2021},
  pages     = {7358--7370},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
}

@article{Clark-arxiv-2018-Think,
  author    = {Peter Clark and
               Isaac Cowhey and
               Oren Etzioni and
               Tushar Khot and
               Ashish Sabharwal and
               Carissa Schoenick and
               Oyvind Tafjord},
  title     = {Think you have Solved Question Answering? Try ARC, the {AI2} Reasoning
               Challenge},
  journal   = {CoRR},
  volume    = {abs/1803.05457},
  year      = {2018},
}

@inproceedings{Lin-ACL-2022-TruthfulQA,
  author    = {Stephanie Lin and
               Jacob Hilton and
               Owain Evans},
  title     = {TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {3214--3252},
  year      = {2022},
}

@inproceedings{Nguyen-NIPS-2016-MS,
  author    = {Tri Nguyen and
               Mir Rosenberg and
               Xia Song and
               Jianfeng Gao and
               Saurabh Tiwary and
               Rangan Majumder and
               Li Deng},
  title     = {{MS} {MARCO:} {A} Human Generated MAchine Reading COmprehension Dataset},
  booktitle = {Proceedings of the Workshop on Cognitive Computation: Integrating
               neural and symbolic approaches 2016 co-located with the 30th Annual
               Conference on Neural Information Processing Systems {(NIPS} 2016),
               Barcelona, Spain, December 9, 2016},
  year      = {2016},
}

@article{Geva-tacl-2021-Did,
  author    = {Mor Geva and
               Daniel Khashabi and
               Elad Segal and
               Tushar Khot and
               Dan Roth and
               Jonathan Berant},
  title     = {Did Aristotle Use a Laptop? {A} Question Answering Benchmark with
               Implicit Reasoning Strategies},
  journal   = {Trans. Assoc. Comput. Linguistics},
  volume    = {9},
  pages     = {346--361},
  year      = {2021},
}


@article{Wang-arXiv-2022-Self,
  author    = {Yizhong Wang and
               Yeganeh Kordi and
               Swaroop Mishra and
               Alisa Liu and
               Noah A. Smith and
               Daniel Khashabi and
               Hannaneh Hajishirzi},
  title     = {Self-Instruct: Aligning Language Model with Self Generated Instructions},
  journal   = {CoRR},
  volume    = {abs/2212.10560},
  year      = {2022},
}

@article{xu-arxiv-2023-baize,
  title={Baize: An open-source chat model with parameter-efficient tuning on self-chat data},
  author={Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
  journal={arXiv preprint arXiv:2304.01196},
  year={2023}
}

@article{ding-arxiv-2023-enhancing,
  title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  journal={arXiv preprint arXiv:2305.14233},
  year={2023}
}

@article{ji-arxiv-2023-towards,
  title={Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation},
  author={Ji, Yunjie and Gong, Yan and Deng, Yong and Peng, Yiping and Niu, Qiang and Ma, Baochang and Li, Xiangang},
  journal={arXiv preprint arXiv:2304.07854},
  year={2023}
}

@article{singhal-arxiv-2022-large,
  title={Large Language Models Encode Clinical Knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={arXiv preprint arXiv:2212.13138},
  year={2022}
}

@inproceedings{Dua-NAACL-2019-DROP,
  author    = {Dheeru Dua and
               Yizhong Wang and
               Pradeep Dasigi and
               Gabriel Stanovsky and
               Sameer Singh and
               Matt Gardner},
  title     = {{DROP:} {A} Reading Comprehension Benchmark Requiring Discrete Reasoning
               Over Paragraphs},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
               and Short Papers)},
  pages     = {2368--2378},
  year      = {2019},
}

@article{Shao-arxiv-2023-Synthetic,
  author    = {Zhihong Shao and
               Yeyun Gong and
               Yelong Shen and
               Minlie Huang and
               Nan Duan and
               Weizhu Chen},
  title     = {Synthetic Prompting: Generating Chain-of-Thought Demonstrations for
               Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2302.00618},
  year      = {2023},
}

@inproceedings{Xue-NAACL-2021-mT5,
  author    = {Linting Xue and
               Noah Constant and
               Adam Roberts and
               Mihir Kale and
               Rami Al{-}Rfou and
               Aditya Siddhant and
               Aditya Barua and
               Colin Raffel},
  title     = {mT5: {A} Massively Multilingual Pre-trained Text-to-Text Transformer},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2021, Online, June 6-11, 2021},
  pages     = {483--498},
  year      = {2021}
}

@article{Black-CoRR-2022-GPT,
  author    = {Sid Black and
               Stella Biderman and
               Eric Hallahan and
               Quentin Anthony and
               Leo Gao and
               Laurence Golding and
               Horace He and
               Connor Leahy and
               Kyle McDonell and
               Jason Phang and
               Michael Pieler and
               USVSN Sai Prashanth and
               Shivanshu Purohit and
               Laria Reynolds and
               Jonathan Tow and
               Ben Wang and
               Samuel Weinbach},
  title     = {GPT-NeoX-20B: An Open-Source Autoregressive Language Model},
  journal   = {CoRR},
  volume    = {abs/2204.06745},
  year      = {2022}
}

@article{Thoppilan-CoRR-2022-LaMDA,
  author    = {Romal Thoppilan and
               Daniel De Freitas and
               Jamie Hall and
               Noam Shazeer and
               Apoorv Kulshreshtha and
               Heng{-}Tze Cheng and
               Alicia Jin and
               Taylor Bos and
               Leslie Baker and
               Yu Du and
               YaGuang Li and
               Hongrae Lee and
               Huaixiu Steven Zheng and
               Amin Ghafouri and
               Marcelo Menegali and
               Yanping Huang and
               Maxim Krikun and
               Dmitry Lepikhin and
               James Qin and
               Dehao Chen and
               Yuanzhong Xu and
               Zhifeng Chen and
               Adam Roberts and
               Maarten Bosma and
               Yanqi Zhou and
               Chung{-}Ching Chang and
               Igor Krivokon and
               Will Rusch and
               Marc Pickett and
               Kathleen S. Meier{-}Hellstern and
               Meredith Ringel Morris and
               Tulsee Doshi and
               Renelito Delos Santos and
               Toju Duke and
               Johnny Soraker and
               Ben Zevenbergen and
               Vinodkumar Prabhakaran and
               Mark Diaz and
               Ben Hutchinson and
               Kristen Olson and
               Alejandra Molina and
               Erin Hoffman{-}John and
               Josh Lee and
               Lora Aroyo and
               Ravi Rajakumar and
               Alena Butryna and
               Matthew Lamm and
               Viktoriya Kuzmina and
               Joe Fenton and
               Aaron Cohen and
               Rachel Bernstein and
               Ray Kurzweil and
               Blaise Aguera{-}Arcas and
               Claire Cui and
               Marian Croak and
               Ed H. Chi and
               Quoc Le},
  title     = {LaMDA: Language Models for Dialog Applications},
  journal   = {CoRR},
  volume    = {abs/2201.08239},
  year      = {2022}
}

@article{lieber-2021-jurassic,
  title={Jurassic-1: Technical details and evaluation},
  author={Lieber, Opher and Sharir, Or and Lenz, Barak and Shoham, Yoav},
  journal={White Paper. AI21 Labs},
  volume={1},
  year={2021}
}

@article{Smith-CoRR-2022-Using,
  author    = {Shaden Smith and
               Mostofa Patwary and
               Brandon Norick and
               Patrick LeGresley and
               Samyam Rajbhandari and
               Jared Casper and
               Zhun Liu and
               Shrimai Prabhumoye and
               George Zerveas and
               Vijay Korthikanti and
               Elton Zheng and
               Rewon Child and
               Reza Yazdani Aminabadi and
               Julie Bernauer and
               Xia Song and
               Mohammad Shoeybi and
               Yuxiong He and
               Michael Houston and
               Saurabh Tiwary and
               Bryan Catanzaro},
  title     = {Using DeepSpeed and Megatron to Train Megatron-Turing {NLG} 530B,
               {A} Large-Scale Generative Language Model},
  journal   = {CoRR},
  volume    = {abs/2201.11990},
  year      = {2022},
}

@inproceedings{Rasley-KDD-2020-DeepSpeed,
  title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
  author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle={{KDD}},
  pages={3505--3506},
  year={2020}
}

@inproceedings{Wolf-EMNLP-2020-Transformers,
  author    = {Thomas Wolf and
               Lysandre Debut and
               Victor Sanh and
               Julien Chaumond and
               Clement Delangue and
               Anthony Moi and
               Pierric Cistac and
               Tim Rault and
               R{\'{e}}mi Louf and
               Morgan Funtowicz and
               Joe Davison and
               Sam Shleifer and
               Patrick von Platen and
               Clara Ma and
               Yacine Jernite and
               Julien Plu and
               Canwen Xu and
               Teven Le Scao and
               Sylvain Gugger and
               Mariama Drame and
               Quentin Lhoest and
               Alexander M. Rush},
  title     = {Transformers: State-of-the-Art Natural Language Processing},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural
               Language Processing: System Demonstrations, {EMNLP} 2020 - Demos,
               Online, November 16-20, 2020},
  pages     = {38--45},
  publisher = {Association for Computational Linguistics},
  year      = {2020}
}

@article{Bian-CoRR-2021-Colossal-AI,
  author    = {Zhengda Bian and
               Hongxin Liu and
               Boxiang Wang and
               Haichen Huang and
               Yongbin Li and
               Chuanrui Wang and
               Fan Cui and
               Yang You},
  title     = {Colossal-AI: {A} Unified Deep Learning System For Large-Scale Parallel
               Training},
  journal   = {CoRR},
  volume    = {abs/2110.14883},
  year      = {2021}
}

@software{Bradbury-github-2018-jax,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
  
}

@inproceedings{Narayanan-ACM-2021-Efficient,
  author    = {Deepak Narayanan and
               Mohammad Shoeybi and
               Jared Casper and
               Patrick LeGresley and
               Mostofa Patwary and
               Vijay Korthikanti and
               Dmitri Vainbrand and
               Prethvi Kashinkunti and
               Julie Bernauer and
               Bryan Catanzaro and
               Amar Phanishayee and
               Matei Zaharia},
  title     = {Efficient large-scale language model training on {GPU} clusters using
               megatron-LM},
  booktitle = {International Conference for High Performance Computing, Networking,
               Storage and Analysis, {SC} 2021, St. Louis, Missouri, USA, November
               14-19, 2021},
  pages     = {58},
  publisher = {{ACM}},
  year      = {2021}
}

@inproceedings{Petroni-EMNLP-2019-Language,
  author    = {Fabio Petroni and
               Tim Rockt{\"{a}}schel and
               Sebastian Riedel and
               Patrick S. H. Lewis and
               Anton Bakhtin and
               Yuxiang Wu and
               Alexander H. Miller},
  title     = {Language Models as Knowledge Bases?},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural
               Language Processing and the 9th International Joint Conference on
               Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China,
               November 3-7, 2019},
  pages     = {2463--2473},
  year      = {2019},
}

@inproceedings{Zhu-ICCV-2015-Aligning,
  author    = {Yukun Zhu and
               Ryan Kiros and
               Richard S. Zemel and
               Ruslan Salakhutdinov and
               Raquel Urtasun and
               Antonio Torralba and
               Sanja Fidler},
  title     = {Aligning Books and Movies: Towards Story-Like Visual Explanations
               by Watching Movies and Reading Books},
  booktitle = {2015 {IEEE} International Conference on Computer Vision, {ICCV} 2015,
               Santiago, Chile, December 7-13, 2015},
  pages     = {19--27},
  publisher = {{IEEE} Computer Society},
  year      = {2015},
  
}

@article{Lu-arxiv-2023-Chameleon,
  title={Chameleon: Plug-and-play compositional reasoning with large language models},
  author={Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.09842},
  year={2023}
}

@article{Beurer-arxiv-2023-Prompting,
  title={Prompting is programming: A query language for large language models},
  author={Beurer-Kellner, Luca and Fischer, Marc and Vechev, Martin},
  journal={Proceedings of the ACM on Programming Languages},
  volume={7},
  number={PLDI},
  pages={1946--1969},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@misc{Gutenberg,
  url = {https://www.gutenberg.org/},
  title = {Project Gutenberg}
}

@misc{commoncrawl,
  url = {https://commoncrawl.org/},
  title = {Common Crawl}
}


@article{Trinh-CoRR-2018-A,
  author    = {Trieu H. Trinh and
               Quoc V. Le},
  title     = {A Simple Method for Commonsense Reasoning},
  journal   = {CoRR},
  volume    = {abs/1806.02847},
  year      = {2018},
  
}

@inproceedings{Zellers-NeurIPS-2019-Defending,
  author    = {Rowan Zellers and
               Ari Holtzman and
               Hannah Rashkin and
               Yonatan Bisk and
               Ali Farhadi and
               Franziska Roesner and
               Yejin Choi},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Defending Against Neural Fake News},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {9051--9062},
  year      = {2019},
}


@inproceedings{Khot-AAAI-2020-QASC,
  author    = {Tushar Khot and
               Peter Clark and
               Michal Guerquin and
               Peter Jansen and
               Ashish Sabharwal},
  title     = {{QASC:} {A} Dataset for Question Answering via Sentence Composition},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
               February 7-12, 2020},
  pages     = {8082--8090},
  year      = {2020},
}

@inproceedings{Miller-EMNLP-2016-Key,
  author    = {Alexander H. Miller and
               Adam Fisch and
               Jesse Dodge and
               Amir{-}Hossein Karimi and
               Antoine Bordes and
               Jason Weston},
  title     = {Key-Value Memory Networks for Directly Reading Documents},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2016, Austin, Texas, USA, November 1-4,
               2016},
  pages     = {1400--1409},
  year      = {2016},
}

@inproceedings{Rajpurkar-EMNLP-2016-SQuAD,
  author    = {Pranav Rajpurkar and
               Jian Zhang and
               Konstantin Lopyrev and
               Percy Liang},
  title     = {SQuAD: 100, 000+ Questions for Machine Comprehension of Text},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2016, Austin, Texas, USA, November 1-4,
               2016},
  pages     = {2383--2392},
  year      = {2016},
}

@inproceedings{Baudis-CLEF-2015-Modeling,
  author    = {Petr Baudis and
               Jan Sediv{\'{y}}},
  title     = {Modeling of the Question Answering Task in the YodaQA System},
  booktitle = {Experimental {IR} Meets Multilinguality, Multimodality, and Interaction
               - 6th International Conference of the {CLEF} Association, {CLEF} 2015,
               Toulouse, France, September 8-11, 2015, Proceedings},
  pages     = {222--228},
  year      = {2015},
}

@inproceedings{Suchanek-WWW-2007-Yago,
  author    = {Fabian M. Suchanek and
               Gjergji Kasneci and
               Gerhard Weikum},
  title     = {Yago: a core of semantic knowledge},
  booktitle = {Proceedings of the 16th International Conference on World Wide Web,
               {WWW} 2007, Banff, Alberta, Canada, May 8-12, 2007},
  pages     = {697--706},
  year      = {2007},
}

@inproceedings{Mahdisoltani-CIDR-2015-YAGO3,
  author    = {Farzaneh Mahdisoltani and
               Joanna Biega and
               Fabian M. Suchanek},
  title     = {{YAGO3:} {A} Knowledge Base from Multilingual Wikipedias},
  booktitle = {Seventh Biennial Conference on Innovative Data Systems Research, {CIDR}
               2015, Asilomar, CA, USA, January 4-7, 2015, Online Proceedings},
  year      = {2015},
}

@article{Miller-Commun-1995-WordNet,
  author    = {George A. Miller},
  title     = {WordNet: {A} Lexical Database for English},
  journal   = {Commun. {ACM}},
  pages     = {39--41},
  year      = {1995},
}

@inproceedings{Bollacker-SIGMOD-2008-Freebase,
  author    = {Kurt D. Bollacker and
               Colin Evans and
               Praveen K. Paritosh and
               Tim Sturge and
               Jamie Taylor},
  title     = {Freebase: a collaboratively created graph database for structuring
               human knowledge},
  booktitle = {Proceedings of the {ACM} {SIGMOD} International Conference on Management
               of Data, {SIGMOD} 2008, Vancouver, BC, Canada, June 10-12, 2008},
  pages     = {1247--1250},
  year      = {2008},
}

@misc{ccstories-reproduction,
    url = {https://huggingface.co/datasets/spacemanidol/cc-stories},
    title = {CC-Stories Reproduction},
}

@misc{bigquery-google,
title     = {BigQuery Dataset}, 
    url = {https://cloud.google.com/bigquery?hl=zh-cn},
}

@inproceedings{Ye-EMNLP-2021-CrossFit,
  author    = {Qinyuan Ye and
               Bill Yuchen Lin and
               Xiang Ren},
  title     = {CrossFit: {A} Few-shot Learning Challenge for Cross-task Generalization
               in {NLP}},
  booktitle = {{EMNLP} {(1)}},
  pages     = {7163--7189},
  publisher = {Association for Computational Linguistics},
  year      = {2021}
}

@inproceedings{Xie-EMNLP-2022-UnifiedSKG,
  author    = {Tianbao Xie and
               Chen Henry Wu and
               Peng Shi and
               Ruiqi Zhong and
               Torsten Scholak and
               Michihiro Yasunaga and
               Chien{-}Sheng Wu and
               Ming Zhong and
               Pengcheng Yin and
               Sida I. Wang and
               Victor Zhong and
               Bailin Wang and
               Chengzu Li and
               Connor Boyle and
               Ansong Ni and
               Ziyu Yao and
               Dragomir Radev and
               Caiming Xiong and
               Lingpeng Kong and
               Rui Zhang and
               Noah A. Smith and
               Luke Zettlemoyer and
               Tao Yu},
  title     = {UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding
               with Text-to-Text Language Models},
  booktitle = {{EMNLP}},
  pages     = {602--631},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@article{Wei-arxiv-2023-Larger,
  title={Larger language models do in-context learning differently},
  author={Wei, Jerry and Wei, Jason and Tay, Yi and Tran, Dustin and Webson, Albert and Lu, Yifeng and Chen, Xinyun and Liu, Hanxiao and Huang, Da and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2303.03846},
  year={2023}
}

@article{Wu-arxiv-2023-OpenICL,
  title={OpenICL: An Open-Source Framework for In-context Learning},
  author={Wu, Zhenyu and Wang, YaoXiang and Ye, Jiacheng and Feng, Jiangtao and Xu, Jingjing and Qiao, Yu and Wu, Zhiyong},
  journal={arXiv preprint arXiv:2303.02913},
  year={2023}
}

@inproceedings{Jiang-AITP-2021-LISA,
  title={LISA: Language models of ISAbelle proofs},
  author={Jiang, Albert Qiaochu and Li, Wenda and Han, Jesse Michael and Wu, Yuhuai},
  booktitle={6th Conference on Artificial Intelligence and Theorem Proving},
  pages={378--392},
  year={2021}
}

@inproceedings{Zhao-KDD-2022-JiuZhang,
  author    = {Wayne Xin Zhao and
               Kun Zhou and
               Zheng Gong and
               Beichen Zhang and
               Yuanhang Zhou and
               Jing Sha and
               Zhigang Chen and
               Shijin Wang and
               Cong Liu and
               Ji{-}Rong Wen},
  editor    = {Aidong Zhang and
               Huzefa Rangwala},
  title     = {JiuZhang: {A} Chinese Pre-trained Language Model for Mathematical
               Problem Understanding},
  booktitle = {{KDD} '22: The 28th {ACM} {SIGKDD} Conference on Knowledge Discovery
               and Data Mining, Washington, DC, USA, August 14 - 18, 2022},
  pages     = {4571--4581},
  publisher = {{ACM}},
  year      = {2022},
}

@inproceedings{Zhou-FITEE-2023-ChatGPT,
  title={ChatGPT: potential, prospects, and limitations},
  author={Jie Zhou and Pei Ke and Xipeng Qiu and Minlie Huang and Junping Zhang},
  booktitle={Frontiers of Information Technology \& Electronic Engineering},
  pages={1--6},
  year={2023}
}

@article{Ji-Computing-2022-Hallucination,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  year={2022},
  publisher={ACM New York, NY}
}

@misc{Chen-arxiv-2023-Robust,
  author = {Chen, Xuanting and Ye, Junjie and Zu, Can and Xu, Nuo and Zheng, Rui and Peng, Minlong and Zhou, Jie and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
  title = {How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks},
  publisher = {arXiv},
  year = {2023}
}

@article{Anli-Nature-2023-bigger,
  title={In AI, is bigger always better?},
  author={Anil Ananthaswamy},
  journal={Nature},
  year={2023},
  publisher={Nature Publishing Group}
}

@misc{he2023icld3ie,
    title={ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction},
    author={Jiabang He and Lei Wang and Yi Hu and Ning Liu and Hui Liu and Xing Xu and Heng Tao Shen},
    year={2023},
    publisher = {arXiv}
}

@article{Lou-arXiv-2023-Is,
  author    = {Renze Lou and
               Kai Zhang and
               Wenpeng Yin},
  title     = {Is Prompt All You Need? No. {A} Comprehensive and Broader View of
               Instruction Learning},
  journal   = {CoRR},
  volume    = {abs/2303.10475},
  year      = {2023}
}

@inproceedings{Cao-ACL-2022-KQA,
  author    = {Shulin Cao and
               Jiaxin Shi and
               Liangming Pan and
               Lunyiu Nie and
               Yutong Xiang and
               Lei Hou and
               Juanzi Li and
               Bin He and
               Hanwang Zhang},
  title     = {{KQA} Pro: {A} Dataset with Explicit Compositional Programs for Complex
               Question Answering over Knowledge Base},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {6101--6119},
  year      = {2022},
}

@inproceedings{Dubey-ISWC-2019-LC,
  author    = {Mohnish Dubey and
               Debayan Banerjee and
               Abdelrahman Abdelkawi and
               Jens Lehmann},
  title     = {LC-QuAD 2.0: {A} Large Dataset for Complex Question Answering over
               Wikidata and DBpedia},
  booktitle = {The Semantic Web - {ISWC} 2019 - 18th International Semantic Web Conference,
               Auckland, New Zealand, October 26-30, 2019, Proceedings, Part {II}},
  pages     = {69--78},
  year      = {2019},
}

@inproceedings{Gu-WWW-2021-Beyond,
  author    = {Yu Gu and
               Sue Kase and
               Michelle Vanni and
               Brian M. Sadler and
               Percy Liang and
               Xifeng Yan and
               Yu Su},
  title     = {Beyond {I.I.D.:} Three Levels of Generalization for Question Answering
               on Knowledge Bases},
  booktitle = {{WWW} '21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia,
               April 19-23, 2021},
  pages     = {3477--3488},
  year      = {2021},
}

@inproceedings{Hu-COLING-2022-Logical,
  author    = {Xixin Hu and
               Xuan Wu and
               Yiheng Shu and
               Yuzhong Qu},
  title     = {Logical Form Generation via Multi-task Learning for Complex Question
               Answering over Knowledge Bases},
  booktitle = {Proceedings of the 29th International Conference on Computational
               Linguistics, {COLING} 2022, Gyeongju, Republic of Korea, October 12-17,
               2022},
  pages     = {1687--1696},
  year      = {2022},
}

@article{Longpre-TACL-2021-MKQA,
  author    = {Shayne Longpre and
               Yi Lu and
               Joachim Daiber},
  title     = {{MKQA:} {A} Linguistically Diverse Benchmark for Multilingual Open
               Domain Question Answering},
  journal   = {Trans. Assoc. Comput. Linguistics},
  volume    = {9},
  pages     = {1389--1406},
  year      = {2021},
  
}

@article{Imani-arxiv-2022-MathPrompter,
  title={MathPrompter: Mathematical Reasoning using Large Language Models},
  author={Imani, Shima and Du, Liang and Shrivastava, Harsh},
  journal={arXiv preprint arXiv:2303.05398},
  year={2023}
}

@article{Omar-arxiv-2023-KGQA,
  author    = {Reham Omar and
               Omij Mangukiya and
               Panos Kalnis and
               Essam Mansour},
  title     = {ChatGPT versus Traditional Question Answering for Knowledge Graphs:
               Current Status and Future Directions Towards Knowledge Graph Chatbots},
  journal   = {CoRR},
  volume    = {abs/2302.06466},
  year      = {2023},
}

@inproceedings{Zheng-OSDI-2022-Alpa,
  title={Alpa: Automating Inter-and $\{$Intra-Operator$\}$ Parallelism for Distributed Deep Learning},
  author={Zheng, Lianmin and Li, Zhuohan and Zhang, Hao and Zhuang, Yonghao and Chen, Zhifeng and Huang, Yanping and Wang, Yida and Xu, Yuanzhong and Zhuo, Danyang and Xing, Eric P and others},
  booktitle={{OSDI}},
  pages={559--578},
  year={2022}
}

@misc{vllm-pagedattention,
title     = {vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention}, 
    url = {https://vllm.ai/},
}

@misc{Taori-github-2023-Stanford,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}
@article{Martin-Speech-1998-clustering,
  title={Algorithms for bigram and trigram word clustering},
  author={Martin, Sven and Liermann, J{\"o}rg and Ney, Hermann},
  journal={Speech communication},
  volume={24},
  number={1},
  pages={19--37},
  year={1998},
  publisher={Elsevier}
}

@article{Navigli-ACM-2009-disambiguation,
  title={Word sense disambiguation: A survey},
  author={Navigli, Roberto},
  journal={ACM computing surveys (CSUR)},
  volume={41},
  number={2},
  pages={1--69},
  year={2009},
  publisher={ACM New York, NY, USA}
}

@article{Minaee-ACM-2021-classification,
  title={Deep learning--based text classification: a comprehensive review},
  author={Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={3},
  pages={1--40},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{Gomaa-International-2013-similarity,
  title={A survey of text similarity approaches},
  author={Gomaa, Wael H and Fahmy, Aly A and others},
  journal={international journal of Computer Applications},
  volume={68},
  number={13},
  pages={13--18},
  year={2013},
  publisher={Citeseer}
}

@article{Nadeau-Lingvisticae-2007-NER,
  title={A survey of named entity recognition and classification},
  author={Nadeau, David and Sekine, Satoshi},
  journal={Lingvisticae Investigationes},
  volume={30},
  number={1},
  pages={3--26},
  year={2007},
  publisher={John Benjamins}
}

@inproceedings{Ratnaparkhi-EMNLP-1996-maximum,
  title={A maximum entropy model for part-of-speech tagging},
  author={Ratnaparkhi, Adwait},
  booktitle={Conference on empirical methods in natural language processing},
  year={1996}
}

@article{Souza-arxiv-2019-portuguese,
  title={Portuguese named entity recognition using BERT-CRF},
  author={Souza, F{\'a}bio and Nogueira, Rodrigo and Lotufo, Roberto},
  journal={arXiv preprint arXiv:1909.10649},
  year={2019}
}

@inproceedings{Yadav-COLING-2018-survey,
  title={A Survey on Recent Advances in Named Entity Recognition from Deep Learning models},
  author={Yadav, Vikas and Bethard, Steven},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={2145--2158},
  year={2018}
}

@article{Pawar-arxiv-2017-relation,
  title={Relation extraction: A survey},
  author={Pawar, Sachin and Palshikar, Girish K and Bhattacharyya, Pushpak},
  journal={arXiv preprint arXiv:1712.05191},
  year={2017}
}

@article{Kumar-arxiv-2017-survey,
  title={A survey of deep learning methods for relation extraction},
  author={Kumar, Shantanu},
  journal={arXiv preprint arXiv:1705.03645},
  year={2017}
}

@article{Smirnova-ACM-2018-relation,
  title={Relation extraction using distant supervision: A survey},
  author={Smirnova, Alisa and Cudr{\'e}-Mauroux, Philippe},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={5},
  pages={1--35},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{wei-arxiv-2023-zero,
  title={Zero-Shot Information Extraction via Chatting with ChatGPT},
  author={Wei, Xiang and Cui, Xingyu and Cheng, Ning and Wang, Xiaobin and Zhang, Xin and Huang, Shen and Xie, Pengjun and Xu, Jinan and Chen, Yufeng and Zhang, Meishan and others},
  journal={arXiv preprint arXiv:2302.10205},
  year={2023}
}

@article{Trautmann-arxiv-2022-Legal,
  author    = {Dietrich Trautmann and
               Alina Petrova and
               Frank Schilder},
  title     = {Legal Prompt Engineering for Multilingual Legal Judgement Prediction},
  journal   = {CoRR},
  volume    = {abs/2212.02199},
  year      = {2022},
}

@article{Choi-SSRN-2023-Chatgpt,
  title={Chatgpt goes to law school},
  author={Choi, Jonathan H and Hickman, Kristin E and Monahan, Amy and Schwarcz, Daniel},
  journal={Available at SSRN},
  year={2023}
}

@misc{Li-arxiv-2023-ChatDoctor,
      title={ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge}, 
      author={Li Yunxiang and Li Zihan and Zhang Kai and Dan Ruilong and Zhang You},
      year={2023},
      eprint={2303.14070},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Sun-arxiv-2023-A,
  author    = {Zhongxiang Sun},
  title     = {A Short Survey of Viewing Large Language Models in Legal Aspect},
  journal   = {CoRR},
  volume    = {abs/2303.09136},
  year      = {2023},
  
}

@inproceedings{Abid-AIES-2021-Persistent,
  author    = {Abubakar Abid and
               Maheen Farooqi and
               James Zou},
  editor    = {Marion Fourcade and
               Benjamin Kuipers and
               Seth Lazar and
               Deirdre K. Mulligan},
  title     = {Persistent Anti-Muslim Bias in Large Language Models},
  booktitle = {{AIES} '21: {AAAI/ACM} Conference on AI, Ethics, and Society, Virtual
               Event, USA, May 19-21, 2021},
  pages     = {298--306},
  publisher = {{ACM}},
  year      = {2021}
}

@article{Tamkin-arxiv-2021-Understanding,
  author    = {Alex Tamkin and
               Miles Brundage and
               Jack Clark and
               Deep Ganguli},
  title     = {Understanding the Capabilities, Limitations, and Societal Impact of
               Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2102.02503},
  year      = {2021},
  
}

@article{Nay-arxiv-2022-Law,
  author    = {John J. Nay},
  title     = {Law Informs Code: {A} Legal Informatics Approach to Aligning Artificial
               Intelligence with Humans},
  journal   = {CoRR},
  volume    = {abs/2209.13020},
  year      = {2022},
  
}

@article{Yu-arxiv-2022-Legal,
  author    = {Fangyi Yu and
               Lee Quartey and
               Frank Schilder},
  title     = {Legal Prompting: Teaching a Language Model to Think Like a Lawyer},
  journal   = {CoRR},
  volume    = {abs/2212.01326},
  year      = {2022},
  
}

@article{Stanek-arxiv-2023-Can,
  author    = {Andrew Blair{-}Stanek and
               Nils Holzenberger and
               Benjamin Van Durme},
  title     = {Can {GPT-3} Perform Statutory Reasoning?},
  journal   = {CoRR},
  volume    = {abs/2302.06100},
  year      = {2023},
  
}

@article{Opara-arxiv-2023-ChatGPT,
  title={ChatGPT for Teaching, Learning and Research: Prospects and Challenges},
  author={Opara, Emmanuel and Mfon-Ette Theresa, Adalikwu and Aduke, Tolorunleke Caroline},
  volume={5},
  year={2023}
}

@article{tang-arxiv-2023-does,
  title={Does Synthetic Data Generation of LLMs Help Clinical Text Mining?},
  author={Tang, Ruixiang and Han, Xiaotian and Jiang, Xiaoqian and Hu, Xia},
  journal={arXiv preprint arXiv:2303.04360},
  year={2023}
}

@article{driess-arxiv-2023-palm,
  title={PaLM-E: An Embodied Multimodal Language Model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{Cao-arxiv-2023-comprehensive,
  title={A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT},
  author={Cao, Yihan and Li, Siyu and Liu, Yixin and Yan, Zhiling and Dai, Yutong and Yu, Philip S and Sun, Lichao},
  journal={arXiv preprint arXiv:2303.04226},
  year={2023}
}

@article{wu-arxiv-2023-visual,
  title={Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models},
  author={Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
  journal={arXiv preprint arXiv:2303.04671},
  year={2023}
}

@inproceedings{chan-ICLR-2023-knife,
  title={KNIFE: Distilling Meta-Reasoning Knowledge with Free-Text Rationales},
  author={Chan, Aaron and Zeng, Zhiyuan and Lake, Wyatt and Joshi, Brihi and Chen, Hanjie and Ren, Xiang},
  booktitle={ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML}
}

@article{Li-arxiv-2023-on,
  author    = {Zongjie Li and
               Chaozheng Wang and
               Pingchuan Ma and
               Chaowei Liu and
               Shuai Wang and
               Daoyuan Wu and
               Cuiyun Gao},
  title     = {On the Feasibility of Specialized Ability Stealing for Large Language
               Code Models},
  journal   = {CoRR},
  year      = {2023},
}

@article{Dai-ARXIV-2022-Promptagator,
  author    = {Zhuyun Dai and
               Vincent Y. Zhao and
               Ji Ma and
               Yi Luan and
               Jianmo Ni and
               Jing Lu and
               Anton Bakalov and
               Kelvin Guu and
               Keith B. Hall and
               Ming{-}Wei Chang},
  title     = {Promptagator: Few-shot Dense Retrieval From 8 Examples},
  journal   = {CoRR},
  year      = {2022},
}

@article{Zhao-arxiv-2022-Dense,
  author    = {Wayne Xin Zhao and
               Jing Liu and
               Ruiyang Ren and
               Ji{-}Rong Wen},
  title     = {Dense Text Retrieval based on Pretrained Language Models: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2211.14876},
  year      = {2022},
  
}

@inproceedings{Tan-ACL-2022-MSP,
  author    = {Zhixing Tan and
               Xiangwen Zhang and
               Shuo Wang and
               Yang Liu},
  editor    = {Smaranda Muresan and
               Preslav Nakov and
               Aline Villavicencio},
  title     = {{MSP:} Multi-Stage Prompting for Making Pre-trained Language Models
               Better Translators},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {6131--6142},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@inproceedings{Gao-ACL-2021-Making,
  author       = {Tianyu Gao and
                  Adam Fisch and
                  Danqi Chen},
  editor       = {Chengqing Zong and
                  Fei Xia and
                  Wenjie Li and
                  Roberto Navigli},
  title        = {Making Pre-trained Language Models Better Few-shot Learners},
  booktitle    = {Proceedings of the 59th Annual Meeting of the Association for Computational
                  Linguistics and the 11th International Joint Conference on Natural
                  Language Processing, {ACL/IJCNLP} 2021, (Volume 1: Long Papers), Virtual
                  Event, August 1-6, 2021},
  pages        = {3816--3830},
  publisher    = {Association for Computational Linguistics},
  year         = {2021}
}

@article{Zhou-CoRR-2023-InstructZero,
  author       = {Lichang Chen and
                  Jiuhai Chen and
                  Tom Goldstein and
                  Heng Huang and
                  Tianyi Zhou},
  title        = {InstructZero: Efficient Instruction Optimization for Black-Box Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2306.03082},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2306.03082},
  doi          = {10.48550/ARXIV.2306.03082},
  eprinttype    = {arXiv},
  eprint       = {2306.03082}
}

@inproceedings{Wang-EMNLP-2022-Iteratively,
  author    = {Boshi Wang and
               Xiang Deng and
               Huan Sun},
  editor    = {Yoav Goldberg and
               Zornitsa Kozareva and
               Yue Zhang},
  title     = {Iteratively Prompt Pre-trained Language Models for Chain of Thought},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {2714--2730},
  publisher = {Association for Computational Linguistics},
  year      = {2022}
}

@article{Lan-2021-arxiv-Complex,
  author    = {Yunshi Lan and
               Gaole He and
               Jinhao Jiang and
               Jing Jiang and
               Wayne Xin Zhao and
               Ji{-}Rong Wen},
  title     = {Complex Knowledge Base Question Answering: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2108.06688},
  year      = {2021},
  
}

@inproceedings{Rudinger-NAACL-2018-Gender,
  author    = {Rachel Rudinger and
               Jason Naradowsky and
               Brian Leonard and
               Benjamin Van Durme},
  title     = {Gender Bias in Coreference Resolution},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               NAACL-HLT, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 2 (Short
               Papers)},
  pages     = {8--14},
  year      = {2018},
}

@inproceedings{Nangia-EMNLP-2020-CrowS,
  author    = {Nikita Nangia and
               Clara Vania and
               Rasika Bhalerao and
               Samuel R. Bowman},
  title     = {CrowS-Pairs: {A} Challenge Dataset for Measuring Social Biases in
               Masked Language Models},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages     = {1953--1967},
  year      = {2020},
}

@misc{Wikipedia,
    url = {https://en.wikipedia.org/wiki/Main_Page},
    title = {Wikipedia},
}

@inproceedings{Koncel-NAACL-2016-MAWPS,
  title={MAWPS: A math word problem repository},
  author={Koncel-Kedziorski, Rik and Roy, Subhro and Amini, Aida and Kushman, Nate and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the 2016 conference of the north american chapter of the association for computational linguistics: human language technologies},
  pages={1152--1157},
  year={2016}
}

@article{Kwon-arxiv-2022-Reward,
  author    = {Minae Kwon and
               Sang Michael Xie and
               Kalesha Bullard and
               Dorsa Sadigh},
  title     = {Reward Design with Language Models},
  journal   = {CoRR},
  year      = {2023},
}

@inproceedings{Pi-EMNLP-2022-Reasoning,
  author    = {Xinyu Pi and
               Qian Liu and
               Bei Chen and
               Morteza Ziyadi and
               Zeqi Lin and
               Qiang Fu and
               Yan Gao and
               Jian{-}Guang Lou and
               Weizhu Chen},
  title     = {Reasoning Like Program Executors},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {761--779},
  year      = {2022},
}

@incollection{Michael-Psychology-1989-Catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  pages={109--165},
  year={1989},
}

@inproceedings{Kemker-AAAI-2018-Measuring,
  author    = {Ronald Kemker and
               Marc McClure and
               Angelina Abitino and
               Tyler L. Hayes and
               Christopher Kanan},
  title     = {Measuring Catastrophic Forgetting in Neural Networks},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence,
               (AAAI-18), the 30th innovative Applications of Artificial Intelligence
               (IAAI-18), and the 8th {AAAI} Symposium on Educational Advances in
               Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
               2-7, 2018},
  pages     = {3390--3398},
  year      = {2018},
}

@article{Weng-arxiv-2022-Large,
  author    = {Yixuan Weng and
               Minjun Zhu and
               Shizhu He and
               Kang Liu and
               Jun Zhao},
  title     = {Large Language Models are reasoners with Self-Verification},
  journal   = {CoRR},
  volume    = {abs/2212.09561},
  year      = {2022},
}






@article{Soltan-arxiv-2022-AlexaTM20B,
  author    = {Saleh Soltan and
               Shankar Ananthakrishnan and
               Jack FitzGerald and
               Rahul Gupta and
               Wael Hamza and
               Haidar Khan and
               Charith Peris and
               Stephen Rawls and
               Andy Rosenbaum and
               Anna Rumshisky and
               Chandana Satya Prakash and
               Mukund Sridhar and
               Fabian Triefenbach and
               Apurv Verma and
               G{\"{o}}khan T{\"{u}}r and
               Prem Natarajan},
  title     = {AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq
               Model},
  journal   = {CoRR},
  volume    = {abs/2208.01448},
  year      = {2022}
}

@inproceedings{Lepikhin-ILR-2021-GShard,
  author    = {Dmitry Lepikhin and
               HyoukJoong Lee and
               Yuanzhong Xu and
               Dehao Chen and
               Orhan Firat and
               Yanping Huang and
               Maxim Krikun and
               Noam Shazeer and
               Zhifeng Chen},
  title     = {GShard: Scaling Giant Models with Conditional Computation and Automatic
               Sharding},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  year      = {2021},
}

@article{Zhang-ICLR-2023-Planning,
  author    = {Shun Zhang and
               Zhenfang Chen and
               Yikang Shen and
               Mingyu Ding and
               Joshua B. Tenenbaum and
               Chuang Gan},
  title     = {Planning with Large Language Models for Code Generation},
  booktitle={The Eleventh International Conference on Learning Representations },
  year      = {2023},
}
@article{Kocon-arxiv-2023-ChatGPT,
  author    = {Jan Kocon and
               Igor Cichecki and
               Oliwier Kaszyca and
               Mateusz Kochanek and
               Dominika Szydlo and
               Joanna Baran and
               Julita Bielaniewicz and
               Marcin Gruza and
               Arkadiusz Janz and
               Kamil Kanclerz and
               Anna Kocon and
               Bartlomiej Koptyra and
               Wiktoria Mieleszczenko{-}Kowszewicz and
               Piotr Milkowski and
               Marcin Oleksy and
               Maciej Piasecki and
               Lukasz Radlinski and
               Konrad Wojtasik and
               Stanislaw Wozniak and
               Przemyslaw Kazienko},
  title     = {ChatGPT: Jack of all trades, master of none},
  journal   = {CoRR},
  volume    = {abs/2302.10724},
  year      = {2023},
}
@article{Cheng-arxiv-2023-UPRISE,
  title={UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation},
  author={Cheng, Daixuan and Huang, Shaohan and Bi, Junyu and Zhan, Yuefeng and Liu, Jianfeng and Wang, Yujing and Sun, Hao and Wei, Furu and Deng, Denvy and Zhang, Qi},
  journal={arXiv preprint arXiv:2303.08518},
  year={2023}
}


@article{Zhong-arxiv-2023-Can,
  author    = {Qihuang Zhong and
               Liang Ding and
               Juhua Liu and
               Bo Du and
               Dacheng Tao},
  title     = {Can ChatGPT Understand Too? {A} Comparative Study on ChatGPT and Fine-tuned
               {BERT}},
  journal   = {CoRR},
  volume    = {abs/2302.10198},
  year      = {2023},
}
@article{Li-arxiv-2023-Guiding,
  author    = {Zekun Li and
               Baolin Peng and
               Pengcheng He and
               Michel Galley and
               Jianfeng Gao and
               Xifeng Yan},
  title     = {Guiding Large Language Models via Directional Stimulus Prompting},
  journal   = {CoRR},
  volume    = {abs/2302.11520},
  year      = {2023},
}

@inproceedings{Min-EMNLP-2022-Rethinking,
  author    = {Sewon Min and
               Xinxi Lyu and
               Ari Holtzman and
               Mikel Artetxe and
               Mike Lewis and
               Hannaneh Hajishirzi and
               Luke Zettlemoyer},
  title     = {Rethinking the Role of Demonstrations: What Makes In-Context Learning
               Work?},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
               December 7-11, 2022},
  pages     = {11048--11064},
  publisher = {Association for Computational Linguistics},
  year      = {2022},
}

@software{Leo-zenodo-2021-A,
  author       = {Gao, Leo and
                  Tow, Jonathan and
                  Biderman, Stella and
                  Black, Sid and
                  DiPofi, Anthony and
                  Foster, Charles and
                  Golding, Laurence and
                  Hsu, Jeffrey and
                  McDonell, Kyle and
                  Muennighoff, Niklas and
                  Phang, Jason and
                  Reynolds, Laria and
                  Tang, Eric and
                  Thite, Anish and
                  Wang, Ben and
                  Wang, Kevin and
                  Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = sep,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.0.1},
}

@misc{CC-Stories-R,
    url = {https://huggingface.co/datasets/spacemanidol/cc-stories},
    title = {A reproduction version of CC-Stories on Hugging Face.}
}

@misc{Gokaslan2019OpenWeb,
    title={OpenWebText Corpus},
    author={Aaron Gokaslan and Vanya Cohen Ellie Pavlick and Stefanie Tellex},
    howpublished={\url{http://Skylion007.github.io/OpenWebTextCorpus}},
    year={2019}
}
@inproceedings{Dai-ACL-2022-Knowledge,
  author    = {Damai Dai and
               Li Dong and
               Yaru Hao and
               Zhifang Sui and
               Baobao Chang and
               Furu Wei},
  editor    = {Smaranda Muresan and
               Preslav Nakov and
               Aline Villavicencio},
  title     = {Knowledge Neurons in Pretrained Transformers},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {8493--8502},
  publisher = {Association for Computational Linguistics},
  year      = {2022},
}
@inproceedings{Meng-NIPS-2022-Locating,
  title={Locating and editing factual associations in gpt},
  author={Meng, Kevin and Bau, David and Andonian, Alex J and Belinkov, Yonatan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{Su-arxiv-2022-selective,
  author    = {Hongjin Su and
               Jungo Kasai and
               Chen Henry Wu and
               Weijia Shi and
               Tianlu Wang and
               Jiayi Xin and
               Rui Zhang and
               Mari Ostendorf and
               Luke Zettlemoyer and
               Noah A. Smith and
               Tao Yu},
  title     = {Selective Annotation Makes Language Models Better Few-Shot Learners},
  journal   = {CoRR},
  year      = {2022},
}

@article{Loshchilov-arxiv-2017-Fixing,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {Fixing Weight Decay Regularization in Adam},
  journal   = {CoRR},
  volume    = {abs/1711.05101},
  year      = {2017},
  
}

@article{Child-arxiv-2019-Generating,
  author    = {Rewon Child and
               Scott Gray and
               Alec Radford and
               Ilya Sutskever},
  title     = {Generating Long Sequences with Sparse Transformers},
  journal   = {CoRR},
  volume    = {abs/1904.10509},
  year      = {2019},
}

@inproceedings{Peng-ICLR-2021-Random,
  author    = {Hao Peng and
               Nikolaos Pappas and
               Dani Yogatama and
               Roy Schwartz and
               Noah A. Smith and
               Lingpeng Kong},
  title     = {Random Feature Attention},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
}

@inproceedings{Dao-NeurIPS-2020-FLASH,
title={FlashAttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
author={Tri Dao and Daniel Y Fu and Stefano Ermon and Atri Rudra and Christopher Re},
booktitle={{NeurIPS}},
year={2022}
}

@inproceedings{Zaheer-NIPS-2020-Big,
  author    = {Manzil Zaheer and
               Guru Guruganesh and
               Kumar Avinava Dubey and
               Joshua Ainslie and
               Chris Alberti and
               Santiago Onta{\~{n}}{\'{o}}n and
               Philip Pham and
               Anirudh Ravula and
               Qifan Wang and
               Li Yang and
               Amr Ahmed},

  title     = {Big Bird: Transformers for Longer Sequences},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
}

@article{Yao-arXiv-2023-Quantization,
  author    = {Zhewei Yao and
               Cheng Li and
               Xiaoxia Wu and
               Stephen Youn and
               Yuxiong He},
  title     = {A Comprehensive Study on Post-Training Quantization for Large Language
               Models},
  journal   = {CoRR},
  volume    = {abs/2303.08302},
  year      = {2023}
}

@misc{FairScale2021,
  author =       {{FairScale authors}},
  title =        {FairScale:  A general purpose modular PyTorch library for high performance and large scale training},
  howpublished = {\url{https://github.com/facebookresearch/fairscale}},
  year =         {2021}
}
@article{Ye-arxiv-2023-A,
  title={A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models},
  author={Junjie Ye and Xuanting Chen and Nuo Xu and Can Zu and Zekai Shao and Shichun Liu and Yuhan Cui and Zeyang Zhou and Chao Gong and Yang Shen and Jie Zhou and Siming Chen and Tao Gui and Qi Zhang and Xuanjing Huang},
  journal={arXiv preprint arXiv:2303.10420},
  year={2023}
}

@inproceedings{Ding-NIPS-2021-CogView,
  author    = {Ming Ding and
               Zhuoyi Yang and
               Wenyi Hong and
               Wendi Zheng and
               Chang Zhou and
               Da Yin and
               Junyang Lin and
               Xu Zou and
               Zhou Shao and
               Hongxia Yang and
               Jie Tang},
  title     = {CogView: Mastering Text-to-Image Generation via Transformers},
  booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference
               on Neural Information Processing Systems 2021, NeurIPS 2021, December
               6-14, 2021, virtual},
  pages     = {19822--19835},
  year      = {2021},
}
@inproceedings{Bubeck-arxiv-2023-Sparks,
  title={Sparks of Artificial General Intelligence: Early experiments with GPT-4},
  author={S'ebastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
  journal   = {CoRR},
  volume    = {abs/2303.12712},
  year={2023}
}


@article{Collobert-JMLR-2011,
  author    = {Ronan Collobert and
               Jason Weston and
               L{\'{e}}on Bottou and
               Michael Karlen and
               Koray Kavukcuoglu and
               Pavel P. Kuksa},
  title     = {Natural Language Processing (Almost) from Scratch},
  journal   = {J. Mach. Learn. Res.},
  volume    = {12},
  pages     = {2493--2537},
  year      = {2011},
}

@article{Wang-arxiv-2023-On,
  author    = {Jindong Wang and
               Xixu Hu and
               Wenxin Hou and
               Hao Chen and
               Runkai Zheng and
               Yidong Wang and
               Linyi Yang and
               Haojun Huang and
               Wei Ye and
               Xiubo Geng and
               Binxing Jiao and
               Yue Zhang and
               Xing Xie},
  title     = {On the Robustness of ChatGPT: An Adversarial and Out-of-distribution
               Perspective},
  journal   = {CoRR},
  volume    = {abs/2302.12095},
  year      = {2023},
}

@article{Sifatkaur-arxiv-2023-Mind,
  author    = {Sifatkaur and
               Manmeet Singh and
               Vaisakh S. B and
               Neetiraj Malviya},
  title     = {Mind meets machine: Unravelling GPT-4's cognitive psychology},
  journal   = {CoRR},
  volume    = {abs/2303.11436},
  year      = {2023},
}
@article{Dettmers-arxiv-2022-LLM,
  author    = {Tim Dettmers and
               Mike Lewis and
               Younes Belkada and
               Luke Zettlemoyer},
  title     = {LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale},
  journal   = {CoRR},
  volume    = {abs/2208.07339},
  year      = {2022},
}
@inproceedings{Tao-ACL-2022-Compression,
  author    = {Chaofan Tao and
               Lu Hou and
               Wei Zhang and
               Lifeng Shang and
               Xin Jiang and
               Qun Liu and
               Ping Luo and
               Ngai Wong},
  editor    = {Smaranda Muresan and
               Preslav Nakov and
               Aline Villavicencio},
  title     = {Compression of Generative Pre-trained Language Models via Quantization},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational
               Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
               May 22-27, 2022},
  pages     = {4821--4836},
  publisher = {Association for Computational Linguistics},
  year      = {2022},
  
}

@article{Cai-arxiv-2023-Does,
  author    = {Zhenguang G. Cai and
               David A. Haslett and
               Xufeng Duan and
               Shuqi Wang and
               Martin J. Pickering},
  title     = {Does ChatGPT resemble humans in language use?},
  journal   = {CoRR},
  volume    = {abs/2303.08014},
  year      = {2023},
}

@inproceedings{Aiyapa-arxiv-2023-Can,
  title={Can we trust the evaluation on ChatGPT?},
  author={Rachith Aiyappa and Jisun An and Haewoon Kwak and Yong-Yeol Ahn},
  journal   = {CoRR},
  volume    = {abs/2303.12767},
  year      = {2023},
}

@article{Gilson-medRxiv-2023-How,
  title={How Does ChatGPT Perform on the Medical Licensing Exams},
  author={Gilson, A and Safranek, C and Huang, T and Socrates, V and Chi, L and Taylor, RA and others},
  journal={The Implications of Large Language Models for Medical Education and Knowledge Assessment. medRxiv, doi: doi. org/10.1101/2022.12},
  volume={23},
  year={2023}
}

@inproceedings{Nori-arxiv-2023-Capabilities,
  title={Capabilities of GPT-4 on Medical Challenge Problems},
  author={Harsha Nori and Nicholas King and Scott Mayer McKinney and Dean Carignan and Eric Horvitz},
  journal   = {CoRR},
  volume    = {abs/2303.13375},
  year={2023}
}

@article{Livin-arixv-2022-Can,
  author    = {Valentin Li{\'{e}}vin and
               Christoffer Egeberg Hother and
               Ole Winther},
  title     = {Can large language models reason about medical questions?},
  journal   = {CoRR},
  volume    = {abs/2207.08143},
  year      = {2022},
}


@article{Wang-arxiv-2021-ERNIE,
  author    = {Shuohuan Wang and
               Yu Sun and
               Yang Xiang and
               Zhihua Wu and
               Siyu Ding and
               Weibao Gong and
               Shikun Feng and
               Junyuan Shang and
               Yanbin Zhao and
               Chao Pang and
               Jiaxiang Liu and
               Xuyi Chen and
               Yuxiang Lu and
               Weixin Liu and
               Xi Wang and
               Yangfan Bai and
               Qiuliang Chen and
               Li Zhao and
               Shiyong Li and
               Peng Sun and
               Dianhai Yu and
               Yanjun Ma and
               Hao Tian and
               Hua Wu and
               Tian Wu and
               Wei Zeng and
               Ge Li and
               Wen Gao and
               Haifeng Wang},
  title     = {{ERNIE} 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training
               for Language Understanding and Generation},
  journal   = {CoRR},
  volume    = {abs/2112.12731},
  year      = {2021}
}

@inproceedings{Kim-EMNLP-2021-HyperCLOVA,
  author    = {Boseop Kim and
               HyoungSeok Kim and
               Sang{-}Woo Lee and
               Gichang Lee and
               Dong{-}Hyun Kwak and
               Dong Hyeon Jeon and
               Sunghyun Park and
               Sungju Kim and
               Seonhoon Kim and
               Dongpil Seo and
               Heungsub Lee and
               Minyoung Jeong and
               Sungjae Lee and
               Minsub Kim and
               SukHyun Ko and
               Seokhun Kim and
               Taeyong Park and
               Jinuk Kim and
               Soyoung Kang and
               Na{-}Hyeon Ryu and
               Kang Min Yoo and
               Minsuk Chang and
               Soobin Suh and
               Sookyo In and
               Jinseong Park and
               Kyungduk Kim and
               Hiun Kim and
               Jisu Jeong and
               Yong Goo Yeo and
               Donghoon Ham and
               Dongju Park and
               Min Young Lee and
               Jaewook Kang and
               Inho Kang and
               Jung{-}Woo Ha and
               Woo{-}Myoung Park and
               Nako Sung},
  title     = {What Changes Can Large-scale Language Models Bring? Intensive Study
               on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
               Republic, 7-11 November, 2021},
  publisher = {Association for Computational Linguistics},
  year      = {2021}
}

@article{Zeng-arxiv-2021-PanGualpha,
  author    = {Wei Zeng and
               Xiaozhe Ren and
               Teng Su and
               Hui Wang and
               Yi Liao and
               Zhiwei Wang and
               Xin Jiang and
               ZhenZhang Yang and
               Kaisheng Wang and
               Xiaoda Zhang and
               Chen Li and
               Ziyan Gong and
               Yifan Yao and
               Xinjing Huang and
               Jun Wang and
               Jianfeng Yu and
               Qi Guo and
               Yue Yu and
               Yan Zhang and
               Jin Wang and
               Hengtao Tao and
               Dasen Yan and
               Zexuan Yi and
               Fang Peng and
               Fangqing Jiang and
               Han Zhang and
               Lingfeng Deng and
               Yehong Zhang and
               Zhe Lin and
               Chao Zhang and
               Shaojie Zhang and
               Mingyue Guo and
               Shanzhi Gu and
               Gaojun Fan and
               Yaowei Wang and
               Xuefeng Jin and
               Qun Liu and
               Yonghong Tian},
  title     = {PanGu-{\(\alpha\)}: Large-scale Autoregressive Pretrained Chinese
               Language Models with Auto-parallel Computation},
  journal   = {CoRR},
  volume    = {abs/2104.12369},
  year      = {2021}
}

@article{Wu-arxiv-2021-Yuan,
  title={Yuan 1.0: Large-scale pre-trained language model in zero-shot and few-shot learning},
  author={Wu, Shaohua and Zhao, Xudong and Yu, Tong and Zhang, Rongguo and Shen, Chong and Liu, Hongli and Li, Feng and Zhu, Hong and Luo, Jiangang and Xu, Liang and others},
  journal={arXiv preprint arXiv:2110.04725},
  year={2021}
}

@article{Nov-arxiv-2023-Medical,
  author    = {Oded Nov and
               Nina Singh and
               Devin M. Mann},
  title     = {Putting ChatGPT's Medical Advice to the (Turing) Test},
  journal   = {CoRR},
  volume    = {abs/2301.10035},
  year      = {2023},
}

@article{Jeblick-arxiv-2023-Medicine,
  author    = {Katharina Jeblick and
               Balthasar Schachtner and
               Jakob Dexl and
               Andreas Mittermeier and
               Anna Theresa St{\"{u}}ber and
               Johanna Topalis and
               Tobias Weber and
               Philipp Wesp and
               Bastian O. Sabel and
               Jens Ricke and
               Michael Ingrisch},
  title     = {ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study
               on Simplified Radiology Reports},
  journal   = {CoRR},
  volume    = {abs/2212.14882},
  year      = {2022},
}

@article {Chen-medrxiv-2023-cancer,
	author = {Chen, Shan and Kann, Benjamin H and Foote, Michael B and Aerts, Hugo JWL and Savova, Guergana K and Mak, Raymond H and Bitterman, Danielle S},
	title = {The utility of ChatGPT for cancer treatment information},
	year = {2023},
	journal = {medRxiv}
}

@article{Malinka-arxiv-2023-Education,
  author    = {Kamil Malinka and
               Martin Peres{\'{\i}}ni and
               Anton Firc and
               Ondrej Hujnak and
               Filip Janus},
  title     = {On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready
               to Obtain a University Degree?},
  journal   = {CoRR},
  volume    = {abs/2303.11146},
  year      = {2023},
}

@article{Susnjak-arxiv-2022-Education,
  author    = {Teo Susnjak},
  title     = {ChatGPT: The End of Online Exam Integrity?},
  journal   = {CoRR},
  volume    = {abs/2212.09292},
  year      = {2022},
}

@article{Basic-arxiv-2023-Education,
  author    = {Zeljana Basic and
               Ana Banovac and
               Ivana Kruzic and
               Ivan Jerkovic},
  title     = {Better by you, better than me, chatgpt3 as writing assistance in students
               essays},
  journal   = {CoRR},
  volume    = {abs/2302.04536},
  year      = {2023},
}

@article{Ali-arxiv-2023-Program,
  title={ChatGPT for Programming Numerical Methods},
  author={Kashefi, Ali and Mukerji, Tapan},
  journal={arXiv preprint arXiv:2303.12093},
  year={2023}
}

@article{Kortemeyer-arxiv-2023-physics,
  title={Could an Artificial-Intelligence agent pass an introductory physics course?},
  author={Kortemeyer, Gerd},
  journal={arXiv preprint arXiv:2301.12127},
  year={2023}
}

@article{Noever-arxiv-2023-Science,
  author    = {David Noever and
               Forrest McKee},
  title     = {Numeracy from Literacy: Data Science as an Emergent Skill from Large
               Language Models},
  journal   = {CoRR},
  volume    = {abs/2301.13382},
  year      = {2023},
}

@article{Wang-arxiv-2023-Science,
  author    = {Shuai Wang and
               Harrisen Scells and
               Bevan Koopman and
               Guido Zuccon},
  title     = {Can ChatGPT Write a Good Boolean Query for Systematic Review Literature
               Search?},
  journal   = {CoRR},
  volume    = {abs/2302.03495},
  year      = {2023},
}

@article{Frieder-arxiv-2023-Math,
  author    = {Simon Frieder and
               Luca Pinchetti and
               Ryan{-}Rhys Griffiths and
               Tommaso Salvatori and
               Thomas Lukasiewicz and
               Philipp Christian Petersen and
               Alexis Chevalier and
               Julius Berner},
  title     = {Mathematical Capabilities of ChatGPT},
  journal   = {CoRR},
  volume    = {abs/2301.13867},
  year      = {2023},
}

@article{Borji-arxiv-2023-Failures,
  author    = {Ali Borji},
  title     = {A Categorical Archive of ChatGPT Failures},
  journal   = {CoRR},
  volume    = {abs/2302.03494},
  year      = {2023},
}

@article{Sobania-arxiv-2023-Program,
  author    = {Dominik Sobania and
               Martin Briesch and
               Carol Hanna and
               Justyna Petke},
  title     = {An Analysis of the Automatic Bug Fixing Performance of ChatGPT},
  journal   = {CoRR},
  volume    = {abs/2301.08653},
  year      = {2023},
}

@article{Bordt-arxiv-2023-CS,
  author    = {Sebastian Bordt and
               Ulrike von Luxburg},
  title     = {ChatGPT Participates in a Computer Science Exam},
  journal   = {CoRR},
  volume    = {abs/2303.09461},
  year      = {2023},
}


@article{Tan-arxiv-2023-KBQA,
  author    = {Yiming Tan and
               Dehai Min and
               Yu Li and
               Wenbo Li and
               Nan Hu and
               Yongrui Chen and
               Guilin Qi},
  title     = {Evaluation of ChatGPT as a Question Answering System for Answering
               Complex Questions},
  journal   = {CoRR},
  volume    = {abs/2303.07992},
  year      = {2023},
}

@article{Hendy-arxiv-2023-MT,
  author    = {Amr Hendy and
               Mohamed Abdelrehim and
               Amr Sharaf and
               Vikas Raunak and
               Mohamed Gabr and
               Hitokazu Matsushita and
               Young Jin Kim and
               Mohamed Afify and
               Hany Hassan Awadalla},
  title     = {How Good Are {GPT} Models at Machine Translation? {A} Comprehensive
               Evaluation},
  journal   = {CoRR},
  volume    = {abs/2302.09210},
  year      = {2023},
}

@article{Jiao-arxiv-2023-mt,
  title={Is ChatGPT a good translator? A preliminary study},
  author={Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and Wang, Xing and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2301.08745},
  year={2023}
}

@inproceedings{Agrawal-arxiv-2023-Are,
  title={Are LLMs the Master of All Trades? : Exploring Domain-Agnostic Reasoning Skills of LLMs},
  author={Shrivats Agrawal},
  journal   = {CoRR},
  volume    = {abs/2303.12810},
  year={2023}
}

@article{Jang-arxiv-2023-Consistency,
  author    = {Myeongjun Jang and
               Thomas Lukasiewicz},
  title     = {Consistency Analysis of ChatGPT},
  journal   = {CoRR},
  volume    = {abs/2303.06273},
  year      = {2023},
}

@inproceedings{Ma-arxiv-2023-AI,
  title={AI vs. Human -- Differentiation Analysis of Scientific Content Generation},
  author={Yongqiang Ma and Jiawei Liu and Fan Yi and Qikai Cheng and Yong Huang and Wei Lu and Xiaozhong Liu},
  year={2023},
  ournal   = {CoRR},
  volume    = {abs/2301.10416},
  year={2023}
}

@article{Rao-arxiv-2023-psy,
  author    = {Haocong Rao and
               Cyril Leung and
               Chunyan Miao},
  title     = {Can ChatGPT Assess Human Personalities? {A} General Evaluation Framework},
  journal   = {CoRR},
  volume    = {abs/2303.01248},
  year      = {2023},
}

@article{Li-arxiv-2023-psy,
  author    = {Xingxuan Li and
               Yutong Li and
               Linlin Liu and
               Lidong Bing and
               Shafiq R. Joty},
  title     = {Is {GPT-3} a Psychopath? Evaluating Large Language Models from a Psychological
               Perspective},
  journal   = {CoRR},
  volume    = {abs/2212.10529},
  year      = {2022},
}

@article{Kosinski-arxiv-2023-tom,
  author    = {Michal Kosinski},
  title     = {Theory of Mind May Have Spontaneously Emerged in Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2302.02083},
  year      = {2023},
}

@article{Amin-arxiv-2023-affective,
  author    = {Mostafa M. Amin and
               Erik Cambria and
               Bj{\"{o}}rn W. Schuller},
  title     = {Will Affective Computing Emerge from Foundation Models and General
               AI? {A} First Evaluation on ChatGPT},
  journal   = {CoRR},
  volume    = {abs/2303.03186},
  year      = {2023},
}

@online{Leffer-online-2023-cnet,
author = {Lauren Leffer},
title = {CNET is reviewing the accuracy of all its AI-written articles after multiple major corrections},
url = {https://www.gizmodo.com.au/2023/01/cnet-is-reviewing-the-accuracy-of-all-its-ai-written-articles-after-multiple-major-corrections/},
year = {2023},
month = {January},
day = {17}
}


@article{Chen-arxiv-2016-training,
  author    = {Tianqi Chen and
               Bing Xu and
               Chiyuan Zhang and
               Carlos Guestrin},
  title     = {Training Deep Nets with Sublinear Memory Cost},
  journal   = {CoRR},
  volume    = {abs/1604.06174},
  year      = {2016}
}


@article{Korthikanti-arxiv-2022-reducing,
  author    = {Vijay Korthikanti and
               Jared Casper and
               Sangkug Lym and
               Lawrence McAfee and
               Michael Andersch and
               Mohammad Shoeybi and
               Bryan Catanzaro},
  title     = {Reducing Activation Recomputation in Large Transformer Models},
  journal   = {CoRR},
  volume    = {abs/2205.05198},
  year      = {2022}
}

@article{gao-arxiv-2023-exploring,
  author    = {Jun Gao and
               Huan Zhao and
               Changlong Yu and
               Ruifeng Xu},
  title     = {Exploring the Feasibility of ChatGPT for Event Extraction},
  journal   = {CoRR},
  volume    = {abs/2303.03836},
  year      = {2023},
}

@article{ma-arxiv-2023-Large,
  author    = {Yubo Ma and
               Yixin Cao and
               YongChing Hong and
               Aixin Sun},
  title     = {Large Language Model Is Not a Good Few-shot Information Extractor,
               but a Good Reranker for Hard Samples!},
  journal   = {CoRR},
  volume    = {abs/2303.08559},
  year      = {2023},
}

@misc{walker-ldc-2006-ace,
  title={ACE 2005 Multilingual Training Corpus LDC2006T06},
  author={Walker, Christopher and et al.},
  year={2006},
  publisher={Linguistic Data Consortium},
  address={Philadelphia},
}

@inproceedings{Papineni-acl-2002-bleu,
  author    = {Kishore Papineni and
               Salim Roukos and
               Todd Ward and
               Wei{-}Jing Zhu},
  title     = {Bleu: a Method for Automatic Evaluation of Machine Translation},
  booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational
               Linguistics, July 6-12, 2002, Philadelphia, PA, {USA}},
  pages     = {311--318},
  publisher = {{ACL}},
  year      = {2002},
}

@inproceedings{lin-acl-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    publisher = "Association for Computational Linguistics",
    pages = "74--81",
}

@article{He-arXiv-2021-FastMoE,
  author    = {Jiaao He and
               Jiezhong Qiu and
               Aohan Zeng and
               Zhilin Yang and
               Jidong Zhai and
               Jie Tang},
  title     = {FastMoE: {A} Fast Mixture-of-Expert Training System},
  journal   = {CoRR},
  volume    = {abs/2103.13262},
  year      = {2021},
  
}

@article{Yuan-arXiv-2021-OneFlow,
  author    = {Jinhui Yuan and
               Xinqi Li and
               Cheng Cheng and
               Juncheng Liu and
               Ran Guo and
               Shenghang Cai and
               Chi Yao and
               Fei Yang and
               Xiaodong Yi and
               Chuan Wu and
               Haoran Zhang and
               Jie Zhao},
  title     = {OneFlow: Redesign the Distributed Deep Learning Framework from Scratch},
  journal   = {CoRR},
  volume    = {abs/2110.15032},
  year      = {2021},
}


@misc{Gilardi-arXiv-2023-Crowd,
      title={ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks}, 
      author={Fabrizio Gilardi and Meysam Alizadeh and Maël Kubli},
      year={2023},
      eprint={2303.15056},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Ren-arXiv-2023-PanGusigma,
  author    = {Xiaozhe Ren and
               Pingyi Zhou and
               Xinfan Meng and
               Xinjing Huang and
               Yadao Wang and
               Weichao Wang and
               Pengfei Li and
               Xiaoda Zhang and
               Alexander Podolskiy and
               Grigory Arshinov and
               Andrey Bout and
               Irina Piontkovskaya and
               Jiansheng Wei and
               Xin Jiang and
               Teng Su and
               Qun Liu and
               Jun Yao},
  title     = {PanGu-{\(\Sigma\)}: Towards Trillion Parameter Language Model with
               Sparse Heterogeneous Computing},
  journal   = {CoRR},
  volume    = {abs/2303.10845},
  year      = {2023},
  
}

@article{Zhang-arXiv-2021-CPM-2,
  author    = {Zhengyan Zhang and
               Yuxian Gu and
               Xu Han and
               Shengqi Chen and
               Chaojun Xiao and
               Zhenbo Sun and
               Yuan Yao and
               Fanchao Qi and
               Jian Guan and
               Pei Ke and
               Yanzheng Cai and
               Guoyang Zeng and
               Zhixing Tan and
               Zhiyuan Liu and
               Minlie Huang and
               Wentao Han and
               Yang Liu and
               Xiaoyan Zhu and
               Maosong Sun},
  title     = {{CPM-2:} Large-scale Cost-effective Pre-trained Language Models},
  journal   = {CoRR},
  volume    = {abs/2106.10715},
  year      = {2021},
}

@article{Sun-arXiv-2021-ERNIE3.0,
  author    = {Yu Sun and
               Shuohuan Wang and
               Shikun Feng and
               Siyu Ding and
               Chao Pang and
               Junyuan Shang and
               Jiaxiang Liu and
               Xuyi Chen and
               Yanbin Zhao and
               Yuxiang Lu and
               Weixin Liu and
               Zhihua Wu and
               Weibao Gong and
               Jianzhong Liang and
               Zhizhou Shang and
               Peng Sun and
               Wei Liu and
               Xuan Ouyang and
               Dianhai Yu and
               Hao Tian and
               Hua Wu and
               Haifeng Wang},
  title     = {{ERNIE} 3.0: Large-scale Knowledge Enhanced Pre-training for Language
               Understanding and Generation},
  journal   = {CoRR},
  volume    = {abs/2107.02137},
  year      = {2021},
}

@misc{BMTrain,
    url = {https://github.com/OpenBMB/BMTrain},
    title = {BMTrain: Effient Training for Big Models}

}

@inproceedings{Sennrich-ACL-2016-Neural,
  author    = {Rico Sennrich and
               Barry Haddow and
               Alexandra Birch},
  title     = {Neural Machine Translation of Rare Words with Subword Units},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2016, August 7-12, 2016, Berlin, Germany, Volume
               1: Long Papers},
  publisher = {The Association for Computer Linguistics},
  year      = {2016},
}


@misc{Davis-arxiv-2001-Unicode,
  title={Unicode normalization forms},
  author={Davis, Mark and D{\"u}rst, Martin},
  year={2001},
  publisher={March}
}


@inproceedings{Xiong-ICML-2020-On,
  title={On layer normalization in the transformer architecture},
  author={Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tieyan},
  booktitle={{ICML}},
  year={2020}
}

@inproceedings{Kudo-EMNLP-2018-SentencePiece,
  author    = {Taku Kudo and
               John Richardson},
  editor    = {Eduardo Blanco and
               Wei Lu},
  title     = {SentencePiece: {A} simple and language independent subword tokenizer
               and detokenizer for Neural Text Processing},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2018: System Demonstrations, Brussels,
               Belgium, October 31 - November 4, 2018},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
}

@misc{ColossalChat,
    url = {https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b},
    title = {ColossalChat: An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline},
    author = {Yang You},
    year = {2023}
}


@inproceedings{Borgeaud-icml-2022-Improving,
  author    = {Sebastian Borgeaud and
               Arthur Mensch and
               Jordan Hoffmann and
               Trevor Cai and
               Eliza Rutherford and
               Katie Millican and
               George van den Driessche and
               Jean{-}Baptiste Lespiau and
               Bogdan Damoc and
               Aidan Clark and
               Diego de Las Casas and
               Aurelia Guy and
               Jacob Menick and
               Roman Ring and
               Tom Hennigan and
               Saffron Huang and
               Loren Maggiore and
               Chris Jones and
               Albin Cassirer and
               Andy Brock and
               Michela Paganini and
               Geoffrey Irving and
               Oriol Vinyals and
               Simon Osindero and
               Karen Simonyan and
               Jack W. Rae and
               Erich Elsen and
               Laurent Sifre},
  editor    = {Kamalika Chaudhuri and
               Stefanie Jegelka and
               Le Song and
               Csaba Szepesv{\'{a}}ri and
               Gang Niu and
               Sivan Sabato},
  title     = {Improving Language Models by Retrieving from Trillions of Tokens},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {162},
  pages     = {2206--2240},
  publisher = {{PMLR}},
  year      = {2022},
}

@inproceedings{Barrault-WMT-2019-Findings,
  author    = {Lo{\"{\i}}c Barrault and
               Ondrej Bojar and
               Marta R. Costa{-}juss{\`{a}} and
               Christian Federmann and
               Mark Fishel and
               Yvette Graham and
               Barry Haddow and
               Matthias Huck and
               Philipp Koehn and
               Shervin Malmasi and
               Christof Monz and
               Mathias M{\"{u}}ller and
               Santanu Pal and
               Matt Post and
               Marcos Zampieri},
  editor    = {Ondrej Bojar and
               Rajen Chatterjee and
               Christian Federmann and
               Mark Fishel and
               Yvette Graham and
               Barry Haddow and
               Matthias Huck and
               Antonio Jimeno{-}Yepes and
               Philipp Koehn and
               Andr{\'{e}} Martins and
               Christof Monz and
               Matteo Negri and
               Aur{\'{e}}lie N{\'{e}}v{\'{e}}ol and
               Mariana L. Neves and
               Matt Post and
               Marco Turchi and
               Karin Verspoor},
  title     = {Findings of the 2019 Conference on Machine Translation {(WMT19)}},
  booktitle = {Proceedings of the Fourth Conference on Machine Translation, {WMT}
               2019, Florence, Italy, August 1-2, 2019 - Volume 2: Shared Task Papers,
               Day 1},
  pages     = {1--61},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
}

@inproceedings{Barrault-WMT-2020-Findings,
  author    = {Lo{\"{\i}}c Barrault and
               Magdalena Biesialska and
               Ondrej Bojar and
               Marta R. Costa{-}juss{\`{a}} and
               Christian Federmann and
               Yvette Graham and
               Roman Grundkiewicz and
               Barry Haddow and
               Matthias Huck and
               Eric Joanis and
               Tom Kocmi and
               Philipp Koehn and
               Chi{-}kiu Lo and
               Nikola Ljubesic and
               Christof Monz and
               Makoto Morishita and
               Masaaki Nagata and
               Toshiaki Nakazawa and
               Santanu Pal and
               Matt Post and
               Marcos Zampieri},
  editor    = {Lo{\"{\i}}c Barrault and
               Ondrej Bojar and
               Fethi Bougares and
               Rajen Chatterjee and
               Marta R. Costa{-}juss{\`{a}} and
               Christian Federmann and
               Mark Fishel and
               Alexander Fraser and
               Yvette Graham and
               Paco Guzman and
               Barry Haddow and
               Matthias Huck and
               Antonio Jimeno{-}Yepes and
               Philipp Koehn and
               Andr{\'{e}} Martins and
               Makoto Morishita and
               Christof Monz and
               Masaaki Nagata and
               Toshiaki Nakazawa and
               Matteo Negri},
  title     = {Findings of the 2020 Conference on Machine Translation {(WMT20)}},
  booktitle = {Proceedings of the Fifth Conference on Machine Translation, WMT@EMNLP
               2020, Online, November 19-20, 2020},
  pages     = {1--55},
  publisher = {Association for Computational Linguistics},
  year      = {2020},
}

@inproceedings{Akhbardeh-WMT-2021-Findings,
  author    = {Farhad Akhbardeh and
               Arkady Arkhangorodsky and
               Magdalena Biesialska and
               Ondrej Bojar and
               Rajen Chatterjee and
               Vishrav Chaudhary and
               Marta R. Costa{-}juss{\`{a}} and
               Cristina Espa{\~{n}}a{-}Bonet and
               Angela Fan and
               Christian Federmann and
               Markus Freitag and
               Yvette Graham and
               Roman Grundkiewicz and
               Barry Haddow and
               Leonie Harter and
               Kenneth Heafield and
               Christopher Homan and
               Matthias Huck and
               Kwabena Amponsah{-}Kaakyire and
               Jungo Kasai and
               Daniel Khashabi and
               Kevin Knight and
               Tom Kocmi and
               Philipp Koehn and
               Nicholas Lourie and
               Christof Monz and
               Makoto Morishita and
               Masaaki Nagata and
               Ajay Nagesh and
               Toshiaki Nakazawa and
               Matteo Negri and
               Santanu Pal and
               Allahsera Auguste Tapo and
               Marco Turchi and
               Valentin Vydrin and
               Marcos Zampieri},
  editor    = {Lo{\"{\i}}c Barrault and
               Ondrej Bojar and
               Fethi Bougares and
               Rajen Chatterjee and
               Marta R. Costa{-}juss{\`{a}} and
               Christian Federmann and
               Mark Fishel and
               Alexander Fraser and
               Markus Freitag and
               Yvette Graham and
               Roman Grundkiewicz and
               Paco Guzman and
               Barry Haddow and
               Matthias Huck and
               Antonio Jimeno{-}Yepes and
               Philipp Koehn and
               Tom Kocmi and
               Andr{\'{e}} Martins and
               Makoto Morishita and
               Christof Monz},
  title     = {Findings of the 2021 Conference on Machine Translation {(WMT21)}},
  booktitle = {Proceedings of the Sixth Conference on Machine Translation, WMT@EMNLP
               2021, Online Event, November 10-11, 2021},
  pages     = {1--88},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
}

@inproceedings{Kocmi-WMT-2022-Findings,
  author    = {Tom Kocmi and
               Rachel Bawden and
               Ondrej Bojar and
               Anton Dvorkovich and
               Christian Federmann and
               Mark Fishel and
               Thamme Gowda and
               Yvette Graham and
               Roman Grundkiewicz and
               Barry Haddow and
               Rebecca Knowles and
               Philipp Koehn and
               Christof Monz and
               Makoto Morishita and
               Masaaki Nagata and
               Toshiaki Nakazawa and
               Michal Nov{\'{a}}k and
               Martin Popel and
               Maja Popovic},
  editor    = {Philipp Koehn and
               Lo{\"{\i}}c Barrault and
               Ondrej Bojar and
               Fethi Bougares and
               Rajen Chatterjee and
               Marta R. Costa{-}juss{\`{a}} and
               Christian Federmann and
               Mark Fishel and
               Alexander Fraser and
               Markus Freitag and
               Yvette Graham and
               Roman Grundkiewicz and
               Paco Guzman and
               Barry Haddow and
               Matthias Huck and
               Antonio Jimeno{-}Yepes and
               Tom Kocmi and
               Andr{\'{e}} Martins and
               Makoto Morishita and
               Christof Monz and
               Masaaki Nagata and
               Toshiaki Nakazawa and
               Matteo Negri and
               Aur{\'{e}}lie N{\'{e}}v{\'{e}}ol and
               Mariana Neves and
               Martin Popel and
               Marco Turchi and
               Marcos Zampieri},
  title     = {Findings of the 2022 Conference on Machine Translation {(WMT22)}},
  booktitle = {Proceedings of the Seventh Conference on Machine Translation, {WMT}
               2022, Abu Dhabi, United Arab Emirates (Hybrid), December 7-8, 2022},
  pages     = {1--45},
  publisher = {Association for Computational Linguistics},
  year      = {2022},
}

@inproceedings{Nallapati-acl-2016-Abstractive,
  author    = {Ramesh Nallapati and
               Bowen Zhou and
               C{\'{\i}}cero Nogueira dos Santos and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               Bing Xiang},
  editor    = {Yoav Goldberg and
               Stefan Riezler},
  title     = {Abstractive Text Summarization using Sequence-to-sequence RNNs and
               Beyond},
  booktitle = {Proceedings of the 20th {SIGNLL} Conference on Computational Natural
               Language Learning, CoNLL 2016, Berlin, Germany, August 11-12, 2016},
  pages     = {280--290},
  publisher = {{ACL}},
  year      = {2016},
}

@article{Ye-arxiv-2023-Compositional,
  author    = {Jiacheng Ye and
               Zhiyong Wu and
               Jiangtao Feng and
               Tao Yu and
               Lingpeng Kong},
  title     = {Compositional Exemplars for In-context Learning},
  journal   = {CoRR},
  year      = {2023},
}

@article{Li-arxiv-2023-Finding,
  author    = {Xiaonan Li and
               Xipeng Qiu},
  title     = {Finding Supporting Examples for In-Context Learning},
  journal   = {CoRR},
  year      = {2023},
}

@article{Lin-arxiv-2023-Selective,
  author    = {Yen{-}Ting Lin and
               Alexandros Papangelis and
               Seokhwan Kim and
               Sungjin Lee and
               Devamanyu Hazarika and
               Mahdi Namazifar and
               Di Jin and
               Yang Liu and
               Dilek Hakkani{-}Tur},
  title     = {Selective In-Context Data Augmentation for Intent Detection using
               Pointwise V-Information},
  journal   = {CoRR},
  year      = {2023},
}

@inproceedings{Lee-COLING-2022-Does,
  author    = {Young{-}Jun Lee and
               Chae{-}Gyun Lim and
               Ho{-}Jin Choi},
  editor    = {Nicoletta Calzolari and
               Chu{-}Ren Huang and
               Hansaem Kim and
               James Pustejovsky and
               Leo Wanner and
               Key{-}Sun Choi and
               Pum{-}Mo Ryu and
               Hsin{-}Hsi Chen and
               Lucia Donatelli and
               Heng Ji and
               Sadao Kurohashi and
               Patrizia Paggio and
               Nianwen Xue and
               Seokhwan Kim and
               Younggyun Hahm and
               Zhong He and
               Tony Kyungil Lee and
               Enrico Santus and
               Francis Bond and
               Seung{-}Hoon Na},
  title     = {Does {GPT-3} Generate Empathetic Dialogues? {A} Novel In-Context Example
               Selection Method and Automatic Evaluation Metric for Empathetic Dialogue
               Generation},
  booktitle = {Proceedings of the 29th International Conference on Computational
               Linguistics, {COLING} 2022, Gyeongju, Republic of Korea, October 12-17,
               2022},
  pages     = {669--683},
  publisher = {International Committee on Computational Linguistics},
  year      = {2022},
}

@article{Ye-arxiv-2022-Complementary,
  author    = {Xi Ye and
               Srinivasan Iyer and
               Asli Celikyilmaz and
               Ves Stoyanov and
               Greg Durrett and
               Ramakanth Pasunuru},
  title     = {Complementary Explanations for Effective In-Context Learning},
  journal   = {CoRR},
  year      = {2022},
}

@ARTICLE{Ning-arxiv-2023-ChatGPT,
       author = {{Bian}, Ning and {Han}, Xianpei and {Sun}, Le and {Lin}, Hongyu and {Lu}, Yaojie and {He}, Ben},
        title = "{ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models}",
        journal   = {CoRR},
         year = 2023,
}


@article{Press-arxiv-2023-Measuring,
  author    = {Ofir Press and
               Muru Zhang and
               Sewon Min and
               Ludwig Schmidt and
               Noah A. Smith and
               Mike Lewis},
  title     = {Measuring and Narrowing the Compositionality Gap in Language Models},
  journal   = {CoRR},
  volume    = {abs/2210.03350},
  year      = {2022},
}

@inproceedings{Paszke-NeurIPS-2019-Pytorch,
  author    = {Adam Paszke and
               Sam Gross and
               Francisco Massa and
               Adam Lerer and
               James Bradbury and
               Gregory Chanan and
               Trevor Killeen and
               Zeming Lin and
               Natalia Gimelshein and
               Luca Antiga and
               Alban Desmaison and
               Andreas K{\"{o}}pf and
               Edward Z. Yang and
               Zachary DeVito and
               Martin Raison and
               Alykhan Tejani and
               Sasank Chilamkurthy and
               Benoit Steiner and
               Lu Fang and
               Junjie Bai and
               Soumith Chintala},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {8024--8035},
  year      = {2019},
}

@inproceedings{Abadi-OSDI-2016-TensorFlow,
  author    = {Mart{\'{\i}}n Abadi and
               Paul Barham and
               Jianmin Chen and
               Zhifeng Chen and
               Andy Davis and
               Jeffrey Dean and
               Matthieu Devin and
               Sanjay Ghemawat and
               Geoffrey Irving and
               Michael Isard and
               Manjunath Kudlur and
               Josh Levenberg and
               Rajat Monga and
               Sherry Moore and
               Derek Gordon Murray and
               Benoit Steiner and
               Paul A. Tucker and
               Vijay Vasudevan and
               Pete Warden and
               Martin Wicke and
               Yuan Yu and
               Xiaoqiang Zheng},
  editor    = {Kimberly Keeton and
               Timothy Roscoe},
  title     = {TensorFlow: {A} System for Large-Scale Machine Learning},
  booktitle = {12th {USENIX} Symposium on Operating Systems Design and Implementation,
               {OSDI} 2016, Savannah, GA, USA, November 2-4, 2016},
  pages     = {265--283},
  publisher = {{USENIX} Association},
  year      = {2016},
}

@incollection{Huawei-Springer-2022-MindSpore,
  title={Huawei MindSpore AI Development Framework},
  author={Huawei Technologies Co., Ltd.},
  booktitle={Artificial Intelligence Technology},
  pages={137--162},
  year={2022},
  publisher={Springer}
}

@article{Ma-fodc-2019-PaddlePaddle,
    author = {Yanjun Ma and Dianhai Yu and Tian Wu and Haifeng Wang},
    title = {PaddlePaddle: An Open-Source Deep Learning Platform from Industrial Practice},
    publisher = {Frontiers of Data and Computing},
    year = {2019},
    journal = {Frontiers of Data and Domputing},
    volume = {1},
    number = {1},
    eid = {105},
    numpages = {10},
    pages = {105},
    keywords = {;PaddlePaddle;artificial intelligence;deep learning;deep learning framework},
}    

@article{Chen-arxiv-2015-MXNet,
  author    = {Tianqi Chen and
               Mu Li and
               Yutian Li and
               Min Lin and
               Naiyan Wang and
               Minjie Wang and
               Tianjun Xiao and
               Bing Xu and
               Chiyuan Zhang and
               Zheng Zhang},
  title     = {MXNet: {A} Flexible and Efficient Machine Learning Library for Heterogeneous
               Distributed Systems},
  journal   = {CoRR},
  volume    = {abs/1512.01274},
  year      = {2015},
}

@article{Marta-arxiv-2022-NLLB,
  author    = {Marta R. Costa{-}juss{\`{a}} and
               James Cross and
               Onur {\c{C}}elebi and
               Maha Elbayad and
               Kenneth Heafield and
               Kevin Heffernan and
               Elahe Kalbassi and
               Janice Lam and
               Daniel Licht and
               Jean Maillard and
               Anna Sun and
               Skyler Wang and
               Guillaume Wenzek and
               Al Youngblood and
               Bapi Akula and
               Lo{\"{\i}}c Barrault and
               Gabriel Mejia Gonzalez and
               Prangthip Hansanti and
               John Hoffman and
               Semarley Jarrett and
               Kaushik Ram Sadagopan and
               Dirk Rowe and
               Shannon Spruit and
               Chau Tran and
               Pierre Andrews and
               Necip Fazil Ayan and
               Shruti Bhosale and
               Sergey Edunov and
               Angela Fan and
               Cynthia Gao and
               Vedanuj Goswami and
               Francisco Guzm{\'{a}}n and
               Philipp Koehn and
               Alexandre Mourachko and
               Christophe Ropers and
               Safiyyah Saleem and
               Holger Schwenk and
               Jeff Wang},
  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2207.04672},
  year      = {2022},
}


@article{Biderman-arxiv-2023-Pythia,
  title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  journal={arXiv preprint arXiv:2304.01373},
  year={2023}
}

@article{Askell-arxiv-2021-Anthropic,
  author    = {Amanda Askell and
               Yuntao Bai and
               Anna Chen and
               Dawn Drain and
               Deep Ganguli and
               Tom Henighan and
               Andy Jones and
               Nicholas Joseph and
               Benjamin Mann and
               Nova DasSarma and
               Nelson Elhage and
               Zac Hatfield{-}Dodds and
               Danny Hernandez and
               Jackson Kernion and
               Kamal Ndousse and
               Catherine Olsson and
               Dario Amodei and
               Tom B. Brown and
               Jack Clark and
               Sam McCandlish and
               Chris Olah and
               Jared Kaplan},
  title     = {A General Language Assistant as a Laboratory for Alignment},
  journal   = {CoRR},
  volume    = {abs/2112.00861},
  year      = {2021},
}

@article{Su-arxiv-2022-WeLM,
  author    = {Hui Su and
               Xiao Zhou and
               Houjin Yu and
               Yuwen Chen and
               Zilin Zhu and
               Yang Yu and
               Jie Zhou},
  title     = {WeLM: {A} Well-Read Pre-trained Language Model for Chinese},
  journal   = {CoRR},
  volume    = {abs/2209.10372},
  year      = {2022},
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}


@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://vicuna.lmsys.org},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    year = {2023}
}

@misc{ChatLLaMA,
    url = {https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama},
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub repository},
}

@article{Fang-arxiv-2021-PatrickStar,
  author    = {Jiarui Fang and
               Yang Yu and
               Shenggui Li and
               Yang You and
               Jie Zhou},
  title     = {PatrickStar: Parallel Training of Pre-trained Models via a Chunk-based
               Memory Management},
  journal   = {CoRR},
  volume    = {abs/2108.05818},
  year      = {2021},
}

@article{Polu-arxiv-2020-Generative,
  author    = {Stanislas Polu and
               Ilya Sutskever},
  title     = {Generative Language Modeling for Automated Theorem Proving},
  journal   = {CoRR},
  volume    = {abs/2009.03393},
  year      = {2020},
}


@article{OpenAI-blog-2022-alignment,
  title   = {Our approach to alignment research},
  author  = {OpenAI},
  journal = {OpenAI Blog},
  year    = {2022},
  month   = {August},
}


@article{OpenAI-blog-2022-ChatGPT,
  title   = "Introducing ChatGPT",
  author  = {OpenAI},
  journal = "OpenAI Blog",
  year    = {2022},
  month   = "November",
}

@article{Radford-CoRR-2017-Learning,
  author       = {Alec Radford and
                  Rafal J{\'{o}}zefowicz and
                  Ilya Sutskever},
  title        = {Learning to Generate Reviews and Discovering Sentiment},
  journal      = {CoRR},
  volume       = {abs/1704.01444},
  year         = {2017},
}

@article{McCann-CoRR-2018-The,
  author       = {Bryan McCann and
                  Nitish Shirish Keskar and
                  Caiming Xiong and
                  Richard Socher},
  title        = {The Natural Language Decathlon: Multitask Learning as Question Answering},
  journal      = {CoRR},
  volume       = {abs/1806.08730},
  year         = {2018},
}



@inproceedings{Zhang-ACL-2020-DIALOGPT,
  author       = {Yizhe Zhang and
                  Siqi Sun and
                  Michel Galley and
                  Yen{-}Chun Chen and
                  Chris Brockett and
                  Xiang Gao and
                  Jianfeng Gao and
                  Jingjing Liu and
                  Bill Dolan},
  editor       = {Asli Celikyilmaz and
                  Tsung{-}Hsien Wen},
  title        = {{DIALOGPT} : Large-Scale Generative Pre-training for Conversational
                  Response Generation},
  booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational
                  Linguistics: System Demonstrations, {ACL} 2020, Online, July 5-10,
                  2020},
  pages        = {270--278},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
}

@inproceedings{Ham-ACL-2020-End,
  author       = {DongHoon Ham and
                  Jeong{-}Gwan Lee and
                  Youngsoo Jang and
                  Kee{-}Eung Kim},
  title        = {End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using
                  {GPT-2}},
  booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages        = {583--592},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
}


@article{Drori-CoRR-2021-A,
  author       = {Iddo Drori and
                  Sunny Tran and
                  Roman Wang and
                  Newman Cheng and
                  Kevin Liu and
                  Leonard Tang and
                  Elizabeth Ke and
                  Nikhil Singh and
                  Taylor L. Patti and
                  Jayson Lynch and
                  Avi Shporer and
                  Nakul Verma and
                  Eugene Wu and
                  Gilbert Strang},
  title        = {A Neural Network Solves and Generates Mathematics Problems by Program
                  Synthesis: Calculus, Differential Equations, Linear Algebra, and More},
  journal      = {CoRR},
  volume       = {abs/2112.15594},
  year         = {2021},
}

@article{Neelakantan-CoRR-2022-Text,
  author       = {Arvind Neelakantan and
                  Tao Xu and
                  Raul Puri and
                  Alec Radford and
                  Jesse Michael Han and
                  Jerry Tworek and
                  Qiming Yuan and
                  Nikolas Tezak and
                  Jong Wook Kim and
                  Chris Hallacy and
                  Johannes Heidecke and
                  Pranav Shyam and
                  Boris Power and
                  Tyna Eloundou Nekoul and
                  Girish Sastry and
                  Gretchen Krueger and
                  David Schnurr and
                  Felipe Petroski Such and
                  Kenny Hsu and
                  Madeleine Thompson and
                  Tabarak Khan and
                  Toki Sherbakov and
                  Joanne Jang and
                  Peter Welinder and
                  Lilian Weng},
  title        = {Text and Code Embeddings by Contrastive Pre-Training},
  journal      = {CoRR},
  volume       = {abs/2201.10005},
  year         = {2022},
}


@article{OpenAI-blog-2022-lessons,
  author    = {OpenAI},
  title     = {Lessons learned on language model safety and misuse},
  journal   = {OpenAI blog},
  year      = {2022}
}


@inproceedings{Sheng-WISA-2019-CLMed,
  author    = {Ming Sheng and
               Han Zhang and
               Yong Zhang and
               Chao Li and
               Chunxiao Xing and
               Jingwen Wang and
               Yuyao Shao and
               Fei Gao},
  editor    = {Weiwei Ni and
               Xin Wang and
               Wei Song and
               Yukun Li},
  title     = {CLMed: {A} Cross-lingual Knowledge Graph Framework for Cardiovascular
               Diseases},
  booktitle = {Web Information Systems and Applications - 16th International Conference,
               {WISA} 2019, Qingdao, China, September 20-22, 2019, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {11817},
  pages     = {512--517},
  publisher = {Springer},
  year      = {2019}
}



@article{Gehrmann-arxiv-2021-GEM,
  author    = {Sebastian Gehrmann and
               Tosin P. Adewumi and
               Karmanya Aggarwal and
               Pawan Sasanka Ammanamanchi and
               Aremu Anuoluwapo and
               Antoine Bosselut and
               Khyathi Raghavi Chandu and
               Miruna{-}Adriana Clinciu and
               Dipanjan Das and
               Kaustubh D. Dhole and
               Wanyu Du and
               Esin Durmus and
               Ondrej Dusek and
               Chris Emezue and
               Varun Gangal and
               Cristina Garbacea and
               Tatsunori Hashimoto and
               Yufang Hou and
               Yacine Jernite and
               Harsh Jhamtani and
               Yangfeng Ji and
               Shailza Jolly and
               Dhruv Kumar and
               Faisal Ladhak and
               Aman Madaan and
               Mounica Maddela and
               Khyati Mahajan and
               Saad Mahamood and
               Bodhisattwa Prasad Majumder and
               Pedro Henrique Martins and
               Angelina McMillan{-}Major and
               Simon Mille and
               Emiel van Miltenburg and
               Moin Nadeem and
               Shashi Narayan and
               Vitaly Nikolaev and
               Rubungo Andre Niyongabo and
               Salomey Osei and
               Ankur P. Parikh and
               Laura Perez{-}Beltrachini and
               Niranjan Ramesh Rao and
               Vikas Raunak and
               Juan Diego Rodriguez and
               Sashank Santhanam and
               Jo{\~{a}}o Sedoc and
               Thibault Sellam and
               Samira Shaikh and
               Anastasia Shimorina and
               Marco Antonio Sobrevilla Cabezudo and
               Hendrik Strobelt and
               Nishant Subramani and
               Wei Xu and
               Diyi Yang and
               Akhila Yerukola and
               Jiawei Zhou},
  title     = {The {GEM} Benchmark: Natural Language Generation, its Evaluation and
               Metrics},
  journal   = {CoRR},
  volume    = {abs/2102.01672},
  year      = {2021}
}

@inproceedings{Liu-ACL-2021-GLGE,
  author    = {Dayiheng Liu and
               Yu Yan and
               Yeyun Gong and
               Weizhen Qi and
               Hang Zhang and
               Jian Jiao and
               Weizhu Chen and
               Jie Fu and
               Linjun Shou and
               Ming Gong and
               Pengcheng Wang and
               Jiusheng Chen and
               Daxin Jiang and
               Jiancheng Lv and
               Ruofei Zhang and
               Winnie Wu and
               Ming Zhou and
               Nan Duan},
  title     = {{GLGE:} {A} New General Language Generation Evaluation Benchmark},
  booktitle = {{ACL/IJCNLP} (Findings)},
  series    = {Findings of {ACL}},
  volume    = {{ACL/IJCNLP} 2021},
  pages     = {408--420},
  publisher = {Association for Computational Linguistics},
  year      = {2021}
}

@article{Zheng-arXiv-2023-CodeGeex,
  title={CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X},
  author={Zheng, Qinkai and Xia, Xiao and Zou, Xu and Dong, Yuxiao and Wang, Shan and Xue, Yufei and Wang, Zihan and Shen, Lei and Wang, Andi and Li, Yang and others},
  journal={arXiv preprint arXiv:2303.17568},
  year={2023}
}

@inproceedings{Vinod-ICML-2010-Rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}
@article{Ramachandran-arXiv-2017-searching,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}



@inproceedings{Hu-ICLR-2022-LoRA,
  author       = {Edward J. Hu and
                  Yelong Shen and
                  Phillip Wallis and
                  Zeyuan Allen{-}Zhu and
                  Yuanzhi Li and
                  Shean Wang and
                  Lu Wang and
                  Weizhu Chen},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
}


@inproceedings{Li-ACL-2021-prefix,
  author       = {Xiang Lisa Li and
                  Percy Liang},
  editor       = {Chengqing Zong and
                  Fei Xia and
                  Wenjie Li and
                  Roberto Navigli},
  title        = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  booktitle    = {Proceedings of the 59th Annual Meeting of the Association for Computational
                  Linguistics and the 11th International Joint Conference on Natural
                  Language Processing, {ACL/IJCNLP} 2021, (Volume 1: Long Papers), Virtual
                  Event, August 1-6, 2021},
  pages        = {4582--4597},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
}


@inproceedings{Lester-ACL-2021-The,
  author       = {Brian Lester and
                  Rami Al{-}Rfou and
                  Noah Constant},
  editor       = {Marie{-}Francine Moens and
                  Xuanjing Huang and
                  Lucia Specia and
                  Scott Wen{-}tau Yih},
  title        = {The Power of Scale for Parameter-Efficient Prompt Tuning},
  booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
                  Republic, 7-11 November, 2021},
  pages        = {3045--3059},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
}


@article{Valipour-arXiv-2022-DyLoRA,
  author       = {Mojtaba Valipour and
                  Mehdi Rezagholizadeh and
                  Ivan Kobyzev and
                  Ali Ghodsi},
  title        = {DyLoRA: Parameter Efficient Tuning of Pre-trained Models using Dynamic
                  Search-Free Low-Rank Adaptation},
  journal      = {CoRR},
  volume       = {abs/2210.07558},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2210.07558},
  doi          = {10.48550/arXiv.2210.07558},
  eprinttype    = {arXiv},
}


@article{Zhang-arXiv-2023-Adaptive,
  author       = {Qingru Zhang and
                  Minshuo Chen and
                  Alexander Bukharin and
                  Pengcheng He and
                  Yu Cheng and
                  Weizhu Chen and
                  Tuo Zhao},
  title        = {Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning},
  journal      = {CoRR},
  volume       = {abs/2303.10512},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.10512},
  doi          = {10.48550/arXiv.2303.10512},
  eprinttype    = {arXiv},
}


@article{Zhang-arXiv-2023-LLaMA-Adapter,
  author       = {Renrui Zhang and
                  Jiaming Han and
                  Aojun Zhou and
                  Xiangfei Hu and
                  Shilin Yan and
                  Pan Lu and
                  Hongsheng Li and
                  Peng Gao and
                  Yu Qiao},
  title        = {LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init
                  Attention},
  journal      = {CoRR},
  volume       = {abs/2303.16199},
  year         = {2023},
}


@misc{Alpaca-LoRA,
  author = {Alpaca-LoRA},
  title = {Instruct-tune LLaMA on consumer hardware},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tloen/alpaca-lora}},
}


@article{Hu-arXiv-2023,
  author       = {Zhiqiang Hu and
                  Yihuai Lan and
                  Lei Wang and
                  Wanyu Xu and
                  Ee{-}Peng Lim and
                  Roy Ka{-}Wei Lee and
                  Lidong Bing and
                  Soujanya Poria},
  title        = {LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning
                  of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2304.01933},
  year         = {2023},
}


@article{Liu-arXiv-2021-GPT,
  author       = {Xiao Liu and
                  Yanan Zheng and
                  Zhengxiao Du and
                  Ming Ding and
                  Yujie Qian and
                  Zhilin Yang and
                  Jie Tang},
  title        = {{GPT} Understands, Too},
  journal      = {CoRR},
  volume       = {abs/2103.10385},
  year         = {2021},
}

@inproceedings{Vu-ACL-2022-SPoT,
  author       = {Tu Vu and
                  Brian Lester and
                  Noah Constant and
                  Rami Al{-}Rfou' and
                  Daniel Cer},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer},
  booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
                  May 22-27, 2022},
  pages        = {5039--5059},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@inproceedings{Li-NAACL-2022-Learning,
  author       = {Junyi Li and
                  Tianyi Tang and
                  Jian{-}Yun Nie and
                  Ji{-}Rong Wen and
                  Xin Zhao},
  editor       = {Marine Carpuat and
                  Marie{-}Catherine de Marneffe and
                  Iv{\'{a}}n Vladimir Meza Ru{\'{\i}}z},
  title        = {Learning to Transfer Prompts for Text Generation},
  booktitle    = {Proceedings of the 2022 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL} 2022, Seattle, WA, United States, July 10-15, 2022},
  pages        = {3506--3518},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@article{Liu-arXiv-2021-P-tuning,
  author       = {Xiao Liu and
                  Kaixuan Ji and
                  Yicheng Fu and
                  Zhengxiao Du and
                  Zhilin Yang and
                  Jie Tang},
  title        = {P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally
                  Across Scales and Tasks},
  journal      = {CoRR},
  volume       = {abs/2110.07602},
  year         = {2021},
}


@inproceedings{He-ICLR-2022-towards,
  author       = {Junxian He and
                  Chunting Zhou and
                  Xuezhe Ma and
                  Taylor Berg{-}Kirkpatrick and
                  Graham Neubig},
  title        = {Towards a Unified View of Parameter-Efficient Transfer Learning},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
}
@article{Ding-NMI-2023-Parameter,
author = {Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Zonghan, Yang and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and Yi, Jing and Zhao, Weilin and Wang, Xiaozhi and Liu, Zhiyuan and Zheng, Hai-Tao and Chen, Jianfei and Liu, Yang and Tang, Jie and Li, Juanzi and Sun, Maosong},
year = {2023},
month = {03},
pages = {1-16},
title = {Parameter-efficient fine-tuning of large-scale pre-trained language models},
volume = {5},
journal = {Nature Machine Intelligence},
doi = {10.1038/s42256-023-00626-4}
}
@inproceedings{Pfeiffer-EMNLP-2020mad,
  author       = {Jonas Pfeiffer and
                  Ivan Vulic and
                  Iryna Gurevych and
                  Sebastian Ruder},
  editor       = {Bonnie Webber and
                  Trevor Cohn and
                  Yulan He and
                  Yang Liu},
  title        = {{MAD-X:} An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer},
  booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages        = {7654--7673},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
  url          = {https://doi.org/10.18653/v1/2020.emnlp-main.617},
  doi          = {10.18653/v1/2020.emnlp-main.617},
  timestamp    = {Wed, 23 Mar 2022 10:11:55 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/PfeifferVGR20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Pfeiffer-EMNLP-2022-MAD-X,
  author       = {Jonas Pfeiffer and
                  Ivan Vulic and
                  Iryna Gurevych and
                  Sebastian Ruder},
  editor       = {Bonnie Webber and
                  Trevor Cohn and
                  Yulan He and
                  Yang Liu},
  title        = {{MAD-X:} An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer},
  booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages        = {7654--7673},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
}

@article{Lee-CoRR-2023-RLAIF,
  author       = {Harrison Lee and
                  Samrat Phatale and
                  Hassan Mansoor and
                  Kellie Lu and
                  Thomas Mesnard and
                  Colton Bishop and
                  Victor Carbune and
                  Abhinav Rastogi},
  title        = {{RLAIF:} Scaling Reinforcement Learning from Human Feedback with {AI}
                  Feedback},
  journal      = {CoRR},
  volume       = {abs/2309.00267},
  year         = {2023}
}

@Misc{peft-github-2022,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar and Sylvain Gugger and Lysandre Debut and Younes Belkada and Sayak Paul},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}

@article{jiang-TACL-2020-how,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020},
  publisher={MIT Press}
}

@article{Wen-CoRR-2023-Hard,
  author       = {Yuxin Wen and
                  Neel Jain and
                  John Kirchenbauer and
                  Micah Goldblum and
                  Jonas Geiping and
                  Tom Goldstein},
  title        = {Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt
                  Tuning and Discovery},
  journal      = {CoRR},
  volume       = {abs/2302.03668},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2302.03668},
  doi          = {10.48550/ARXIV.2302.03668},
  eprinttype    = {arXiv},
  eprint       = {2302.03668}
}

@inproceedings{Deng-EMNLP-2022-RLPrompt,
  author       = {Mingkai Deng and
                  Jianyu Wang and
                  Cheng{-}Ping Hsieh and
                  Yihan Wang and
                  Han Guo and
                  Tianmin Shu and
                  Meng Song and
                  Eric P. Xing and
                  Zhiting Hu},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning},
  booktitle    = {Proceedings of the 2022 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
                  December 7-11, 2022},
  pages        = {3369--3391},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@inproceedings{Zhang-ICLR-2023-TEMPERA,
  author       = {Tianjun Zhang and
                  Xuezhi Wang and
                  Denny Zhou and
                  Dale Schuurmans and
                  Joseph E. Gonzalez},
  title        = {{TEMPERA:} Test-Time Prompt Editing via Reinforcement Learning},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@inproceedings{shin-EMNLP-2020-autoprompt,
  title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4222--4235},
  year={2020}
}

@inproceedings{gu-ACL-2022-ppt,
  title={PPT: Pre-trained Prompt Tuning for Few-shot Learning},
  author={Gu, Yuxian and Han, Xu and Liu, Zhiyuan and Huang, Minlie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8410--8423},
  year={2022}
}



@inproceedings{Lafferty-ICML-2001,
  author       = {John D. Lafferty and
                  Andrew McCallum and
                  Fernando C. N. Pereira},
  editor       = {Carla E. Brodley and
                  Andrea Pohoreckyj Danyluk},
  title        = {Conditional Random Fields: Probabilistic Models for Segmenting and
                  Labeling Sequence Data},
  booktitle    = {Proceedings of the Eighteenth International Conference on Machine
                  Learning {(ICML} 2001), Williams College, Williamstown, MA, USA, June
                  28 - July 1, 2001},
  pages        = {282--289},
  publisher    = {Morgan Kaufmann},
  year         = {2001},
}


@article{Philip-1994-BPE,
  title={A new algorithm for data compression},
  author={Gage, Philip},
  journal={C Users Journal},
  volume={12},
  number={2},
  pages={23--38},
  year={1994},
  publisher={McPherson, KS: R \& D Publications, c1987-1994.}
}

@inproceedings{Sennrich-ACL-2016-nueral,
  author       = {Rico Sennrich and
                  Barry Haddow and
                  Alexandra Birch},
  title        = {Neural Machine Translation of Rare Words with Subword Units},
  booktitle    = {Proceedings of the 54th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2016, August 7-12, 2016, Berlin, Germany, Volume
                  1: Long Papers},
  publisher    = {The Association for Computer Linguistics},
  year         = {2016},
}


@article{Wu-CoRR-2016,
  author       = {Yonghui Wu and
                  Mike Schuster and
                  Zhifeng Chen and
                  Quoc V. Le and
                  Mohammad Norouzi and
                  Wolfgang Macherey and
                  Maxim Krikun and
                  Yuan Cao and
                  Qin Gao and
                  Klaus Macherey and
                  Jeff Klingner and
                  Apurva Shah and
                  Melvin Johnson and
                  Xiaobing Liu and
                  Lukasz Kaiser and
                  Stephan Gouws and
                  Yoshikiyo Kato and
                  Taku Kudo and
                  Hideto Kazawa and
                  Keith Stevens and
                  George Kurian and
                  Nishant Patil and
                  Wei Wang and
                  Cliff Young and
                  Jason Smith and
                  Jason Riesa and
                  Alex Rudnick and
                  Oriol Vinyals and
                  Greg Corrado and
                  Macduff Hughes and
                  Jeffrey Dean},
  title        = {Google's Neural Machine Translation System: Bridging the Gap between
                  Human and Machine Translation},
  journal      = {CoRR},
  volume       = {abs/1609.08144},
  year         = {2016},
}


@inproceedings{song-emnlp-2021,
  author       = {Xinying Song and
                  Alex Salcianu and
                  Yang Song and
                  Dave Dopson and
                  Denny Zhou},
  editor       = {Marie{-}Francine Moens and
                  Xuanjing Huang and
                  Lucia Specia and
                  Scott Wen{-}tau Yih},
  title        = {Fast WordPiece Tokenization},
  booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
                  Republic, 7-11 November, 2021},
  pages        = {2089--2103},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
}


@inproceedings{Kudo-ACL-2018-Subword,
  author       = {Taku Kudo},
  editor       = {Iryna Gurevych and
                  Yusuke Miyao},
  title        = {Subword Regularization: Improving Neural Network Translation Models
                  with Multiple Subword Candidates},
  booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2018, Melbourne, Australia, July 15-20, 2018, Volume
                  1: Long Papers},
  pages        = {66--75},
  publisher    = {Association for Computational Linguistics},
  year         = {2018},
}

@article{frantar-arxiv-2022-gptq,
  title={GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}

@article{yuan-arxiv-2023-rptq,
  title={RPTQ: Reorder-based Post-training Quantization for Large Language Models},
  author={Yuan, Zhihang and Niu, Lin and Liu, Jiawei and Liu, Wenyu and Wang, Xinggang and Shang, Yuzhang and Sun, Guangyu and Wu, Qiang and Wu, Jiaxiang and Wu, Bingzhe},
  journal={arXiv preprint arXiv:2304.01089},
  year={2023}
}

@article{guo-arxiv-2023-how,
  title={How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection},
  author={Guo, Biyang and Zhang, Xin and Wang, Ziyuan and Jiang, Minqi and Nie, Jinran and Ding, Yuxuan and Yue, Jianwei and Wu, Yupeng},
  journal={arXiv preprint arXiv:2301.07597},
  year={2023}
}


@article{kopf-arxiv-2023-openassistant,
  title={OpenAssistant Conversations--Democratizing Large Language Model Alignment},
  author={K{\"o}pf, Andreas and Kilcher, Yannic and von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi-Rui and Stevens, Keith and Barhoum, Abdullah and Duc, Nguyen Minh and Stanley, Oliver and Nagyfi, Rich{\'a}rd and others},
  journal={arXiv preprint arXiv:2304.07327},
  year={2023}
}


@article{Bai-arxiv-2022-Training,
  author       = {Yuntao Bai and
                  Andy Jones and
                  Kamal Ndousse and
                  Amanda Askell and
                  Anna Chen and
                  Nova DasSarma and
                  Dawn Drain and
                  Stanislav Fort and
                  Deep Ganguli and
                  Tom Henighan and
                  Nicholas Joseph and
                  Saurav Kadavath and
                  Jackson Kernion and
                  Tom Conerly and
                  Sheer El Showk and
                  Nelson Elhage and
                  Zac Hatfield{-}Dodds and
                  Danny Hernandez and
                  Tristan Hume and
                  Scott Johnston and
                  Shauna Kravec and
                  Liane Lovitt and
                  Neel Nanda and
                  Catherine Olsson and
                  Dario Amodei and
                  Tom B. Brown and
                  Jack Clark and
                  Sam McCandlish and
                  Chris Olah and
                  Benjamin Mann and
                  Jared Kaplan},
  title        = {Training a Helpful and Harmless Assistant with Reinforcement Learning
                  from Human Feedback},
  journal      = {CoRR},
  volume       = {abs/2204.05862},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2204.05862},
  doi          = {10.48550/arXiv.2204.05862},
  eprinttype    = {arXiv},
  eprint       = {2204.05862}
}


@article{Dettmers-CoRR-2022-LLM.int8,
  author       = {Tim Dettmers and
                  Mike Lewis and
                  Younes Belkada and
                  Luke Zettlemoyer},
  title        = {LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale},
  journal      = {CoRR},
  volume       = {abs/2208.07339},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2208.07339},
  doi          = {10.48550/arXiv.2208.07339},
  eprinttype    = {arXiv},
  eprint       = {2208.07339},
}



@inproceedings{Yao-NeurlPS-2022-ZeroQuant,
  author       = {Zhewei Yao and
                  Reza Yazdani Aminabadi and
                  Minjia Zhang and
                  Xiaoxia Wu and
                  Conglong Li and
                  Yuxiong He},
  title        = {ZeroQuant: Efficient and Affordable Post-Training Quantization for
                  Large-Scale Transformers},
  booktitle    = {NeurIPS},
  year         = {2022},
}



@article{Xiao-CoRR-2022-SmoothQuant,
  author       = {Guangxuan Xiao and
                  Ji Lin and
                  Micka{\"{e}}l Seznec and
                  Julien Demouth and
                  Song Han},
  title        = {SmoothQuant: Accurate and Efficient Post-Training Quantization for
                  Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2211.10438},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.10438},
  doi          = {10.48550/arXiv.2211.10438},
}


@article{Frantar-CoRR-2022-GPTQ,
  author       = {Elias Frantar and
                  Saleh Ashkboos and
                  Torsten Hoefler and
                  Dan Alistarh},
  title        = {{GPTQ:} Accurate Post-Training Quantization for Generative Pre-trained
                  Transformers},
  journal      = {CoRR},
  volume       = {abs/2210.17323},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2210.17323},
  doi          = {10.48550/arXiv.2210.17323},
  eprinttype    = {arXiv},
}


@inproceedings{Park-EMNLP-2022-Quadapter,
  author       = {Minseop Park and
                  Jaeseong You and
                  Markus Nagel and
                  Simyung Chang},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {Quadapter: Adapter for {GPT-2} Quantization},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages        = {2510--2517},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
}


@article{Gholami-CoRR-2022-A,
  author       = {Amir Gholami and
                  Sehoon Kim and
                  Zhen Dong and
                  Zhewei Yao and
                  Michael W. Mahoney and
                  Kurt Keutzer},
  title        = {A Survey of Quantization Methods for Efficient Neural Network Inference},
  journal      = {CoRR},
  volume       = {abs/2103.13630},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.13630},
  eprinttype    = {arXiv},
  eprint       = {2103.13630},
}


@article{Dettmers-CoRR-2023-QLoRA,
  title={QLoRA: Efficient Finetuning of Quantized LLMs},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2305.14314},
  year={2023}
}


@article{Frantar-CoRR-2023-Optimal,
  title={Optimal Brain Compression: A framework for accurate post-training quantization and pruning},
  author={Frantar, Elias and Alistarh, Dan},
  journal={arXiv preprint arXiv:2208.11580},
  year={2022}
}


@article{Yao-CoRR-2023-ZeroQuant-V2,
      title={ZeroQuant-V2: Exploring Post-training Quantization in LLMs from Comprehensive Study to Low Rank Compensation}, 
      author={Zhewei Yao and Xiaoxia Wu and Cheng Li and Stephen Youn and Yuxiong He},
      year={2023},
      eprint={2303.08302},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Li-arxiv-2023-HaluEval,
  author       = {Junyi Li and
                  Xiaoxue Cheng and
                  Wayne Xin Zhao and
                  Jian{-}Yun Nie and
                  Ji{-}Rong Wen},
  title        = {HaluEval: {A} Large-Scale Hallucination Evaluation Benchmark for Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.11747},
  year         = {2023},
}

@article{Li-arxiv-2023-Evaluating,
  author       = {Yifan Li and
                  Yifan Du and
                  Kun Zhou and
                  Jinpeng Wang and
                  Wayne Xin Zhao and
                  Ji{-}Rong Wen},
  title        = {Evaluating Object Hallucination in Large Vision-Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.10355},
  year         = {2023},
}

@article{Mündler-arxiv-2023-Self,
      author={Niels Mündler and Jingxuan He and Slobodan Jenko and Martin Vechev},
      title={Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation}, 
      journal={CoRR},
      volume={abs/2305.15852},
      year={2023},
}

@misc{Min-arxiv-2023-FActScore,
      author={Sewon Min and Kalpesh Krishna and Xinxi Lyu and Mike Lewis and Wen-tau Yih and Pang Wei Koh and Mohit Iyyer and Luke Zettlemoyer and Hannaneh Hajishirzi},
      title={FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation}, 
      journal={CoRR},
      volume={abs/2305.14251},
      year={2023},
}

@article{Liu-arxiv-2023-Visual,
  author       = {Haotian Liu and
                  Chunyuan Li and
                  Qingyang Wu and
                  Yong Jae Lee},
  title        = {Visual Instruction Tuning},
  journal      = {CoRR},
  volume       = {abs/2304.08485},
  year         = {2023},
}

@article{Zhu-arxiv-2023-MiniGPT-4,
  author       = {Deyao Zhu and
                  Jun Chen and
                  Xiaoqian Shen and
                  Xiang Li and
                  Mohamed Elhoseiny},
  title        = {MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2304.10592},
  year         = {2023},
}

@article{Yuan-arxiv-2023-Arithmetic,
  author       = {Zheng Yuan and
                  Hongyi Yuan and
                  Chuanqi Tan and
                  Wei Wang and
                  Songfang Huang},
  title        = {How well do Large Language Models perform in Arithmetic tasks?},
  journal      = {CoRR},
  volume       = {abs/2304.02015},
  year         = {2023},
}
@article{Yao-arxiv-2023-Tree,
  author       = {Shunyu Yao and
                  Dian Yu and
                  Jeffrey Zhao and
                  Izhak Shafran and
                  Thomas L. Griffiths and
                  Yuan Cao and
                  Karthik Narasimhan},
  title        = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.10601},
  year         = {2023},
}
@article{Xie-arxiv-2023-Decomposition,
  author       = {Yuxi Xie and
                  Kenji Kawaguchi and
                  Yiran Zhao and
                  Xu Zhao and
                  Min{-}Yen Kan and
                  Junxian He and
                  Qizhe Xie},
  title        = {Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding},
  journal      = {CoRR},
  volume       = {abs/2305.00633},
  year         = {2023},
}
@article{Madaan-arxiv-2023-Refine,
  author       = {Aman Madaan and
                  Niket Tandon and
                  Prakhar Gupta and
                  Skyler Hallinan and
                  Luyu Gao and
                  Sarah Wiegreffe and
                  Uri Alon and
                  Nouha Dziri and
                  Shrimai Prabhumoye and
                  Yiming Yang and
                  Sean Welleck and
                  Bodhisattwa Prasad Majumder and
                  Shashank Gupta and
                  Amir Yazdanbakhsh and
                  Peter Clark},
  title        = {Self-Refine: Iterative Refinement with Self-Feedback},
  journal      = {CoRR},
  volume       = {abs/2303.17651},
  year         = {2023},
}
@article{Shinn-arxiv-2023-Reflexion,
  author       = {Noah Shinn and
                  Beck Labash and
                  Ashwin Gopinath},
  title        = {Reflexion: an autonomous agent with dynamic memory and self-reflection},
  journal      = {CoRR},
  volume       = {abs/2303.11366},
  year         = {2023},
}
@article{Kim-arxiv-2023-Language,
  author       = {Geunwoo Kim and
                  Pierre Baldi and
                  Stephen McAleer},
  title        = {Language Models can Solve Computer Tasks},
  journal      = {CoRR},
  volume       = {abs/2303.17491},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.17491},
}
@article{Gou-arxiv-2023-Critic,
  author       = {Zhibin Gou and
                  Zhihong Shao and
                  Yeyun Gong and
                  Yelong Shen and
                  Yujiu Yang and
                  Nan Duan and
                  Weizhu Chen},
  title        = {{CRITIC:} Large Language Models Can Self-Correct with Tool-Interactive
                  Critiquing},
  journal      = {CoRR},
  volume       = {abs/2305.11738},
  year         = {2023},
}

@article{Li-2023-arxiv-Starcoder,
  author       = {Raymond Li and
                  Loubna Ben Allal and
                  Yangtian Zi and
                  Niklas Muennighoff and
                  Denis Kocetkov and
                  Chenghao Mou and
                  Marc Marone and
                  Christopher Akiki and
                  Jia Li and
                  Jenny Chim and
                  Qian Liu and
                  Evgenii Zheltonozhskii and
                  Terry Yue Zhuo and
                  Thomas Wang and
                  Olivier Dehaene and
                  Mishig Davaadorj and
                  Joel Lamy{-}Poirier and
                  Jo{\~{a}}o Monteiro and
                  Oleh Shliazhko and
                  Nicolas Gontier and
                  Nicholas Meade and
                  Armel Zebaze and
                  Ming{-}Ho Yee and
                  Logesh Kumar Umapathi and
                  Jian Zhu and
                  Benjamin Lipkin and
                  Muhtasham Oblokulov and
                  Zhiruo Wang and
                  Rudra Murthy V and
                  Jason Stillerman and
                  Siva Sankalp Patel and
                  Dmitry Abulkhanov and
                  Marco Zocca and
                  Manan Dey and
                  Zhihan Zhang and
                  Nour Fahmy and
                  Urvashi Bhattacharyya and
                  Wenhao Yu and
                  Swayam Singh and
                  Sasha Luccioni and
                  Paulo Villegas and
                  Maxim Kunakov and
                  Fedor Zhdanov and
                  Manuel Romero and
                  Tony Lee and
                  Nadav Timor and
                  Jennifer Ding and
                  Claire Schlesinger and
                  Hailey Schoelkopf and
                  Jan Ebert and
                  Tri Dao and
                  Mayank Mishra and
                  Alex Gu and
                  Jennifer Robinson and
                  Carolyn Jane Anderson and
                  Brendan Dolan{-}Gavitt and
                  Danish Contractor and
                  Siva Reddy and
                  Daniel Fried and
                  Dzmitry Bahdanau and
                  Yacine Jernite and
                  Carlos Mu{\~{n}}oz Ferrandis and
                  Sean Hughes and
                  Thomas Wolf and
                  Arjun Guha and
                  Leandro von Werra and
                  Harm de Vries},
  title        = {StarCoder: may the source be with you!},
  journal      = {CoRR},
  volume       = {abs/2305.06161},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.06161},
  doi          = {10.48550/arXiv.2305.06161},
  eprinttype    = {arXiv},
  eprint       = {2305.06161},
  timestamp    = {Tue, 16 May 2023 18:32:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-06161.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Shazeer-2019-arxiv-Fast,
  author       = {Noam Shazeer},
  title        = {Fast Transformer Decoding: One Write-Head is All You Need},
  journal      = {CoRR},
  volume       = {abs/1911.02150},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.02150},
  eprinttype    = {arXiv},
  eprint       = {1911.02150},
  timestamp    = {Mon, 11 Nov 2019 18:38:09 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-02150.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{zhou-arxiv-2023-lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srini and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={arXiv preprint arXiv:2305.11206},
  year={2023}
}

@article{chen-arxiv-2023-maybe,
  title={Maybe Only 0.5\% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning},
  author={Chen, Hao and Zhang, Yiming and Zhang, Qi and Yang, Hantao and Hu, Xiaomeng and Ma, Xuetao and Yanggong, Yifan and Zhao, Junbo},
  journal={arXiv preprint arXiv:2305.09246},
  year={2023}
}

@article{Yao-arxiv-2023-Editing,
  author       = {Yunzhi Yao and
                  Peng Wang and
                  Bozhong Tian and
                  Siyuan Cheng and
                  Zhoubo Li and
                  Shumin Deng and
                  Huajun Chen and
                  Ningyu Zhang},
  title        = {Editing Large Language Models: Problems, Methods, and Opportunities},
  journal      = {CoRR},
  volume       = {abs/2305.13172},
  year         = {2023},
}

@article{Xu-arxiv-2023-Search,
      title={Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks}, 
      author={Shicheng Xu and Liang Pang and Huawei Shen and Xueqi Cheng and Tat-Seng Chua},
      year={2023},
      volume={abs/2304.14732},
      journal={CoRR},
}

@inproceedings{Cao-EMNLP-2021-Editing,
  author       = {Nicola De Cao and
                  Wilker Aziz and
                  Ivan Titov},
  title        = {Editing Factual Knowledge in Language Models},
  booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
                  Republic, 7-11 November, 2021},
  pages        = {6491--6506},
  year         = {2021},
}
@article{Shishir-2023-arxiv-Gorilla,
  title={Gorilla: Large Language Model Connected with Massive APIs},
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  year={2023},
  volume={abs/2305.15334},
  journal={CoRR},
}
@article{Hao-2023-arxiv-ToolkenGPT,
  author       = {Shibo Hao and
                  Tianyang Liu and
                  Zhen Wang and
                  Zhiting Hu},
  title        = {ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via
                  Tool Embeddings},
  journal      = {CoRR},
  volume       = {abs/2305.11554},
  year         = {2023},
}
@article{Liang-2023-arxiv-TaskMatrix,
  author       = {Yaobo Liang and
                  Chenfei Wu and
                  Ting Song and
                  Wenshan Wu and
                  Yan Xia and
                  Yu Liu and
                  Yang Ou and
                  Shuai Lu and
                  Lei Ji and
                  Shaoguang Mao and
                  Yun Wang and
                  Linjun Shou and
                  Ming Gong and
                  Nan Duan},
  title        = {TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with
                  Millions of APIs},
  journal      = {CoRR},
  volume       = {abs/2303.16434},
  year         = {2023},
}
@article{Cai-arxiv-2023-Tool,
  title={Large Language Models as Tool Makers},
  author={Tianle Cai and Xuezhi Wang and Tengyu Ma and Xinyun Chen and Denny Zhou},
  year={2023},
  journal      = {CoRR},
  volume       = {abs/2305.17126},
  year         = {2023},
}

@article{Sun-2022-arxiv-Length,
  author       = {Yutao Sun and
                  Li Dong and
                  Barun Patra and
                  Shuming Ma and
                  Shaohan Huang and
                  Alon Benhaim and
                  Vishrav Chaudhary and
                  Xia Song and
                  Furu Wei},
  title        = {A Length-Extrapolatable Transformer},
  journal      = {CoRR},
  volume       = {abs/2212.10554},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2212.10554},
  doi          = {10.48550/arXiv.2212.10554},
  eprinttype    = {arXiv},
  eprint       = {2212.10554},
  timestamp    = {Wed, 04 Jan 2023 16:01:37 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2212-10554.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Ioffe-2015-ICML-Batch,
  author       = {Sergey Ioffe and
                  Christian Szegedy},
  editor       = {Francis R. Bach and
                  David M. Blei},
  title        = {Batch Normalization: Accelerating Deep Network Training by Reducing
                  Internal Covariate Shift},
  booktitle    = {Proceedings of the 32nd International Conference on Machine Learning,
                  {ICML} 2015, Lille, France, 6-11 July 2015},
  series       = {{JMLR} Workshop and Conference Proceedings},
  volume       = {37},
  pages        = {448--456},
  publisher    = {JMLR.org},
  year         = {2015},
  url          = {http://proceedings.mlr.press/v37/ioffe15.html},
  timestamp    = {Wed, 29 May 2019 08:41:45 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/IoffeS15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Zhong-2023-arxiv-AGIEval,
  author       = {Wanjun Zhong and
                  Ruixiang Cui and
                  Yiduo Guo and
                  Yaobo Liang and
                  Shuai Lu and
                  Yanlin Wang and
                  Amin Saied and
                  Weizhu Chen and
                  Nan Duan},
  title        = {AGIEval: {A} Human-Centric Benchmark for Evaluating Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2304.06364},
  year         = {2023},
}
@article{Liu-2023-arxiv-M3KE,
  author       = {Chuang Liu and
                  Renren Jin and
                  Yuqi Ren and
                  Linhao Yu and
                  Tianyu Dong and
                  Xiaohan Peng and
                  Shuting Zhang and
                  Jianxiang Peng and
                  Peiyi Zhang and
                  Qingqing Lyu and
                  Xiaowen Su and
                  Qun Liu and
                  Deyi Xiong},
  title        = {{M3KE:} {A} Massive Multi-Level Multi-Subject Knowledge Evaluation
                  Benchmark for Chinese Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.10263},
  year         = {2023},
}
@article{Huang-arxiv-2023-CEval,
  author       = {Yuzhen Huang and
                  Yuzhuo Bai and
                  Zhihao Zhu and
                  Junlei Zhang and
                  Jinghan Zhang and
                  Tangjun Su and
                  Junteng Liu and
                  Chuancheng Lv and
                  Yikai Zhang and
                  Jiayi Lei and
                  Yao Fu and
                  Maosong Sun and
                  Junxian He},
  title        = {C-Eval: {A} Multi-Level Multi-Discipline Chinese Evaluation Suite
                  for Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2305.08322},
  year         = {2023},
}
@article{Zeng-arxiv-2023-MMCU,
  author       = {Hui Zeng},
  title        = {Measuring Massive Multitask Chinese Understanding},
  journal      = {CoRR},
  volume       = {abs/2304.12986},
  year         = {2023},
}

@inproceedings{Baevski-2019-ICLR-Adaptive,
  author       = {Alexei Baevski and
                  Michael Auli},
  title        = {Adaptive Input Representations for Neural Language Modeling},
  booktitle    = {7th International Conference on Learning Representations, {ICLR} 2019,
                  New Orleans, LA, USA, May 6-9, 2019},
  publisher    = {OpenReview.net},
  year         = {2019},
}

@inproceedings{liu-2020-EMNLP-Understanding,
  author       = {Liyuan Liu and
                  Xiaodong Liu and
                  Jianfeng Gao and
                  Weizhu Chen and
                  Jiawei Han},
  title        = {Understanding the Difficulty of Training Transformers},
  booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages        = {5747--5763},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
}

@misc{Lin-arXiv-2023-AWQ,
      title={AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration}, 
      author={Ji Lin and Jiaming Tang and Haotian Tang and Shang Yang and Xingyu Dang and Song Han},
      year={2023},
      eprint={2306.00978},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{Frantar-NeurIPS-2022-Optimal,
  author       = {Elias Frantar and
                  Dan Alistarh},
  title        = {Optimal Brain Compression: {A} Framework for Accurate Post-Training
                  Quantization and Pruning},
  booktitle    = {NeurIPS},
  year         = {2022},
}

@article{Li-arXiv-2023-Unified,
  author       = {Xiaonan Li and
                  Kai Lv and
                  Hang Yan and
                  Tianyang Lin and
                  Wei Zhu and
                  Yuan Ni and
                  Guotong Xie and
                  Xiaoling Wang and
                  Xipeng Qiu},
  title        = {Unified Demonstration Retriever for In-Context Learning},
  journal      = {CoRR},
  volume       = {abs/2305.04320},
  year         = {2023},
}

@article{Diao-arXiv-2023-Active,
  author       = {Shizhe Diao and
                  Pengcheng Wang and
                  Yong Lin and
                  Tong Zhang},
  title        = {Active Prompting with Chain-of-Thought for Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2302.12246},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2302.12246},
  doi          = {10.48550/arXiv.2302.12246},
  eprinttype    = {arXiv},
  eprint       = {2302.12246},
  timestamp    = {Tue, 28 Feb 2023 14:02:05 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2302-12246.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Han-arXiv-2023-In,
  author       = {Chi Han and
                  Ziqi Wang and
                  Han Zhao and
                  Heng Ji},
  title        = {In-Context Learning of Large Language Models Explained as Kernel Regression},
  journal      = {CoRR},
  volume       = {abs/2305.12766},
  year         = {2023},
}

@article{Gu-arXiv-2023-Pre,
  author       = {Yuxian Gu and
                  Li Dong and
                  Furu Wei and
                  Minlie Huang},
  title        = {Pre-Training to Learn in Context},
  journal      = {CoRR},
  volume       = {abs/2305.09137},
  year         = {2023},
}

@article{Huang-arXiv-2023-Not,
  author       = {Haoyang Huang and
                  Tianyi Tang and
                  Dongdong Zhang and
                  Wayne Xin Zhao and
                  Ting Song and
                  Yan Xia and
                  Furu Wei},
  title        = {Not All Languages Are Created Equal in LLMs: Improving Multilingual
                  Capability by Cross-Lingual-Thought Prompting},
  journal      = {CoRR},
  volume       = {abs/2305.07004},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.07004},
  doi          = {10.48550/arXiv.2305.07004},
  eprinttype    = {arXiv},
  eprint       = {2305.07004},
  timestamp    = {Wed, 17 May 2023 15:47:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-07004.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Dettmers-ICLR-2022-8bit,
  title={8-bit Optimizers via Block-wise Quantization},
  author={Dettmers, Tim and Lewis, Mike and Shleifer, Sam and Zettlemoyer, Luke},
  journal={9th International Conference on Learning Representations, ICLR},
  year={2022}
}

@article{Feng-arXiv-2023-Towards,
  title={Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective},
  author={Feng, Guhao and Gu, Yuntian and Zhang, Bohang and Ye, Haotian and He, Di and Wang, Liwei},
  journal={arXiv preprint arXiv:2305.15408},
  year={2023}
}

@article{Hu-arXiv-2023-Chain,
  author       = {Hanxu Hu and
                  Hongyuan Lu and
                  Huajian Zhang and
                  Wai Lam and
                  Yue Zhang},
  title        = {Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models},
  journal      = {CoRR},
  volume       = {abs/2305.10276},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.10276},
  doi          = {10.48550/arXiv.2305.10276},
  eprinttype    = {arXiv},
  eprint       = {2305.10276},
  timestamp    = {Wed, 24 May 2023 14:49:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-10276.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Son-arxiv-2023-Beyond,
  author       = {Guijin Son and
                  Hanearl Jung and
                  Moonjeong Hahm and
                  Keonju Na and
                  Sol Jin},
  title        = {Beyond Classification: Financial Reasoning in State-of-the-Art Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2305.01505},
  year         = {2023},
}

@article{Shah-arxiv-2023-Zero,
      title={Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks}, 
      author={Agam Shah and Sudheer Chava},
      year={2023},
      volume={abs/2305.16633},
      journal={CoRR},
}

@article{Adam-blog-2023-ChatGPT,
author = {Zaremba, Adam and Demir, Ender and Chatgpt},
year = {2023},
title = {ChatGPT: Unlocking the Future of NLP in Finance}
}

@article{Chen-blog-2023-Dissecting,
author = {Lequn Chen},
year = {2023},
title = {Dissecting Batching Effects in GPT Inference},
url = {https://le.qun.ch/en/blog/2023/05/13/transformer-batching/}
}

@article{Yang-arxiv-2023-mental,
  author       = {Kailai Yang and
                  Shaoxiong Ji and
                  Tianlin Zhang and
                  Qianqian Xie and
                  Sophia Ananiadou},
  title        = {On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental
                  Health Analysis},
  journal      = {CoRR},
  volume       = {abs/2304.03347},
  year         = {2023},
}
@article{Liu-arxiv-2023-Health,
  title={Large Language Models are Few-Shot Health Learners},
  author={Xin Liu and Daniel McDuff and Geza Kovacs and Isaac R. Galatzer-Levy and Jacob Sunshine and Jiening Zhan and Ming-Zher Poh and Shun Liao and Paolo Di Achille and Shwetak N. Patel},
  year={2023},
  volume={abs/2305.15525},
  journal={CoRR},
}
@article{Manakul-arxiv-2023-SelfCheckGPT,
  title={SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models},
  author={Potsawee Manakul and Adian Liusie and Mark John Francis Gales},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.06983},
  journal={CoRR},
}
@article{Kadavath-arxiv-2023-Language,
  title={Language Models (Mostly) Know What They Know},
  author={Saurav Kadavath and Tom Conerly and Amanda Askell and T. J. Henighan and Dawn Drain and Ethan Perez and Nicholas Schiefer and Zachary Dodds and Nova DasSarma and Eli Tran-Johnson and Scott Johnston and Sheer El-Showk and Andy Jones and Nelson Elhage and Tristan Hume and Anna Chen and Yuntao Bai and Sam Bowman and Stanislav Fort and Deep Ganguli and Danny Hernandez and Josh Jacobson and John Kernion and Shauna Kravec and Liane Lovitt and Kamal Ndousse and Catherine Olsson and Sam Ringer and Dario Amodei and Tom B. Brown and Jack Clark and Nicholas Joseph and Benjamin Mann and Sam McCandlish and Christopher Olah and Jared Kaplan},
  journal={CoRR},
  year={2022},
  volume={abs/2207.05221}
}
@article{Si-arxiv-2022-Prompting,
  title={Prompting GPT-3 To Be Reliable},
  author={Chenglei Si and Zhe Gan and Zhengyuan Yang and Shuohang Wang and Jianfeng Wang and Jordan L. Boyd-Graber and Lijuan Wang},
  journal={CoRR},
  year={2022},
  volume={abs/2210.09150}
}
@article{Park-arxiv-2023-Generative,
  author       = {Joon Sung Park and
                  Joseph C. O'Brien and
                  Carrie J. Cai and
                  Meredith Ringel Morris and
                  Percy Liang and
                  Michael S. Bernstein},
  title        = {Generative Agents: Interactive Simulacra of Human Behavior},
  journal      = {CoRR},
  volume       = {abs/2304.03442},
  year         = {2023},
}

@article{Wang-arxiv-2023-Voyager,
      title={Voyager: An Open-Ended Embodied Agent with Large Language Models}, 
      author={Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
      year={2023},
      journal={CoRR},
      volume={abs/2305.16291},
}

@article{Zhu-arxiv-2023-Ghost,
      title={Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory}, 
      author={Xizhou Zhu and Yuntao Chen and Hao Tian and Chenxin Tao and Weijie Su and Chenyu Yang and Gao Huang and Bin Li and Lewei Lu and Xiaogang Wang and Yu Qiao and Zhaoxiang Zhang and Jifeng Dai},
      year={2023},
      volume={abs/2305.17144},
      journal={CoRR},
}

@article{Du-arxiv-2023-Improving,
  author       = {Yilun Du and
                  Shuang Li and
                  Antonio Torralba and
                  Joshua B. Tenenbaum and
                  Igor Mordatch},
  title        = {Improving Factuality and Reasoning in Language Models through Multiagent
                  Debate},
  journal      = {CoRR},
  volume       = {abs/2305.14325},
  year         = {2023},
}

@article{Fu-arxiv-2023-Improving,
  author       = {Yao Fu and
                  Hao Peng and
                  Tushar Khot and
                  Mirella Lapata},
  title        = {Improving Language Model Negotiation with Self-Play and In-Context
                  Learning from {AI} Feedback},
  journal      = {CoRR},
  volume       = {abs/2305.10142},
  year         = {2023},
}

@article{Metha-arxiv-2023-Improving,
  author       = {Nikhil Mehta and
                  Milagro Teruel and
                  Patricio Figueroa Sanz and
                  Xin Deng and
                  Ahmed Hassan Awadallah and
                  Julia Kiseleva},
  title        = {Improving Grounded Language Understanding in a Collaborative Environment
                  by Interacting with Agents Through Help Feedback},
  journal      = {CoRR},
  volume       = {abs/2304.10750},
  year         = {2023},
}

@article{Li-arxiv-2023-CAMEL,
  author       = {Guohao Li and
                  Hasan Abed Al Kader Hammoud and
                  Hani Itani and
                  Dmitrii Khizbullin and
                  Bernard Ghanem},
  title        = {{CAMEL:} Communicative Agents for "Mind" Exploration of Large Scale
                  Language Model Society},
  journal      = {CoRR},
  volume       = {abs/2303.17760},
  year         = {2023},
}

@article{Zhang-arxiv-2023-One,
  author       = {Chaoning Zhang and
                  Chenshuang Zhang and
                  Chenghao Li and
                  Yu Qiao and
                  Sheng Zheng and
                  Sumit Kumar Dam and
                  Mengchun Zhang and
                  Jung Uk Kim and
                  Seong Tae Kim and
                  Jinwoo Choi and
                  Gyeong{-}Moon Park and
                  Sung{-}Ho Bae and
                  Lik{-}Hang Lee and
                  Pan Hui and
                  In So Kweon and
                  Choong Seon Hong},
  title        = {One Small Step for Generative AI, One Giant Leap for {AGI:} {A} Complete
                  Survey on ChatGPT in {AIGC} Era},
  journal      = {CoRR},
  volume       = {abs/2304.06488},
  year         = {2023},
}

@inproceedings{Anastasia-blog-2022-BioASQ,
author = {Krithara, Anastasia and Nentidis, Anastasios and Bougiatiotis, Konstantinos and Paliouras, Georgios},
year = {2022},
title = {BioASQ-QA: A manually curated corpus for Biomedical Question Answering},
}

@inproceedings{Jin-emnlp-2019-PubMedQA,
  author       = {Qiao Jin and
                  Bhuwan Dhingra and
                  Zhengping Liu and
                  William W. Cohen and
                  Xinghua Lu},
  title        = {PubMedQA: {A} Dataset for Biomedical Research Question Answering},
  booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural
                  Language Processing and the 9th International Joint Conference on
                  Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China,
                  November 3-7, 2019},
  pages        = {2567--2577},
  year         = {2019},
}

@inproceeding{ChatPaper-github-2023-ChatPaper,
    title        = {ChatPaper},
    howpublished = {\url{https://github.com/kaixindelele/ChatPaper}},
    year         = {2023},
}
@article{Araci-arxiv-2023-FinBERT,
  author       = {Dogu Araci},
  title        = {FinBERT: Financial Sentiment Analysis with Pre-trained Language Models},
  journal      = {CoRR},
  volume       = {abs/1908.10063},
  year         = {2019},
}
@inproceedings{Alvarado-ALTA-2015-Domain,
  author       = {Julio Cesar Salinas Alvarado and
                  Karin Verspoor and
                  Timothy Baldwin},
  editor       = {Ben Hachey and
                  Kellie Webster},
  title        = {Domain Adaption of Named Entity Recognition to Support Credit Risk
                  Assessment},
  booktitle    = {Proceedings of the Australasian Language Technology Association Workshop,
                  {ALTA} 2015, Parramatta, Australia, December 8 - 9, 2015},
  pages        = {84--90},
  publisher    = {{ACL}},
  year         = {2015},
}

@article{Alkaissi-pubmed-2023-Artificial,
    author = {Hussam Alkaissi, Samy I McFarlane},
    title  = {Artificial Hallucinations in ChatGPT: Implications in Scientific Writing},
    journal= {PubMed},
    year   = {2023},
}

@misc{AutoGPT,
    url = {https://github.com/Significant-Gravitas/Auto-GPT},
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub repository},
}

@misc{GPT-Engineer,
    url = {https://github.com/AntonOsika/gpt-engineer},
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub repository},
}

@article{Wang-arXiv-2023-Plan,
  author       = {Lei Wang and
                  Wanyu Xu and
                  Yihuai Lan and
                  Zhiqiang Hu and
                  Yunshi Lan and
                  Roy Ka{-}Wei Lee and
                  Ee{-}Peng Lim},
  title        = {Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning
                  by Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.04091},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.04091},
  doi          = {10.48550/arXiv.2305.04091},
  eprinttype    = {arXiv},
  eprint       = {2305.04091},
  timestamp    = {Thu, 11 May 2023 15:54:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-04091.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Jiang-arXiv-2023-Self,
  author       = {Xue Jiang and
                  Yihong Dong and
                  Lecheng Wang and
                  Qiwei Shang and
                  Ge Li},
  title        = {Self-planning Code Generation with Large Language Model},
  journal      = {CoRR},
  volume       = {abs/2303.06689},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.06689},
  doi          = {10.48550/arXiv.2303.06689},
  eprinttype    = {arXiv},
  eprint       = {2303.06689},
  timestamp    = {Fri, 21 Apr 2023 09:39:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-06689.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Khot-2022-arXiv-Decomposed,
  author       = {Tushar Khot and
                  Harsh Trivedi and
                  Matthew Finlayson and
                  Yao Fu and
                  Kyle Richardson and
                  Peter Clark and
                  Ashish Sabharwal},
  title        = {Decomposed Prompting: {A} Modular Approach for Solving Complex Tasks},
  journal      = {CoRR},
  volume       = {abs/2210.02406},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2210.02406},
  doi          = {10.48550/arXiv.2210.02406},
  eprinttype    = {arXiv},
  eprint       = {2210.02406},
  timestamp    = {Fri, 07 Oct 2022 15:24:59 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2210-02406.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Shen-2023-arXiv-Hugginggpt,
  title={Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={arXiv preprint arXiv:2303.17580},
  year={2023}
}

@misc{koala_blogpost_2023,
  author = {Xinyang Geng and Arnav Gudibande and Hao Liu and Eric Wallace and Pieter Abbeel and Sergey Levine and Dawn Song},
  title = {Koala: A Dialogue Model for Academic Research},
  howpublished = {Blog post},
  month = {April},
  year = {2023},
}


@misc{BELLE,
  author = {Yunjie Ji and Yong Deng and Yan Gong and Yiping Peng and Qiang Niu and Baochang Ma and Xiangang Li},
  title = {BELLE: Be Everyone's Large Language model Engine },
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/LianjiaTech/BELLE}},
}

@article{Liu-2023-arxiv-Visual,
  author       = {Haotian Liu and
                  Chunyuan Li and
                  Qingyang Wu and
                  Yong Jae Lee},
  title        = {Visual Instruction Tuning},
  journal      = {CoRR},
  volume       = {abs/2304.08485},
  year         = {2023},
}


@article{Zhu-2023-arxiv-MiniGPT-4,
  author       = {Deyao Zhu and
                  Jun Chen and
                  Xiaoqian Shen and
                  Xiang Li and
                  Mohamed Elhoseiny},
  title        = {MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2304.10592},
  year         = {2023},
  
}

@article{Dai-2023-arxiv-InstructBLIP,
  author       = {Wenliang Dai and
                  Junnan Li and
                  Dongxu Li and
                  Anthony Meng Huat Tiong and
                  Junqi Zhao and
                  Weisheng Wang and
                  Boyang Li and
                  Pascale Fung and
                  Steven C. H. Hoi},
  title        = {InstructBLIP: Towards General-purpose Vision-Language Models with
                  Instruction Tuning},
  journal      = {CoRR},
  volume       = {abs/2305.06500},
  year         = {2023},
  
}

@misc{su-2023-arxiv-pandagpt,
      title={PandaGPT: One Model To Instruction-Follow Them All}, 
      author={Yixuan Su and Tian Lan and Huayang Li and Jialu Xu and Yan Wang and Deng Cai},
      year={2023},
      eprint={2305.16355},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{shaw-2018-acl-self,
  author       = {Peter Shaw and
                  Jakob Uszkoreit and
                  Ashish Vaswani},
  editor       = {Marilyn A. Walker and
                  Heng Ji and
                  Amanda Stent},
  title        = {Self-Attention with Relative Position Representations},
  booktitle    = {Proceedings of the 2018 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  NAACL-HLT, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 2 (Short
                  Papers)},
  pages        = {464--468},
  publisher    = {Association for Computational Linguistics},
  year         = {2018},
  url          = {https://doi.org/10.18653/v1/n18-2074},
  doi          = {10.18653/v1/n18-2074},
  timestamp    = {Fri, 06 Aug 2021 00:41:32 +0200},
}

@inproceedings{dai-2019-acl-transformer,
  author       = {Zihang Dai and
                  Zhilin Yang and
                  Yiming Yang and
                  Jaime G. Carbonell and
                  Quoc Viet Le and
                  Ruslan Salakhutdinov},
  editor       = {Anna Korhonen and
                  David R. Traum and
                  Llu{\'{\i}}s M{\`{a}}rquez},
  title        = {Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
  booktitle    = {Proceedings of the 57th Conference of the Association for Computational
                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
                  Volume 1: Long Papers},
  pages        = {2978--2988},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1285},
  doi          = {10.18653/v1/p19-1285},
  timestamp    = {Fri, 06 Aug 2021 00:41:01 +0200},
}

@article{Pan-2023-arXiv-what,
  author       = {Jane Pan and
                  Tianyu Gao and
                  Howard Chen and
                  Danqi Chen},
  title        = {What In-Context Learning "Learns" In-Context: Disentangling Task Recognition
                  and Task Learning},
  journal      = {CoRR},
  volume       = {abs/2305.09731},
  year         = {2023},
}

@article{Tirumala-2023-arXiv-D4,
  title={D4: Improving llm pretraining via document de-duplication and diversification},
  author={Tirumala, Kushal and Simig, Daniel and Aghajanyan, Armen and Morcos, Ari S},
  journal={arXiv preprint arXiv:2308.12284},
  year={2023}
}

@article{Shen-2023-arXiv-SlimPajamaDC,
  title={SlimPajama-DC: Understanding Data Combinations for LLM Training},
  author={Shen, Zhiqiang and Tao, Tianhua and Ma, Liqun and Neiswanger, Willie and Hestness, Joel and Vassilieva, Natalia and Soboleva, Daria and Xing, Eric},
  journal={arXiv preprint arXiv:2309.10818},
  year={2023}
}

@article{Wang-2023-arXiv-farewell,
  title={Farewell to Aimless Large-scale Pretraining: Influential Subset Selection for Language Model},
  author={Wang, Xiao and Zhou, Weikang and Zhang, Qi and Zhou, Jie and Gao, Songyang and Wang, Junzhe and Zhang, Menghan and Gao, Xiang and Chen, Yunwen and Gui, Tao},
  journal={arXiv preprint arXiv:2305.12816},
  year={2023}
}

@inproceedings{Bengio-2009-arXiv-curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={{ICML}},
  pages={41--48},
  year={2009}
}

@article{Chen-2023-arXiv-skill,
  title={Skill-it! A data-driven skills framework for understanding and training language models},
  author={Chen, Mayee F and Roberts, Nicholas and Bhatia, Kush and Wang, Jue and Zhang, Ce and Sala, Frederic and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2307.14430},
  year={2023}
}

@article{Xu-2023-arXiv-contrastive,
  title={Contrastive Post-training Large Language Models on Data Curriculum},
  author={Xu, Canwen and Rosset, Corby and Del Corro, Luciano and Mahajan, Shweti and McAuley, Julian and Neville, Jennifer and Awadallah, Ahmed Hassan and Rao, Nikhil},
  journal={arXiv preprint arXiv:2310.02263},
  year={2023}
}



@article{Wies-2023-arXiv-the,
  author       = {Noam Wies and
                  Yoav Levine and
                  Amnon Shashua},
  title        = {The Learnability of In-Context Learning},
  journal      = {CoRR},
  volume       = {abs/2303.07895},
  year         = {2023},
}

@article{su-2021-arxiv-reformer,
  author       = {Jianlin Su and
                  Yu Lu and
                  Shengfeng Pan and
                  Bo Wen and
                  Yunfeng Liu},
  title        = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  journal      = {CoRR},
  volume       = {abs/2104.09864},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.09864},
  eprinttype    = {arXiv},
  eprint       = {2104.09864},
  timestamp    = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2104-09864.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{sun-2022-arxiv-a,
  author       = {Yutao Sun and
                  Li Dong and
                  Barun Patra and
                  Shuming Ma and
                  Shaohan Huang and
                  Alon Benhaim and
                  Vishrav Chaudhary and
                  Xia Song and
                  Furu Wei},
  title        = {A Length-Extrapolatable Transformer},
  journal      = {CoRR},
  volume       = {abs/2212.10554},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2212.10554},
  doi          = {10.48550/arXiv.2212.10554},
  eprinttype    = {arXiv},
  eprint       = {2212.10554},
  timestamp    = {Wed, 04 Jan 2023 16:01:37 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2212-10554.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{qu-2021-emnlp-explore,
  author       = {Anlin Qu and
                  Jianwei Niu and
                  Shasha Mo},
  editor       = {Marie{-}Francine Moens and
                  Xuanjing Huang and
                  Lucia Specia and
                  Scott Wen{-}tau Yih},
  title        = {Explore Better Relative Position Embeddings from Encoding Perspective
                  for Transformer Models},
  booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
                  Republic, 7-11 November, 2021},
  pages        = {2989--2997},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
  url          = {https://doi.org/10.18653/v1/2021.emnlp-main.237},
  doi          = {10.18653/v1/2021.emnlp-main.237},
  timestamp    = {Thu, 20 Jan 2022 10:02:29 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/Qu0M21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ke-2021-iclr-rethinking,
  author       = {Guolin Ke and
                  Di He and
                  Tie{-}Yan Liu},
  title        = {Rethinking Positional Encoding in Language Pre-training},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  publisher    = {OpenReview.net},
  year         = {2021},
  url          = {https://openreview.net/forum?id=09-528y2Fgf},
  timestamp    = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/KeHL21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Si-2023-arXiv-measuring,
  author       = {Chenglei Si and
                  Dan Friedman and
                  Nitish Joshi and
                  Shi Feng and
                  Danqi Chen and
                  He He},
  title        = {Measuring Inductive Biases of In-Context Learning with Underspecified
                  Demonstrations},
  journal      = {CoRR},
  volume       = {abs/2305.13299},
  year         = {2023},
}

@article{Creswell-2022-arXiv-selection,
  author       = {Antonia Creswell and
                  Murray Shanahan and
                  Irina Higgins},
  title        = {Selection-Inference: Exploiting Large Language Models for Interpretable
                  Logical Reasoning},
  journal      = {CoRR},
  volume       = {abs/2205.09712},
  year         = {2022},
}


@inproceedings{Katharopoulos-2020-icml-transformers,
  author       = {Angelos Katharopoulos and
                  Apoorv Vyas and
                  Nikolaos Pappas and
                  Fran{\c{c}}ois Fleuret},
  title        = {Transformers are RNNs: Fast Autoregressive Transformers with Linear
                  Attention},
  booktitle    = {Proceedings of the 37th International Conference on Machine Learning,
                  {ICML} 2020, 13-18 July 2020, Virtual Event},
  series       = {Proceedings of Machine Learning Research},
  volume       = {119},
  pages        = {5156--5165},
  publisher    = {{PMLR}},
  year         = {2020},
  url          = {http://proceedings.mlr.press/v119/katharopoulos20a.html},
  timestamp    = {Tue, 15 Dec 2020 17:40:19 +0100},
  biburl       = {https://dblp.org/rec/conf/icml/KatharopoulosV020.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zhu-2021-nips-long,
  author       = {Chen Zhu and
                  Wei Ping and
                  Chaowei Xiao and
                  Mohammad Shoeybi and
                  Tom Goldstein and
                  Anima Anandkumar and
                  Bryan Catanzaro},
  editor       = {Marc'Aurelio Ranzato and
                  Alina Beygelzimer and
                  Yann N. Dauphin and
                  Percy Liang and
                  Jennifer Wortman Vaughan},
  title        = {Long-Short Transformer: Efficient Transformers for Language and Vision},
  booktitle    = {Advances in Neural Information Processing Systems 34: Annual Conference
                  on Neural Information Processing Systems 2021, NeurIPS 2021, December
                  6-14, 2021, virtual},
  pages        = {17723--17736},
  year         = {2021},
  url          = {https://proceedings.neurips.cc/paper/2021/hash/9425be43ba92c2b4454ca7bf602efad8-Abstract.html},
  timestamp    = {Tue, 03 May 2022 16:20:48 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/ZhuPXSGAC21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Choromanski-2021-iclr-rethinking,
  author       = {Krzysztof Marcin Choromanski and
                  Valerii Likhosherstov and
                  David Dohan and
                  Xingyou Song and
                  Andreea Gane and
                  Tam{\'{a}}s Sarl{\'{o}}s and
                  Peter Hawkins and
                  Jared Quincy Davis and
                  Afroz Mohiuddin and
                  Lukasz Kaiser and
                  David Benjamin Belanger and
                  Lucy J. Colwell and
                  Adrian Weller},
  title        = {Rethinking Attention with Performers},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  publisher    = {OpenReview.net},
  year         = {2021},
  url          = {https://openreview.net/forum?id=Ua6zuk0WRH},
  timestamp    = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ChoromanskiLDSG21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Ouyang-2023-arXiv-prompt,
  author       = {Siqi Ouyang and
                  Lei Li},
  title        = {Prompt Optimization of Large Language Model for Interactive Tasks
                  without Gradient and Demonstrations},
  journal      = {CoRR},
  volume       = {abs/2305.15064},
  year         = {2023},
}

@inproceedings{Huang-2022-CoRL-inner,
  author       = {Wenlong Huang and
                  Fei Xia and
                  Ted Xiao and
                  Harris Chan and
                  Jacky Liang and
                  Pete Florence and
                  Andy Zeng and
                  Jonathan Tompson and
                  Igor Mordatch and
                  Yevgen Chebotar and
                  Pierre Sermanet and
                  Tomas Jackson and
                  Noah Brown and
                  Linda Luu and
                  Sergey Levine and
                  Karol Hausman and
                  Brian Ichter},
  title        = {Inner Monologue: Embodied Reasoning through Planning with Language
                  Models},
  booktitle    = {Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland,
                  New Zealand},
  volume       = {205},
  pages        = {1769--1782},
  year         = {2022},
}

@inproceedings{Dua-2022-EMNLP-successive,
  author       = {Dheeru Dua and
                  Shivanshu Gupta and
                  Sameer Singh and
                  Matt Gardner},
  title        = {Successive Prompting for Decomposing Complex Questions},
  booktitle    = {Proceedings of the 2022 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
                  December 7-11, 2022},
  pages        = {1251--1265},
  year         = {2022},
}

@inproceedings{kitaev-2020-iclr-reformer,
  author       = {Nikita Kitaev and
                  Lukasz Kaiser and
                  Anselm Levskaya},
  title        = {Reformer: The Efficient Transformer},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},
  url          = {https://openreview.net/forum?id=rkgNKkHtvB},
  timestamp    = {Thu, 07 May 2020 17:11:48 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/KitaevKL20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Wang-2023-arXiv-describe,
  author       = {Zihao Wang and
                  Shaofei Cai and
                  Anji Liu and
                  Xiaojian Ma and
                  Yitao Liang},
  title        = {Describe, Explain, Plan and Select: Interactive Planning with Large
                  Language Models Enables Open-World Multi-Task Agents},
  journal      = {CoRR},
  volume       = {abs/2302.01560},
  year         = {2023},
}


@article{Mehta-2022-arxiv-long,
  author       = {Harsh Mehta and
                  Ankit Gupta and
                  Ashok Cutkosky and
                  Behnam Neyshabur},
  title        = {Long Range Language Modeling via Gated State Spaces},
  journal      = {CoRR},
  volume       = {abs/2206.13947},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2206.13947},
  doi          = {10.48550/arXiv.2206.13947},
  eprinttype    = {arXiv},
  eprint       = {2206.13947},
  timestamp    = {Fri, 09 Dec 2022 09:06:45 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2206-13947.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Wu-2023-arXiv-visual,
  author       = {Chenfei Wu and
                  Shengming Yin and
                  Weizhen Qi and
                  Xiaodong Wang and
                  Zecheng Tang and
                  Nan Duan},
  title        = {Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation
                  Models},
  journal      = {CoRR},
  volume       = {abs/2303.04671},
  year         = {2023},
}

@article{Yao-2022-arXiv-react,
  author       = {Shunyu Yao and
                  Jeffrey Zhao and
                  Dian Yu and
                  Nan Du and
                  Izhak Shafran and
                  Karthik Narasimhan and
                  Yuan Cao},
  title        = {ReAct: Synergizing Reasoning and Acting in Language Models},
  journal      = {CoRR},
  volume       = {abs/2210.03629},
  year         = {2022},
}

@article{Lu-2023-arXiv-multimodal,
  author       = {Yujie Lu and
                  Pan Lu and
                  Zhiyu Chen and
                  Wanrong Zhu and
                  Xin Eric Wang and
                  William Yang Wang},
  title        = {Multimodal Procedural Planning via Dual Text-Image Prompting},
  journal      = {CoRR},
  volume       = {abs/2305.01795},
  year         = {2023},
}


@article{dao-2022-arxiv-hungry,
  author       = {Tri Dao and
                  Daniel Y. Fu and
                  Khaled Kamal Saab and
                  Armin W. Thomas and
                  Atri Rudra and
                  Christopher R{\'{e}}},
  title        = {Hungry Hungry Hippos: Towards Language Modeling with State Space Models},
  journal      = {CoRR},
  volume       = {abs/2212.14052},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2212.14052},
  doi          = {10.48550/arXiv.2212.14052},
  eprinttype    = {arXiv},
  eprint       = {2212.14052},
  timestamp    = {Sun, 08 Jan 2023 14:16:55 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2212-14052.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{poli-2023-icml-hyena,
  author={Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Fu, Daniel Y and Dao, Tri and Baccus, Stephen and Bengio, Yoshua and Ermon, Stefano and R{\'e}, Christopher},
  title     = {Hyena Hierarchy: Towards Larger Convolutional Language Models},
  booktitle = {{ICML}},
  year      = {2023}
}

@inproceedings{orvieto-2023-icml-lru,
  title={Resurrecting recurrent neural networks for long sequences},
  author={Orvieto, Antonio and Smith, Samuel L and Gu, Albert and Fernando, Anushan and Gulcehre, Caglar and Pascanu, Razvan and De, Soham},
  booktitle = {{ICML}},
  year={2023}
}

@article{zhai-2021-arxiv-aft,
  title={An attention free transformer},
  author={Zhai, Shuangfei and Talbott, Walter and Srivastava, Nitish and Huang, Chen and Goh, Hanlin and Zhang, Ruixiang and Susskind, Josh},
  journal={arXiv preprint arXiv:2105.14103},
  year={2021}
}

@article{sun-2023-arxiv-retnet,
  title={Retentive Network: A Successor to Transformer for Large Language Models},
  author={Sun, Yutao and Dong, Li and Huang, Shaohan and Ma, Shuming and Xia, Yuqing and Xue, Jilong and Wang, Jianyong and Wei, Furu},
  journal={arXiv preprint arXiv:2307.08621},
  year={2023}
}

@inproceedings{smith-2023-iclr-s5,
title={Simplified State Space Layers for Sequence Modeling},
author={Jimmy T.H. Smith and Andrew Warrington and Scott Linderman},
booktitle={{ICLR}},
year={2023}
}

@inproceedings{gu-2022-iclr-efficiently,
  author       = {Albert Gu and
                  Karan Goel and
                  Christopher R{\'{e}}},
  title        = {Efficiently Modeling Long Sequences with Structured State Spaces},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=uYLFoz1vlAC},
  timestamp    = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/GuGR22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Raman-2022-arXiv-planning,
  author       = {Shreyas Sundara Raman and
                  Vanya Cohen and
                  Eric Rosen and
                  Ifrah Idrees and
                  David Paulius and
                  Stefanie Tellex},
  title        = {Planning with Large Language Models via Corrective Re-prompting},
  journal      = {CoRR},
  volume       = {abs/2211.09935},
  year         = {2022},
}


@article{peng-2023-arxiv-rwkv,
  author       = {Bo Peng and
                  Eric Alcaide and
                  Quentin Anthony and
                  Alon Albalak and
                  Samuel Arcadinho and
                  Huanqi Cao and
                  Xin Cheng and
                  Michael Chung and
                  Matteo Grella and
                  Kranthi Kiran G. V. and
                  Xuzheng He and
                  Haowen Hou and
                  Przemyslaw Kazienko and
                  Jan Kocon and
                  Jiaming Kong and
                  Bartlomiej Koptyra and
                  Hayden Lau and
                  Krishna Sri Ipsit Mantri and
                  Ferdinand Mom and
                  Atsushi Saito and
                  Xiangru Tang and
                  Bolun Wang and
                  Johan S. Wind and
                  Stanislaw Wozniak and
                  Ruichong Zhang and
                  Zhenyuan Zhang and
                  Qihang Zhao and
                  Peng Zhou and
                  Jian Zhu and
                  Rui{-}Jie Zhu},
  title        = {{RWKV:} Reinventing RNNs for the Transformer Era},
  journal      = {CoRR},
  volume       = {abs/2305.13048},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.13048},
  doi          = {10.48550/arXiv.2305.13048},
  eprinttype    = {arXiv},
  eprint       = {2305.13048},
  timestamp    = {Fri, 26 May 2023 11:29:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-13048.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Yao-2023-arXiv-tree,
  author       = {Shunyu Yao and
                  Dian Yu and
                  Jeffrey Zhao and
                  Izhak Shafran and
                  Thomas L. Griffiths and
                  Yuan Cao and
                  Karthik Narasimhan},
  title        = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.10601},
  year         = {2023},
}

@inproceedings{Shinn-2023-arXiv-Reflexion,
  title={Reflexion: Language Agents with Verbal Reinforcement Learning},
  author={Noah Shinn and Federico Cassano and Beck Labash and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
  year={2023}
}

@article{Press-2022-arXiv-measuring,
  author       = {Ofir Press and
                  Muru Zhang and
                  Sewon Min and
                  Ludwig Schmidt and
                  Noah A. Smith and
                  Mike Lewis},
  title        = {Measuring and Narrowing the Compositionality Gap in Language Models},
  journal      = {CoRR},
  volume       = {abs/2210.03350},
  year         = {2022},
}

@article{Yu-2023-arXiv-prompt,
  author       = {Xiao Yu and
                  Maximillian Chen and
                  Zhou Yu},
  title        = {Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy
                  Planning},
  journal      = {CoRR},
  volume       = {abs/2305.13660},
  year         = {2023},
}

@article{Chen-2023-arXiv-chatcot,
  author       = {Zhipeng Chen and
                  Kun Zhou and
                  Beichen Zhang and
                  Zheng Gong and
                  Wayne Xin Zhao and
                  Ji{-}Rong Wen},
  title        = {ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.14323},
  year         = {2023},
}

@article{Hao-2023-arXiv-reasoning,
  author       = {Shibo Hao and
                  Yi Gu and
                  Haodi Ma and
                  Joshua Jiahua Hong and
                  Zhen Wang and
                  Daisy Zhe Wang and
                  Zhiting Hu},
  title        = {Reasoning with Language Model is Planning with World Model},
  journal      = {CoRR},
  volume       = {abs/2305.14992},
  year         = {2023},
}

@article{Wang-2023-arXiv-voyager,
  title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{Sun-2023-arXiv-adaplanner,
  title={AdaPlanner: Adaptive Planning from Feedback with Language Models},
  author={Sun, Haotian and Zhuang, Yuchen and Kong, Lingkai and Dai, Bo and Zhang, Chao},
  journal={arXiv preprint arXiv:2305.16653},
  year={2023}
}

@article{Qian-2022-arXiv-limitations,
  author       = {Jing Qian and
                  Hong Wang and
                  Zekun Li and
                  Shiyang Li and
                  Xifeng Yan},
  title        = {Limitations of Language Models in Arithmetic and Symbolic Induction},
  journal      = {CoRR},
  volume       = {abs/2208.05051},
  year         = {2022},
}

@article{Liu-2023-arXiv-LLM+P,
  author       = {Bo Liu and
                  Yuqian Jiang and
                  Xiaohan Zhang and
                  Qiang Liu and
                  Shiqi Zhang and
                  Joydeep Biswas and
                  Peter Stone},
  title        = {{LLM+P:} Empowering Large Language Models with Optimal Planning Proficiency},
  journal      = {CoRR},
  volume       = {abs/2304.11477},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.11477},
  doi          = {10.48550/arXiv.2304.11477},
  eprinttype    = {arXiv},
  eprint       = {2304.11477},
  timestamp    = {Tue, 02 May 2023 18:58:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2304-11477.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Forno-2023-arXiv-meta,
  author       = {Julian Coda{-}Forno and
                  Marcel Binz and
                  Zeynep Akata and
                  Matthew M. Botvinick and
                  Jane X. Wang and
                  Eric Schulz},
  title        = {Meta-in-context learning in large language models},
  journal      = {CoRR},
  volume       = {abs/2305.12907},
  year         = {2023},
}

@article{Wei-2023-arXiv-symbol,
  author       = {Jerry W. Wei and
                  Le Hou and
                  Andrew K. Lampinen and
                  Xiangning Chen and
                  Da Huang and
                  Yi Tay and
                  Xinyun Chen and
                  Yifeng Lu and
                  Denny Zhou and
                  Tengyu Ma and
                  Quoc V. Le},
  title        = {Symbol tuning improves in-context learning in language models},
  journal      = {CoRR},
  volume       = {abs/2305.08298},
  year         = {2023},
}

@inproceedings{Razeghi-2022-EMNLP-impact,
  author       = {Yasaman Razeghi and
                  Robert L. Logan IV and
                  Matt Gardner and
                  Sameer Singh},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {Impact of Pretraining Term Frequencies on Few-Shot Numerical Reasoning},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages        = {840--854},
  year         = {2022},
}

@article{Hahn-2023-arXiv-a,
  author       = {Michael Hahn and
                  Navin Goyal},
  title        = {A Theory of Emergent In-Context Learning as Implicit Structure Induction},
  journal      = {CoRR},
  volume       = {abs/2303.07971},
  year         = {2023},
}
@article{Zhang-2023-arxiv-Benchmarking,
  author       = {Tianyi Zhang and
                  Faisal Ladhak and
                  Esin Durmus and
                  Percy Liang and
                  Kathleen R. McKeown and
                  Tatsunori B. Hashimoto},
  title        = {Benchmarking Large Language Models for News Summarization},
  journal      = {CoRR},
  volume       = {abs/2301.13848},
  year         = {2023},
}
@article{Goyal-2023-arxiv-News,
  author       = {Tanya Goyal and
                  Junyi Jessy Li and
                  Greg Durrett},
  title        = {News Summarization and Evaluation in the Era of {GPT-3}},
  journal      = {CoRR},
  volume       = {abs/2209.12356},
  year         = {2022},
}
@article{Gehrmann-2022-arxiv-Repairing,
  author       = {Sebastian Gehrmann and
                  Elizabeth Clark and
                  Thibault Sellam},
  title        = {Repairing the Cracked Foundation: {A} Survey of Obstacles in Evaluation
                  Practices for Generated Text},
  journal      = {CoRR},
  volume       = {abs/2202.06935},
  year         = {2022},
}
@article{Liu-arxiv-2022-Revisiting,
  author       = {Yixin Liu and
                  Alexander R. Fabbri and
                  Pengfei Liu and
                  Yilun Zhao and
                  Linyong Nan and
                  Ruilin Han and
                  Simeng Han and
                  Shafiq R. Joty and
                  Chien{-}Sheng Wu and
                  Caiming Xiong and
                  Dragomir Radev},
  title        = {Revisiting the Gold Standard: Grounding Summarization Evaluation with
                  Robust Human Evaluation},
  journal      = {CoRR},
  volume       = {abs/2212.07981},
  year         = {2022},
}
@article{Fabri-2021-tacl-SummEval,
  author       = {Alexander R. Fabbri and
                  Wojciech Kryscinski and
                  Bryan McCann and
                  Caiming Xiong and
                  Richard Socher and
                  Dragomir R. Radev},
  title        = {SummEval: Re-evaluating Summarization Evaluation},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {9},
  pages        = {391--409},
  year         = {2021},
}
@article{Wang-2023-arxiv-Is,
  author       = {Jiaan Wang and
                  Yunlong Liang and
                  Fandong Meng and
                  Haoxiang Shi and
                  Zhixu Li and
                  Jinan Xu and
                  Jianfeng Qu and
                  Jie Zhou},
  title        = {Is ChatGPT a Good {NLG} Evaluator? {A} Preliminary Study},
  journal      = {CoRR},
  volume       = {abs/2303.04048},
  year         = {2023},
}
@article{Liu-2023-arxiv-G-Eval,
  author       = {Yang Liu and
                  Dan Iter and
                  Yichong Xu and
                  Shuohang Wang and
                  Ruochen Xu and
                  Chenguang Zhu},
  title        = {G-Eval: {NLG} Evaluation using {GPT-4} with Better Human Alignment},
  journal      = {CoRR},
  volume       = {abs/2303.16634},
  year         = {2023},
}
@article{Kocmi-2023-arxiv-Large,
  author       = {Tom Kocmi and
                  Christian Federmann},
  title        = {Large Language Models Are State-of-the-Art Evaluators of Translation
                  Quality},
  journal      = {CoRR},
  volume       = {abs/2302.14520},
  year         = {2023},
}
@article{Liu-2023-arxiv-Evaluate,
  author       = {Yongkang Liu and
                  Shi Feng and
                  Daling Wang and
                  Yifei Zhang and
                  Hinrich Sch{\"{u}}tze},
  title        = {Evaluate What You Can't Evaluate: Unassessable Generated Responses
                  Quality},
  journal      = {CoRR},
  volume       = {abs/2305.14658},
  year         = {2023},
}
@article{Gao-arxiv-2023-Human,
  author       = {Mingqi Gao and
                  Jie Ruan and
                  Renliang Sun and
                  Xunjian Yin and
                  Shiping Yang and
                  Xiaojun Wan},
  title        = {Human-like Summarization Evaluation with ChatGPT},
  journal      = {CoRR},
  volume       = {abs/2304.02554},
  year         = {2023},
}
@article{Fu-arxiv-2023-GPTScore,
  author       = {Jinlan Fu and
                  See{-}Kiong Ng and
                  Zhengbao Jiang and
                  Pengfei Liu},
  title        = {GPTScore: Evaluate as You Desire},
  journal      = {CoRR},
  volume       = {abs/2302.04166},
  year         = {2023},
}
@article{Chiang-2023-arxiv-Can,
  author       = {David Cheng{-}Han Chiang and
                  Hung{-}yi Lee},
  title        = {Can Large Language Models Be an Alternative to Human Evaluations?},
  journal      = {CoRR},
  volume       = {abs/2305.01937},
  year         = {2023},
}
@article{Ji-2023-arxiv-Exploring,
  author       = {Yunjie Ji and
                  Yan Gong and
                  Yiping Peng and
                  Chao Ni and
                  Peiyan Sun and
                  Dongyu Pan and
                  Baochang Ma and
                  Xiangang Li},
  title        = {Exploring ChatGPT's Ability to Rank Content: {A} Preliminary Study
                  on Consistency with Human Preferences},
  journal      = {CoRR},
  volume       = {abs/2303.07610},
  year         = {2023},
}
@article{Tang-2023-arxiv-Not,
  author       = {Tianyi Tang and
                  Hongyuan Lu and
                  Yuchen Eleanor Jiang and
                  Haoyang Huang and
                  Dongdong Zhang and
                  Wayne Xin Zhao and
                  Furu Wei},
  title        = {Not All Metrics Are Guilty: Improving {NLG} Evaluation with {LLM}
                  Paraphrasing},
  journal      = {CoRR},
  volume       = {abs/2305.15067},
  year         = {2023},
}
@article{Wang-2023-arxiv-Large,
  author       = {Peiyi Wang and
                  Lei Li and
                  Liang Chen and
                  Dawei Zhu and
                  Binghuai Lin and
                  Yunbo Cao and
                  Qi Liu and
                  Tianyu Liu and
                  Zhifang Sui},
  title        = {Large Language Models are not Fair Evaluators},
  journal      = {CoRR},
  volume       = {abs/2305.17926},
  year         = {2023},
}
@article{Wang-2023-arxiv-rethinking,
  author       = {Xiaolei Wang and
                  Xinyu Tang and
                  Wayne Xin Zhao and
                  Jingyuan Wang and
                  Ji{-}Rong Wen},
  title        = {Rethinking the Evaluation for Conversational Recommendation in the
                  Era of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.13112},
  year         = {2023},
}
@article{Jiang-2023-arxiv-StructGPT,
  author       = {Jinhao Jiang and
                  Kun Zhou and
                  Zican Dong and
                  Keming Ye and
                  Wayne Xin Zhao and
                  Ji{-}Rong Wen},
  title        = {StructGPT: {A} General Framework for Large Language Model to Reason
                  over Structured Data},
  journal      = {CoRR},
  volume       = {abs/2305.09645},
  year         = {2023}
}
@article{Jiang-2023-arxiv-Active,
  author       = {Zhengbao Jiang and
                  Frank F. Xu and
                  Luyu Gao and
                  Zhiqing Sun and
                  Qian Liu and
                  Jane Dwivedi{-}Yu and
                  Yiming Yang and
                  Jamie Callan and
                  Graham Neubig},
  title        = {Active Retrieval Augmented Generation},
  journal      = {CoRR},
  volume       = {abs/2305.06983},
  year         = {2023},
}
@article{Singhal-2023-arxiv-Towards,
  author       = {Karan Singhal and
                  Tao Tu and
                  Juraj Gottweis and
                  Rory Sayres and
                  Ellery Wulczyn and
                  Le Hou and
                  Kevin Clark and
                  Stephen Pfohl and
                  Heather Cole{-}Lewis and
                  Darlene Neal and
                  Mike Schaekermann and
                  Amy Wang and
                  Mohamed Amin and
                  Sami Lachgar and
                  Philip Andrew Mansfield and
                  Sushant Prakash and
                  Bradley Green and
                  Ewa Dominowska and
                  Blaise Ag{\"{u}}era y Arcas and
                  Nenad Tomasev and
                  Yun Liu and
                  Renee Wong and
                  Christopher Semturs and
                  S. Sara Mahdavi and
                  Joelle K. Barral and
                  Dale R. Webster and
                  Gregory S. Corrado and
                  Yossi Matias and
                  Shekoofeh Azizi and
                  Alan Karthikesalingam and
                  Vivek Natarajan},
  title        = {Towards Expert-Level Medical Question Answering with Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2305.09617},
  year         = {2023},
}
@article{Yu-2022-arxiv-Legal,
  author       = {Fangyi Yu and
                  Lee Quartey and
                  Frank Schilder},
  title        = {Legal Prompting: Teaching a Language Model to Think Like a Lawyer},
  journal      = {CoRR},
  volume       = {abs/2212.01326},
  year         = {2022},
}
@article{Trautmann-2022-arxiv-Legal,
  author       = {Dietrich Trautmann and
                  Alina Petrova and
                  Frank Schilder},
  title        = {Legal Prompt Engineering for Multilingual Legal Judgement Prediction},
  journal      = {CoRR},
  volume       = {abs/2212.02199},
  year         = {2022},
}
@article{Iu-2023-ssrn-ChatGPT,
  title={ChatGPT by OpenAI: The End of Litigation Lawyers?},
  author={Kwansai Iu and Vanessa Man-Yi Wong},
  journal={SSRN Electronic Journal},
  year={2023}
}
@article{MaceyDar-2023-ssrn-ChatGPT,
  title={ChatGPT \& Generative AI Systems as Quasi-Expert Legal Advice Lawyers - Case Study Considering Potential Appeal Against Conviction of Tom Hayes},
  author={Rupert Macey-Dare},
  journal={SSRN Electronic Journal},
  year={2023}
}
@article{PettinatoOltz-2023-ssrn-ChatGPT,
  title={ChatGPT, Professor of Law},
  author={Tammy Pettinato Oltz},
  journal={SSRN Electronic Journal},
  year={2023}
}
@article{Haman-2023-air-Using,
  title={Using ChatGPT to conduct a literature review.},
  author={Michael Haman and Milan Skolnik},
  journal={Accountability in research},
  year={2023},
}
@article{Aydn-2022-ssrn-OpenAI,
  title={OpenAI ChatGPT Generated Literature Review: Digital Twin in Healthcare},
  author={{\"O}mer Aydın and Enis Karaarslan},
  journal={SSRN Electronic Journal},
  year={2022}
}
@article{Part-2023-arxiv-Can,
  author       = {Yang Jeong Park and
                  Daniel Kaplan and
                  Zhichu Ren and
                  Chia{-}Wei Hsu and
                  Changhao Li and
                  Haowei Xu and
                  Sipei Li and
                  Ju Li},
  title        = {Can ChatGPT be used to generate scientific hypotheses?},
  journal      = {CoRR},
  volume       = {abs/2304.12208},
  year         = {2023},
}
@article{Chen-2023-arxiv-GenSpectrum,
  author       = {Chaoran Chen and
                  Tanja Stadler},
  title        = {GenSpectrum Chat: Data Exploration in Public Health Using Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2305.13821},
  year         = {2023},
}
@article{Hasaan-2023-arxiv-ChatGPT,
  author       = {Md. Mahadi Hassan and
                  R. Alexander Knipper and
                  Shubhra Kanti Karmaker Santu},
  title        = {ChatGPT as your Personal Data Scientist},
  journal      = {CoRR},
  volume       = {abs/2305.13657},
  year         = {2023},
}
@article{Noever-2023-arxiv-Numeracy,
  author       = {David Noever and
                  Forrest McKee},
  title        = {Numeracy from Literacy: Data Science as an Emergent Skill from Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2301.13382},
  year         = {2023},
}
@article{Cheng-2023-arxiv-Is,
  author       = {Liying Cheng and
                  Xingxuan Li and
                  Lidong Bing},
  title        = {Is {GPT-4} a Good Data Analyst?},
  journal      = {CoRR},
  volume       = {abs/2305.15038},
  year         = {2023},
}
@article{Zhang-2023-arxiv-BiomedGPT,
  author       = {Kai Zhang and
                  Jun Yu and
                  Zhiling Yan and
                  Yixin Liu and
                  Eashan Adhikarla and
                  Sunyang Fu and
                  Xun Chen and
                  Chen Chen and
                  Yuyin Zhou and
                  Xiang Li and
                  Lifang He and
                  Brian D. Davison and
                  Quanzheng Li and
                  Yong Chen and
                  Hongfang Liu and
                  Lichao Sun},
  title        = {BiomedGPT: {A} Unified and Generalist Biomedical Generative Pre-trained
                  Transformer for Vision, Language, and Multimodal Tasks},
  journal      = {CoRR},
  volume       = {abs/2305.17100},
  year         = {2023},
}
@article{Nascimento-2023-arxiv-Do,
  author       = {Cayque Monteiro Castro Nascimento and
                  Andr{\'{e}} Silva Pimentel},
  title        = {Do Large Language Models Understand Chemistry? {A} Conversation with
                  ChatGPT},
  journal      = {J. Chem. Inf. Model.},
  volume       = {63},
  number       = {6},
  pages        = {1649--1655},
  year         = {2023},
}
@article{Jin-2023-arxiv-GeneGPT,
  author       = {Qiao Jin and
                  Yifan Yang and
                  Qingyu Chen and
                  Zhiyong Lu},
  title        = {GeneGPT: Augmenting Large Language Models with Domain Tools for Improved
                  Access to Biomedical Information},
  journal      = {CoRR},
  volume       = {abs/2304.09667},
  year         = {2023},
}
@article{Kashefi-2023-arxiv-ChatGPT,
  author       = {Ali Kashefi and
                  Tapan Mukerji},
  title        = {ChatGPT for Programming Numerical Methods},
  journal      = {CoRR},
  volume       = {abs/2303.12093},
  year         = {2023},
}
@article{Mai-2023-arxiv-On,
  author       = {Gengchen Mai and
                  Weiming Huang and
                  Jin Sun and
                  Suhang Song and
                  Deepak Mishra and
                  Ninghao Liu and
                  Song Gao and
                  Tianming Liu and
                  Gao Cong and
                  Yingjie Hu and
                  Chris Cundy and
                  Ziyuan Li and
                  Rui Zhu and
                  Ni Lao},
  title        = {On the Opportunities and Challenges of Foundation Models for Geospatial
                  Artificial Intelligence},
  journal      = {CoRR},
  volume       = {abs/2304.06798},
  year         = {2023},
}
@article{Azaria-2023-arxiv-ChatGPT,
  title={ChatGPT is a Remarkable Tool -- For Experts},
  author={Amos Azaria and Rina Azoulay and Shulamit Reches},
  journal      = {CoRR},
  volume       = {abs/2306.03102},
  year         = {2023},
}
@article{Liu-2023-arxiv-ReviewerGPT,
  title={ReviewerGPT? An Exploratory Study on Using Large Language Models for Paper Reviewing},
  author={Ryan Liu and Nihar B. Shah},
  journal      = {CoRR},
  volume       = {abs/2306.00622},
  year         = {2023},
}
@article{Sun-2023-arxiv-Automatic,
  author       = {Weisong Sun and
                  Chunrong Fang and
                  Yudu You and
                  Yun Miao and
                  Yi Liu and
                  Yuekang Li and
                  Gelei Deng and
                  Shenghan Huang and
                  Yuchen Chen and
                  Quanjun Zhang and
                  Hanwei Qian and
                  Yang Liu and
                  Zhenyu Chen},
  title        = {Automatic Code Summarization via ChatGPT: How Far Are We?},
  journal      = {CoRR},
  volume       = {abs/2305.12865},
  year         = {2023},
}
@article{Le-2023-arxiv-An,
  title={An Evaluation of Log Parsing with ChatGPT},
  author={Van-Hoang Le and Hongyu Zhang},
   journal      = {CoRR},
  volume       = {abs/2306.01590},
  year         = {2023},
}
@article{Sridhara-2023-arxiv-ChatGPT,
  author       = {Giriprasad Sridhara and
                  Ranjani H. G. and
                  Sourav Mazumdar},
  title        = {ChatGPT: {A} Study on its Utility for Ubiquitous Software Engineering
                  Tasks},
  journal      = {CoRR},
  volume       = {abs/2305.16837},
  year         = {2023},
}
@article{Xia-2023-arxiv-Conversational,
  author       = {Chunqiu Steven Xia and
                  Lingming Zhang},
  title        = {Conversational Automated Program Repair},
  journal      = {CoRR},
  volume       = {abs/2301.13246},
  year         = {2023},
}
@article{Ma-arxiv-2023-The,
  author       = {Wei Ma and
                  Shangqing Liu and
                  Wenhan Wang and
                  Qiang Hu and
                  Ye Liu and
                  Cen Zhang and
                  Liming Nie and
                  Yang Liu},
  title        = {The Scope of ChatGPT in Software Engineering: {A} Thorough Investigation},
  journal      = {CoRR},
  volume       = {abs/2305.12138},
  year         = {2023},
}
@inproceedings{yang-2018-acl-HotpotQA,
  author       = {Zhilin Yang and
                  Peng Qi and
                  Saizheng Zhang and
                  Yoshua Bengio and
                  William W. Cohen and
                  Ruslan Salakhutdinov and
                  Christopher D. Manning},
  title        = {HotpotQA: {A} Dataset for Diverse, Explainable Multi-hop Question
                  Answering},
  booktitle    = {Proceedings of the 2018 Conference on Empirical Methods in Natural
                  Language Processing, Brussels, Belgium, October 31 - November 4, 2018},
  pages        = {2369--2380},
  publisher    = {Association for Computational Linguistics},
  year         = {2018},
}
@article{Zhang-2023-arxiv-Evaluating,
  title={Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning},
  author={Beichen Zhang and Kun Zhou and Xilin Wei and Wayne Xin Zhao and Jing Sha and Shijin Wang and Ji-rong Wen},
  journal      = {CoRR},
  volume       = {abs/2306.02408},
  year         = {2023},
}
@inproceedings{Yao-2022-nips-WebShop,
  author       = {Shunyu Yao and
                  Howard Chen and
                  John Yang and
                  Karthik Narasimhan},
  title        = {WebShop: Towards Scalable Real-World Web Interaction with Grounded
                  Language Agents},
  booktitle    = {NeurIPS},
  year         = {2022},
}
@inproceedings{Shridhar-2021-iclr-ALFWorld,
  author       = {Mohit Shridhar and
                  Xingdi Yuan and
                  Marc{-}Alexandre C{\^{o}}t{\'{e}} and
                  Yonatan Bisk and
                  Adam Trischler and
                  Matthew J. Hausknecht},
  title        = {ALFWorld: Aligning Text and Embodied Environments for Interactive
                  Learning},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  publisher    = {OpenReview.net},
  year         = {2021},
}
@inproceedings{Guss-2019-ijcai-MineRL,
  author       = {William H. Guss and
                  Brandon Houghton and
                  Nicholay Topin and
                  Phillip Wang and
                  Cayden Codel and
                  Manuela Veloso and
                  Ruslan Salakhutdinov},
  editor       = {Sarit Kraus},
  title        = {MineRL: {A} Large-Scale Dataset of Minecraft Demonstrations},
  booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on
                  Artificial Intelligence, {IJCAI} 2019, Macao, China, August 10-16,
                  2019},
  pages        = {2442--2448},
  publisher    = {ijcai.org},
  year         = {2019},
}
@inproceedings{Fan-2022-nips-minedojo,
  author       = {Linxi Fan and
                  Guanzhi Wang and
                  Yunfan Jiang and
                  Ajay Mandlekar and
                  Yuncong Yang and
                  Haoyi Zhu and
                  Andrew Tang and
                  De{-}An Huang and
                  Yuke Zhu and
                  Anima Anandkumar},
  title        = {MineDojo: Building Open-Ended Embodied Agents with Internet-Scale
                  Knowledge},
  booktitle    = {NeurIPS},
  year         = {2022},
}
@inproceedings{Gehman-2023-arxiv-RealToxicityPrompts,
  author       = {Samuel Gehman and
                  Suchin Gururangan and
                  Maarten Sap and
                  Yejin Choi and
                  Noah A. Smith},
  editor       = {Trevor Cohn and
                  Yulan He and
                  Yang Liu},
  title        = {RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language
                  Models},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2020, Online Event, 16-20 November 2020},
  series       = {Findings of {ACL}},
  volume       = {{EMNLP} 2020},
  pages        = {3356--3369},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
}
@article{Lu-2022-arxiv-Dynamic,
  author       = {Pan Lu and
                  Liang Qiu and
                  Kai{-}Wei Chang and
                  Ying Nian Wu and
                  Song{-}Chun Zhu and
                  Tanmay Rajpurohit and
                  Peter Clark and
                  Ashwin Kalyan},
  title        = {Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical
                  Reasoning},
  journal      = {CoRR},
  volume       = {abs/2209.14610},
  year         = {2022},
}
@article{yang-2023-arxiv-GPT4Tools,
  author       = {Rui Yang and
                  Lin Song and
                  Yanwei Li and
                  Sijie Zhao and
                  Yixiao Ge and
                  Xiu Li and
                  Ying Shan},
  title        = {GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction},
  journal      = {CoRR},
  volume       = {abs/2305.18752},
  year         = {2023},
}
@article{Patil-2023-arxiv-Gorilla,
  author       = {Shishir G. Patil and
                  Tianjun Zhang and
                  Xin Wang and
                  Joseph E. Gonzalez},
  title        = {Gorilla: Large Language Model Connected with Massive APIs},
  journal      = {CoRR},
  volume       = {abs/2305.15334},
  year         = {2023},
}
@inproceedings{Yih-2016-acl-The,
  author       = {Wen{-}tau Yih and
                  Matthew Richardson and
                  Christopher Meek and
                  Ming{-}Wei Chang and
                  Jina Suh},
  title        = {The Value of Semantic Parse Labeling for Knowledge Base Question Answering},
  booktitle    = {Proceedings of the 54th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2016, August 7-12, 2016, Berlin, Germany, Volume
                  2: Short Papers},
  publisher    = {The Association for Computer Linguistics},
  year         = {2016},
}
@inproceedings{Puerto-2023-eacl-MetaQA,
  author       = {Haritz Puerto and
                  G{\"{o}}zde G{\"{u}}l Sahin and
                  Iryna Gurevych},
  editor       = {Andreas Vlachos and
                  Isabelle Augenstein},
  title        = {MetaQA: Combining Expert Agents for Multi-Skill Question Answering},
  booktitle    = {Proceedings of the 17th Conference of the European Chapter of the
                  Association for Computational Linguistics, {EACL} 2023, Dubrovnik,
                  Croatia, May 2-6, 2023},
  pages        = {3548--3562},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
}
@inproceedings{Pasupat-2015-acl-Compositional,
  author       = {Panupong Pasupat and
                  Percy Liang},
  title        = {Compositional Semantic Parsing on Semi-Structured Tables},
  booktitle    = {Proceedings of the 53rd Annual Meeting of the Association for Computational
                  Linguistics and the 7th International Joint Conference on Natural
                  Language Processing of the Asian Federation of Natural Language Processing,
                  {ACL} 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers},
  pages        = {1470--1480},
  publisher    = {The Association for Computer Linguistics},
  year         = {2015},
}
@article{Zhang-2017-arxiv-Seq2SQL,
  author       = {Victor Zhong and
                  Caiming Xiong and
                  Richard Socher},
  title        = {Seq2SQL: Generating Structured Queries from Natural Language using
                  Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1709.00103},
  year         = {2017},
}
@inproceedings{Chen-2020-iclr-TabFact,
  author       = {Wenhu Chen and
                  Hongmin Wang and
                  Jianshu Chen and
                  Yunkai Zhang and
                  Hong Wang and
                  Shiyang Li and
                  Xiyou Zhou and
                  William Yang Wang},
  title        = {TabFact: {A} Large-scale Dataset for Table-based Fact Verification},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},
}
@inproceedings{Yu-2018-emnlp-Spider,
  author       = {Tao Yu and
                  Rui Zhang and
                  Kai Yang and
                  Michihiro Yasunaga and
                  Dongxu Wang and
                  Zifan Li and
                  James Ma and
                  Irene Li and
                  Qingning Yao and
                  Shanelle Roman and
                  Zilin Zhang and
                  Dragomir R. Radev},
  editor       = {Ellen Riloff and
                  David Chiang and
                  Julia Hockenmaier and
                  Jun'ichi Tsujii},
  title        = {Spider: {A} Large-Scale Human-Labeled Dataset for Complex and Cross-Domain
                  Semantic Parsing and Text-to-SQL Task},
  booktitle    = {Proceedings of the 2018 Conference on Empirical Methods in Natural
                  Language Processing, Brussels, Belgium, October 31 - November 4, 2018},
  pages        = {3911--3921},
  publisher    = {Association for Computational Linguistics},
  year         = {2018},
}
@article{Bai-2023-arxiv-Benchmarking,
  title={Benchmarking Foundation Models with Language-Model-as-an-Examiner},
  author={Yushi Bai and Jiahao Ying and Yixin Cao and Xin Lv and Yuze He and Xiaozhi Wang and Jifan Yu and Kaisheng Zeng and Yijia Xiao and Haozhe Lyu and Jiayin Zhang and Juanzi Li and Lei Hou},
  journal      = {CoRR},
  volume       = {abs/2306.04181},
  year         = {2023},
}

@article{Li-arxiv-2023-RESDSQL,
  author       = {Haoyang Li and
                  Jing Zhang and
                  Cuiping Li and
                  Hong Chen},
  title        = {{RESDSQL:} Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL},
  journal      = {CoRR},
  volume       = {abs/2302.05965},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2302.05965},
  doi          = {10.48550/arXiv.2302.05965},
  eprinttype    = {arXiv},
  eprint       = {2302.05965}
}

@article{Nguyen-arxiv-2023-Meet,
  author       = {Anh Nguyen and
                  Nikos Karampatziakis and
                  Weizhu Chen},
  title        = {Meet in the Middle: {A} New Pre-training Paradigm},
  journal      = {CoRR},
  volume       = {abs/2303.07295},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.07295},
  doi          = {10.48550/arXiv.2303.07295},
  eprinttype    = {arXiv},
  eprint       = {2303.07295},
  timestamp    = {Thu, 16 Mar 2023 16:04:57 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-07295.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Lightman-2023-arxiv-Let,
  author       = {Hunter Lightman and
                  Vineet Kosaraju and
                  Yura Burda and
                  Harrison Edwards and
                  Bowen Baker and
                  Teddy Lee and
                  Jan Leike and
                  John Schulman and
                  Ilya Sutskever and
                  Karl Cobbe},
  title        = {Let's Verify Step by Step},
  journal      = {CoRR},
  volume       = {abs/2305.20050},
  year         = {2023},
}
@article{Uesate-2023-arxiv-Solving,
  author       = {Jonathan Uesato and
                  Nate Kushman and
                  Ramana Kumar and
                  H. Francis Song and
                  Noah Y. Siegel and
                  Lisa Wang and
                  Antonia Creswell and
                  Geoffrey Irving and
                  Irina Higgins},
  title        = {Solving math word problems with process- and outcome-based feedback},
  journal      = {CoRR},
  volume       = {abs/2211.14275},
  year         = {2022},
}

@article{Zhu-arxiv-2022-Solving,
  title={Solving Math Word Problem via Cooperative Reasoning induced Language Models},
  author={Zhu, Xinyu and Wang, Junjie and Zhang, Lin and Zhang, Yuxiang and Gan, Ruyi and Zhang, Jiaxing and Yang, Yujiu},
  journal={arXiv preprint arXiv:2210.16257},
  year={2022}
}

@inproceedings{Yuan-2022-IUI-Wordcraft,
  title={Wordcraft: story writing with large language models},
  author={Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne},
  booktitle={27th International Conference on Intelligent User Interfaces},
  pages={841--852},
  year={2022}
}

@article{liu-2023-arxiv-LLM-QAT,
      title={LLM-QAT: Data-Free Quantization Aware Training for Large Language Models}, 
      author={Zechun Liu and Barlas Oguz and Changsheng Zhao and Ernie Chang and Pierre Stock and Yashar Mehdad and Yangyang Shi and Raghuraman Krishnamoorthi and Vikas Chandra},
      year={2023},
      eprint={2305.17888},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{Yang-2023-arxiv-FinGPT,
  title={FinGPT: Open-Source Financial Large Language Models},
  author={Hongyang Yang and Xiao-Yang Liu and Christina Dan Wang},
  journal      = {CoRR},
  volume       = {abs/2306.06031},
  year         = {2023},
}


@article{Dettmers-2022-arxiv-case,
  author       = {Tim Dettmers and
                  Luke Zettlemoyer},
  title        = {The case for 4-bit precision: k-bit Inference Scaling Laws},
  journal      = {CoRR},
  volume       = {abs/2212.09720},
  year         = {2022},
}

@inproceedings{Rombach-2022-CVPR-high,
  author       = {Robin Rombach and
                  Andreas Blattmann and
                  Dominik Lorenz and
                  Patrick Esser and
                  Bj{\"{o}}rn Ommer},
  title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages        = {10674--10685},
  year         = {2022},
}

@inproceedings{Webson-2022-NAACL-do,
  author       = {Albert Webson and
                  Ellie Pavlick},
  title        = {Do Prompt-Based Models Really Understand the Meaning of Their Prompts?},
  booktitle    = {Proceedings of the 2022 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL} 2022, Seattle, WA, United States, July 10-15, 2022},
  pages        = {2300--2344},
  year         = {2022},
}

@inproceedings{Lampinen-2022-EMNLP-can,
  author       = {Andrew K. Lampinen and
                  Ishita Dasgupta and
                  Stephanie C. Y. Chan and
                  Kory W. Mathewson and
                  Mh Tessler and
                  Antonia Creswell and
                  James L. McClelland and
                  Jane Wang and
                  Felix Hill},
  title        = {Can language models learn from explanations in context?},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages        = {537--563},
  year         = {2022},
}
@inproceedings{Geva-2021-emnlp-Transformer,
  author       = {Mor Geva and
                  Roei Schuster and
                  Jonathan Berant and
                  Omer Levy},
  editor       = {Marie{-}Francine Moens and
                  Xuanjing Huang and
                  Lucia Specia and
                  Scott Wen{-}tau Yih},
  title        = {Transformer Feed-Forward Layers Are Key-Value Memories},
  booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
                  Republic, 7-11 November, 2021},
  pages        = {5484--5495},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
}
@article{Gu-2023-arxiv-Xiezhi,
  author       = {Zhouhong Gu and
                  Xiaoxuan Zhu and
                  Haoning Ye and
                  Lin Zhang and
                  Jianchen Wang and
                  Sihang Jiang and
                  Zhuozhi Xiong and
                  Zihan Li and
                  Qianyu He and
                  Rui Xu and
                  Wenhao Huang and
                  Weiguo Zheng and
                  Hongwei Feng and
                  Yanghua Xiao},
  title        = {Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge Evaluation},
  journal      = {CoRR},
  volume       = {abs/2306.05783},
  year         = {2023},
}
@article{Kamalov-2023-arxiv-A,
  author       = {Firuz Kamalov and
                  Ikhlaas Gurrib},
  title        = {A New Era of Artificial Intelligence in Education: {A} Multifaceted
                  Revolution},
  journal      = {CoRR},
  volume       = {abs/2305.18303},
  year         = {2023},
}

@article{Johnson-2021-BD-billion,
  author       = {Jeff Johnson and
                  Matthijs Douze and
                  Herv{\'{e}} J{\'{e}}gou},
  title        = {Billion-Scale Similarity Search with GPUs},
  journal      = {{IEEE} Trans. Big Data},
  volume       = {7},
  number       = {3},
  pages        = {535--547},
  year         = {2021},
  url          = {https://doi.org/10.1109/TBDATA.2019.2921572},
  doi          = {10.1109/TBDATA.2019.2921572},
  timestamp    = {Tue, 16 Aug 2022 23:09:18 +0200},
  biburl       = {https://dblp.org/rec/journals/tbd/JohnsonDJ21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Deng-2023-arxiv-Mind2Web,
  author       = {Xiang Deng and
                  Yu Gu and
                  Boyuan Zheng and
                  Shijie Chen and
                  Samuel Stevens and
                  Boshi Wang and
                  Huan Sun and
                  Yu Su},
  title        = {Mind2Web: Towards a Generalist Agent for the Web},
  journal      = {CoRR},
  volume       = {abs/2306.06070},
  year         = {2023},
}

@article{Zhang-2023-arxiv-recommendation,
  author       = {Junjie Zhang and
                  Ruobing Xie and
                  Yupeng Hou and
                  Wayne Xin Zhao and
                  Leyu Lin and
                  Ji{-}Rong Wen},
  title        = {Recommendation as Instruction Following: {A} Large Language Model
                  Empowered Recommendation Approach},
  journal      = {CoRR},
  volume       = {abs/2305.07001},
  year         = {2023},
}

@article{Hou-2023-arxiv-large,
  author       = {Yupeng Hou and
                  Junjie Zhang and
                  Zihan Lin and
                  Hongyu Lu and
                  Ruobing Xie and
                  Julian J. McAuley and
                  Wayne Xin Zhao},
  title        = {Large Language Models are Zero-Shot Rankers for Recommender Systems},
  journal      = {CoRR},
  volume       = {abs/2305.08845},
  year         = {2023},
}
@article{Liu-2023-arxiv-RETA-LLM,
  author       = {Jiongnan Liu and
                  Jiajie Jin and
                  Zihan Wang and
                  Jiehan Cheng and
                  Zhicheng Dou and
                  Ji{-}Rong Wen},
  title        = {{RETA-LLM:} {A} Retrieval-Augmented Large Language Model Toolkit},
  journal      = {CoRR},
  volume       = {abs/2306.05212},
  year         = {2023},
}
@article{Qian-2023-arxiv-WebBrain,
  author       = {Hongjing Qian and
                  Yutao Zhu and
                  Zhicheng Dou and
                  Haoqi Gu and
                  Xinyu Zhang and
                  Zheng Liu and
                  Ruofei Lai and
                  Zhao Cao and
                  Jian{-}Yun Nie and
                  Ji{-}Rong Wen},
  title        = {WebBrain: Learning to Generate Factually Correct Articles for Queries
                  by Grounding on Large Web Corpus},
  journal      = {CoRR},
  volume       = {abs/2304.04358},
  year         = {2023},
}

@inproceedings{Wang-2021-ICDM-Milvus,
  title={Milvus: A Purpose-Built Vector Data Management System},
  author={Wang, Jianguo and Yi, Xiaomeng and Guo, Rentong and Jin, Hai and Xu, Peng and Li, Shengjun and Wang, Xiangyu and Guo, Xiangzhou and Li, Chengming and Xu, Xiaohai and others},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={2614--2627},
  year={2021}
}
@article{Zhou-2023-arxiv-RecurrentGPT,
  author       = {Wangchunshu Zhou and
                  Yuchen Eleanor Jiang and
                  Peng Cui and
                  Tiannan Wang and
                  Zhenxin Xiao and
                  Yifan Hou and
                  Ryan Cotterell and
                  Mrinmaya Sachan},
  title        = {RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text},
  journal      = {CoRR},
  volume       = {abs/2305.13304},
  year         = {2023},
}
@article{Buruk-2023-arxiv-Academic,
  author       = {Oguz 'Oz' Buruk},
  title        = {Academic Writing with {GPT-3.5:} Reflections on Practices, Efficacy
                  and Transparency},
  journal      = {CoRR},
  volume       = {abs/2304.11079},
  year         = {2023},
}

@inproceedings{Mike-ICASSP-2012-Japanese,
  title={Japanese and korean voice search},
  author={Schuster, Mike and Nakajima, Kaisuke},
  booktitle={2012 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5149--5152},
  year={2012},
  organization={IEEE}
}

@article{Falcon40b,
  title={{Falcon-40B}: an open large language model with state-of-the-art performance},
  author={Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme},
  year={2023}
}
@article{Zhou-2023-arxiv-Teaching,
  author       = {Hattie Zhou and
                  Azade Nova and
                  Hugo Larochelle and
                  Aaron C. Courville and
                  Behnam Neyshabur and
                  Hanie Sedghi},
  title        = {Teaching Algorithmic Reasoning via In-context Learning},
  journal      = {CoRR},
  volume       = {abs/2211.09066},
  year         = {2022},
}

@article{Penedo-2023-arxiv-Refinedweb,
  title={The {R}efined{W}eb dataset for {F}alcon {LLM}: outperforming curated corpora with web data, and web data only},
  author={Guilherme Penedo and Quentin Malartic and Daniel Hesslow and Ruxandra Cojocaru and Alessandro Cappelli and Hamza Alobeidli and Baptiste Pannier and Ebtesam Almazrouei and Julien Launay},
  journal={arXiv preprint arXiv:2306.01116},
  eprint={2306.01116},
  eprinttype = {arXiv},
  year={2023}
}

@article{Zheng-2023-arxiv-Judging,
  author       = {Lianmin Zheng and
                  Wei{-}Lin Chiang and
                  Ying Sheng and
                  Siyuan Zhuang and
                  Zhanghao Wu and
                  Yonghao Zhuang and
                  Zi Lin and
                  Zhuohan Li and
                  Dacheng Li and
                  Eric P. Xing and
                  Hao Zhang and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  title        = {Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  journal      = {CoRR},
  volume       = {abs/2306.05685},
  year         = {2023},
}

@misc{Li-2023-github-alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@article{Wang-2023-arxiv-PandaLM,
  author       = {Yidong Wang and
                  Zhuohao Yu and
                  Zhengran Zeng and
                  Linyi Yang and
                  Cunxiang Wang and
                  Hao Chen and
                  Chaoya Jiang and
                  Rui Xie and
                  Jindong Wang and
                  Xing Xie and
                  Wei Ye and
                  Shikun Zhang and
                  Yue Zhang},
  title        = {PandaLM: An Automatic Evaluation Benchmark for {LLM} Instruction Tuning
                  Optimization},
  journal      = {CoRR},
  volume       = {abs/2306.05087},
  year         = {2023},
}

@article{Jain-2023-arxiv-Bring,
  author       = {Neel Jain and
                  Khalid Saifullah and
                  Yuxin Wen and
                  John Kirchenbauer and
                  Manli Shu and
                  Aniruddha Saha and
                  Micah Goldblum and
                  Jonas Geiping and
                  Tom Goldstein},
  title        = {Bring Your Own Data! Self-Supervised Evaluation for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2306.13651},
  year         = {2023},
}

@inproceedings{Shah-2022-EMNLP-When,
  title={When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain},
  author={Shah, Raj and Chawla, Kunal and Eidnani, Dheeraj and Shah, Agam and Du, Wendi and Chava, Sudheer and Raman, Natraj and Smiley, Charese and Chen, Jiaao and Yang, Diyi},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={2322--2335},
  year={2022}
}

@article{Touvron-2023-llama2-arxiv,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{Mukherjee-2023-orca-arxiv,
  title={Orca: Progressive learning from complex explanation traces of gpt-4},
  author={Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
  journal={arXiv preprint arXiv:2306.02707},
  year={2023}
}

@article{Gunasekar-2023-textbooks-arxiv,
  title={Textbooks Are All You Need},
  author={Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others},
  journal={arXiv preprint arXiv:2306.11644},
  year={2023}
}

@misc{Edward-2023-hf-open,
  author = {Edward Beeching and 
            Clémentine Fourrier and 
            Nathan Habib and 
            Sheon Han and
            Nathan Lambert and
            Nazneen Rajani and
            Omar Sanseviero and
            Lewis Tunstall and
            Thomas Wolf},
  title = {Open LLM Leaderboard},
  year = {2023},
  publisher = {Hugging Face},
  howpublished = "\url{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}"
}

@article{Nijkamp-2023-codegen2-arxiv,
  author       = {Erik Nijkamp and
                  Hiroaki Hayashi and
                  Caiming Xiong and
                  Silvio Savarese and
                  Yingbo Zhou},
  title        = {CodeGen2: Lessons for Training LLMs on Programming and Natural Languages},
  journal      = {CoRR},
  volume       = {abs/2305.02309},
  year         = {2023},
}

@article{Zhong-2023-arxiv-MemoryBank,
  author       = {Wanjun Zhong and
                  Lianghong Guo and
                  Qiqi Gao and
                  He Ye and
                  Yanlin Wang},
  title        = {MemoryBank: Enhancing Large Language Models with Long-Term Memory},
  journal      = {CoRR},
  volume       = {abs/2305.10250},
  year         = {2023},
}

@article{Fu-2023-arxiv-Chain,
  author       = {Yao Fu and
                  Litu Ou and
                  Mingyu Chen and
                  Yuhao Wan and
                  Hao Peng and
                  Tushar Khot},
  title        = {Chain-of-Thought Hub: {A} Continuous Effort to Measure Large Language
                  Models' Reasoning Performance},
  journal      = {CoRR},
  volume       = {abs/2305.17306},
  year         = {2023},
}

@article{Ainslie-2023-arxiv-gqa,
  title={GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  author={Ainslie, Joshua and Lee-Thorp, James and de Jong, Michiel and Zemlyanskiy, Yury and Lebr{\'o}n, Federico and Sanghai, Sumit},
  journal={arXiv preprint arXiv:2305.13245},
  year={2023}
}

@article{Dao-2023-arxiv-flashattention2,
  title={FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}

@article{Krell-2021-arxiv-efficient,
  title={Efficient Sequence Packing without Cross-contamination: Accelerating Large Language Models without Impacting Performance},
  author={Krell, Mario Michael and Kosec, Matej and Perez, Sergio P and Fitzgibbon, Andrew},
  journal={arXiv preprint arXiv:2107.02027},
  year={2021}
}

@article{Cao-2023-arxiv-instruction,
  title={Instruction Mining: High-Quality Instruction Data Selection for Large Language Models},
  author={Cao, Yihan and Kang, Yanbin and Sun, Lichao},
  journal={arXiv preprint arXiv:2307.06290},
  year={2023}
}

@article{zheng2023secrets,
  title={Secrets of RLHF in Large Language Models Part I: PPO},
  author={Zheng, Rui and Dou, Shihan and Gao, Songyang and Shen, Wei and Wang, Binghai and Liu, Yan and Jin, Senjie and Liu, Qin and Xiong, Limao and Chen, Lu and others},
  journal={arXiv preprint arXiv:2307.04964},
  year={2023}
}

@misc{2023opencompass,
    title={OpenCompass: A Universal Evaluation Platform for Foundation Models},
    author={OpenCompass Contributors},
    howpublished = {\url{https://github.com/InternLM/OpenCompass}},
    year={2023}
}

@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}

@inproceedings{Fan-2018-ACL-Hierarchical,
  author       = {Angela Fan and
                  Mike Lewis and
                  Yann N. Dauphin},
  title        = {Hierarchical Neural Story Generation},
  booktitle    = {{ACL} {(1)}},
  pages        = {889--898},
  publisher    = {Association for Computational Linguistics},
  year         = {2018}
}

@inproceedings{Holtzman-2020-ICLR-The,
  author       = {Ari Holtzman and
                  Jan Buys and
                  Li Du and
                  Maxwell Forbes and
                  Yejin Choi},
  title        = {The Curious Case of Neural Text Degeneration},
  booktitle    = {{ICLR}},
  year         = {2020}
}

@inproceedings{Su-2022-NIPS-A,
  author       = {Yixuan Su and
                  Tian Lan and
                  Yan Wang and
                  Dani Yogatama and
                  Lingpeng Kong and
                  Nigel Collier},
  title        = {A Contrastive Framework for Neural Text Generation},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@article{Meister-TACL-2023-Locally,
  author       = {Clara Meister and
                  Tiago Pimentel and
                  Gian Wiher and
                  Ryan Cotterell},
  title        = {Locally Typical Sampling},
  journal      = {Trans. Assoc. Comput. Linguistics},
  year         = {2023}
}


@inproceedings{Stern-NIPS-2018-Blockwise,
  author       = {Mitchell Stern and
                  Noam Shazeer and
                  Jakob Uszkoreit},
  title        = {Blockwise Parallel Decoding for Deep Autoregressive Models},
  booktitle    = {NeurIPS},
  year         = {2018}
}

@inproceedings{Yaniv-ICML-2023-Fast,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@article{Wu-arxiv-2016-Google,
  author       = {Yonghui Wu and
                  Mike Schuster and
                  Zhifeng Chen and
                  Quoc V. Le and
                  Mohammad Norouzi and
                  Wolfgang Macherey and
                  Maxim Krikun and
                  Yuan Cao and
                  Qin Gao and
                  Klaus Macherey and
                  Jeff Klingner and
                  Apurva Shah and
                  Melvin Johnson and
                  Xiaobing Liu and
                  Lukasz Kaiser and
                  Stephan Gouws and
                  Yoshikiyo Kato and
                  Taku Kudo and
                  Hideto Kazawa and
                  Keith Stevens and
                  George Kurian and
                  Nishant Patil and
                  Wei Wang and
                  Cliff Young and
                  Jason Smith and
                  Jason Riesa and
                  Alex Rudnick and
                  Oriol Vinyals and
                  Greg Corrado and
                  Macduff Hughes and
                  Jeffrey Dean},
  title        = {Google's Neural Machine Translation System: Bridging the Gap between
                  Human and Machine Translation},
  journal      = {CoRR},
  volume       = {abs/1609.08144},
  year         = {2016}
}

@article{Vijayakumar-arxiv-2016-Diverse,
  author       = {Ashwin K. Vijayakumar and
                  Michael Cogswell and
                  Ramprasaath R. Selvaraju and
                  Qing Sun and
                  Stefan Lee and
                  David J. Crandall and
                  Dhruv Batra},
  title        = {Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence
                  Models},
  journal      = {CoRR},
  volume       = {abs/1610.02424},
  year         = {2016}
}

@inproceedings{Paulus-iclr-2018-A,
  author       = {Romain Paulus and
                  Caiming Xiong and
                  Richard Socher},
  title        = {A Deep Reinforced Model for Abstractive Summarization},
  booktitle    = {{ICLR} (Poster)},
  publisher    = {OpenReview.net},
  year         = {2018}
}

@inproceedings{Hewitt-emnlp-2022-Truncation,
  author       = {John Hewitt and
                  Christopher D. Manning and
                  Percy Liang},
  title        = {Truncation Sampling as Language Model Desmoothing},
  booktitle    = {{EMNLP} (Findings)},
  pages        = {3414--3427},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}

@article{Chen-arxiv-2023-Accelerating,
  author       = {Charlie Chen and
                  Sebastian Borgeaud and
                  Geoffrey Irving and
                  Jean{-}Baptiste Lespiau and
                  Laurent Sifre and
                  John Jumper},
  title        = {Accelerating Large Language Model Decoding with Speculative Sampling},
  journal      = {CoRR},
  volume       = {abs/2302.01318},
  year         = {2023}
}

@misc{GSAI-github-2023-YuLan,
  author = {YuLan-Team},
  title = {YuLan-Chat: An Open-Source Bilingual Chatbot},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/RUC-GSAI/YuLan-Chat}},
}

@book{CMU-book-1977-speech,
  title={Speech Understanding Systems. Summary of Results of the Five-Year Research Effort at Carnegie-Mellon University},
  author={CARNEGIE-MELLON UNIV PITTSBURGH PA DEPT OF COMPUTER SCIENCE},
  year={1977}
}

@article{Corro-arxiv-2023-SkipDecode,
  author       = {Luciano Del Corro and
                  Allie Del Giorno and
                  Sahaj Agarwal and
                  Bin Yu and
                  Ahmed Hassan Awadallah and
                  Subhabrata Mukherjee},
  title        = {SkipDecode: Autoregressive Skip Decoding with Batching and Caching
                  for Efficient {LLM} Inference},
  journal      = {CoRR},
  volume       = {abs/2307.02628},
  year         = {2023}
}


@inproceedings{Murray-WMT-2018-Correcting,
  author       = {Kenton Murray and
                  David Chiang},
  title        = {Correcting Length Bias in Neural Machine Translation},
  booktitle    = {{WMT}},
  pages        = {212--223},
  publisher    = {Association for Computational Linguistics},
  year         = {2018}
}

@inproceedings{Koehn-ACL-2017-Six,
  author       = {Philipp Koehn and
                  Rebecca Knowles},
  title        = {Six Challenges for Neural Machine Translation},
  booktitle    = {NMT@ACL},
  pages        = {28--39},
  publisher    = {Association for Computational Linguistics},
  year         = {2017}
}

@article{Miao-arxiv-2023-SpecInfer,
  author       = {Xupeng Miao and
                  Gabriele Oliaro and
                  Zhihao Zhang and
                  Xinhao Cheng and
                  Zeyu Wang and
                  Rae Ying Yee Wong and
                  Zhuoming Chen and
                  Daiyaan Arfeen and
                  Reyna Abhyankar and
                  Zhihao Jia},
  title        = {SpecInfer: Accelerating Generative {LLM} Serving with Speculative
                  Inference and Token Tree Verification},
  journal      = {CoRR},
  volume       = {abs/2305.09781},
  year         = {2023}
}

@article{Fu-arxiv-2023-Chain,
  author       = {Yao Fu and
                  Litu Ou and
                  Mingyu Chen and
                  Yuhao Wan and
                  Hao Peng and
                  Tushar Khot},
  title        = {Chain-of-Thought Hub: {A} Continuous Effort to Measure Large Language
                  Models' Reasoning Performance},
  journal      = {CoRR},
  volume       = {abs/2305.17306},
  year         = {2023},
}

@article{Yu-arxiv-2023-KoLA,
  author       = {Jifan Yu and
                  Xiaozhi Wang and
                  Shangqing Tu and
                  Shulin Cao and
                  Daniel Zhang{-}li and
                  Xin Lv and
                  Hao Peng and
                  Zijun Yao and
                  Xiaohan Zhang and
                  Hanming Li and
                  Chunyang Li and
                  Zheyuan Zhang and
                  Yushi Bai and
                  Yantao Liu and
                  Amy Xin and
                  Nianyi Lin and
                  Kaifeng Yun and
                  Linlu Gong and
                  Jianhui Chen and
                  Zhili Wu and
                  Yunjia Qi and
                  Weikai Li and
                  Yong Guan and
                  Kaisheng Zeng and
                  Ji Qi and
                  Hailong Jin and
                  Jinxin Liu and
                  Yu Gu and
                  Yuan Yao and
                  Ning Ding and
                  Lei Hou and
                  Zhiyuan Liu and
                  Bin Xu and
                  Jie Tang and
                  Juanzi Li},
  title        = {KoLA: Carefully Benchmarking World Knowledge of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2306.09296},
  year         = {2023},
}
@article{Sawada-arxiv-2023-ARB,
  author       = {Tomohiro Sawada and
                  Daniel Paleka and
                  Alexander Havrilla and
                  Pranav Tadepalli and
                  Paula Vidas and
                  Alexander Kranias and
                  John J. Nay and
                  Kshitij Gupta and
                  Aran Komatsuzaki},
  title        = {{ARB:} Advanced Reasoning Benchmark for Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2307.13692},
  year         = {2023},
}
@article{Peng-arxiv-2023-Revisiting,
  author       = {Yun Peng and
                  Shuqing Li and
                  Wenwei Gu and
                  Yichen Li and
                  Wenxuan Wang and
                  Cuiyun Gao and
                  Michael R. Lyu},
  title        = {Revisiting, Benchmarking and Exploring {API} Recommendation: How Far
                  Are We?},
  journal      = {{IEEE} Trans. Software Eng.},
  volume       = {49},
  number       = {4},
  pages        = {1876--1897},
  year         = {2023},
}
@article{Li-arxiv-2023-API-Bank,
  author       = {Minghao Li and
                  Feifan Song and
                  Bowen Yu and
                  Haiyang Yu and
                  Zhoujun Li and
                  Fei Huang and
                  Yongbin Li},
  title        = {API-Bank: {A} Benchmark for Tool-Augmented LLMs},
  journal      = {CoRR},
  volume       = {abs/2304.08244},
  year         = {2023},
}
@article{Tang-arxiv-2023-ToolAlpaca,
  author       = {Qiaoyu Tang and
                  Ziliang Deng and
                  Hongyu Lin and
                  Xianpei Han and
                  Qiao Liang and
                  Le Sun},
  title        = {ToolAlpaca: Generalized Tool Learning for Language Models with 3000
                  Simulated Cases},
  journal      = {CoRR},
  volume       = {abs/2306.05301},
  year         = {2023},
}
@article{Xu-arxiv-2023-On,
  author       = {Qiantong Xu and
                  Fenglu Hong and
                  Bo Li and
                  Changran Hu and
                  Zhengyu Chen and
                  Jian Zhang},
  title        = {On the Tool Manipulation Capability of Open-source Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2305.16504},
  year         = {2023},
}
@article{Qin-arxiv-2023-ToolLLM,
  author       = {Yujia Qin and
                  Shihao Liang and
                  Yining Ye and
                  Kunlun Zhu and
                  Lan Yan and
                  Yaxi Lu and
                  Yankai Lin and
                  Xin Cong and
                  Xiangru Tang and
                  Bill Qian and
                  Sihan Zhao and
                  Runchu Tian and
                  Ruobing Xie and
                  Jie Zhou and
                  Mark Gerstein and
                  Dahai Li and
                  Zhiyuan Liu and
                  Maosong Sun},
  title        = {ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world
                  APIs},
  journal      = {CoRR},
  volume       = {abs/2307.16789},
  year         = {2023},
}
@article{Liu-arxiv-2023-BOLAA,
  author       = {Zhiwei Liu and
                  Weiran Yao and
                  Jianguo Zhang and
                  Le Xue and
                  Shelby Heinecke and
                  Rithesh Murthy and
                  Yihao Feng and
                  Zeyuan Chen and
                  Juan Carlos Niebles and
                  Devansh Arpit and
                  Ran Xu and
                  Phil Mui and
                  Huan Wang and
                  Caiming Xiong and
                  Silvio Savarese},
  title        = {{BOLAA:} Benchmarking and Orchestrating LLM-augmented Autonomous Agents},
  journal      = {CoRR},
  volume       = {abs/2308.05960},
  year         = {2023},
}
@article{Liu-arxiv-2023-AgentBench,
  author       = {Xiao Liu and
                  Hao Yu and
                  Hanchen Zhang and
                  Yifan Xu and
                  Xuanyu Lei and
                  Hanyu Lai and
                  Yu Gu and
                  Hangliang Ding and
                  Kaiwen Men and
                  Kejuan Yang and
                  Shudan Zhang and
                  Xiang Deng and
                  Aohan Zeng and
                  Zhengxiao Du and
                  Chenhui Zhang and
                  Sheng Shen and
                  Tianjun Zhang and
                  Yu Su and
                  Huan Sun and
                  Minlie Huang and
                  Yuxiao Dong and
                  Jie Tang},
  title        = {AgentBench: Evaluating LLMs as Agents},
  journal      = {CoRR},
  volume       = {abs/2308.03688},
  year         = {2023},
}
@article{Zhu-arxiv-2023-PromptBench,
  author       = {Kaijie Zhu and
                  Jindong Wang and
                  Jiaheng Zhou and
                  Zichen Wang and
                  Hao Chen and
                  Yidong Wang and
                  Linyi Yang and
                  Wei Ye and
                  Neil Zhenqiang Gong and
                  Yue Zhang and
                  Xing Xie},
  title        = {PromptBench: Towards Evaluating the Robustness of Large Language Models
                  on Adversarial Prompts},
  journal      = {CoRR},
  volume       = {abs/2306.04528},
  year         = {2023},
}
@article{Shah-arxiv-2023-FLUE,
  author       = {Raj Sanjay Shah and
                  Kunal Chawla and
                  Dheeraj Eidnani and
                  Agam Shah and
                  Wendi Du and
                  Sudheer Chava and
                  Natraj Raman and
                  Charese Smiley and
                  Jiaao Chen and
                  Diyi Yang},
  title        = {{WHEN} {FLUE} {MEETS} {FLANG:} Benchmarks and Large Pre-trained Language
                  Model for Financial Domain},
  journal      = {CoRR},
  volume       = {abs/2211.00083},
  year         = {2022},
}
@article{Wang-arxiv-2023-SciBench,
  author       = {Xiaoxuan Wang and
                  Ziniu Hu and
                  Pan Lu and
                  Yanqiao Zhu and
                  Jieyu Zhang and
                  Satyen Subramaniam and
                  Arjun R. Loomba and
                  Shichang Zhang and
                  Yizhou Sun and
                  Wei Wang},
  title        = {SciBench: Evaluating College-Level Scientific Problem-Solving Abilities
                  of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2307.10635},
  year         = {2023},
}

@article{Huang-arxiv-2023-TrustGPT,
  author       = {Yue Huang and
                  Qihui Zhang and
                  Philip S. Yu and
                  Lichao Sun},
  title        = {TrustGPT: {A} Benchmark for Trustworthy and Responsible Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2306.11507},
  year         = {2023},
}

@article{Bai-arxiv-2023-Benchmarking,
  author       = {Yushi Bai and
                  Jiahao Ying and
                  Yixin Cao and
                  Xin Lv and
                  Yuze He and
                  Xiaozhi Wang and
                  Jifan Yu and
                  Kaisheng Zeng and
                  Yijia Xiao and
                  Haozhe Lyu and
                  Jiayin Zhang and
                  Juanzi Li and
                  Lei Hou},
  title        = {Benchmarking Foundation Models with Language-Model-as-an-Examiner},
  journal      = {CoRR},
  volume       = {abs/2306.04181},
  year         = {2023},
}

@article{Chan-arixiv-2023-ChatEval,
  author       = {Chi{-}Min Chan and
                  Weize Chen and
                  Yusheng Su and
                  Jianxuan Yu and
                  Wei Xue and
                  Shanghang Zhang and
                  Jie Fu and
                  Zhiyuan Liu},
  title        = {ChatEval: Towards Better LLM-based Evaluators through Multi-Agent
                  Debate},
  journal      = {CoRR},
  volume       = {abs/2308.07201},
  year         = {2023},
}

@inproceedings{Zhou-2023-ICLR-Large,
  author       = {Yongchao Zhou and
                  Andrei Ioan Muresanu and
                  Ziwen Han and
                  Keiran Paster and
                  Silviu Pitis and
                  Harris Chan and
                  Jimmy Ba},
  title        = {Large Language Models are Human-Level Prompt Engineers},
  booktitle    = {Proc. of ICLR},
  year         = {2023},
}

@article{Hao-2022-arxiv-Structured,
  author       = {Yaru Hao and
                  Yutao Sun and
                  Li Dong and
                  Zhixiong Han and
                  Yuxian Gu and
                  Furu Wei},
  title        = {Structured Prompting: Scaling In-Context Learning to 1, 000 Examples},
  journal      = {CoRR},
  year         = {2022},
}

@article{Liu-2023-arxiv-Do_emergent,
  title={Do emergent abilities exist in quantized large language models: An empirical study},
  author={Liu Peiyu and Liu Zikang and Gao Ze-Feng and Gao Dawei and Zhao Wayne Xin and Li Yaliang and Ding Bolin and Wen Ji-Rong},
  journal={arXiv preprint arXiv:2307.08072},
  year={2023}
}


@article{Chang-2023-arxiv-A,
  author       = {Yupeng Chang and
                  Xu Wang and
                  Jindong Wang and
                  Yuan Wu and
                  Kaijie Zhu and
                  Hao Chen and
                  Linyi Yang and
                  Xiaoyuan Yi and
                  Cunxiang Wang and
                  Yidong Wang and
                  Wei Ye and
                  Yue Zhang and
                  Yi Chang and
                  Philip S. Yu and
                  Qiang Yang and
                  Xing Xie},
  title        = {A Survey on Evaluation of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2307.03109},
  year         = {2023},
}

@article{Zhuang-2023-arxiv-Through,
  author       = {Ziyu Zhuang and
                  Qiguang Chen and
                  Longxuan Ma and
                  Mingda Li and
                  Yi Han and
                  Yushan Qian and
                  Haopeng Bai and
                  Zixian Feng and
                  Weinan Zhang and
                  Ting Liu},
  title        = {Through the Lens of Core Competency: Survey on Evaluation of Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2308.07902},
  year         = {2023},
}

@article{Kim-2022-arxiv-Self,
  author       = {Hyuhng Joon Kim and
                  Hyunsoo Cho and
                  Junyeob Kim and
                  Taeuk Kim and
                  Kang Min Yoo and
                  Sang{-}goo Lee},
  title        = {Self-Generated In-Context Learning: Leveraging Auto-regressive Language
                  Models as a Demonstration Generator},
  journal      = {CoRR},
  volume       = {abs/2206.08082},
  year         = {2022},
}
@article{wang-2023-arxiv-easyedit,
  title={EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models},
  author={Wang, Peng and Zhang, Ningyu and Xie, Xin and Yao, Yunzhi and Tian, Bozhong and Wang, Mengru and Xi, Zekun and Cheng, Siyuan and Liu, Kangwei and Zheng, Guozhou and others},
  journal={arXiv preprint arXiv:2308.07269},
  year={2023}
}
@article{yao-2023-arxiv-editing,
  title={Editing Large Language Models: Problems, Methods, and Opportunities},
  author={Yao, Yunzhi and Wang, Peng and Tian, Bozhong and Cheng, Siyuan and Li, Zhoubo and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2305.13172},
  year={2023}
}


@article{Ahmed-ACM-2017-Imitation,
author = {Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
title = {Imitation Learning: A Survey of Learning Methods},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3054912},
doi = {10.1145/3054912},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {21},
numpages = {35},
}

@misc{John-youtube-2023-RLHF,
  title= {Reinforcement Learning from Human Feedback: Progress and Challenges},
  author={John Schulman},
  url={https://www.youtube.com/watch?v=hhiLw5Q_UFg},
  year={2023}
}

@misc{Levine-youtube-2022-Imitate,
  title= {Should I Imitate or Reinforce},
  author={Sergey Levine},
  url={https://www.youtube.com/watch?v=sVPm7zOrBxM},
  year={2022}
}


@article{wang-CoRR-2023-EasyEdit,
  author       = {Peng Wang and
                  Ningyu Zhang and
                  Xin Xie and
                  Yunzhi Yao and
                  Bozhong Tian and
                  Mengru Wang and
                  Zekun Xi and
                  Siyuan Cheng and
                  Kangwei Liu and
                  Guozhou Zheng and
                  Huajun Chen},
  title        = {EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2308.07269},
  year         = {2023},
}

@article{Guha-arxiv-2022-LegalBench,
  title={Legalbench: Prototyping a collaborative benchmark for legal reasoning},
  author={Guha, Neel and Ho, Daniel E and Nyarko, Julian and R{\'e}, Christopher},
  journal      = {CoRR},
  volume       = {abs/2209.06120},
  year={2022}
}

@article{Uesato-arxiv-2022-Solving,
  author       = {Jonathan Uesato and
                  Nate Kushman and
                  Ramana Kumar and
                  H. Francis Song and
                  Noah Y. Siegel and
                  Lisa Wang and
                  Antonia Creswell and
                  Geoffrey Irving and
                  Irina Higgins},
  title        = {Solving math word problems with process- and outcome-based feedback},
  journal      = {CoRR},
  volume       = {abs/2211.14275},
  year         = {2022},
}

@article{Luo-arxiv-2023-WizardMath,
  author       = {Haipeng Luo and
                  Qingfeng Sun and
                  Can Xu and
                  Pu Zhao and
                  Jianguang Lou and
                  Chongyang Tao and
                  Xiubo Geng and
                  Qingwei Lin and
                  Shifeng Chen and
                  Dongmei Zhang},
  title        = {WizardMath: Empowering Mathematical Reasoning for Large Language Models
                  via Reinforced Evol-Instruct},
  journal      = {CoRR},
  volume       = {abs/2308.09583},
  year         = {2023},
}

@article{Fu-arxiv-2023-KwaiYiiMath,
  author       = {Jia{-}Yi Fu and
                  Lei Lin and
                  Xiaoyang Gao and
                  Pengli Liu and
                  Zhengzong Chen and
                  Zhirui Yang and
                  Shengnan Zhang and
                  Xue Zheng and
                  Yan Li and
                  Yuliang Liu and
                  Xucheng Ye and
                  Yiqiao Liao and
                  Chao Liao and
                  Bin Chen and
                  Chengru Song and
                  Junchen Wan and
                  Zijia Lin and
                  Fuzheng Zhang and
                  Zhongyuan Wang and
                  Di Zhang and
                  Kun Gai},
  title        = {KwaiYiiMath: Technical Report},
  journal      = {CoRR},
  volume       = {abs/2310.07488},
  year         = {2023},
}

@article{Lightman-arxiv-2023-let,
  author       = {Hunter Lightman and
                  Vineet Kosaraju and
                  Yura Burda and
                  Harrison Edwards and
                  Bowen Baker and
                  Teddy Lee and
                  Jan Leike and
                  John Schulman and
                  Ilya Sutskever and
                  Karl Cobbe},
  title        = {Let's Verify Step by Step},
  journal      = {CoRR},
  volume       = {abs/2305.20050},
  year         = {2023},
}

@misc{McKenzie-2022-inverse,
    title={The Inverse Scaling Prize},
    url={https://github.com/inverse-scaling/prize},
    author={McKenzie, Ian and Lyzhov, Alexander and Parrish, Alicia and Prabhu, Ameya and Mueller, Aaron and Kim, Najoung and Bowman, Sam and Perez, Ethan},
    year={2022}
}

@article{Henighan-2020-scalinglaw,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}


@article{Muennighoff-arXiv-2023-dataconstrained,
  title={Scaling Data-Constrained Language Models},
  author={Muennighoff, Niklas and Rush, Alexander M and Barak, Boaz and Scao, Teven Le and Piktus, Aleksandra and Tazi, Nouamane and Pyysalo, Sampo and Wolf, Thomas and Raffel, Colin},
  journal={arXiv preprint arXiv:2305.16264},
  year={2023}
}

@misc{Hu-arXiv-2023-unlock,
      title={Unlock Predictable Scaling from Emergent Abilities}, 
      author={Shengding Hu and Xin Liu and Xu Han and Xinrong Zhang and Chaoqun He and Weilin Zhao and Yankai Lin and Ning Ding and Zebin Ou and Guoyang Zeng and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2310.03262},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{Srivastava-arXiv-2023-Beyond,
      title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models}, 
      author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmüller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and César Ferri Ramírez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D. Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Moseguí González and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A. Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martínez-Plumed and Francesca Happé and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germán Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang and Gonzalo Jaimovitch-López and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Shevlin and Hinrich Schütze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fernández Fisac and James B. Simon and James Koppel and James Zheng and James Zou and Jan Kocoń and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and Jörg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh D. Dhole and Kevin Gimpel and Kevin Omondi and Kory Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros Colón and Luke Metz and Lütfi Kerem Şenel and Maarten Bosma and Maarten Sap and Maartje ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramírez Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L. Leavitt and Matthias Hagen and Mátyás Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael A. Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Michał Swędrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan A. Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Miłkowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Raphaël Millière and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan LeBras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Ruslan Salakhutdinov and Ryan Chi and Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel S. Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima and Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven T. Piantadosi and Stuart M. Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsu Hashimoto and Te-Lin Wu and Théo Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Ramasesh and Vinay Uday Prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
      year={2023},
      eprint={2206.04615},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Schaeffer-arXiv-2023-mirage,
  title={Are emergent abilities of Large Language Models a mirage?},
  author={Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2304.15004},
  year={2023}
}

@article{Ma-arxiv-2023-Let,
  author       = {Qianli Ma and
                  Haotian Zhou and
                  Tingkai Liu and
                  Jianbo Yuan and
                  Pengfei Liu and
                  Yang You and
                  Hongxia Yang},
  title        = {Let's reward step by step: Step-Level reward model as the Navigators
                  for Reasoning},
  journal      = {CoRR},
  volume       = {abs/2310.10080},
  year         = {2023},
}

@article{Beltagy-arxiv-2020-longformer,
  author       = {Iz Beltagy and
                  Matthew E. Peters and
                  Arman Cohan},
  title        = {Longformer: The Long-Document Transformer},
  journal      = {CoRR},
  volume       = {abs/2004.05150},
  year         = {2020},

}

@article{wang-arxiv-2020-linformer,
  author       = {Sinong Wang and
                  Belinda Z. Li and
                  Madian Khabsa and
                  Han Fang and
                  Hao Ma},
  title        = {Linformer: Self-Attention with Linear Complexity},
  journal      = {CoRR},
  volume       = {abs/2006.04768},
  year         = {2020},

}

@inproceedings{Rae-ICLR-2020-compressive,
  author       = {Jack W. Rae and
                  Anna Potapenko and
                  Siddhant M. Jayakumar and
                  Chloe Hillier and
                  Timothy P. Lillicrap},
  title        = {Compressive Transformers for Long-Range Sequence Modelling},
  booktitle    = {8th International Conference on Learning Representations, {ICLR} 2020,
                  Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher    = {OpenReview.net},
  year         = {2020},

}

@article{Chen-arxiv-2023-longlora,
  author       = {Yukang Chen and
                  Shengju Qian and
                  Haotian Tang and
                  Xin Lai and
                  Zhijian Liu and
                  Song Han and
                  Jiaya Jia},
  title        = {LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.12307},
  year         = {2023},

}

@article{Zhu-arxiv-2023-PoSE,
  author       = {Dawei Zhu and
                  Nan Yang and
                  Liang Wang and
                  Yifan Song and
                  Wenhao Wu and
                  Furu Wei and
                  Sujian Li},
  title        = {PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise
                  Training},
  journal      = {CoRR},
  volume       = {abs/2309.10400},
  year         = {2023},

}

@inproceedings{Ruoss-ACL-2023-Randomized,
  author       = {Anian Ruoss and
                  Gr{\'{e}}goire Del{\'{e}}tang and
                  Tim Genewein and
                  Jordi Grau{-}Moya and
                  R{\'{o}}bert Csord{\'{a}}s and
                  Mehdi Bennani and
                  Shane Legg and
                  Joel Veness},

  title        = {Randomized Positional Encodings Boost Length Generalization of Transformers},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 2: Short Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {1889--1903},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},

}

@article{kazemnejad-arxiv-2023-impact,
  title={The Impact of Positional Encoding on Length Generalization in Transformers},
  author={Kazemnejad, Amirhossein and Padhi, Inkit and Ramamurthy, Karthikeyan Natesan and Das, Payel and Reddy, Siva},
    journal      = {CoRR},
  volume       = {abs/2305.19466},
  year         = {2023},
}

@inproceedings{vaswani-CAMT-2018-tensor2tensor,
  title={Tensor2Tensor for Neural Machine Translation},
  author={Vaswani, Ashish and Bengio, Samy and Brevdo, Eugene and Chollet, Francois and Gomez, Aidan and Gouws, Stephan and Jones, Llion and Kaiser, {\L}ukasz and Kalchbrenner, Nal and Parmar, Niki and others},
  booktitle={Proceedings of the 13th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track)},
  pages={193--199},
  year={2018}
}
@article{zhang-arxiv-2023-prompting,
  title={Prompting large language model for machine translation: A case study},
  author={Zhang, Biao and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:2301.07069},
  year={2023}
}
@article{wang-arxiv-2023-document,
  title={Document-level machine translation with large language models},
  author={Wang, Longyue and Lyu, Chenyang and Ji, Tianbo and Zhang, Zhirui and Yu, Dian and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2304.02210},
  year={2023}
}
@article{ghazvininejad-arxiv-2023-dictionary,
  title={Dictionary-based phrase-level prompting of large language models for machine translation},
  author={Ghazvininejad, Marjan and Gonen, Hila and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2302.07856},
  year={2023}
}
@article{jiao-arxiv-2023-parrot,
  title={Parrot: Translating during chat using large language models},
  author={Jiao, Wenxiang and Huang, Jen-tse and Wang, Wenxuan and Wang, Xing and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2304.02426},
  year={2023}
}
@article{zhu-arxiv-2023-multilingual,
  title={Multilingual machine translation with large language models: Empirical results and analysis},
  author={Zhu, Wenhao and Liu, Hongyi and Dong, Qingxiu and Xu, Jingjing and Kong, Lingpeng and Chen, Jiajun and Li, Lei and Huang, Shujian},
  journal={arXiv preprint arXiv:2304.04675},
  year={2023}
}

@article{zhou-arxiv-2023-recurrentgpt,
  author       = {Wangchunshu Zhou and
                  Yuchen Eleanor Jiang and
                  Peng Cui and
                  Tiannan Wang and
                  Zhenxin Xiao and
                  Yifan Hou and
                  Ryan Cotterell and
                  Mrinmaya Sachan},
  title        = {RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text},
  journal      = {CoRR},
  volume       = {abs/2305.13304},
  year         = {2023},

}

@article{Xu-arxiv-2023-retrieval,
  author       = {Peng Xu and
                  Wei Ping and
                  Xianchao Wu and
                  Lawrence McAfee and
                  Chen Zhu and
                  Zihan Liu and
                  Sandeep Subramanian and
                  Evelina Bakhturina and
                  Mohammad Shoeybi and
                  Bryan Catanzaro},
  title        = {Retrieval meets Long Context Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2310.03025},
  year         = {2023},
}

@article{Packer-arxiv-2023-MemGPT,
  author       = {Charles Packer and
                  Vivian Fang and
                  Shishir G. Patil and
                  Kevin Lin and
                  Sarah Wooders and
                  Joseph E. Gonzalez},
  title        = {MemGPT: Towards LLMs as Operating Systems},
  journal      = {CoRR},
  volume       = {abs/2310.08560},
  year         = {2023},

}

@article{Chen-arxiv-2023-Walking,
  author       = {Howard Chen and
                  Ramakanth Pasunuru and
                  Jason Weston and
                  Asli Celikyilmaz},
  title        = {Walking Down the Memory Maze: Beyond Context Limit through Interactive
                  Reading},
  journal      = {CoRR},
  volume       = {abs/2310.05029},
  year         = {2023},

}

@article{Peng-arxiv-2023-Yarn,
  author       = {Bowen Peng and
                  Jeffrey Quesnelle and
                  Honglu Fan and
                  Enrico Shippole},
  title        = {YaRN: Efficient Context Window Extension of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.00071},
  year         = {2023},

}
@article{Chen-arxiv-2023-Extending,
  author       = {Shouyuan Chen and
                  Sherman Wong and
                  Liangjian Chen and
                  Yuandong Tian},
  title        = {Extending Context Window of Large Language Models via Positional Interpolation},
  journal      = {CoRR},
  volume       = {abs/2306.15595},
  year         = {2023},
}

@article{Liu-arxiv-2023_scaling,
  author       = {Xiaoran Liu and
                  Hang Yan and
                  Shuo Zhang and
                  Chenxin An and
                  Xipeng Qiu and
                  Dahua Lin},
  title        = {Scaling Laws of RoPE-based Extrapolation},
  journal      = {CoRR},
  volume       = {abs/2310.05209},
  year         = {2023},

}

@inproceedings{Partner-ACL-2023-Parallel,
  author       = {Nir Ratner and
                  Yoav Levine and
                  Yonatan Belinkov and
                  Ori Ram and
                  Inbal Magar and
                  Omri Abend and
                  Ehud Karpas and
                  Amnon Shashua and
                  Kevin Leyton{-}Brown and
                  Yoav Shoham},

  title        = {Parallel Context Windows for Large Language Models},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {6383--6402},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},

}

@article{Han-arxiv-2023-LMinfinite,
  author       = {Chi Han and
                  Qifan Wang and
                  Wenhan Xiong and
                  Yu Chen and
                  Heng Ji and
                  Sinong Wang},
  title        = {LM-Infinite: Simple On-the-Fly Length Generalization for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2308.16137},
  year         = {2023},

}





@article{Xiao-arxiv-2023-Efficient,
  author       = {Guangxuan Xiao and
                  Yuandong Tian and
                  Beidi Chen and
                  Song Han and
                  Mike Lewis},
  title        = {Efficient Streaming Language Models with Attention Sinks},
  journal      = {CoRR},
  volume       = {abs/2309.17453},
  year         = {2023},

}

@inproceedings{Izacard-EACL-2021-Leveraging,
  author       = {Gautier Izacard and
                  Edouard Grave},

  title        = {Leveraging Passage Retrieval with Generative Models for Open Domain
                  Question Answering},
  booktitle    = {Proceedings of the 16th Conference of the European Chapter of the
                  Association for Computational Linguistics: Main Volume, {EACL} 2021,
                  Online, April 19 - 23, 2021},
  pages        = {874--880},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},

}

@inproceedings{Wu-ICLR-2022-Memorizing,
  author       = {Yuhuai Wu and
                  Markus Norman Rabe and
                  DeLesley Hutchins and
                  Christian Szegedy},
  title        = {Memorizing Transformers},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
}

@article{Bertsch-arxiv-2023-Unlimiformer,
  author       = {Amanda Bertsch and
                  Uri Alon and
                  Graham Neubig and
                  Matthew R. Gormley},
  title        = {Unlimiformer: Long-Range Transformers with Unlimited Length Input},
  journal      = {CoRR},
  volume       = {abs/2305.01625},
  year         = {2023},

}

@article{Tworkowski-arxiv-2023-Focused,
  author       = {Szymon Tworkowski and
                  Konrad Staniszewski and
                  Mikolaj Pacek and
                  Yuhuai Wu and
                  Henryk Michalewski and
                  Piotr Milos},
  title        = {Focused Transformer: Contrastive Training for Context Scaling},
  journal      = {CoRR},
  volume       = {abs/2307.03170},
  year         = {2023},

}

@article{Roziere-arxiv-2023-codellama,
  author       = {Baptiste Rozi{\`{e}}re and
                  Jonas Gehring and
                  Fabian Gloeckle and
                  Sten Sootla and
                  Itai Gat and
                  Xiaoqing Ellen Tan and
                  Yossi Adi and
                  Jingyu Liu and
                  Tal Remez and
                  J{\'{e}}r{\'{e}}my Rapin and
                  Artyom Kozhevnikov and
                  Ivan Evtimov and
                  Joanna Bitton and
                  Manish Bhatt and
                  Cristian Canton{-}Ferrer and
                  Aaron Grattafiori and
                  Wenhan Xiong and
                  Alexandre D{\'{e}}fossez and
                  Jade Copet and
                  Faisal Azhar and
                  Hugo Touvron and
                  Louis Martin and
                  Nicolas Usunier and
                  Thomas Scialom and
                  Gabriel Synnaeve},
  title        = {Code Llama: Open Foundation Models for Code},
  journal      = {CoRR},
  volume       = {abs/2308.12950},
  year         = {2023},

}

@article{xiong-arxiv-2023-effective,
  author       = {Wenhan Xiong and
                  Jingyu Liu and
                  Igor Molybog and
                  Hejia Zhang and
                  Prajjwal Bhargava and
                  Rui Hou and
                  Louis Martin and
                  Rashi Rungta and
                  Karthik Abinav Sankararaman and
                  Barlas Oguz and
                  Madian Khabsa and
                  Han Fang and
                  Yashar Mehdad and
                  Sharan Narang and
                  Kshitiz Malik and
                  Angela Fan and
                  Shruti Bhosale and
                  Sergey Edunov and
                  Mike Lewis and
                  Sinong Wang and
                  Hao Ma},
  title        = {Effective Long-Context Scaling of Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2309.16039},
  year         = {2023},

}

@online{su-online-2023-Rerope,
        title={Transformer Upgrade Path: 12, Infinite Extrapolation of ReRoPE?},
        author={Jianlin Su},
        year={2023}
}

@misc{kaiokendev-github-2023-Things,
    title = {{Things I'm learning while training superhot.}},
    author = {kaiokendev},
    year = {2023}
}

@article{Pal-arxiv-2023-giraffe,
  author       = {Arka Pal and
                  Deep Karkhanis and
                  Manley Roberts and
                  Samuel Dooley and
                  Arvind Sundararajan and
                  Siddartha Naidu},
  title        = {Giraffe: Adventures in Expanding Context Lengths in LLMs},
  journal      = {CoRR},
  volume       = {abs/2308.10882},
  year         = {2023},

}

@article{Li-arXiv-2023-Multimodal,
  author       = {Chunyuan Li and
                  Zhe Gan and
                  Zhengyuan Yang and
                  Jianwei Yang and
                  Linjie Li and
                  Lijuan Wang and
                  Jianfeng Gao},
  title        = {Multimodal Foundation Models: From Specialists to General-Purpose
                  Assistants},
  journal      = {CoRR},
  volume       = {abs/2309.10020},
  year         = {2023},
}

@article{Yin-arxiv-2023-survey,
  author       = {Shukang Yin and
                  Chaoyou Fu and
                  Sirui Zhao and
                  Ke Li and
                  Xing Sun and
                  Tong Xu and
                  Enhong Chen},
  title        = {A Survey on Multimodal Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2306.13549},
  year         = {2023},
}

@inproceedings{Alayrac-nips-2022-flamingo,
  author       = {Jean{-}Baptiste Alayrac and
                  Jeff Donahue and
                  Pauline Luc and
                  Antoine Miech and
                  Iain Barr and
                  Yana Hasson and
                  Karel Lenc and
                  Arthur Mensch and
                  Katherine Millican and
                  Malcolm Reynolds and
                  Roman Ring and
                  Eliza Rutherford and
                  Serkan Cabi and
                  Tengda Han and
                  Zhitao Gong and
                  Sina Samangooei and
                  Marianne Monteiro and
                  Jacob L. Menick and
                  Sebastian Borgeaud and
                  Andy Brock and
                  Aida Nematzadeh and
                  Sahand Sharifzadeh and
                  Mikolaj Binkowski and
                  Ricardo Barreira and
                  Oriol Vinyals and
                  Andrew Zisserman and
                  Kar{\'{e}}n Simonyan},
  title        = {Flamingo: a Visual Language Model for Few-Shot Learning},
  booktitle    = {NeurIPS},
  year         = {2022},
}

@inproceedings{Schuhmann-nips-2022-laion5b,
  author       = {Christoph Schuhmann and
                  Romain Beaumont and
                  Richard Vencu and
                  Cade Gordon and
                  Ross Wightman and
                  Mehdi Cherti and
                  Theo Coombes and
                  Aarush Katta and
                  Clayton Mullis and
                  Mitchell Wortsman and
                  Patrick Schramowski and
                  Srivatsa Kundurthy and
                  Katherine Crowson and
                  Ludwig Schmidt and
                  Robert Kaczmarczyk and
                  Jenia Jitsev},
  title        = {{LAION-5B:} An open large-scale dataset for training next generation
                  image-text models},
  booktitle    = {NeurIPS},
  year         = {2022},
}

@inproceedings{Changpinyo-cvpr-2023-conceptual,
  author       = {Soravit Changpinyo and
                  Piyush Sharma and
                  Nan Ding and
                  Radu Soricut},
  title        = {Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize
                  Long-Tail Visual Concepts},
  booktitle    = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
                  2021, virtual, June 19-25, 2021},
  pages        = {3558--3568},
  publisher    = {Computer Vision Foundation / {IEEE}},
  year         = {2021},
}

@article{Bai-arxiv-2023-qwen,
  author       = {Jinze Bai and
                  Shuai Bai and
                  Shusheng Yang and
                  Shijie Wang and
                  Sinan Tan and
                  Peng Wang and
                  Junyang Lin and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {Qwen-VL: {A} Frontier Large Vision-Language Model with Versatile Abilities},
  journal      = {CoRR},
  volume       = {abs/2308.12966},
  year         = {2023},
}

@article{Ye-arxiv-2023-mplug,
  author       = {Qinghao Ye and
                  Haiyang Xu and
                  Guohai Xu and
                  Jiabo Ye and
                  Ming Yan and
                  Yiyang Zhou and
                  Junyang Wang and
                  Anwen Hu and
                  Pengcheng Shi and
                  Yaya Shi and
                  Chenliang Li and
                  Yuanhong Xu and
                  Hehong Chen and
                  Junfeng Tian and
                  Qian Qi and
                  Ji Zhang and
                  Fei Huang},
  title        = {mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality},
  journal      = {CoRR},
  volume       = {abs/2304.14178},
  year         = {2023},
}

@article{Chen-arxiv-2023-shikra,
  author       = {Keqin Chen and
                  Zhao Zhang and
                  Weili Zeng and
                  Richong Zhang and
                  Feng Zhu and
                  Rui Zhao},
  title        = {Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic},
  journal      = {CoRR},
  volume       = {abs/2306.15195},
  year         = {2023},
}

@article{Zhang-arxiv-2023-internlm,
  author       = {Pan Zhang and
                  Xiaoyi Dong and
                  Bin Wang and
                  Yuhang Cao and
                  Chao Xu and
                  Linke Ouyang and
                  Zhiyuan Zhao and
                  Shuangrui Ding and
                  Songyang Zhang and
                  Haodong Duan and
                  Wenwei Zhang and
                  Hang Yan and
                  Xinyue Zhang and
                  Wei Li and
                  Jingwen Li and
                  Kai Chen and
                  Conghui He and
                  Xingcheng Zhang and
                  Yu Qiao and
                  Dahua Lin and
                  Jiaqi Wang},
  title        = {InternLM-XComposer: {A} Vision-Language Large Model for Advanced Text-image
                  Comprehension and Composition},
  journal      = {CoRR},
  volume       = {abs/2309.15112},
  year         = {2023},
}

@article{Liu-arxiv-2023-improved,
  author       = {Haotian Liu and
                  Chunyuan Li and
                  Yuheng Li and
                  Yong Jae Lee},
  title        = {Improved Baselines with Visual Instruction Tuning},
  journal      = {CoRR},
  volume       = {abs/2310.03744},
  year         = {2023},
}

@inproceedings{Anthony-nips-2017-Thinking,
  author       = {Thomas Anthony and
                  Zheng Tian and
                  David Barber},
  title        = {Thinking Fast and Slow with Deep Learning and Tree Search},
  booktitle    = {Advances in Neural Information Processing Systems 30: Annual Conference
                  on Neural Information Processing Systems 2017, December 4-9, 2017,
                  Long Beach, CA, {USA}},
  pages        = {5360--5370},
  year         = {2017},
}

@article{Silver-nat-2017-Mastering,
  author       = {David Silver and
                  Julian Schrittwieser and
                  Karen Simonyan and
                  Ioannis Antonoglou and
                  Aja Huang and
                  Arthur Guez and
                  Thomas Hubert and
                  Lucas Baker and
                  Matthew Lai and
                  Adrian Bolton and
                  Yutian Chen and
                  Timothy P. Lillicrap and
                  Fan Hui and
                  Laurent Sifre and
                  George van den Driessche and
                  Thore Graepel and
                  Demis Hassabis},
  title        = {Mastering the game of Go without human knowledge},
  journal      = {Nat.},
  pages        = {354--359},
  year         = {2017},
}

@article{Li-arxiv-2023-M3IT,
  title={M3IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning},
  author={Li, Lei and Yin, Yuwei and Li, Shicheng and Chen, Liang and Wang, Peiyi and Ren, Shuhuai and Li, Mukai and Yang, Yazheng and Xu, Jingjing and Sun, Xu and others},
  journal={arXiv preprint arXiv:2306.04387},
  year={2023}
}

@misc{Du-arxiv-2023-What,
      title={What Makes for Good Visual Instructions? Synthesizing Complex Visual Reasoning Instructions for Visual Instruction Tuning}, 
      author={Yifan Du and Hangyu Guo and Kun Zhou and Wayne Xin Zhao and Jinpeng Wang and Chuyuan Wang and Mingchen Cai and Ruihua Song and Ji-Rong Wen},
      year={2023},
      eprint={2311.01487},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Zhang-arxiv-2023-LLaVAR,
  title={Llavar: Enhanced visual instruction tuning for text-rich image understanding},
  author={Zhang, Yanzhe and Zhang, Ruiyi and Gu, Jiuxiang and Zhou, Yufan and Lipka, Nedim and Yang, Diyi and Sun, Tong},
  journal={arXiv preprint arXiv:2306.17107},
  year={2023}
}

@inproceedings{Ye-arxiv-2023-mplug-owl2,
  title={mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration},
  author={Qinghao Ye and Haiyang Xu and Jiabo Ye and Ming Yan and Haowei Liu and Qi Qian and Ji Zhang and Fei Huang and Jingren Zhou},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:265050943}
}

@inproceedings{Ren-EMNLP-2021-rocketqav2,
  title={RocketQAv2: A Joint Training Method for Dense Passage Retrieval and Passage Re-ranking},
  author={Ren, Ruiyang and Qu, Yingqi and Liu, Jing and Zhao, Wayne Xin and She, Qiaoqiao and Wu, Hua and Wang, Haifeng and Wen, Ji-Rong},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={2825--2835},
  year={2021}
}

@inproceedings{Ren-ACL-2023-tome,
    title = "{TOME}: A Two-stage Approach for Model-based Retrieval",
    author = "Ren, Ruiyang  and
      Zhao, Wayne Xin  and
      Liu, Jing  and
      Wu, Hua  and
      Wen, Ji-Rong  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2023",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.336",
    pages = "6102--6114",
}

@article{Ma-arxiv-2023-fine,
  title={Fine-Tuning LLaMA for Multi-Stage Text Retrieval},
  author={Ma, Xueguang and Wang, Liang and Yang, Nan and Wei, Furu and Lin, Jimmy},
  journal={arXiv preprint arXiv:2310.08319},
  year={2023}
}

@inproceedings{Tay-NIPS-2022-transformer,
  title={Transformer Memory as a Differentiable Search Index},
  author={Tay, Yi and Tran, Vinh Q and Dehghani, Mostafa and Ni, Jianmo and Bahri, Dara and Mehta, Harsh and Qin, Zhen and Hui, Kai and Zhao, Zhe and Gupta, Jai and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{ziems-arxiv-2023-large,
  title={Large Language Models are Built-in Autoregressive Search Engines},
  author={Ziems, Noah and Yu, Wenhao and Zhang, Zhihan and Jiang, Meng},
  journal={arXiv preprint arXiv:2305.09612},
  year={2023}
}

@article{sun-arxiv-2023-chatgpt,
  title={Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent},
  author={Sun, Weiwei and Yan, Lingyong and Ma, Xinyu and Ren, Pengjie and Yin, Dawei and Ren, Zhaochun},
  journal={arXiv preprint arXiv:2304.09542},
  year={2023}
}

@article{qin-arxiv-2023-large,
  title={Large language models are effective text rankers with pairwise ranking prompting},
  author={Qin, Zhen and Jagerman, Rolf and Hui, Kai and Zhuang, Honglei and Wu, Junru and Shen, Jiaming and Liu, Tianqi and Liu, Jialu and Metzler, Donald and Wang, Xuanhui and others},
  journal={arXiv preprint arXiv:2306.17563},
  year={2023}
}

@article{ma-arxiv-2023-zero,
  title={Zero-Shot Listwise Document Reranking with a Large Language Model},
  author={Ma, Xueguang and Zhang, Xinyu and Pradeep, Ronak and Lin, Jimmy},
  journal={arXiv preprint arXiv:2305.02156},
  year={2023}
}

@article{Zhu-arxiv-2023-large,
  title={Large language models for information retrieval: A survey},
  author={Zhu, Yutao and Yuan, Huaying and Wang, Shuting and Liu, Jiongnan and Liu, Wenhan and Deng, Chenlong and Dou, Zhicheng and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2308.07107},
  year={2023}
}

@inproceedings{Qu-NAACL-2021-rocketqa,
  title={RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering},
  author={Qu, Yingqi and Ding, Yuchen and Liu, Jing and Liu, Kai and Ren, Ruiyang and Zhao, Wayne Xin and Dong, Daxiang and Wu, Hua and Wang, Haifeng},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={5835--5847},
  year={2021}
}

@inproceedings{Dai-ICLR-2023-promptagator,
  title={Promptagator: Few-shot Dense Retrieval From 8 Examples},
  author={Dai, Zhuyun and Zhao, Vincent Y and Ma, Ji and Luan, Yi and Ni, Jianmo and Lu, Jing and Bakalov, Anton and Guu, Kelvin and Hall, Keith and Chang, Ming-Wei},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{peng-arxiv-2023-soft,
  title={Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models},
  author={Peng, Zhiyuan and Wu, Xuyang and Fang, Yi},
  journal={arXiv preprint arXiv:2307.08303},
  year={2023}
}

@inproceedings{Gao-ACL-2023-precise,
    title = "Precise Zero-Shot Dense Retrieval without Relevance Labels",
    author = "Gao, Luyu  and
      Ma, Xueguang  and
      Lin, Jimmy  and
      Callan, Jamie",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2023",
    publisher = "Association for Computational Linguistics",
    pages = "1762--1777",
}

@article{ma-arxiv-2023-pre,
  title={Pre-training with Large Language Model-based Document Expansion for Dense Passage Retrieval},
  author={Ma, Guangyuan and Wu, Xing and Wang, Peng and Lin, Zijia and Hu, Songlin},
  journal={arXiv preprint arXiv:2308.08285},
  year={2023}
}

@article{mao-arxiv-2023-large,
  title={Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search},
  author={Mao, Kelong and Dou, Zhicheng and Chen, Haonan and Mo, Fengran and Qian, Hongjin},
  journal={arXiv preprint arXiv:2303.06573},
  year={2023}
}

@misc{xagent2023,
      title={XAgent: An Autonomous Agent for Complex Task Solving}, 
      author={XAgent Team},
      year={2023},
}

@inproceedings{zhao-cikm-2021-recbole,
  author       = {Wayne Xin Zhao and
                  Shanlei Mu and
                  Yupeng Hou and
                  Zihan Lin and
                  Yushuo Chen and
                  Xingyu Pan and
                  Kaiyuan Li and
                  Yujie Lu and
                  Hui Wang and
                  Changxin Tian and
                  Yingqian Min and
                  Zhichao Feng and
                  Xinyan Fan and
                  Xu Chen and
                  Pengfei Wang and
                  Wendi Ji and
                  Yaliang Li and
                  Xiaoling Wang and
                  Ji{-}Rong Wen},
  editor       = {Gianluca Demartini and
                  Guido Zuccon and
                  J. Shane Culpepper and
                  Zi Huang and
                  Hanghang Tong},
  title        = {RecBole: Towards a Unified, Comprehensive and Efficient Framework
                  for Recommendation Algorithms},
  booktitle    = {{CIKM}},
  pages        = {4653--4664},
  publisher    = {{ACM}},
  year         = {2021}
}

@inproceedings{Zhao-cikm-2022-recbole-2,
  author       = {Wayne Xin Zhao and
                  Yupeng Hou and
                  Xingyu Pan and
                  Chen Yang and
                  Zeyu Zhang and
                  Zihan Lin and
                  Jingsen Zhang and
                  Shuqing Bian and
                  Jiakai Tang and
                  Wenqi Sun and
                  Yushuo Chen and
                  Lanling Xu and
                  Gaowei Zhang and
                  Zhen Tian and
                  Changxin Tian and
                  Shanlei Mu and
                  Xinyan Fan and
                  Xu Chen and
                  Ji{-}Rong Wen},
  editor       = {Mohammad Al Hasan and
                  Li Xiong},
  title        = {RecBole 2.0: Towards a More Up-to-Date Recommendation Library},
  booktitle    = {{CIKM}},
  pages        = {4722--4726},
  publisher    = {{ACM}},
  year         = {2022},
}

@inproceedings{Xu-sigir-2023-towards,
  author       = {Lanling Xu and
                  Zhen Tian and
                  Gaowei Zhang and
                  Junjie Zhang and
                  Lei Wang and
                  Bowen Zheng and
                  Yifan Li and
                  Jiakai Tang and
                  Zeyu Zhang and
                  Yupeng Hou and
                  Xingyu Pan and
                  Wayne Xin Zhao and
                  Xu Chen and
                  Ji{-}Rong Wen},
  editor       = {Hsin{-}Hsi Chen and
                  Wei{-}Jou (Edward) Duh and
                  Hen{-}Hsen Huang and
                  Makoto P. Kato and
                  Josiane Mothe and
                  Barbara Poblete},
  title        = {Towards a More User-Friendly and Easy-to-Use Benchmark Library for
                  Recommender Systems},
  booktitle    = {{SIGIR}},
  pages        = {2837--2847},
  publisher    = {{ACM}},
  year         = {2023},
}


@inproceedings{zhou-cikm-2021-s3rec,
  author       = {Kun Zhou and
                  Hui Wang and
                  Wayne Xin Zhao and
                  Yutao Zhu and
                  Sirui Wang and
                  Fuzheng Zhang and
                  Zhongyuan Wang and
                  Ji{-}Rong Wen},
  editor       = {Mathieu d'Aquin and
                  Stefan Dietze and
                  Claudia Hauff and
                  Edward Curry and
                  Philippe Cudr{\'{e}}{-}Mauroux},
  title        = {S3-Rec: Self-Supervised Learning for Sequential Recommendation with
                  Mutual Information Maximization},
  booktitle    = {{CIKM}},
  pages        = {1893--1902},
  publisher    = {{ACM}},
  year         = {2020},
}

@article{Rendle-arxiv-2012-bpr,
  author       = {Steffen Rendle and
                  Christoph Freudenthaler and
                  Zeno Gantner and
                  Lars Schmidt{-}Thieme},
  title        = {{BPR:} Bayesian Personalized Ranking from Implicit Feedback},
  journal      = {CoRR},
  volume       = {abs/1205.2618},
  year         = {2012},
}

@inproceedings{he-www-2017-neural,
  author       = {Xiangnan He and
                  Lizi Liao and
                  Hanwang Zhang and
                  Liqiang Nie and
                  Xia Hu and
                  Tat{-}Seng Chua},
  editor       = {Rick Barrett and
                  Rick Cummings and
                  Eugene Agichtein and
                  Evgeniy Gabrilovich},
  title        = {Neural Collaborative Filtering},
  booktitle    = {{WWW}},
  pages        = {173--182},
  publisher    = {{ACM}},
  year         = {2017},
}


@inproceedings{hou-kdd-2022-towards,
  author       = {Yupeng Hou and
                  Shanlei Mu and
                  Wayne Xin Zhao and
                  Yaliang Li and
                  Bolin Ding and
                  Ji{-}Rong Wen},
  editor       = {Aidong Zhang and
                  Huzefa Rangwala},
  title        = {Towards Universal Sequence Representation Learning for Recommender
                  Systems},
  booktitle    = {{KDD}},
  pages        = {585--593},
  publisher    = {{ACM}},
  year         = {2022},
}

@article{wang-arxiv-2022-transrec,
  author       = {Jie Wang and
                  Fajie Yuan and
                  Mingyue Cheng and
                  Joemon M. Jose and
                  Chenyun Yu and
                  Beibei Kong and
                  Zhijin Wang and
                  Bo Hu and
                  Zang Li},
  title        = {TransRec: Learning Transferable Recommendation from Mixture-of-Modality
                  Feedback},
  journal      = {CoRR},
  volume       = {abs/2206.06190},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2206.06190},
}

@article{gao-arixv-2023-chat_rec,
  author       = {Yunfan Gao and
                  Tao Sheng and
                  Youlin Xiang and
                  Yun Xiong and
                  Haofen Wang and
                  Jiawei Zhang},
  title        = {Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender
                  System},
  journal      = {CoRR},
  volume       = {abs/2303.14524},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.14524},
  doi          = {10.48550/ARXIV.2303.14524},
  eprinttype    = {arXiv},
  eprint       = {2303.14524},
  timestamp    = {Mon, 04 Sep 2023 20:09:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-14524.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{fan-arxiv-2023-recommender,
  author       = {Wenqi Fan and
                  Zihuai Zhao and
                  Jiatong Li and
                  Yunqing Liu and
                  Xiaowei Mei and
                  Yiqi Wang and
                  Jiliang Tang and
                  Qing Li},
  title        = {Recommender Systems in the Era of Large Language Models (LLMs)},
  journal      = {{CoRR}},
  year         = {2023},
}

@article{lin-arxiv-2023-how,
  author       = {Jianghao Lin and
                  Xinyi Dai and
                  Yunjia Xi and
                  Weiwen Liu and
                  Bo Chen and
                  Xiangyang Li and
                  Chenxu Zhu and
                  Huifeng Guo and
                  Yong Yu and
                  Ruiming Tang and
                  Weinan Zhang},
  title        = {How Can Recommender Systems Benefit from Large Language Models: {A}
                  Survey},
  journal      = {{CoRR}},
  year         = {2023},
}

@article{wu-arixv-2023-a,
  author       = {Likang Wu and
                  Zhi Zheng and
                  Zhaopeng Qiu and
                  Hao Wang and
                  Hongchao Gu and
                  Tingjia Shen and
                  Chuan Qin and
                  Chen Zhu and
                  Hengshu Zhu and
                  Qi Liu and
                  Hui Xiong and
                  Enhong Chen},
  title        = {A Survey on Large Language Models for Recommendation},
  journal      = {{CoRR}},
  year         = {2023},
}

@article{hou-arxiv-2023-large,
  author       = {Yupeng Hou and
                  Junjie Zhang and
                  Zihan Lin and
                  Hongyu Lu and
                  Ruobing Xie and
                  Julian J. McAuley and
                  Wayne Xin Zhao},
  title        = {Large Language Models are Zero-Shot Rankers for Recommender Systems},
  journal      = {{CoRR}},
  year         = {2023},
}

@inproceedings{dai-recsys-2023-uncovering,
  author       = {Sunhao Dai and
                  Ninglu Shao and
                  Haiyuan Zhao and
                  Weijie Yu and
                  Zihua Si and
                  Chen Xu and
                  Zhongxiang Sun and
                  Xiao Zhang and
                  Jun Xu},
  editor       = {Jie Zhang and
                  Li Chen and
                  Shlomo Berkovsky and
                  Min Zhang and
                  Tommaso Di Noia and
                  Justin Basilico and
                  Luiz Pizzato and
                  Yang Song},
  title        = {Uncovering ChatGPT's Capabilities in Recommender Systems},
  booktitle    = {{RecSys}},
  pages        = {1126--1132},
  publisher    = {{ACM}},
  year         = {2023},
}

@inproceedings{bao-recsys-2023-tallrec,
  author       = {Keqin Bao and
                  Jizhi Zhang and
                  Yang Zhang and
                  Wenjie Wang and
                  Fuli Feng and
                  Xiangnan He},
  editor       = {Jie Zhang and
                  Li Chen and
                  Shlomo Berkovsky and
                  Min Zhang and
                  Tommaso Di Noia and
                  Justin Basilico and
                  Luiz Pizzato and
                  Yang Song},
  title        = {TALLRec: An Effective and Efficient Tuning Framework to Align Large
                  Language Model with Recommendation},
  booktitle    = {{RecSys}},
  pages        = {1007--1014},
  publisher    = {{ACM}},
  year         = {2023},
}

@article{xi-arxiv-2023-towards,
  author       = {Yunjia Xi and
                  Weiwen Liu and
                  Jianghao Lin and
                  Jieming Zhu and
                  Bo Chen and
                  Ruiming Tang and
                  Weinan Zhang and
                  Rui Zhang and
                  Yong Yu},
  title        = {Towards Open-World Recommendation with Knowledge Augmentation from
                  Large Language Models},
  journal      = {{CoRR}},
  volume       = {abs/2306.10933},
  year         = {2023},
}

@article{liu-arxiv-2023-a,
  author       = {Qijiong Liu and
                  Nuo Chen and
                  Tetsuya Sakai and
                  Xiao{-}Ming Wu},
  title        = {A First Look at LLM-Powered Generative News Recommendation},
  journal      = {CoRR},
  volume       = {abs/2305.06566},
  year         = {2023},
}

@article{li-arxiv-2023-exploring,
  author       = {Ruyu Li and
                  Wenhao Deng and
                  Yu Cheng and
                  Zheng Yuan and
                  Jiaqi Zhang and
                  Fajie Yuan},
  title        = {Exploring the Upper Limits of Text-Based Collaborative Filtering Using
                  Large Language Models: Discoveries and Insights},
  journal      = {CoRR},
  volume       = {abs/2305.11700},
  year         = {2023},
}

@article{wang-arxiv-2023-a,
  author       = {Lei Wang and
                  Chen Ma and
                  Xueyang Feng and
                  Zeyu Zhang and
                  Hao Yang and
                  Jingsen Zhang and
                  Zhiyuan Chen and
                  Jiakai Tang and
                  Xu Chen and
                  Yankai Lin and
                  Wayne Xin Zhao and
                  Zhewei Wei and
                  Ji{-}Rong Wen},
  title        = {A Survey on Large Language Model based Autonomous Agents},
  journal      = {CoRR},
  volume       = {abs/2308.11432},
  year         = {2023},
}



@article{huang-arxiv-2023-recommender,
  author       = {Xu Huang and
                  Jianxun Lian and
                  Yuxuan Lei and
                  Jing Yao and
                  Defu Lian and
                  Xing Xie},
  title        = {Recommender {AI} Agent: Integrating Large Language Models for Interactive
                  Recommendations},
  journal      = {CoRR},
  volume       = {abs/2308.16505},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.16505},
  doi          = {10.48550/ARXIV.2308.16505},
  eprinttype    = {arXiv},
  eprint       = {2308.16505},
  timestamp    = {Mon, 04 Sep 2023 15:29:24 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2308-16505.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{zhang-arxiv-2023-on,
  author       = {An Zhang and
                  Leheng Sheng and
                  Yuxin Chen and
                  Hao Li and
                  Yang Deng and
                  Xiang Wang and
                  Tat{-}Seng Chua},
  title        = {On Generative Agents in Recommendation},
  journal      = {CoRR},
  volume       = {abs/2310.10108},
  year         = {2023},
}

@article{Hone-arxiv-2023-MetaGPT,
  author       = {Sirui Hong and
                  Xiawu Zheng and
                  Jonathan Chen and
                  Yuheng Cheng and
                  Jinlin Wang and
                  Ceyao Zhang and
                  Zili Wang and
                  Steven Ka Shing Yau and
                  Zijuan Lin and
                  Liyang Zhou and
                  Chenyu Ran and
                  Lingfeng Xiao and
                  Chenglin Wu},
  title        = {MetaGPT: Meta Programming for Multi-Agent Collaborative Framework},
  journal      = {CoRR},
  volume       = {abs/2308.00352},
  year         = {2023},
}

@article{Pham-arxiv-2023-Let,
  author       = {Chau Pham and
                  Boyi Liu and
                  Yingxiang Yang and
                  Zhengyu Chen and
                  Tianyi Liu and
                  Jianbo Yuan and
                  Bryan A. Plummer and
                  Zhaoran Wang and
                  Hongxia Yang},
  title        = {Let Models Speak Ciphers: Multiagent Debate through Embeddings},
  journal      = {CoRR},
  volume       = {abs/2310.06272},
  year         = {2023},
}

@article{Wang-arxiv-2023-RecAgent,
  author       = {Lei Wang and
                  Jingsen Zhang and
                  Xu Chen and
                  Yankai Lin and
                  Ruihua Song and
                  Wayne Xin Zhao and
                  Ji{-}Rong Wen},
  title        = {RecAgent: {A} Novel Simulation Paradigm for Recommender Systems},
  journal      = {CoRR},
  volume       = {abs/2306.02552},
  year         = {2023},
}

@article{Zhang-arxiv-2023-AgentCF,
  author       = {Junjie Zhang and
                  Yupeng Hou and
                  Ruobing Xie and
                  Wenqi Sun and
                  Julian J. McAuley and
                  Wayne Xin Zhao and
                  Leyu Lin and
                  Ji{-}Rong Wen},
  title        = {AgentCF: Collaborative Learning with Autonomous Language Agents for
                  Recommender Systems},
  journal      = {CoRR},
  volume       = {abs/2310.09233},
  year         = {2023},
}

@book{Russell-Pearson-2020-Artificial,
  author       = {Stuart Russell and
                  Peter Norvig},
  title        = {Artificial Intelligence: {A} Modern Approach (4th Edition)},
  publisher    = {Pearson},
  year         = {2020},
  url          = {http://aima.cs.berkeley.edu/},
}

@article{Lake-arxiv-2016-Building,
  author       = {Brenden M. Lake and
                  Tomer D. Ullman and
                  Joshua B. Tenenbaum and
                  Samuel J. Gershman},
  title        = {Building Machines That Learn and Think Like People},
  journal      = {CoRR},
  volume       = {abs/1604.00289},
  year         = {2016},
}

@article{Pan-arxiv-2023-Unifying,
  author       = {Shirui Pan and
                  Linhao Luo and
                  Yufei Wang and
                  Chen Chen and
                  Jiapu Wang and
                  Xindong Wu},
  title        = {Unifying Large Language Models and Knowledge Graphs: {A} Roadmap},
  journal      = {CoRR},
  volume       = {abs/2306.08302},
  year         = {2023},
}

@article{Ji-TNNLS-2020-KGSurvey,
  author       = {Shaoxiong Ji and
                  Shirui Pan and
                  Erik Cambria and
                  Pekka Marttinen and
                  Philip S. Yu},
  title        = {A Survey on Knowledge Graphs: Representation, Acquisition, and Applications},
  journal      = {{IEEE} Trans. Neural Networks Learn. Syst.},
  volume       = {33},
  number       = {2},
  pages        = {494--514},
  year         = {2022},
}

@article{ERNIE3,
  author       = {Yu Sun and
                  Shuohuan Wang and
                  Shikun Feng and
                  Siyu Ding and
                  Chao Pang and
                  Junyuan Shang and
                  Jiaxiang Liu and
                  Xuyi Chen and
                  Yanbin Zhao and
                  Yuxiang Lu and
                  Weixin Liu and
                  Zhihua Wu and
                  Weibao Gong and
                  Jianzhong Liang and
                  Zhizhou Shang and
                  Peng Sun and
                  Wei Liu and
                  Xuan Ouyang and
                  Dianhai Yu and
                  Hao Tian and
                  Hua Wu and
                  Haifeng Wang},
  title        = {{ERNIE} 3.0: Large-scale Knowledge Enhanced Pre-training for Language
                  Understanding and Generation},
  journal      = {CoRR},
  volume       = {abs/2107.02137},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.02137},
}

@inproceedings{Zhang-ACL-19-ERNIE,
  author       = {Zhengyan Zhang and
                  Xu Han and
                  Zhiyuan Liu and
                  Xin Jiang and
                  Maosong Sun and
                  Qun Liu},
  title        = {{ERNIE:} Enhanced Language Representation with Informative Entities},
  booktitle    = {Proceedings of the 57th Conference of the Association for Computational
                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
                  Volume 1: Long Papers},
  pages        = {1441--1451},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
}

@article{Wang-TACL-21-KEPLER,
  author       = {Xiaozhi Wang and
                  Tianyu Gao and
                  Zhaocheng Zhu and
                  Zhengyan Zhang and
                  Zhiyuan Liu and
                  Juanzi Li and
                  Jian Tang},
  title        = {{KEPLER:} {A} Unified Model for Knowledge Embedding and Pre-trained
                  Language Representation},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {9},
  pages        = {176--194},
  year         = {2021},
}

@article{Axelsson-arxiv-23-Using,
  author       = {Agnes Axelsson and
                  Gabriel Skantze},
  title        = {Using Large Language Models for Zero-Shot Natural Language Generation
                  from Knowledge Graphs},
  journal      = {CoRR},
  volume       = {abs/2307.07312},
  year         = {2023},
}

@inproceedings{Zhang-ACL-2022-Subgraph,
  author       = {Jing Zhang and
                  Xiaokang Zhang and
                  Jifan Yu and
                  Jian Tang and
                  Jie Tang and
                  Cuiping Li and
                  Hong Chen},
  title        = {Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question
                  Answering},
  booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
                  May 22-27, 2022},
  pages        = {5773--5784},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
}

@inproceedings{Ke-ACL-21-JointGT,
  author       = {Pei Ke and
                  Haozhe Ji and
                  Yu Ran and
                  Xin Cui and
                  Liwei Wang and
                  Linfeng Song and
                  Xiaoyan Zhu and
                  Minlie Huang},
  title        = {JointGT: Graph-Text Joint Representation Learning for Text Generation
                  from Knowledge Graphs},
  booktitle    = {Findings of the Association for Computational Linguistics: {ACL/IJCNLP}
                  2021, Online Event, August 1-6, 2021},
  series       = {Findings of {ACL}},
  volume       = {{ACL/IJCNLP} 2021},
  pages        = {2526--2538},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
}
@article{Zhong-arxiv-23,
  author       = {Lingfeng Zhong and
                  Jia Wu and
                  Qian Li and
                  Hao Peng and
                  Xindong Wu},
  title        = {A Comprehensive Survey on Automatic Knowledge Graph Construction},
  journal      = {CoRR},
  volume       = {abs/2302.05019},
  year         = {2023},
}
@inproceedings{Heinzerling-ACL-21-Lan,
  author       = {Benjamin Heinzerling and
                  Kentaro Inui},
  title        = {Language Models as Knowledge Bases: On Entity Representations, Storage
                  Capacity, and Paraphrased Queries},
  booktitle    = {Proceedings of the 16th Conference of the European Chapter of the
                  Association for Computational Linguistics: Main Volume, {EACL} 2021,
                  Online, April 19 - 23, 2021},
  pages        = {1772--1791},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
}
@inproceedings{Petroni-EMNLP-19-Language,
  author       = {Fabio Petroni and
                  Tim Rockt{\"{a}}schel and
                  Sebastian Riedel and
                  Patrick S. H. Lewis and
                  Anton Bakhtin and
                  Yuxiang Wu and
                  Alexander H. Miller},
  title        = {Language Models as Knowledge Bases?},
  booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural
                  Language Processing and the 9th International Joint Conference on
                  Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China,
                  November 3-7, 2019},
  pages        = {2463--2473},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
}

@inproceedings{Li-ACL-2023-Contrastive,
  author       = {Xiang Lisa Li and
                  Ari Holtzman and
                  Daniel Fried and
                  Percy Liang and
                  Jason Eisner and
                  Tatsunori Hashimoto and
                  Luke Zettlemoyer and
                  Mike Lewis},
  title        = {Contrastive Decoding: Open-ended Text Generation as Optimization},
  booktitle    = {{ACL} {(1)}},
  pages        = {12286--12312},
  publisher    = {Association for Computational Linguistics},
  year         = {2023}
}

@article{Chuang-arxiv-2023-DoLa,
  author       = {Yung{-}Sung Chuang and
                  Yujia Xie and
                  Hongyin Luo and
                  Yoon Kim and
                  James R. Glass and
                  Pengcheng He},
  title        = {DoLa: Decoding by Contrasting Layers Improves Factuality in Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.03883},
  year         = {2023}
}

@inproceedings{West-NAACL-22-Symbolic,
  author       = {Peter West and
                  Chandra Bhagavatula and
                  Jack Hessel and
                  Jena D. Hwang and
                  Liwei Jiang and
                  Ronan Le Bras and
                  Ximing Lu and
                  Sean Welleck and
                  Yejin Choi},
  title        = {Symbolic Knowledge Distillation: from General Language Models to Commonsense
                  Models},
  booktitle    = {Proceedings of the 2022 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL} 2022, Seattle, WA, United States, July 10-15, 2022},
  pages        = {4602--4625},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
}

@article{Zhu-arxiv-23-LLMs,
  author       = {Yuqi Zhu and
                  Xiaohan Wang and
                  Jing Chen and
                  Shuofei Qiao and
                  Yixin Ou and
                  Yunzhi Yao and
                  Shumin Deng and
                  Huajun Chen and
                  Ningyu Zhang},
  title        = {LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities
                  and Future Opportunities},
  journal      = {CoRR},
  volume       = {abs/2305.13168},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.13168},
}

@inproceedings{Gu-ACL-23-Pangu,
  author       = {Yu Gu and
                  Xiang Deng and
                  Yu Su},
  title        = {Don't Generate, Discriminate: {A} Proposal for Grounding Language
                  Models to Real-World Environments},
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada,
                  July 9-14, 2023},
  pages        = {4928--4949},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
}

@article{Luo-arxiv-23-Reasoning,
  author       = {Linhao Luo and
                  Yuan{-}Fang Li and
                  Gholamreza Haffari and
                  Shirui Pan},
  title        = {Reasoning on Graphs: Faithful and Interpretable Large Language Model
                  Reasoning},
  journal      = {CoRR},
  volume       = {abs/2310.01061},
  year         = {2023},
}

@article{Choi-arxiv-23-KCTs,
  author       = {Sehyun Choi and
                  Tianqing Fang and
                  Zhaowei Wang and
                  Yangqiu Song},
  title        = {{KCTS:} Knowledge-Constrained Tree Search Decoding with Token-Level
                  Hallucination Detection},
  journal      = {CoRR},
  volume       = {abs/2310.09044},
  year         = {2023},
}

@article{Zhang-arxiv-23-Mitigating,
  author       = {Shuo Zhang and
                  Liangming Pan and
                  Junzhou Zhao and
                  William Yang Wang},
  title        = {Mitigating Language Model Hallucination with Interactive Question-Knowledge
                  Alignment},
  journal      = {CoRR},
  volume       = {abs/2305.13669},
  year         = {2023},
}

@article{Wang-arxiv-23-easyedit,
  author       = {Peng Wang and
                  Ningyu Zhang and
                  Xin Xie and
                  Yunzhi Yao and
                  Bozhong Tian and
                  Mengru Wang and
                  Zekun Xi and
                  Siyuan Cheng and
                  Kangwei Liu and
                  Guozhou Zheng and
                  Huajun Chen},
  title        = {EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2308.07269},
  year         = {2023},
}

@article{Yao-arxiv-23-editing,
  author       = {Yunzhi Yao and
                  Peng Wang and
                  Bozhong Tian and
                  Siyuan Cheng and
                  Zhoubo Li and
                  Shumin Deng and
                  Huajun Chen and
                  Ningyu Zhang},
  title        = {Editing Large Language Models: Problems, Methods, and Opportunities},
  journal      = {CoRR},
  volume       = {abs/2305.13172},
  year         = {2023},
}

@inproceedings{Karpinska-arxiv-23-The,
  author       = {Marzena Karpinska and
                  Nader Akoury and
                  Mohit Iyyer},
  editor       = {Marie{-}Francine Moens and
                  Xuanjing Huang and
                  Lucia Specia and
                  Scott Wen{-}tau Yih},
  title        = {The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation},
  booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
                  Republic, 7-11 November, 2021},
  pages        = {1265--1285},
  publisher    = {Association for Computational Linguistics},
  year         = {2021},
}

@article{Peng-23-arxiv-Instruction,
  author       = {Baolin Peng and
                  Chunyuan Li and
                  Pengcheng He and
                  Michel Galley and
                  Jianfeng Gao},
  title        = {Instruction Tuning with {GPT-4}},
  journal      = {CoRR},
  volume       = {abs/2304.03277},
  year         = {2023},
}

@article{Lee-23-arxiv-RLAIF,
  author       = {Harrison Lee and
                  Samrat Phatale and
                  Hassan Mansoor and
                  Kellie Lu and
                  Thomas Mesnard and
                  Colton Bishop and
                  Victor Carbune and
                  Abhinav Rastogi},
  title        = {{RLAIF:} Scaling Reinforcement Learning from Human Feedback with {AI}
                  Feedback},
  journal      = {CoRR},
  volume       = {abs/2309.00267},
  year         = {2023},
}

@article{Wang-23-arxiv-MINT,
  author       = {Xingyao Wang and
                  Zihan Wang and
                  Jiateng Liu and
                  Yangyi Chen and
                  Lifan Yuan and
                  Hao Peng and
                  Heng Ji},
  title        = {{MINT:} Evaluating LLMs in Multi-turn Interaction with Tools and Language
                  Feedback},
  journal      = {CoRR},
  volume       = {abs/2309.10691},
  year         = {2023},
}

@article{Wang-23-arxiv-Shepherd,
  author       = {Tianlu Wang and
                  Ping Yu and
                  Xiaoqing Ellen Tan and
                  Sean O'Brien and
                  Ramakanth Pasunuru and
                  Jane Dwivedi{-}Yu and
                  Olga Golovneva and
                  Luke Zettlemoyer and
                  Maryam Fazel{-}Zarandi and
                  Asli Celikyilmaz},
  title        = {Shepherd: {A} Critic for Language Model Generation},
  journal      = {CoRR},
  volume       = {abs/2308.04592},
  year         = {2023},
}

@article{Cui-23-arxiv-UltraFeedback,
  author       = {Ganqu Cui and
                  Lifan Yuan and
                  Ning Ding and
                  Guanming Yao and
                  Wei Zhu and
                  Yuan Ni and
                  Guotong Xie and
                  Zhiyuan Liu and
                  Maosong Sun},
  title        = {UltraFeedback: Boosting Language Models with High-quality Feedback},
  journal      = {CoRR},
  volume       = {abs/2310.01377},
  year         = {2023},
}

@article{Saha-23-arxiv-Branch,
  author       = {Swarnadeep Saha and
                  Omer Levy and
                  Asli Celikyilmaz and
                  Mohit Bansal and
                  Jason Weston and
                  Xian Li},
  title        = {Branch-Solve-Merge Improves Large Language Model Evaluation and Generation},
  journal      = {CoRR},
  volume       = {abs/2310.15123},
  year         = {2023},
}

@article{Chan-23-arxiv-ChatEval,
  author       = {Chi{-}Min Chan and
                  Weize Chen and
                  Yusheng Su and
                  Jianxuan Yu and
                  Wei Xue and
                  Shanghang Zhang and
                  Jie Fu and
                  Zhiyuan Liu},
  title        = {ChatEval: Towards Better LLM-based Evaluators through Multi-Agent
                  Debate},
  journal      = {CoRR},
  volume       = {abs/2308.07201},
  year         = {2023},
}

@article{Li-23-arxiv-PRD,
  author       = {Ruosen Li and
                  Teerth Patel and
                  Xinya Du},
  title        = {{PRD:} Peer Rank and Discussion Improve Large Language Model based
                  Evaluations},
  journal      = {CoRR},
  volume       = {abs/2307.02762},
  year         = {2023},
}

@article{Zhang-23-arxiv-Wider,
  author       = {Xinghua Zhang and
                  Bowen Yu and
                  Haiyang Yu and
                  Yangyu Lv and
                  Tingwen Liu and
                  Fei Huang and
                  Hongbo Xu and
                  Yongbin Li},
  title        = {Wider and Deeper {LLM} Networks are Fairer {LLM} Evaluators},
  journal      = {CoRR},
  volume       = {abs/2308.01862},
  year         = {2023},
}

@article{Zeng-23-arxiv-Evaluating,
  author       = {Zhiyuan Zeng and
                  Jiatong Yu and
                  Tianyu Gao and
                  Yu Meng and
                  Tanya Goyal and
                  Danqi Chen},
  title        = {Evaluating Large Language Models at Evaluating Instruction Following},
  journal      = {CoRR},
  volume       = {abs/2310.07641},
  year         = {2023},
}

@article{Koo-23-arxiv-Benchmarking,
  author       = {Ryan Koo and
                  Minhwa Lee and
                  Vipul Raheja and
                  Jong Inn Park and
                  Zae Myung Kim and
                  Dongyeop Kang},
  title        = {Benchmarking Cognitive Biases in Large Language Models as Evaluators},
  journal      = {CoRR},
  volume       = {abs/2309.17012},
  year         = {2023},
}

@article{Zhu-23-arxiv-Judge,
  author       = {Lianghui Zhu and
                  Xinggang Wang and
                  Xinlong Wang},
  title        = {JudgeLM: Fine-tuned Large Language Models are Scalable Judges},
  journal      = {CoRR},
  volume       = {abs/2310.17631},
  year         = {2023},
}

@article{West-23-arxiv-The,
  author       = {Peter West and
                  Ximing Lu and
                  Nouha Dziri and
                  Faeze Brahman and
                  Linjie Li and
                  Jena D. Hwang and
                  Liwei Jiang and
                  Jillian Fisher and
                  Abhilasha Ravichander and
                  Khyathi Chandu and
                  Benjamin Newman and
                  Pang Wei Koh and
                  Allyson Ettinger and
                  Yejin Choi},
  title        = {The Generative {AI} Paradox: "What It Can Create, It May Not Understand"},
  journal      = {CoRR},
  volume       = {abs/2311.00059},
  year         = {2023},
}

@article{Huang-23-arixv-Large,
  author       = {Jie Huang and
                  Xinyun Chen and
                  Swaroop Mishra and
                  Huaixiu Steven Zheng and
                  Adams Wei Yu and
                  Xinying Song and
                  Denny Zhou},
  title        = {Large Language Models Cannot Self-Correct Reasoning Yet},
  journal      = {CoRR},
  volume       = {abs/2310.01798},
  year         = {2023},
}

@article{Stechly-23-arxiv-GPT4,
  author       = {Kaya Stechly and
                  Matthew Marquez and
                  Subbarao Kambhampati},
  title        = {{GPT-4} Doesn't Know It's Wrong: An Analysis of Iterative Prompting
                  for Reasoning Problems},
  journal      = {CoRR},
  volume       = {abs/2310.12397},
  year         = {2023},
}

@article{peng-23-arxiv-rwkv,
  title={RWKV: Reinventing RNNs for the Transformer Era},
  author={Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Cao, Huanqi and Cheng, Xin and Chung, Michael and Grella, Matteo and GV, Kranthi Kiran and others},
  journal={arXiv preprint arXiv:2305.13048},
  year={2023}
}

@article{bai-2023-qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{wei-2023-skywork,
  title={Skywork: A More Open Bilingual Foundation Model},
  author={Wei, Tianwen and Zhao, Liang and Zhang, Lichang and Zhu, Bo and Wang, Lijie and Yang, Haihua and Li, Biye and Cheng, Cheng and L{\"u}, Weiwei and Hu, Rui and others},
  journal={arXiv preprint arXiv:2310.19341},
  year={2023}
}
@article{yang-2023-baichuan2,
  title={Baichuan 2: Open large-scale language models},
  author={Yang, Aiyuan and Xiao, Bin and Wang, Bingning and Zhang, Borong and Yin, Chao and Lv, Chenxu and Pan, Da and Wang, Dian and Yan, Dong and Yang, Fan and others},
  journal={arXiv preprint arXiv:2309.10305},
  year={2023}
}

@article{Spector-2023-arxiv-Accelerating,
  author       = {Benjamin Spector and
                  Christopher R{\'{e}}},
  title        = {Accelerating {LLM} Inference with Staged Speculative Decoding},
  journal      = {CoRR},
  volume       = {abs/2308.04623},
  year         = {2023}
}

@inproceedings{Sanh-2022-ICLR-P3,
  author       = {Victor Sanh and
                  Albert Webson and
                  Colin Raffel and
                  Stephen H. Bach and
                  Lintang Sutawika and
                  Zaid Alyafeai and
                  Antoine Chaffin and
                  Arnaud Stiegler and
                  Arun Raja and
                  Manan Dey and
                  M Saiful Bari and
                  Canwen Xu and
                  Urmish Thakker and
                  Shanya Sharma Sharma and
                  Eliza Szczechla and
                  Taewoon Kim and
                  Gunjan Chhablani and
                  Nihal V. Nayak and
                  Debajyoti Datta and
                  Jonathan Chang and
                  Mike Tian{-}Jian Jiang and
                  Han Wang and
                  Matteo Manica and
                  Sheng Shen and
                  Zheng Xin Yong and
                  Harshit Pandey and
                  Rachel Bawden and
                  Thomas Wang and
                  Trishala Neeraj and
                  Jos Rozen and
                  Abheesht Sharma and
                  Andrea Santilli and
                  Thibault F{\'{e}}vry and
                  Jason Alan Fries and
                  Ryan Teehan and
                  Teven Le Scao and
                  Stella Biderman and
                  Leo Gao and
                  Thomas Wolf and
                  Alexander M. Rush},
  title        = {Multitask Prompted Training Enables Zero-Shot Task Generalization},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022}
}

@article{Longpre-2023-arxiv-Flan_v2,
  title={The Flan Collection: Designing Data and Methods for Effective Instruction Tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  journal={arXiv preprint arXiv:2301.13688},
  year={2023}
}

@inproceedings{Mihra-2022-arxiv-NI,
  author       = {Swaroop Mishra and
                  Daniel Khashabi and
                  Chitta Baral and
                  Hannaneh Hajishirzi},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
  booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
                  May 22-27, 2022},
  pages        = {3470--3487},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  
}

@inproceedings{Camburu-2020-ACL-Make,
  author       = {Oana{-}Maria Camburu and
                  Brendan Shillingford and
                  Pasquale Minervini and
                  Thomas Lukasiewicz and
                  Phil Blunsom},
  editor       = {Dan Jurafsky and
                  Joyce Chai and
                  Natalie Schluter and
                  Joel R. Tetreault},
  title        = {Make Up Your Mind! Adversarial Generation of Inconsistent Natural
                  Language Explanations},
  booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages        = {4157--4165},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
  
}

@online{Conover-2023-arxiv-Dolly,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},
    year      = {2023},
}

@inproceedings{kwon-2023-SIGOPS-efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@misc{jiang-2023-arxiv-mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
}

@article{yao-2023-arxiv-dschat,
  title={{DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales}},
  author={Zhewei Yao and Reza Yazdani Aminabadi and Olatunji Ruwase and Samyam Rajbhandari and Xiaoxia Wu and Ammar Ahmad Awan and Jeff Rasley and Minjia Zhang and Conglong Li and Connor Holmes and Zhongzhu Zhou and Michael Wyatt and Molly Smith and Lev Kurilenko and Heyang Qin and Masahiro Tanaka and Shuai Che and Shuaiwen Leon Song and Yuxiong He},
  journal={arXiv preprint arXiv:2308.01320},
  year={2023}
}
@article{Chen-arxiv-2022-Program,
  author       = {Wenhu Chen and
                  Xueguang Ma and
                  Xinyi Wang and
                  William W. Cohen},
  title        = {Program of Thoughts Prompting: Disentangling Computation from Reasoning
                  for Numerical Reasoning Tasks},
  journal      = {CoRR},
  volume       = {abs/2211.12588},
  year         = {2022},
}
@inproceedings{Gao-ICML-2023-PAL,
  author       = {Luyu Gao and
                  Aman Madaan and
                  Shuyan Zhou and
                  Uri Alon and
                  Pengfei Liu and
                  Yiming Yang and
                  Jamie Callan and
                  Graham Neubig},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {{PAL:} Program-aided Language Models},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  year         = {2023},
}
@article{Besta-arxiv-2023-Graph,
  author       = {Maciej Besta and
                  Nils Blach and
                  Ales Kubicek and
                  Robert Gerstenberger and
                  Lukas Gianinazzi and
                  Joanna Gajda and
                  Tomasz Lehmann and
                  Michal Podstawski and
                  Hubert Niewiadomski and
                  Piotr Nyczyk and
                  Torsten Hoefler},
  title        = {Graph of Thoughts: Solving Elaborate Problems with Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2308.09687},
  year         = {2023},
}

@article{Li-arxiv-2023-Self,
  author       = {Xian Li and
                  Ping Yu and
                  Chunting Zhou and
                  Timo Schick and
                  Luke Zettlemoyer and
                  Omer Levy and
                  Jason Weston and
                  Mike Lewis},
  title        = {Self-Alignment with Instruction Backtranslation},
  journal      = {CoRR},
  volume       = {abs/2308.06259},
  year         = {2023}
}

@article{Lei-arxiv-2023-Boosting,
  author       = {Bin Lei and
                  Pei{-}Hung Lin and
                  Chunhua Liao and
                  Caiwen Ding},
  title        = {Boosting Logical Reasoning in Large Language Models through a New
                  Framework: The Graph of Thought},
  journal      = {CoRR},
  volume       = {abs/2308.08614},
  year         = {2023},
}

@article{Long-arxiv-2023-Large,
  author       = {Jieyi Long},
  title        = {Large Language Model Guided Tree-of-Thought},
  journal      = {CoRR},
  volume       = {abs/2305.08291},
  year         = {2023},
}

@article{Chen-arxiv-2023-AlpaGasus,
  author       = {Lichang Chen and
                  Shiyang Li and
                  Jun Yan and
                  Hai Wang and
                  Kalpa Gunaratna and
                  Vikas Yadav and
                  Zheng Tang and
                  Vijay Srinivasan and
                  Tianyi Zhou and
                  Heng Huang and
                  Hongxia Jin},
  title        = {AlpaGasus: Training {A} Better Alpaca with Fewer Data},
  journal      = {CoRR},
  volume       = {abs/2307.08701},
  year         = {2023}
}

@article{Mukherjee-arxiv-2023-Orca,
  author       = {Subhabrata Mukherjee and
                  Arindam Mitra and
                  Ganesh Jawahar and
                  Sahaj Agarwal and
                  Hamid Palangi and
                  Ahmed Hassan Awadallah},
  title        = {Orca: Progressive Learning from Complex Explanation Traces of {GPT-4}},
  journal      = {CoRR},
  volume       = {abs/2306.02707},
  year         = {2023}
}

@article{Mo-arxiv-2023-Tree,
  author       = {Shentong Mo and
                  Miao Xin},
  title        = {Tree of Uncertain Thoughts Reasoning for Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.07694},
  year         = {2023},
}

@article{Yoran-arxiv-2023-Answering,
  author       = {Ori Yoran and
                  Tomer Wolfson and
                  Ben Bogin and
                  Uri Katz and
                  Daniel Deutch and
                  Jonathan Berant},
  title        = {Answering Questions by Meta-Reasoning over Multiple Chains of Thought},
  journal      = {CoRR},
  volume       = {abs/2304.13007},
  year         = {2023},
}

@article{Ling-arxiv-2023-Deductive,
  author       = {Zhan Ling and
                  Yunhao Fang and
                  Xuanlin Li and
                  Zhiao Huang and
                  Mingu Lee and
                  Roland Memisevic and
                  Hao Su},
  title        = {Deductive Verification of Chain-of-Thought Reasoning},
  journal      = {CoRR},
  volume       = {abs/2306.03872},
  year         = {2023},
}

@misc{Li-arxiv-2023-Making,
      title={Making Large Language Models Better Reasoners with Step-Aware Verifier}, 
      author={Yifei Li and Zeqi Lin and Shizhuo Zhang and Qiang Fu and Bei Chen and Jian-Guang Lou and Weizhu Chen},
      year={2023},
      eprint={2206.02336},
      archivePrefix={arXiv},
}

@article{Xue-arxiv-2023-RCOT,
  author       = {Tianci Xue and
                  Ziqi Wang and
                  Zhenhailong Wang and
                  Chi Han and
                  Pengfei Yu and
                  Heng Ji},
  title        = {{RCOT:} Detecting and Rectifying Factual Inconsistency in Reasoning
                  by Reversing Chain-of-Thought},
  journal      = {CoRR},
  volume       = {abs/2305.11499},
  year         = {2023},
}

@misc{Jiang-arxiv-2023-Forward,
      title={Forward-Backward Reasoning in Large Language Models for Mathematical Verification}, 
      author={Weisen Jiang and Han Shi and Longhui Yu and Zhengying Liu and Yu Zhang and Zhenguo Li and James T. Kwok},
      year={2023},
      eprint={2308.07758},
}

@article{Weng-arxiv-2023-Large,
  title={Large language models are better reasoners with self-verification},
  author={Weng, Yixuan and Zhu, Minjun and Xia, Fei and Li, Bin and He, Shizhu and Liu, Kang and Zhao, Jun},
  journal={CoRR, abs/2212.09561},
  year={2023}
}

@article{Hu-arxiv-2023-Chain,
  author       = {Hanxu Hu and
                  Hongyuan Lu and
                  Huajian Zhang and
                  Wai Lam and
                  Yue Zhang},
  title        = {Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models},
  journal      = {CoRR},
  volume       = {abs/2305.10276},
  year         = {2023},
}

@article{Zhao-arxiv-2023-Automatic,
  author       = {Xu Zhao and
                  Yuxi Xie and
                  Kenji Kawaguchi and
                  Junxian He and
                  Qizhe Xie},
  title        = {Automatic Model Selection with Large Language Models for Reasoning},
  journal      = {CoRR},
  volume       = {abs/2305.14333},
  year         = {2023},
}


@article{Wang-arxiv-2023-How,
  author       = {Yizhong Wang and
                  Hamish Ivison and
                  Pradeep Dasigi and
                  Jack Hessel and
                  Tushar Khot and
                  Khyathi Raghavi Chandu and
                  David Wadden and
                  Kelsey MacMillan and
                  Noah A. Smith and
                  Iz Beltagy and
                  Hannaneh Hajishirzi},
  title        = {How Far Can Camels Go? Exploring the State of Instruction Tuning on
                  Open Resources},
  journal      = {CoRR},
  volume       = {abs/2306.04751},
  year         = {2023}
}

@article{Wang-2023-arxiv-OpenChat,
  author       = {Guan Wang and
                  Sijie Cheng and
                  Xianyuan Zhan and
                  Xiangang Li and
                  Sen Song and
                  Yang Liu},
  title        = {OpenChat: Advancing Open-source Language Models with Mixed-Quality
                  Data},
  journal      = {CoRR},
  volume       = {abs/2309.11235},
  year         = {2023}
}

@misc{Nguyen-laion-2023-The,
  author = {Huu Nguyen and Sameer Suri and Ken Tsui and Shahules786 and Together.xyz team and Christoph Schuhmann},
  title = {The OIG dataset},
  year = {2023},
  journal = {LAION},
  howpublished = {\url{https://laion.ai/blog/oig-dataset/}},
}


@misc{ShareGPT,
  author = {Dom Eccleston},
  title = {ShareGPT},
  year = {2023},
  howpublished = {\url{https://sharegpt.com/}},
}

@article{sun2023moss,
  title={MOSS: Training Conversational Language Models from Synthetic Data}, 
  author={Tianxiang Sun and Xiaotian Zhang and Zhengfu He and Peng Li and Qinyuan Cheng and Hang Yan and Xiangyang Liu and Yunfan Shao and Qiong Tang and Xingjian Zhao and Ke Chen and Yining Zheng and Zhejian Zhou and Ruixiao Li and Jun Zhan and Yunhua Zhou and Linyang Li and Xiaogui Yang and Lingling Wu and Zhangyue Yin and Xuanjing Huang and Xipeng Qiu},
  year={2023}
}

@misc{Cheung-2023-Guanaco,
  author = {Joséphus Cheung},
  title = {Guanaco - Generative Universal Assistant for Natural-language Adaptive Context-aware Omnilingual outputs},
  year = {2023},
  howpublished = {\url{https://guanaco-model.github.io/}},
}

@misc{Dao-stanford-2023-Flash,
  author = {Tri Dao and Daniel Haziza and Francisco Massa and Grigory Sizov},
  title = {Flash-Decoding for long-context inference
},
  year = {2023},
  howpublished = {\url{https://crfm.stanford.edu/2023/10/12/flashdecoding.html}},
}


@article{Villalobos-arXiv-2023-runout,
  author       = {Pablo Villalobos and
                  Jaime Sevilla and
                  Lennart Heim and
                  Tamay Besiroglu and
                  Marius Hobbhahn and
                  Anson Ho},
  title        = {Will we run out of data? An analysis of the limits of scaling datasets
                  in Machine Learning},
  journal      = {CoRR},
  volume       = {abs/2211.04325},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.04325},
  doi          = {10.48550/ARXIV.2211.04325},
  eprinttype    = {arXiv},
}



@article{OpenAI-OpenAI-2023-GPT-4v,
  author    = {OpenAI},
  title     = {GPT-4V(ision) System Card},
  journal   = {OpenAI},
  year      = {2023}
}

@article{Wang-arxiv-2023-what,
  author       = {Guangzhi Wang and
                  Yixiao Ge and
                  Xiaohan Ding and
                  Mohan S. Kankanhalli and
                  Ying Shan},
  title        = {What Makes for Good Visual Tokenizers for Large Language Models?},
  journal      = {CoRR},
  volume       = {abs/2305.12223},
  year         = {2023},
}

@article{ding-arxiv-2023-everything,
  title={Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation},
  author={Ding, Ruomeng and Zhang, Chaoyun and Wang, Lu and Xu, Yong and Ma, Minghua and Zhang, Wei and Qin, Si and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2311.04254},
  year={2023}
}


@InProceedings{Ethayarajh-ICLM-2022-Understanding,
  title = 	 {Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author =       {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {5988--6008},
  year = 	 {2022},
}

@article{Dai-arxiv-2023-SafeRLHF,
  title={Safe RLHF: Safe Reinforcement Learning from Human Feedback},
  author={Dai, Josef and Pan, Xuehai and Sun, Ruiyang and Ji, Jiaming and Xu, Xinbo and Liu, Mickel and Wang, Yizhou and Yang, Yaodong},
  journal={arXiv preprint arXiv:2310.12773},
  year={2023}
}

@online{Lambert-2023-StackH4,
  author = {Lambert, Nathan and Tunstall, Lewis and Rajani, Nazneen and Thrush, Tristan},
  title = {HuggingFace H4 Stack Exchange Preference Dataset},
  year = 2023,
  url = {https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences},
}

@online{DeepSpeed-MII,
  title = {DeepSpeed-MII},
  year = 2023,
  url = {https://github.com/microsoft/DeepSpeed-MII},
}

@article{Ren-arxiv-2023-Investigating,
  title={Investigating the factual knowledge boundary of large language models with retrieval augmentation},
  author={Ren, Ruiyang and Wang, Yuhao and Qu, Yingqi and Zhao, Wayne Xin and Liu, Jing and Tian, Hao and Wu, Hua and Wen, Ji-Rong and Wang, Haifeng},
  journal={arXiv preprint arXiv:2307.11019},
  year={2023}
}

@article{Zhu-arxiv-2023-Collaborative,
  title={Collaborative Large Language Model for Recommender Systems},
  author={Zhu, Yaochen and Wu, Liang and Guo, Qi and Hong, Liangjie and Li, Jundong},
  journal={arXiv preprint arXiv:2311.01343},
  year={2023}
}

@inproceedings{Zheng-2023-arxiv-Adapting,
  title={Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation},
  author={Bowen Zheng and Yupeng Hou and Hongyu Lu and Yu Chen and Wayne Xin Zhao and Ji-Rong Wen},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:265213194}
}

@article{Zhai-2023-arxiv-Investigating,
  title={Investigating the catastrophic forgetting in multimodal large language models},
  author={Zhai, Yuexiang and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
  journal={arXiv preprint arXiv:2309.10313},
  year={2023}
}

@inproceedings{Qi-2023-NAML-Visual,
  title={Visual adversarial examples jailbreak aligned large language models},
  author={Qi, Xiangyu and Huang, Kaixuan and Panda, Ashwinee and Wang, Mengdi and Mittal, Prateek},
  booktitle={The Second Workshop on New Frontiers in Adversarial Machine Learning},
  year={2023}
}

@article{Cho-ACL-2023-Discrete,
  title={Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker},
  author={Cho, Sukmin and Jeong, Soyeong and Seo, Jeongyeon and Park, Jong C},
  journal={arXiv preprint arXiv:2305.13729},
  year={2023}
}

@inproceedings{Ren-ACL-2021-PAIR,
  title={PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval},
  author={Ren, Ruiyang and Lv, Shangwen and Qu, Yingqi and Liu, Jing and Zhao, Wayne Xin and She, Qiaoqiao and Wu, Hua and Wang, Haifeng and Wen, Ji-Rong},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={2173--2183},
  year={2021}
}

@article{Sel-arxiv-2023-Algorithm,
  author       = {Bilgehan Sel and
                  Ahmad Al{-}Tawaha and
                  Vanshaj Khattar and
                  Lu Wang and
                  Ruoxi Jia and
                  Ming Jin},
  title        = {Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2308.10379},
  year         = {2023},
}

@inproceedings{Ruiz-arxiv-2023-SemTab,
  author       = {Ernesto Jim{\'{e}}nez{-}Ruiz and
                  Oktie Hassanzadeh and
                  Vasilis Efthymiou and
                  Jiaoyan Chen and
                  Kavitha Srinivas},
  title        = {SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph
                  Matching Systems},
  booktitle    = {The Semantic Web - 17th International Conference, {ESWC} 2020, Heraklion,
                  Crete, Greece, May 31-June 4, 2020, Proceedings},
  series       = {Lecture Notes in Computer Science},
  volume       = {12123},
  pages        = {514--530},
  publisher    = {Springer},
  year         = {2020},
}

@article{Guo-arxiv-2023-Beyond,
  title={Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment},
  author={Guo, Geyang and Zhao, Ranchi and Tang, Tianyi and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2311.04072},
  year={2023}
}

@article{Wang-arxiv-2023-Resolving,
  author       = {Yike Wang and
                  Shangbin Feng and
                  Heng Wang and
                  Weijia Shi and
                  Vidhisha Balachandran and
                  Tianxing He and
                  Yulia Tsvetkov},
  title        = {Resolving Knowledge Conflicts in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2310.00935},
  year         = {2023},
}

@article{Agarwal-arxiv-2020-Large,
  author       = {Oshin Agarwal and
                  Heming Ge and
                  Siamak Shakeri and
                  Rami Al{-}Rfou},
  title        = {Large Scale Knowledge Graph Based Synthetic Corpus Generation for
                  Knowledge-Enhanced Language Model Pre-training},
  journal      = {CoRR},
  volume       = {abs/2010.12688},
  year         = {2020},
}

@inproceedings{Chen-EMNLP-2020-KGPT,
  author       = {Wenhu Chen and
                  Yu Su and
                  Xifeng Yan and
                  William Yang Wang},
  title        = {{KGPT:} Knowledge-Grounded Pre-Training for Data-to-Text Generation},
  booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages        = {8635--8648},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
}

@article{Wang-arxiv-2023-query2doc,
  title={Query2doc: Query Expansion with Large Language Models},
  author={Wang, Liang and Yang, Nan and Wei, Furu},
  journal={arXiv preprint arXiv:2303.07678},
  year={2023}
}

@article{Gao-arxiv-2023-Leveraging,
  author       = {Yanjun Gao and
                  Ruizhe Li and
                  John R. Caskey and
                  Dmitriy Dligach and
                  Timothy A. Miller and
                  Matthew M. Churpek and
                  Majid Afshar},
  title        = {Leveraging {A} Medical Knowledge Graph into Large Language Models
                  for Diagnosis Prediction},
  journal      = {CoRR},
  volume       = {abs/2308.14321},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.14321},
}

@inproceedings{Cheng-CEUR-2022-Democratizing,
  author       = {Zehua Cheng and
                  Lianlong Wu and
                  Thomas Lukasiewicz and
                  Emanuel Sallinger and
                  Georg Gottlob},
  title        = {Democratizing Financial Knowledge Graph Construction by Mining Massive
                  Brokerage Research Reports},
  booktitle    = {Proceedings of the Workshops of the {EDBT/ICDT} 2022 Joint Conference,
                  Edinburgh, UK, March 29, 2022},
  series       = {{CEUR} Workshop Proceedings},
  volume       = {3135},
  publisher    = {CEUR-WS.org},
  year         = {2022},
}


@article{Li-arxiv-2023-ctrl,
  title={CTRL: Connect Tabular and Language Model for CTR Prediction},
  author={Li, Xiangyang and Chen, Bo and Hou, Lu and Tang, Ruiming},
  journal={arXiv preprint arXiv:2306.02841},
  year={2023}
}


@article{zhang-arxiv-2023-briding,
  author       = {Wenxuan Zhang and
                  Hongzhi Liu and
                  Yingpeng Du and
                  Chen Zhu and
                  Yang Song and
                  Hengshu Zhu and
                  Zhonghai Wu},
  title        = {Bridging the Information Gap Between Domain-Specific Model and General
                  {LLM} for Personalized Recommendation},
  journal      = {CoRR},
  volume       = {abs/2311.03778},
  year         = {2023},
}

@inproceedings{Muhamed-nips-2021-ctr-bert,
  title={CTR-BERT: Cost-effective knowledge distillation for billion-parameter teacher models},
  author={Muhamed, Aashiq and Keivanloo, Iman and Perera, Sujan and Mracek, James and Xu, Yi and Cui, Qingjun and Rajagopalan, Santosh and Zeng, Belinda and Chilimbi, Trishul},
  booktitle={NeurIPS Efficient Natural Language and Speech Processing Workshop},
  year={2021}
}


@article{Wei-arixiv-2023-llmrec,
  author       = {Wei Wei and
                  Xubin Ren and
                  Jiabin Tang and
                  Qinyong Wang and
                  Lixin Su and
                  Suqi Cheng and
                  Junfeng Wang and
                  Dawei Yin and
                  Chao Huang},
  title        = {LLMRec: Large Language Models with Graph Augmentation for Recommendation},
  journal      = {CoRR},
  volume       = {abs/2311.00423},
  year         = {2023},
}


@article{Liu-arxiv-2023-is,
  author       = {Junling Liu and
                  Chao Liu and
                  Renjie Lv and
                  Kang Zhou and
                  Yan Zhang},
  title        = {Is ChatGPT a Good Recommender? {A} Preliminary Study},
  journal      = {CoRR},
  volume       = {abs/2304.10149},
  year         = {2023},
}


@article{Gao-arxiv-2023-chat-rec,
  author       = {Yunfan Gao and
                  Tao Sheng and
                  Youlin Xiang and
                  Yun Xiong and
                  Haofen Wang and
                  Jiawei Zhang},
  title        = {Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender
                  System},
  journal      = {CoRR},
  volume       = {abs/2303.14524},
  year         = {2023},
}



@article{Lin-2023-arxiv-ClickPrompt,
  author       = {Jianghao Lin and
                  Bo Chen and
                  Hangyu Wang and
                  Yunjia Xi and
                  Yanru Qu and
                  Xinyi Dai and
                  Kangning Zhang and
                  Ruiming Tang and
                  Yong Yu and
                  Weinan Zhang},
  title        = {ClickPrompt: {CTR} Models are Strong Prompt Generators for Adapting
                  Language Models to {CTR} Prediction},
  journal      = {CoRR},
  volume       = {abs/2310.09234},
  year         = {2023},
}

@misc{Xu-2023-arxiv-CValues,
      title={CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility}, 
      author={Guohai Xu and Jiayi Liu and Ming Yan and Haotian Xu and Jinghui Si and Zhuoran Zhou and Peng Yi and Xing Gao and Jitao Sang and Rong Zhang and Ji Zhang and Chao Peng and Fei Huang and Jingren Zhou},
      year={2023},
      eprint={2307.09705},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Lan-2020-ACL-Query,
  author       = {Yunshi Lan and
                  Jing Jiang},
  editor       = {Dan Jurafsky and},
  title        = {Query Graph Generation for Answering Multi-hop Complex Questions from
                  Knowledge Bases},
  booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational
                  Linguistics, {ACL} 2020, Online, July 5-10, 2020},
  pages        = {969--974},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
}

@article{Liu-arxiv-2023-Lost,
  author       = {Nelson F. Liu and
                  Kevin Lin and
                  John Hewitt and
                  Ashwin Paranjape and
                  Michele Bevilacqua and
                  Fabio Petroni and
                  Percy Liang},
  title        = {Lost in the Middle: How Language Models Use Long Contexts},
  journal      = {CoRR},
  volume       = {abs/2307.03172},
  year         = {2023},
}


@article{zhou-arxiv-2023-dont,
  title={Don't Make Your LLM an Evaluation Benchmark Cheater},
  author={Zhou, Kun and Zhu, Yutao and Chen, Zhipeng and Chen, Wentong and Zhao, Wayne Xin and Chen, Xu and Lin, Yankai and Wen, Ji-Rong and Han, Jiawei},
  journal={arXiv preprint arXiv:2311.01964},
  year={2023}
}



@article{Power-arxiv-2022-grokking,
  title={Grokking: Generalization beyond overfitting on small algorithmic datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
  journal={arXiv preprint arXiv:2201.02177},
  year={2022}
}


@article{Ie-arxiv-2019-recsim,
  author       = {Eugene Ie and
                  Chih{-}Wei Hsu and
                  Martin Mladenov and
                  Vihan Jain and
                  Sanmit Narvekar and
                  Jing Wang and
                  Rui Wu and
                  Craig Boutilier},
  title        = {RecSim: {A} Configurable Simulation Platform for Recommender Systems},
  journal      = {CoRR},
  volume       = {abs/1909.04847},
  year         = {2019},
}

@inproceedings{Sheng-ICML-2023-FlexGen,
  author       = {Ying Sheng and
                  Lianmin Zheng and
                  Binhang Yuan and
                  Zhuohan Li and
                  Max Ryabinin and
                  Beidi Chen and
                  Percy Liang and
                  Christopher R{\'{e}} and
                  Ion Stoica and
                  Ce Zhang},
  title        = {FlexGen: High-Throughput Generative Inference of Large Language Models
                  with a Single {GPU}},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {31094--31116},
  publisher    = {{PMLR}},
  year         = {2023}
}

@article{Dong-arxiv-2023-BAMBOO,
  author       = {Zican Dong and
                  Tianyi Tang and
                  Junyi Li and
                  Wayne Xin Zhao and
                  Ji{-}Rong Wen},
  title        = {{BAMBOO:} {A} Comprehensive Benchmark for Evaluating Long Text Modeling
                  Capacities of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.13345},
  year         = {2023},

}

@article{Sun-arxiv-2023-Aligning,
  title={Aligning large multimodal models with factually augmented rlhf},
  author={Sun, Zhiqing and Shen, Sheng and Cao, Shengcao and Liu, Haotian and Li, Chunyuan and Shen, Yikang and Gan, Chuang and Gui, Liang-Yan and Wang, Yu-Xiong and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2309.14525},
  year={2023}
}

@inproceedings{Du-arxiv-2023-survey,
  author       = {Yifan Du and
                  Zikang Liu and
                  Junyi Li and
                  Wayne Xin Zhao},
  editor       = {Luc De Raedt},
  title        = {A Survey of Vision-Language Pre-Trained Models},
  booktitle    = {Proceedings of the Thirty-First International Joint Conference on
                  Artificial Intelligence, {IJCAI} 2022, Vienna, Austria, 23-29 July
                  2022},
  pages        = {5436--5443},
  publisher    = {ijcai.org},
  year         = {2022},
}

@article{Gan-Foundation-2022-vision,
  author       = {Zhe Gan and
                  Linjie Li and
                  Chunyuan Li and
                  Lijuan Wang and
                  Zicheng Liu and
                  Jianfeng Gao},
  title        = {Vision-Language Pre-Training: Basics, Recent Advances, and Future
                  Trends},
  journal      = {Found. Trends Comput. Graph. Vis.},
  volume       = {14},
  number       = {3-4},
  pages        = {163--352},
  year         = {2022},
}

@article{Rubenstein-2023-arxiv-audiopalm,
  author       = {Paul K. Rubenstein and
                  Chulayuth Asawaroengchai and
                  Duc Dung Nguyen and
                  Ankur Bapna and
                  Zal{\'{a}}n Borsos and
                  F{\'{e}}lix de Chaumont Quitry and
                  Peter Chen and
                  Dalia El Badawy and
                  Wei Han and
                  Eugene Kharitonov and
                  others},
  title        = {AudioPaLM: {A} Large Language Model That Can Speak and Listen},
  journal      = {CoRR},
  year         = {2023},
}

@article{Zhou-arxiv-2023-analyzing,
  title={Analyzing and mitigating object hallucination in large vision-language models},
  author={Zhou, Yiyang and Cui, Chenhang and Yoon, Jaehong and Zhang, Linjun and Deng, Zhun and Finn, Chelsea and Bansal, Mohit and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2310.00754},
  year={2023}
}

@article{yang-arxiv-2023-bigtrans,
  title={BigTrans: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages},
  author={Yang, Wen and Li, Chong and Zhang, Jiajun and Zong, Chengqing},
  journal={arXiv preprint arXiv:2305.18098},
  year={2023}
}

@article{Wang-arxiv-2023-To,
  author       = {Junke Wang and
                  Lingchen Meng and
                  Zejia Weng and
                  Bo He and
                  Zuxuan Wu and
                  Yu{-}Gang Jiang},
  title        = {To See is to Believe: Prompting {GPT-4V} for Better Visual Instruction
                  Tuning},
  journal      = {CoRR},
  volume       = {abs/2311.07574},
  year         = {2023},
}

@article{tang-arxiv-2023-found,
  title={Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models},
  author={Tang, Raphael and Zhang, Xinyu and Ma, Xueguang and Lin, Jimmy and Ture, Ferhan},
  journal={arXiv preprint arXiv:2310.07712},
  year={2023}
}

@article{pradeep-arxiv-2023-rankvicuna,
  title={RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models},
  author={Pradeep, Ronak and Sharifymoghaddam, Sahel and Lin, Jimmy},
  journal={arXiv preprint arXiv:2309.15088},
  year={2023}
}

@article{zhuang-arxiv-2023-setwise,
  title={A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models},
  author={Zhuang, Shengyao and Zhuang, Honglei and Koopman, Bevan and Zuccon, Guido},
  journal={arXiv preprint arXiv:2310.09497},
  year={2023}
}

@article{sun-arxiv-2023-instruction,
  title={Instruction Distillation Makes Large Language Models Efficient Zero-shot Rankers},
  author={Sun, Weiwei and Chen, Zheng and Ma, Xinyu and Yan, Lingyong and Wang, Shuaiqiang and Ren, Pengjie and Chen, Zhumin and Yin, Dawei and Ren, Zhaochun},
  journal={arXiv preprint arXiv:2311.01555},
  year={2023}
}

@article{zhuang-arxiv-2023-beyond,
  title={Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels},
  author={Zhuang, Honglei and Qin, Zhen and Hui, Kai and Wu, Junru and Yan, Le and Wang, Xuanhui and Berdersky, Michael},
  journal={arXiv preprint arXiv:2310.14122},
  year={2023}
}

@article{askari-arxiv-2023-generating,
  title={Generating Synthetic Documents for Cross-Encoder Re-Rankers: A Comparative Study of ChatGPT and Human Experts},
  author={Askari, Arian and Aliannejadi, Mohammad and Kanoulas, Evangelos and Verberne, Suzan},
  journal={arXiv preprint arXiv:2305.02320},
  year={2023}
}

@article{Bi-arxiv-2023-When,
  author       = {Zhen Bi and
                  Ningyu Zhang and
                  Yinuo Jiang and
                  Shumin Deng and
                  Guozhou Zheng and
                  Huajun Chen},
  title        = {When Do Program-of-Thoughts Work for Reasoning?},
  journal      = {CoRR},
  volume       = {abs/2308.15452},
  year         = {2023},
}

@article{Chu-arxiv-2023-A,
  author       = {Zheng Chu and
                  Jingchang Chen and
                  Qianglong Chen and
                  Weijiang Yu and
                  Tao He and
                  Haotian Wang and
                  Weihua Peng and
                  Ming Liu and
                  Bing Qin and
                  Ting Liu},
  title        = {A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future},
  journal      = {CoRR},
  volume       = {abs/2309.15402},
  year         = {2023},
}

@article{Huang-arxiv-2023-A,
  author       = {Lei Huang and
                  Weijiang Yu and
                  Weitao Ma and
                  Weihong Zhong and
                  Zhangyin Feng and
                  Haotian Wang and
                  Qianglong Chen and
                  Weihua Peng and
                  Xiaocheng Feng and
                  Bing Qin and
                  Ting Liu},
  title        = {A Survey on Hallucination in Large Language Models: Principles, Taxonomy,
                  Challenges, and Open Questions},
  journal      = {CoRR},
  volume       = {abs/2311.05232},
  year         = {2023},
}

@article{Yang-arxiv-2023-zhongjing,
  author       = {Songhua Yang and
                  Hanjie Zhao and
                  Senbin Zhu and
                  Guangyu Zhou and
                  Hongfei Xu and
                  Yuxiang Jia and
                  Hongying Zan},
  title        = {Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language
                  Model through Expert Feedback and Real-world Multi-turn Dialogue},
  journal      = {CoRR},
  volume       = {abs/2308.03549},
  year         = {2023},
}

@article{Bi-arxiv-2023-OceanGPT,
  author       = {Zhen Bi and
                  Ningyu Zhang and
                  Yida Xue and
                  Yixin Ou and
                  Daxiong Ji and
                  Guozhou Zheng and
                  Huajun Chen},
  title        = {OceanGPT: {A} Large Language Model for Ocean Science Tasks},
  journal      = {CoRR},
  volume       = {abs/2310.02031},
  year         = {2023},
}