\section{Identity types}\label{sec:identity}

\index{identity type|(}
\index{inductive type!identity type|(}
From the perspective of types as proof-relevant propositions, how should we think of \emph{equality} in type theory? Given a type $A$, and two elements $x,y:A$, the equality $\id{x}{y}$ should again be a type. Indeed, we want to \emph{use} type theory to prove equalities. \emph{Dependent} type theory provides us with a convenient setting for this: the identity type $\id{x}{y}$ is dependent on $x,y:A$. 

Then, if $\id{x}{y}$ is to be a type, how should we think of the elements of $\id{x}{y}$. An element $p:\id{x}{y}$ witnesses that $x$ and $y$ are equal elements of type $A$. In other words $p:\id{x}{y}$ is an \emph{identification} of $x$ and $y$. In a proof-relevant world, there might be many elements of type $\id{x}{y}$. I.e., there might be many identifications of $x$ and $y$. And, since $\id{x}{y}$ is itself a type, we can form the type $\id{p}{q}$ for any two identifications $p,q:\id{x}{y}$. That is, since $\id{x}{y}$ is a type, we may also use the type theory to prove things \emph{about} identifications (for instance, that two given such identifications can themselves be identified), and we may use the type theory to perform constructions with them. As we will see in this section, we can give every type a groupoidal structure.

Clearly, the equality type should not just be any type dependent on $x,y:A$. Then how do we form the equality type, and what ways are there to use identifications in constructions in type theory? The answer to both these questions is that we will form the identity type as an \emph{inductive} type, generated by just a reflexivity identification providing an identification of $x$ to itself. The induction principle then provides us with a way of performing constructions with identifications, such as concatenating them, inverting them, and so on. Thus, the identity type is equipped with a reflexivity element, and further possesses the structure that are generated by its induction principle and by the type theory. This inductive construction of the identity type is elegant, beautifully simple, but far from trivial!

The situation where two elements can be identified in possibly more than one way is analogous to the situation in \emph{homotopy theory}, where two points of a space can be connected by possibly more than one \emph{path}. Indeed, for any two points $x,y$ in a space, there is a \emph{space of paths} from $x$ to $y$. Moreover, between any two paths from $x$ to $y$ there is a space of \emph{homotopies} between them, and so on. From \cref{chap:uf} on we will take full advantage of this idea in order to develop the univalent foundations of mathematics.

\subsection{The inductive definition of identity types}

\begin{defn}
  Consider a type $A$ and let $a:A$. Then we define the \define{identity type}\index{identity type|textbf} of $A$ at $a$ as an inductive family of types $a =_A x$\index{a = x@{$a = x$}|see {identity type}} indexed by $x:A$, of which the constructor is\index{refl@{$\refl{}$}|textbf}\index{identity type!refl@{$\refl{}$}|textbf}
  \begin{equation*}
    \refl{a}:a=_Aa.
  \end{equation*}
  The induction principle of the identity type\index{identity type!induction principle|textbf}\index{induction principle!of the identity type|textbf} postulates that for any family of types $P(x,p)$ indexed by $x:A$ and $p:a=_A x$, there is a function\index{path-ind@{$\pathind$}|textbf}\index{identity type!path-ind@{$\pathind$}|textbf}
  \begin{equation*}
    \pathind_a:P(a,\refl{a}) \to \prd{x:A}\prd{p:a=_A x} P(x,p)
  \end{equation*}
  that satisfies $\pathind_a(u,a,\refl{a})\jdeq u$, give $u:P(a,\refl{a})$.

  An element of type $a=_A x$ is also called an \define{identification}\index{identification|textbf}\index{identity type!identification|textbf} of $a$ with $x$, and sometimes it is called a \define{path}\index{path|textbf}\index{identity type!path|textbf} from $a$ to $x$.
The induction principle for identity types is sometimes called \define{identification elimination}\index{identification elimination|textbf}\index{induction principle!identification elimination|textbf}\index{identity type!identification elimination|textbf} or \define{path induction}\index{path induction|textbf}\index{identity type!path induction|textbf}\index{induction principle!path induction|textbf}. We also write $\idtypevar{A}$\index{Id A@{$\idtypevar{A}$}|see {identity type}}\index{Id A@{$\idtypevar{A}$}|textbf} for the identity type on $A$, and often we write $a=x$ for the type of identifications of $a$ with $x$, omitting reference to the ambient type $A$.
\end{defn}

\begin{rmk}
  We see that the identity type is not just an inductive type, like the inductive types $\N$, $\emptyt$, and $\unit$ for example, but it is an inductive \emph{family} of types. Even though we have a type $a=_A x$ for any $x:A$, the constructor only provides an element $\refl{a}:a=_A a$, identifying $a$ with itself. The induction principle then asserts that in order to prove something about all identifications of $a$ with some $x:A$, it suffices to prove this assertion about $\refl{a}$ only. We will see in the next sections that this induction principle is strong enough to derive many familiar facts about equality, namely that it is a symmetric and transitive relation, and that all functions preserve equality.
\end{rmk}

\begin{rmk}
  \index{rules!identity type|(}\index{identity type!rules|(}
  Since the identity types require getting used to, we provide the formal rules
  for identity types. The identity type is formed by the formation rule:
  \begin{prooftree}
    \AxiomC{$\Gamma\vdash a:A$}
    \UnaryInfC{$\Gamma,x:A\vdash a=_A x~\type$}
  \end{prooftree}
  The constructor of the identity type is then given by the introduction rule:
  \begin{prooftree}
    \AxiomC{$\Gamma\vdash a:A$}
    \UnaryInfC{$\Gamma\vdash \refl{a}:a=_A a$}
  \end{prooftree}
  The induction principle is now given by the elimination rule:
  \begin{prooftree}
    \AxiomC{$\Gamma\vdash a:A$}
    \AxiomC{$\Gamma,x:A,p:a=_A x\vdash P(x,p)~\type$}
    \BinaryInfC{$\Gamma\vdash \pathind_a:P(a,\refl{a})\to\prd{x:A}\prd{p:a=_A x}P(x,p)$}
  \end{prooftree}
  And finally the computation rule is:
  \begin{prooftree}
    \AxiomC{$\Gamma\vdash a:A$}
    \AxiomC{$\Gamma,x:A,p:a=_A x\vdash P(x,p)~\type$}
    \BinaryInfC{$\Gamma,u:P(a,\refl{a}) \vdash \pathind_a(u,a,\refl{a})\jdeq u : P(a,\refl{a})$}
  \end{prooftree}
  \index{rules!identity type|)}\index{identity type!rules|)}
\end{rmk}

\begin{rmk}
  One might wonder whether it is also possible to form the identity type at a \emph{variable} of type $A$, rather than at an element. This is certainly possible: since we can form the identity type in \emph{any} context, we can form the identity type at a variable $x:A$ as follows:
  \begin{prooftree}
    \AxiomC{$\Gamma,x:A\vdash x:A$}
    \UnaryInfC{$\Gamma,x:A,y:A\vdash x=_A y~\type$}
  \end{prooftree}
  In this way we obtain the `binary' identity type. Its constructor is then also indexed by $x:A$. We have the following introduction rule
  \begin{prooftree}
    \AxiomC{$\Gamma,x:A\vdash x:A$}
    \UnaryInfC{$\Gamma,x:A\vdash \refl{x}:x=_A x$}
  \end{prooftree}
  and similarly we have elimination and computation rules.
\end{rmk}

\subsection{The groupoidal structure of types}\label{sec:groupoid}
\index{groupoid laws!of identifications|(}
We show that identifications can be \emph{concatenated} and \emph{inverted}, which corresponds to the transitivity and symmetry of the identity type.

\begin{defn}\label{defn:id_concat}
Let $A$ be a type. We define the \define{concatenation}\index{concatenation!of identifications|textbf}\index{concat@{$\concat$}|textbf}\index{identity type!concatenation|textbf} operation
\begin{equation*}
\concat : \prd{x,y,z:A} (\id{x}{y})\to ((\id{y}{z})\to (\id{x}{z})).
\end{equation*}
We will write $\ct{p}{q}$ for $\concat(p,q)$.
\end{defn}

\begin{constr}
  We first construct a function
  \begin{equation*}
    f(x):\prd{y:A}(x=y)\to\prd{z:A}(y=z)\to(x=z)
  \end{equation*}
  for any $x:A$. By the induction principle for identity types, it suffices to construct
  \begin{equation*}
    f(x,x,\refl{x}):\prd{z:A} (x=z)\to(x=z).
  \end{equation*}
  Here we have the function $\lam{z}\idfunc[(x=z)]$. The function $f(x)$ we obtain via identity elimination is explicitly thus defined as
  \begin{equation*}
    f(x)\defeq\pathind_x(\lam{z}\idfunc):\prd{y:A} (x=y)\to \prd{z:A} (y=z)\to (x=z).
  \end{equation*}
  To finish the construction of $\concat$, we use \cref{ex:swap} to swap the order of the third and fourth variable of $f$, i.e., we define
  \begin{equation*}
    \concat_{x,y,z}(p,q):=f(x,y,p,z,q).\qedhere
  \end{equation*}
\end{constr}

\begin{defn}\label{defn:id_inv}
Let $A$ be a type. We define the \define{inverse operation}\index{inverse operation!for identifications|textbf}\index{inv@{$\invfunc$}|textbf}\index{identity type!inverse operation|textbf}
\begin{equation*}
\invfunc:\prd{x,y:A} (x=y)\to (y=x).
\end{equation*}
Most of the time we will write $p^{-1}$ for $\invfunc(p)$.
\end{defn}

\begin{constr}
By the induction principle for identity types, it suffices to construct
\begin{equation*}
\invfunc(\refl{x}): x=x,
\end{equation*}
for any $x:A$. Here we take $\invfunc(\refl{x})\defeq \refl{x}$.
\end{constr}

The next question is whether the concatenation and inverting operations on identifications behave as expected. More concretely: is concatenation of identifications associative, does it satisfy the unit laws, and is the inverse of an identification indeed a two-sided inverse?

For example, in the case of associativity we are asking to compare the identifications
\begin{equation*}
  \ct{(\ct{p}{q})}{r}\qquad\text{and}\qquad\ct{p}{(\ct{q}{r})}
\end{equation*}
for any $p:x=y$, $q:y=z$, and $r:z=w$ in a type $A$. The computation rules of the identity type are not strong enough to conclude that $\ct{(\ct{p}{q})}{r}$ and $\ct{p}{(\ct{q}{r})}$ are judgmentally equal. However, both $\ct{(\ct{p}{q})}{r}$ and $\ct{p}{(\ct{q}{r})}$ are elements of the same type: they are identifications of type $x=w$. Since the identity type is a type like any other, we can ask whether there is an \emph{identification}
\begin{equation*}
\ct{(\ct{p}{q})}{r}=\ct{p}{(\ct{q}{r})}.
\end{equation*}
This is a very useful idea: while it is often impossible to show that two elements of the same type are judgmentally equal, it may be the case that those two elements can be \emph{identified}. Indeed, we identify two elements by constructing an element of the identity type, and we can use all the type theory at our disposal in order to construct such an element. In this way we can show, for example, that addition on the natural numbers or on the integers is associative and satisfies the unit laws. And indeed, here we will show that concatenation of identifications is associative and satisfies the unit laws.

\begin{defn}\label{defn:id_assoc}
  Let $A$ be a type and consider three consecutive identifications
  \begin{equation*}
    \begin{tikzcd}
      x \arrow[r,equals,"p"] & y \arrow[r,equals,"q"] & z \arrow[r,equals,"r"] & w
    \end{tikzcd}
  \end{equation*}
  in $A$. We define the \define{associator}\index{associativity!of concatenation of identifications}
  \begin{equation*}
    \assoc(p,q,r) : \ct{(\ct{p}{q})}{r}=\ct{p}{(\ct{q}{r})}.
  \end{equation*}
\end{defn}

\begin{constr}
By the induction principle for identity types it suffices to show that
\begin{equation*}
\prd{z:A}\prd{q:x=z}\prd{w:A}\prd{r:z=w} \ct{(\ct{\refl{x}}{q})}{r}= \ct{\refl{x}}{(\ct{q}{r})}.
\end{equation*}
Let $q:x=z$ and $r:z=w$. Note that by the computation rule of identity types we have a judgmental equality $\ct{\refl{x}}{q}\jdeq q$. Therefore we conclude that
\begin{equation*}
  \ct{(\ct{\refl{x}}{q})}{r}\jdeq \ct{q}{r}.
\end{equation*}
Similarly we have a judgmental equality $\ct{\refl{x}}{(\ct{q}{r})}\jdeq \ct{q}{r}$. Thus we see that the left-hand side and the right-hand side in
\begin{equation*}
  \ct{(\ct{\refl{x}}{q})}{r}=\ct{\refl{x}}{(\ct{q}{r})}
\end{equation*}
are judgmentally equal, so we can simply define $\assoc(\refl{x},q,r)\defeq\refl{\ct{q}{r}}$.
\end{constr}

\begin{defn}\label{defn:id_unit}
Let $A$ be a type. We define the left and right \define{unit law operations}\index{unit laws!for concatenation of identifications}, which assigns to each $p:x=y$ the identifications\index{left unit@{$\leftunit$}|textbf}\index{right unit@{$\rightunit$}|textbf}
\begin{align*}
\leftunit(p) & : \ct{\refl{x}}{p}=p \\
\rightunit(p) & : \ct{p}{\refl{y}}=p,
\end{align*}
respectively.
\end{defn}

\begin{constr}
By identification elimination it suffices to construct
\begin{align*}
\leftunit(\refl{x}) & : \ct{\refl{x}}{\refl{x}} = \refl{x} \\
\rightunit(\refl{x}) & : \ct{\refl{x}}{\refl{x}} = \refl{x}.
\end{align*}
In both cases we take $\refl{\refl{x}}$.
\end{constr}

\begin{defn}\label{defn:id_invlaw}
Let $A$ be a type. We define left and right \define{inverse law operations}\index{inverse law operations!for identifications}\index{left inv@{$\leftinv$}|textbf}\index{right inv@{$\rightinv$}|textbf}
\begin{align*}
\leftinv(p) & : \ct{p^{-1}}{p} = \refl{y} \\
\rightinv(p) & : \ct{p}{p^{-1}} = \refl{x}.
\end{align*}
\end{defn}

\begin{constr}
By identification elimination it suffices to construct
\begin{align*}
\leftinv(\refl{x}) & : \ct{\refl{x}^{-1}}{\refl{x}} = \refl{x} \\
\rightinv(\refl{x}) & : \ct{\refl{x}}{\refl{x}^{-1}} = \refl{x}.
\end{align*}
Using the computation rules we see that
\begin{equation*}
\ct{\refl{x}^{-1}}{\refl{x}}\jdeq \ct{\refl{x}}{\refl{x}}\jdeq\refl{x},
\end{equation*}
so we define $\leftinv(\refl{x})\defeq \refl{\refl{x}}$. Similarly it follows from the computation rules that
\begin{equation*}
\ct{\refl{x}}{\refl{x}^{-1}} \jdeq \refl{x}^{-1}\jdeq \refl{x}
\end{equation*}
so we again define $\rightinv(\refl{x})\defeq\refl{\refl{x}}$. 
\end{constr}

\begin{rmk}
  We have seen that the associator, the unit laws, and the inverse laws, are all proven by constructing an identification of identifications. And indeed, there is nothing that would stop us from considering identifications of those identifications of identifications. We can go up as far as we like in the \emph{tower of identity types}\index{tower of identity types}\index{identity type!tower of identity types}, which is obtained by iteratively taking identity types.

  The iterated identity types give types in homotopy type theory a very intricate structure. One important way of studying this structure is via the homotopy groups of types, a subject that we will gradually be working towards.
\end{rmk}
\index{groupoid laws!of identifications|)}

\subsection{The action on identifications of functions}

\index{action on paths|(}
\index{identity type!action on paths|(}
Using the induction principle of the identity type we can show that every function preserves identifications.
In other words, every function sends identified elements to identified elements.
Note that this is a form of continuity for functions in type theory: if there is an identification that identifies two points $x$ and $y$ of a type $A$, then there also is an identification that identifies the values $f(x)$ and $f(y)$ in the codomain of $f$. 

\begin{defn}\label{defn:ap}
Let $f:A\to B$ be a map. We define the \define{action on paths}\index{function!action on paths|textbf}\index{identity type!action on paths|textbf}\index{action on paths|textbf} of $f$ as an operation\index{ap f@{$\apfunc{f}$}|see {action on paths}}\index{ap f@{$\apfunc{f}$}|textbf}
\begin{equation*}
\apfunc{f} : \prd{x,y:A} (\id{x}{y})\to(\id{f(x)}{f(y)}).
\end{equation*}
Moreover, there are operations\index{ap-id@{$\apid$}|textbf}\index{action on paths!ap-id@{$\apid$}|textbf}\index{ap-comp@{$\apcomp$}|textbf}\index{action on paths!ap-comp@{$\apcomp$}|textbf}
\begin{align*}
\apid_A & : \prd{x,y:A}\prd{p:\id{x}{y}} \id{p}{\ap{\idfunc[A]}{p}} \\
\apcomp(f,g) & : \prd{x,y:A}\prd{p:\id{x}{y}} \id{\ap{g}{\ap{f}{p}}}{\ap{g\circ f}{p}}.
\end{align*}
\end{defn}

\begin{constr}
First we define $\apfunc{f}$ by the induction principle of identity types, taking
\begin{equation*}
\apfunc{f}(\refl{x})\defeq \refl{f(x)}.
\end{equation*}
Next, we construct $\apid_A$ by the induction principle of identity types, taking
\begin{equation*}
\apid_A(\refl{x}) \defeq \refl{\refl{x}}.
\end{equation*}
Finally, we construct $\apcomp(f,g)$ by the induction principle of identity types, taking
\begin{equation*}
\apcomp(f,g,\refl{x}) \defeq \refl{\refl{g(f(x))}}.\qedhere
\end{equation*}
\end{constr}

\begin{defn}\label{defn:ap-preserve}
Let $f:A\to B$ be a map. Then there are identifications\index{ap-refl@{$\aprefl$}|textbf}\index{ap-inv@{$\apinv$}|textbf}\index{ap-concat@{$\apconcat$}|textbf}\index{action on paths!ap-refl@{$\aprefl$}|textbf}\index{action on paths!ap-inv@{$\apinv$}|textbf}\index{action on paths!ap-concat@{$\apconcat$}|textbf}
\begin{align*}
\aprefl(f,x) & : \id{\ap{f}{\refl{x}}}{\refl{f(x)}} \\
\apinv(f,p) & : \id{\ap{f}{p^{-1}}}{\ap{f}{p}^{-1}} \\
\apconcat(f,p,q) & : \id{\ap{f}{\ct{p}{q}}}{\ct{\ap{f}{p}}{\ap{f}{q}}}
\end{align*}
for every $p:\id{x}{y}$ and $q:\id{x}{y}$.
\end{defn}

\begin{constr}
To construct $\aprefl(f,x)$ we simply observe that ${\ap{f}{\refl{x}}}\jdeq {\refl{f(x)}}$, so we take
\begin{equation*}
\aprefl(f,x)\defeq\refl{\refl{f(x)}}.
\end{equation*}
We construct $\apinv(f,p)$ by identification elimination on $p$, taking
\begin{equation*}
\apinv(f,\refl{x}) \defeq \refl{\ap{f}{\refl{x}}}.
\end{equation*}
Finally we construct $\apconcat(f,p,q)$ by identification elimination on $p$, taking
\begin{equation*}
\apconcat(f,\refl{x},q)  \defeq \refl{\ap{f}{q}}.\qedhere
\end{equation*}
\end{constr}
\index{action on paths|)}
\index{identity type!action on paths|)}

\subsection{Transport}

\index{transport|(}
Dependent types also come with an action on identifications: the \emph{transport} functions.
Given an identification $p:\id{x}{y}$ in the base type $A$, we can transport any element $b:B(x)$ to the fiber $B(y)$.

\begin{defn}
Let $A$ be a type, and let $B$ be a type family over $A$.
We will construct a \define{transport}\index{transport|textbf}\index{type family!transport|textbf}\index{identity type!transport|textbf} operation\index{tr B@{$\tr_B$}|textbf}
\begin{equation*}
\tr_B:\prd{x,y:A} (\id{x}{y})\to (B(x)\to B(y)).
\end{equation*}
\end{defn}

\begin{constr}
We construct $\tr_B(p)$ by induction on $p:x=_A y$, taking
\begin{equation*}
\tr_B(\refl{x}) \defeq \idfunc[B(x)].\qedhere
\end{equation*}
\end{constr}

Thus we see that type theory cannot distinguish between identified elements $x$ and $y$, because for any type family $B$ over $A$ one obtains an element of $B(y)$ from the elements of $B(x)$.

As an application of the transport function we construct the \emph{dependent} action on paths\index{dependent action on paths|textbf} of a dependent function $f:\prd{x:A}B(x)$. Note that for such a dependent function $f$, and an identification $p:\id[A]{x}{y}$, it does not make sense to directly compare $f(x)$ and $f(y)$, since the type of $f(x)$ is $B(x)$ whereas the type of $f(y)$ is $B(y)$, which might not be exactly the same type. However, we can first \emph{transport} $f(x)$ along $p$, so that we obtain the element $\tr_B(p,f(x))$ which is of type $B(y)$. Now we can ask whether it is the case that $\tr_B(p,f(x))=f(y)$. The dependent action on paths of $f$ establishes this identification.

\begin{defn}\label{defn:apd}
Given a dependent function $f:\prd{a:A}B(a)$ and an identification $p:\id{x}{y}$ in $A$, we construct an identification\index{apd f@{$\apdfunc{f}$}|textbf}
\begin{equation*}
\apd{f}{p} : \id{\tr_B(p,f(x))}{f(y)}.
\end{equation*}
\end{defn}

\begin{constr}
The identification $\apd{f}{p}$ is constructed by the induction principle for identity types. Thus, it suffices to construct an identification
\begin{equation*}
\apd{f}{\refl{x}}:\id{\tr_B(\refl{x},f(x))}{f(x)}.
\end{equation*}
Since transporting along $\refl{x}$ is the identity function on $B(x)$, we simply take $\apd{f}{\refl{x}}\defeq\refl{f(x)}$. 
\end{constr}
\index{transport|)}

\subsection{The uniqueness of \texorpdfstring{$\refl{}$}{refl}}\label{sec:refl-unique}%

The identity type is an inductive \emph{family} of types. This has some subtle, but important implications. For instance, while the type $a=x$ indexed by $x:A$ is inductively generated by $\refl{a}$, the type $a=a$ is \emph{not} inductively generated by $\refl{a}$. Hence we cannot use the induction principle of identity types to show that $p=\refl{a}$ for any $p:a=a$. The obstacle, which prevents us from applying the induction principle of identity types in this case, is that the endpoint of $p:a=a$ is not free.

Nevertheless, the identity type $a=x$ is generated by a single element $\refl{a}:a=a$, so it is natural to wonder in what sense the reflexivity identification is unique. An identification with an element $a$ is specified by first giving the endpoint $x$ with which we seek to identify $a$, and then giving the identification $p:a=x$. It is therefore only the pair $(a,\refl{a})$ which is unique in the type of all pairs
\begin{equation*}
  (x,p):\sm{x:A}a=x.
\end{equation*}
We prove this fact in the following proposition.

\begin{prp}\label{prp:contraction-total-space-id}
  Consider an element $a:A$. Then there is an identification
  \begin{equation*}
    (a,\refl{a})=y
  \end{equation*}
  in the type $\sm{x:A}a=x$, for any $y:\sm{x:A}a=x$.
\end{prp}

\begin{proof}
  By $\Sigma$-induction it suffices to show that there is an identification
  \begin{equation*}
    (a,\refl{a})=(x,p)
  \end{equation*}
  for any $x:A$ and $p:a=x$. We proceed by the induction principle of identity types.
  Therefore it suffices to show that
  \begin{equation*}
    (a,\refl{a})=(a,\refl{a}).
  \end{equation*}
  We obtain such an identification by reflexivity.
\end{proof}

\cref{prp:contraction-total-space-id} shows that there is, up to identification, only one element in $\Sigma$-type of the identity type. Such types are called contractible, and they are the subject of \cref{sec:contractible}.

\subsection{The laws of addition on \texorpdfstring{$\N$}{â„•}}\label{subsec:addN}

Now that we have introduced the identity type, we can start proving equations. We will prove here that there are identifications\index{unit laws!for addition on N@{for addition on $\N$}}\index{successor laws!for addition on N@{for addition on $\N$}}\index{associativity!of addition on N@{of addition on $\N$}}\index{commutativity!of addition on N@{of addition on $\N$}}\index{natural numbers!unit laws for addition}\index{natural numbers!successor laws for addition}\index{natural numbers!associativity of addition}\index{natural numbers!commutativity of addition}
\begin{align*}
  0+n & = n & m+0 & = m \\
  \succN(m)+n & = \succN(m+n) & m+\succN(n) & = \succN(m+n) \\
  (m+n)+k & = m+(n+k) & m+n & = n+m.
\end{align*}
The unit laws, associativity, and commutativity of addition are of course familiar. The successor laws will be useful to prove commutativity. In \cref{ex:semi-ring-laws-N} you will be asked to prove the laws of multiplication on $\N$. There will again be \emph{successor laws} as part of this exercise, because they are useful intermediate steps in the more complicated laws.

Recall that addition on the natural numbers is defined in such a way that
\begin{align*}
  m+0 & \jdeq m & m+\succN(n) & \jdeq \succN(m+n).
\end{align*}
These two judgmental equalities are all we currently know about the function $m,n\mapsto m+n$ on $\N$. Consequently, we will have to find ways to apply these two judgmental equalities in our proofs of the laws of addition. Of course, the judgmental equalities coincide with two of the six laws. For the remaining four laws, we will have to proceed by induction on $\N$.

\begin{prp}\label{prp:unit-laws-add-N}
  For any natural number $n$, there are identifications
  \begin{align*}
    \leftunitlawaddN(n) & : 0+n=n \\
    \rightunitlawaddN(n) & : n+0=n.
  \end{align*}
\end{prp}

\begin{proof}
  We can define
  \begin{equation*}
    \rightunitlawaddN(n)\defeq\refl{n},
  \end{equation*}
  because the computation rule for addition gives us that $n+0\jdeq n$.

  It remains to define the left unit law. We proceed by induction on $n$. In the base case we have to show that $0+0=0$, which holds by reflexivity. For the inductive step, assume that we have an identification $p:0+n=n$. Our goal is to show that $0+\succN(n)=\succN(n)$. However, it suffices to construct an identification
  \begin{equation*}
    \succN(0+n)=\succN(n),
  \end{equation*}
  because by the computation rule for addition we have that $0+\succN(n)\jdeq\succN(0+n)$. Now we use the action on paths of $\succN:\N\to\N$ to obtain
  \begin{equation*}
    \ap{\succN}{p}:\succN(0+n)=\succN(n).
  \end{equation*}
  The left unit law is therefore defined by
  \begin{equation*}
    \leftunitlawaddN(n)\defeq\indN(\refl{0},\lam{p}\ap{\succN}{p}).\qedhere
  \end{equation*}
\end{proof}

\begin{prp}\label{prp:successor-laws-add-N}
  For any natural numbers $m$ and $n$, there are identifications
  \begin{align*}
    \leftsuccessorlawaddN(m,n) & : \succN(m)+n=\succN(m+n) \\
    \rightsuccessorlawaddN(m,n) & : m+\succN(n)=\succN(m+n).
  \end{align*}
\end{prp}

\begin{proof}
  We can define
  \begin{equation*}
    \rightsuccessorlawaddN(m,n)\defeq\refl{\succN(m+n)}
  \end{equation*}
  because we have a judgmental equality $m+\succN(n)\jdeq\succN(m+n)$ by the computation rules for $\addN$.

  The left successor law is constructed by induction on $n$. In the base case we have to construct an identification $\succN(m)+0=\succN(m+0)$, which is obtained by reflexivity. For the inductive step, assume that we have an identification $p:\succN(m)+n=\succN(m+n)$. Our goal is to show that
  \begin{equation*}
    \succN(m)+\succN(n)=\succN(m+\succN(n)). 
  \end{equation*}
  Note that we have the judgmental equalities
  \begin{align*}
    \succN(m)+\succN(n) & \jdeq\succN(\succN(m)+n) \\
    \succN(m+\succN(n)) & \jdeq\succN(\succN(m+n))
  \end{align*}
  Therefore it suffices to construct an identification
  \begin{equation*}
    \succN(\succN(m)+n)=\succN(\succN(m+n)).
  \end{equation*}
  Such an identification is given by $\ap{\succN}{p}$.
\end{proof}

\begin{prp}
  Addition on the natural numbers is associative, i.e., for any three natural numbers $m$, $n$, and $k$, there is an identification
  \begin{equation*}
    \associativeaddN(m,n,k):(m+n)+k=m+(n+k).
  \end{equation*}
\end{prp}

\begin{proof}
  We construct $\associativeaddN(m,n,k)$ by induction on $k$. In the base case we have the judgmental equalities
  \begin{equation*}
    (m+n)+0\jdeq m+n\jdeq m+(n+0).
  \end{equation*}
  Therefore we define $\associativeaddN(m,n,0)\defeq\refl{m+n}$.

  For the inductive step, let $p:(m+n)+k=m+(n+k)$. Our goal is to show that
  \begin{equation*}
    (m+n)+\succN(k)=m+(n+\succN(k)).
  \end{equation*}
  Note that we have the judgmental equalities
  \begin{align*}
    (m+n)+\succN(k) & \jdeq \succN((m+n)+k) \\
    m+(n+\succN(k)) & \jdeq m+(\succN(n+k)) \\
                    & \jdeq \succN(m+(n+k))
  \end{align*}
  Therefore it suffices to construct an identification
  \begin{equation*}
    \succN((m+n)+k)=\succN(m+(n+k)),
  \end{equation*}
  which we have by $\ap{\succN}{p}$.
\end{proof}

\begin{prp}
  Addition on the natural numbers is commutative, i.e., for any two natural numbers $m$ and $n$ there is an identification
  \begin{equation*}
    \commutativeaddN(m,n) : m+n=n+m.
  \end{equation*}
\end{prp}

\begin{proof}
  We construct $\commutativeaddN(m,n)$ by induction on $m$. In the base case we have to show that $0+n=n+0$, which holds by the unit laws for $n$, proven in \cref{prp:unit-laws-add-N}.

  For the inductive step, let $p:m+n=n+m$. Our goal is to construct an identification $\succN(m)+n=n+\succN(m)$. Now it is clear why we first proved the successor laws: we compute
  \begin{align*}
    \succN(m)+n & = \succN(m+n) \\
                & = \succN(n+m) \\
                & \jdeq n+\succN(m).
  \end{align*}
  The first identification is obtained by \cref{prp:successor-laws-add-N}, and the second identification is the identification $\ap{\succN}{p}$.
\end{proof}

\begin{exercises}
  \exitem \label{ex:inv_assoc}Show that the operation inverting identifications distributes over the concatenation operation, i.e., construct an identification
  \index{distributivity!of inv over concat@{of $\invfunc$ over $\concat$}}
  \index{identity type!distributive-inv-concat@{$\distributiveinvconcat$}|textbf}
  \begin{align*}
    \distributiveinvconcat(p,q):\id{(\ct{p}{q})^{-1}}{\ct{q^{-1}}{p^{-1}}}.
  \end{align*}
  for any $p:\id{x}{y}$ and $q:\id{y}{z}$.
  \exitem \label{ex:inv_con}For any $p:x=y$, $q:y=z$, and $r:x=z$, construct maps
  \index{identity type!inv-con@{$\invcon$}|textbf}
  \index{inv-con@{$\invcon$}|textbf}
  \index{identity type!con-inv@{$\coninv$}|textbf}
  \index{con-inv@{$\coninv$}|textbf}
  \begin{align*}
    \invcon(p,q,r) & : (\ct{p}{q}=r)\to (q=\ct{p^{-1}}{r}) \\
    \coninv(p,q,r) & : (\ct{p}{q}=r)\to (p=\ct{r}{q^{-1}}).
  \end{align*}
  \exitem Let $B$ be a type family over $A$, and consider an identification $p:\id{a}{x}$ in $A$. Construct for any $b:B(a)$ an identification\index{lift@{$\lift$}|textbf}\index{identity type!lift@{$\lift$}|textbf}
  \begin{equation*}
    \lift_B(p,b) : \id{(a,b)}{(x,\tr_B(p,b))}.
  \end{equation*}
  In other words, an identification $p:x=y$ in the \emph{base type} $A$ \emph{lifts} to an identification in $\sm{x:A}B(x)$ for every element in $B(x)$, analogous to the path lifting property for fibrations in homotopy theory.
  \exitem Consider four consecutive identifications
  \begin{equation*}
    \begin{tikzcd}
      a \arrow[r,equals,"p"] & b \arrow[r,equals,"q"] & c \arrow[r,equals,"r"] & d \arrow[r,equals,"s"] & e
    \end{tikzcd}
  \end{equation*}
  in a type $A$. In this exercise we will show that the \define{Mac Lane pentagon}\index{Mac Lane pentagon|textbf}\index{identity type!Mac Lane pentagon|textbf} for identifications commutes.
  \begin{subexenum}
  \item Construct the five identifications $\alpha_1,\ldots,\alpha_5$ in the pentagon
    \begin{equation*}
      \begin{tikzcd}[column sep=-1.5em]
        &[-2em] \ct{(\ct{(\ct{p}{q})}{r})}{s} \arrow[rr,equals,"\alpha_4"] \arrow[dl,equals,swap,"\alpha_1"] & & \ct{(\ct{p}{q})}{(\ct{r}{s})} \arrow[dr,equals,"\alpha_5"] &[-2em] \\
        \ct{(\ct{p}{(\ct{q}{r})})}{s} \arrow[drr,equals,swap,"\alpha_2"] & & & & \ct{p}{(\ct{q}{(\ct{r}{s})})}, \\
        & & \ct{p}{(\ct{(\ct{q}{r})}{s})} \arrow[urr,equals,swap,"\alpha_3"]
      \end{tikzcd}
    \end{equation*}
    where $\alpha_1$, $\alpha_2$, and $\alpha_3$ run counter-clockwise, and $\alpha_4$ and $\alpha_5$ run clockwise.
  \item Show that
    \begin{equation*}
      \ct{(\ct{\alpha_1}{\alpha_2})}{\alpha_3} = \ct{\alpha_4}{\alpha_5}.
    \end{equation*}
  \end{subexenum}
  \exitem \label{ex:semi-ring-laws-N}In this exercise we show that the operations of addition and multiplication on the natural numbers satisfy the laws of a commutative \define{semi-ring}.%
  \index{semi-ring laws!for N@{for $\N$}}%
  \index{natural numbers!semi-ring laws}%
  \index{associativity!of multiplication on N@{of multiplication on $\N$}}%
  \index{unit laws!for multiplication on N@{for multiplication on $\N$}}%
  \index{commutativity!of multiplication on N@{of multiplication on $\N$}}%
  \index{distributivity!of mulN over addN@{of $\mulN$ over $\addN$}}%
  \index{natural numbers!associativity of multiplicatoin@{associativity of multiplication}}
  \index{natural numbers!unit laws for multiplication}
  \index{natural numbers!zero laws for multiplication}
  \index{natural numbers!commutativity of multiplication}
  \index{natural numbers!distributivity of multiplication over addition}
  \begin{subexenum}
  \item Show that multiplication satisfies the following laws:
    \begin{align*}
      m\cdot 0 & = 0 & m\cdot 1 & = m & m\cdot \succN(n) & = m+m\cdot n \\
      0\cdot m & = 0 & 1\cdot m & = m & \succN(m)\cdot n & = m\cdot n+n.
    \end{align*}
  \item Show that multiplication on $\N$ is commutative:
    \begin{equation*}
      m\cdot n=n\cdot m.
    \end{equation*}
  \item \label{ex:distributive-mul-addN}Show that multiplication on $\N$ distributes over addition from the left and from the right, i.e., show that we have identifications
    \begin{align*}
      m\cdot (n+k) & = m\cdot n + m\cdot k \\
      (m+n)\cdot k & = m\cdot k + n\cdot k.
    \end{align*}
  \item Show that multiplication on $\N$ is associative:
    \begin{align*}
      (m\cdot n)\cdot k & = m\cdot (n\cdot k).
    \end{align*}
  \end{subexenum}
  \exitem \label{ex:is-equiv-succ-Z}Show that
  \begin{equation*}
    \succZ(\predZ(k))=k \qquad\text{and}\qquad \predZ(\succZ(k))=k
  \end{equation*}
  for any $k:\Z$, where $\predZ$ is the predecessor function on the integers, defined in \cref{ex:int_pred}.
  \exitem \label{ex:int_group_laws}\index{integers!group laws} In this exercise we will show that the laws for abelian groups hold for addition on the integers, using the group operations on $\Z$ defined in \cref{ex:int_group_ops}.
  \begin{subexenum}
  \item Show that addition satisfies the left and right unit laws, i.e., show that\index{unit laws!for addition on Z@{for addition on $\Z$}}\index{integers!unit laws for addition}
    \begin{align*}
      0+x & = x \\
      x+0 & = x.
    \end{align*}
  \item Show that the following successor and predecessor laws hold for addition on $\Z$.
    \begin{align*}
      \predZ(x)+y & = \predZ(x+y) & \succZ(x)+y & = \succZ(x+y) \\
      x+\predZ(y) & = \predZ(x+y) & x+\succZ(y) & = \succZ(x+y).
    \end{align*}
  \item Use part (b) to show that addition on the integers is associative and commutative, show that\index{associativity!of addition on Z@{of addition on $\Z$}}\index{commutativity!of addition on Z@{of addition on $\Z$}}\index{integers!associativity of addition}\index{integers!commutativity of addition}
    \begin{align*}
      (x+y)+z & = x + (y+z) \\
      x+y & = y+x.
    \end{align*}
  \item Show that addition satisfies the left and right inverse laws:\index{inverse laws!for addition on Z@{for addition on $\Z$}}\index{integers!inverse laws for addition}
    \begin{align*}
      (-x)+x & =0 \\
      x+(-x) &=0.
    \end{align*}
  \end{subexenum}
  \exitem \label{ex:ring-Z}In this exercise we will show that $\Z$ satisfies the axioms of a \define{ring}\index{ring!integers}\index{integers!is a ring}, using the multiplication operation defined in \cref{ex:mulZ}.
  \begin{subexenum}
  \item Show that multiplication on $\Z$ satisfies the following laws for $0$ and $1$\index{zero laws!for mulZ@{for $\mulZ$}}\index{unit laws!for multiplication on Z@{for multiplication on $\Z$}}\index{mul Z@{$\mulZ$}!unit laws}\index{mul Z@{$\mulZ$}!zero laws}\index{integers!zero laws for multiplication}\index{unit laws for multiplication}:
    \begin{align*}
      0\cdot x & = 0 & 1\cdot x & = x \\
      x\cdot 0 & = 0 & x\cdot 1 & = x.
    \end{align*}
  \item Show that multiplication on $\Z$ satisfies the predecessor and successor laws\index{mul Z@{$\mulZ$}!predecessor laws}\index{mul Z@{$\mulZ$}!successor laws}\index{integers!successor laws for addition}\index{integers!predecessor laws for addition}:
    \begin{align*}
      \predZ(x)\cdot y & = x\cdot y-y & \succZ(x)\cdot y & = x\cdot y + y \\
      x\cdot \predZ(y) & = x\cdot y-x & y\cdot \succZ(y) & = x\cdot y + x.
    \end{align*}
  \item Show that multiplication on $\Z$ distributes over addition, both from the left and from the right\index{mul Z@{$\mulZ$}!distributive over addZ@{distributive over $\addZ$}}\index{distributivity!of mulZ over addZ@{of $\mulZ$ over $\addZ$}}\index{integers!distributivity of multiplication over addition}:
    \begin{align*}
      x\cdot(y+z) & = x\cdot y+ x\cdot z \\
      (x+y)\cdot z & = x\cdot z + y\cdot z.
    \end{align*}
  \item Show that multiplication on $Z$ is associative and commutative\index{associativity!of multiplication on Z@{of multiplication on $\Z$}}\index{mul Z@{$\mulZ$}!associativity}\index{commutativity!of multiplication on Z@{of multiplication on $\Z$}}\index{mul Z@{$\mulZ$}!commutativity}\index{integers!associativity of multiplication}\index{integers!commutativity of multiplication}:
    \begin{align*}
      (x\cdot y)\cdot z & = x\cdot (y\cdot z) \\
      x\cdot y & = y\cdot x.
    \end{align*}
  \end{subexenum}
\end{exercises}

\index{identity type|)}
\index{inductive type!identity type|)}
\index{inductive type|)}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "hott-intro"
%%% End:
