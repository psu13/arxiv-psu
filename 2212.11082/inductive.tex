\section{More inductive types}\label{sec:inductive}

In the previous section we introduced the type of natural numbers. Many other types can also be introduced as inductive types. In this section we will see by example how that works. We will introduce the unit type, the empty type, coproducts, dependent pair types, and cartesian products as inductive types, and in the next section the identity type will be introduced as an inductive family of types.

From this section on, we will also start using a more informal style. The inductive types will be specified by a description of their constructors and induction principles in terms of operations on dependent function types, which is more tightly connected with how we will use them, but we will not display the formal rules. It is a good exercise for the reader to formally specify at least some of the inductive types of this section by stating their formal rules.

\subsection{The idea of general inductive types}

Just like the type of natural numbers, other inductive types are also specified by their \emph{constructors}, an \emph{induction principle}, and their \emph{computation rules}: 
\begin{enumerate}
\item The constructors tell what structure the inductive type comes equipped with. There may be any finite number of constructors, even no constructors at all, in the specification of an inductive type. 
\item The induction principle specifies the data that should be provided in order to construct a section of an arbitrary type family over the inductive type. The idea of the induction principle is always the same: in order to define a dependent function $f:\prd{x:A}B(x)$, one has to specify the behaviour of $f$ at the constructors of $A$.
\item The computation rules assert that the inductively defined section agrees on the constructors with the data that was used to define the section. Thus, there is a computation rule for every constructor.
\end{enumerate}
Since any inductively defined function is entirely determined by its behavior on the constructors, we can again present such inductive definitions by pattern matching. Therefore, we will also specify for each inductive type how to give definitions by pattern matching.

\subsection{The unit type}
\index{unit type|(}
\index{inductive type!unit type|(}
A straightforward example of an inductive type is the \emph{unit type}, which has just one constructor. 
Its induction principle is analogous to just the base case of induction on the natural numbers.

\begin{defn}
We define the \define{unit type}\index{1 @{$\unit$}|see {unit type}}\index{1 @{$\unit$}|textbf}\index{unit type|textbf} to be a type $\unit$ equipped with a term\index{unit type!star@{$\ttt$}|textbf}
\begin{equation*}
\ttt:\unit,
\end{equation*}
satisfying the induction principle\index{induction principle!of the unit type|textbf}\index{unit type!induction principle|textbf} that for any family of types $P(x)$ indexed by $x:\unit$, there is a function\index{ind 1@{$\indunit$}|textbf}\index{unit type!indunit@{$\indunit$}|textbf}
\begin{equation*}
\indunit : P(\ttt)\to\prd{x:\unit}P(x)
\end{equation*}
for which the computation rule\index{computation rules!for the unit type|textbf}\index{unit type!computation rules|textbf}
\begin{equation*}
\indunit(p,\ttt) \jdeq p
\end{equation*}
holds. Alternatively, a definition of a dependent function $f:\prd{x:\unit}P(x)$ by induction using $p:P(\ttt)$ can be presented by pattern matching as
\begin{equation*}
  f(\ttt)\defeq p.
\end{equation*}
\end{defn}

A special case of the induction principle arises when $P$ does not actually depend on $\unit$. If we are given a type $A$, then we can first weaken it to obtain the constant family over $\unit$, with value $A$. Then the induction principle of the unit type provides a function
\begin{equation*}
  \indunit : A \to (\unit\to A).
\end{equation*}
In other words, by the induction principle for the unit type we obtain for every $x:A$ a function $\pt_x\defeq\indunit(x):\unit\to A$.\index{pt x@{$\pt_x$}|textbf}
\index{unit type|)}
\index{inductive type!unit type|)}

\subsection{The empty type}
\index{empty type|(}
\index{inductive type!empty type|(}
The empty type is a degenerate example of an inductive type. It does \emph{not} come equipped with any constructors, and therefore there are also no computation rules. The induction principle merely asserts that any type family has a section. In other words: if we assume the empty type has a term, then we can prove anything.

\begin{defn}
We define the \define{empty type}\index{0 @{$\emptyt$}|see {empty type}}\index{0 @{$\emptyt$}|textbf}\index{empty type|textbf} to be a type $\emptyt$ satisfying the induction principle\index{induction principle!of the empty type|textbf}\index{empty type!induction principle|textbf} that for any family of types $P(x)$ indexed by $x:\emptyt$, there is a term\index{ind 0@{$\indempty$}|textbf}\index{empty type!indempty@{$\indempty$}|textbf}
\begin{equation*}
\indempty : \prd{x:\emptyt}P(x).
\end{equation*}
\end{defn}

It is again a special case of the induction principle that we have a function
\begin{equation*}
  \exfalso\defeq\indempty:\emptyt\to A
\end{equation*}
for any type $A$. Indeed, to obtain this function one first weakens $A$ to obtain the constant family over $\emptyt$ with value $A$, and then the induction principle gives the desired function. The function $\exfalso$ can be used to draw any conclusion after deriving a contradiction, because \emph{ex falso quodlibet}.

We can also use the empty type to define the negation operation on types.

\begin{defn}
  For any type $A$ we define \define{negation}\index{negation!of types|textbf}\index{n A@{$\neg A$}|see {negation}|textbf} of $A$ by
  \begin{align*}
    \neg A & \defeq A\to\emptyt.
  \intertext{We also say that a type $A$ \define{is empty} if it comes equipped with an element of type $\neg A$. Therefore, we also define}
    \isempty(A) & \defeq A\to\emptyt.
  \end{align*}
\end{defn}

\begin{rmk}
  Since $\neg A$ is the type of functions from $A$ to $\emptyt$, a proof of $\neg A$ is given by assuming that $A$ holds, and then constructing an element of the empty type. In other words, we prove $\neg A$ by assuming $A$ and deriving a contradiction. This proof technique is called \define{proof of negation}\index{proof of negation}.

  Proofs of negation should not be confused with proofs by contradiction\index{proof by contradiction}. Even though a proof of negation involves deriving a contradiction, in logic a \define{proof by contradiction} of a proposition $P$ is an argument where we conclude that $P$ holds after showing that $\neg P$ implies a contradiction. In other words, a proof by contradiction uses the logical step $\neg\neg P \Rightarrow P$, which is also called \define{double negation elimination}.

  In type theory, however, note that the type $\neg\neg A$ is the type of functions
  \begin{equation*}
    (A\to\emptyt)\to\emptyt.
  \end{equation*}
  This type is quite different from the type $A$ itself, and with the given rules of type theory it is not possible to construct a function $\neg\neg A \to A$ unless more is known about the type $A$. In other words, before one can prove by contradiction that there is an element in $A$, one has to construct a function $\neg\neg A\to A$, and it depends on the specific type $A$ whether this is possible at all. In \cref{ex:dne-is-decidable} we will see a situation where we can indeed construct a function $\neg\neg A\to A$. In practice, however, we will rarely use double negation elimination.
\end{rmk}

In the following proposition we illustrate how to work with the type theoretic definition of negation.

\begin{prp}\label{prp:contravariant-neg}
  For any two types $P$ and $Q$, there is a function
  \begin{equation*}
    (P\to Q)\to (\neg Q \to \neg P).
  \end{equation*}
\end{prp}

\begin{proof}
  The desired function is defined by $\lambda$-abstraction, so we begin by assuming that we have a function $f:P\to Q$. Then we have to construct a function $\neg Q\to\neg P$, which is again constructed by $\lambda$-abstraction. We assume that we have $\tilde{q}:\neg Q$. By our definition of $\neg Q$ we see that $\tilde{q}$ is a function $Q\to\emptyt$. Now we have to construct a term of type $\neg P$, which is the type of functions $P\to\emptyt$. We apply $\lambda$-abstraction once more, so we assume $p:P$. Now we have
  \begin{align*}
    f & : P \to Q \\*
    \tilde{q} & : Q\to \emptyt \\*
    p & : P,
  \end{align*}
  and our goal is to construct a term of the empty type.

  Since we have $f:P\to Q$ and $p:P$, we obtain $f(p):Q$. Moreover, we have $\tilde{q}:Q\to\emptyt$, so we obtain $\tilde{q}(f(p)):\emptyt$. This completes the proof. The function we have constructed is
  \begin{equation*}
    \lam{f}\lam{\tilde{q}}\lam{p}\tilde{q}(f(p)):(P\to Q)\to(\neg Q\to\neg P).\qedhere
  \end{equation*}
\end{proof}

We leave it to the reader to construct the corresponding natural deduction tree, that formally constructs a function
\begin{equation*}
  (P\to Q)\to(\neg Q\to \neg P).
\end{equation*}
\index{empty type|)}
\index{inductive type!empty type|)}

\subsection{Coproducts}\label{sec:coprod}
\index{coproduct|(}
\index{inductive type!coproduct|(}
\begin{defn}
Let $A$ and $B$ be types. We define the \define{coproduct}\index{disjoint sum|see {coproduct}}\index{coproduct|textbf} $A+B$\index{A + B@{$A+B$}|see {coproduct}} to be a type that comes equipped with\index{inl@{$\inl$}|textbf}\index{coproduct!inl@{$\inl$}|textbf}\index{inr@{$\inr$}|textbf}\index{coproduct!inr@{$\inr$}|textbf}
\begin{align*}
\inl & : A \to A+B \\*
\inr & : B \to A+B,
\end{align*}
satisfying the induction principle\index{induction principle!of coproducts|textbf}\index{coproduct!induction principle|textbf} that for any family of types $P(x)$ indexed by $x:A+B$, there is a term\index{ind +@{$\indcoprod$}|textbf}\index{coproduct!ind+@{$\indcoprod$}|textbf}
\begin{equation*}
\indcoprod : \Big(\prd{x:A}P(\inl(x))\Big)\to\Big(\Big(\prd{y:B}P(\inr(y))\Big)\to\prd{z:A+B}P(z)\Big)
\end{equation*}
for which the computation rules\index{computation rules!for coproducts|textbf}\index{coproduct!computation rules|textbf}
\begin{align*}
\indcoprod(f,g,\inl(x)) & \jdeq f(x) \\*
\indcoprod(f,g,\inr(y)) & \jdeq g(y)
\end{align*}
hold. Alternatively, a definition of a dependent function $h:\prd{x:A+B}P(x)$ by induction using $f:\prd{x:A}P(\inl(x))$ and $g:\prd{y:B}P(\inr(y))$ can be presented by pattern matching as
\begin{align*}
  h(\inl(x)) & \defeq f(x) \\*
  h(\inr(y)) & \defeq g(y).
\end{align*}
Sometimes we write $[f,g]$ for the function $\indcoprod(f,g)$. The coproduct of two types is sometimes also called the \define{disjoint sum}.
\end{defn}

By the induction principle of coproducts we obtain a function
\begin{equation*}
  \indcoprod:(A\to X) \to \big((B\to X) \to (A+B\to X)\big)
\end{equation*}
for any type $X$. Note that this special case of the induction principle of coproducts is very similar to the elimination rule of disjunction in first order logic: if $P$, $P'$, and $Q$ are propositions, then we have
\begin{equation*}
  (P\to Q)\to \big((P'\to Q)\to (P\lor P'\to Q)\big).
\end{equation*}
Indeed, we can think of \emph{propositions as types} and of terms as their constructive proofs. Under this interpretation of type theory the coproduct is indeed the disjunction.

\begin{rmk}\label{rmk:functor-coprod}
  A simple application of the induction principle for coproducts gives us a map\index{coproduct!functorial action|textbf}\index{functorial action!of coproducts|textbf}\index{f + g@{$f+g$}|see {functorial action, of coproducts}}\index{f + g@{$f+g$}|textbf}
  \begin{equation*}
    f+g:A+B\to A'+B'
  \end{equation*}
  for every $f:A\to A'$ and $g:B\to B'$. Indeed, the map $f+g$ is defined by
  \begin{align*}
    (f+g)(\inl(x)) & \defeq \inl(f(x)) \\*
    (f+g)(\inr(y)) & \defeq \inr(g(y)).
  \end{align*}
\end{rmk}

\begin{prp}
  Consider two types $A$ and $B$, and suppose that $B$ is empty. Then there is a function
  \begin{equation*}
    (A+B)\to A.
  \end{equation*}
\end{prp}

\begin{rmk}
  In other words, there is a function
  \begin{equation*}
    \isempty(B) \to ((A+B)\to A),
  \end{equation*}
  for any two types $A$ and $B$. Similarly, there is a function
  \begin{equation*}
    \isempty(A)\to ((A+B)\to B),
  \end{equation*}
  for any two types $A$ and $B$.
\end{rmk}

\begin{proof}
  We will construct the function $(A+B)\to A$ with the induction principle of the coproduct $A+B$. Therefore, we must construct two functions:
  \begin{align*}
    f & : A\to A \\*
    g & : B\to A.
  \end{align*}
  The function $f$ is simply defined to be the identity function $\idfunc:A\to A$. Recall that we have assumed that $B$ is empty, so we have a function $\tilde{b}:B\to\emptyt$. Furthermore, we always have the function $\exfalso:\emptyt\to A$. Therefore, we can define $g\defeq \exfalso\circ \tilde{b}$ to complete the proof.
\end{proof}
\index{coproduct|)}
\index{inductive type!coproduct|)}

\subsection{The type of integers}
\index{integers|(}
The set of integers is usually defined as a quotient of the set $\N\times\N$, by the equivalence relation
\begin{equation*}
  ((n,m)\sim (n',m')) := (n+m' = n'+m).
\end{equation*}
We haven't introduced the identity type yet, in order to consider the type of identifications $n+m'=n'+m$, but more importantly there are no quotient types in Martin-L\"of's dependent type theory. We will only discuss quotient types in \cref{sec:set-quotients} after we have assumed the univalence axiom and propositional truncations, because we will use the univalence axiom and propositional truncations to define them and derive their basic properties. Nevertheless, the type of integers is also definable in dependent type theory without set quotients, but we have to settle for a more pedestrian version of the integers that is defined using coproducts.

\begin{defn}
  We define the \define{integers}\index{Z@{$\Z$}|see {integers}} to be the type $\Z\defeq\N+(\unit+\N)$. The type of integers comes equipped with inclusion functions of the positive and negative integers\index{integers!in-pos@{$\inpos$}}\index{integers!in-neg@{$\inneg$}}
  \begin{alignat*}{2}
    \inpos & \defeq \inr\circ\inr\quad & & : \N\to \Z \\*
    \inneg & \defeq \inl\quad & & : \N \to \Z
  \end{alignat*}
  and with the constants\index{integers!-1 Z@{$-1_\Z$}}\index{integers!0 Z@{$0_\Z$}}\index{integers!1 Z@{$1_\Z$}}\index{-1 Z@{$-1_\Z$}}\index{0 Z@{$0_\Z$}}\index{1 Z@{$1_{\Z}$}}
  \begin{align*}
    -1_\Z & \defeq \inneg(0)\\*
    0_\Z & \defeq \inr(\inl(\ttt))\\*
    1_\Z & \defeq \inpos(0).
  \end{align*}
\end{defn}

The definition of the integers as the coproduct $\N+(\unit+\N)$ can be pictured as follows:
\begin{equation*}
  \begin{tikzcd}[column sep=0]
    \phantom{\unit+\N} & \unit \arrow[dr] & & \N \arrow[dl] \\
    \N \arrow[dr] & \phantom{\unit+\N} & \unit+\N \arrow[dl] & \phantom{\unit+\N} \\
    & \Z
  \end{tikzcd}
\end{equation*}

\begin{rmk}\label{lem:Z_ind}
  The type of integers is built entirely out of inductive types. Therefore it is possible to derive an induction principle especially tailored for the type $\Z$, which can be used to define the basic operations on $\Z$, such as the successor map, addition and multiplication. This induction principle asserts that for any type family $P$ over $\Z$,  we can define a dependent function $f:\prd{k:\Z}P(k)$ recursively by
  \begin{align*}
    f(-1_\Z) & \defeq p_{-1} \\*
    f(\inneg(\succN(n))) & \defeq p_{-S}(n,f(\inneg(n))) \\*
    f(0_\Z) & \defeq p_{0} \\*
    f(1_\Z) & \defeq p_{1} \\*
    f(\inpos(\succN(n))) & \defeq p_S(n,f(\inpos(n))),
  \end{align*}
  where the types of $p_{-1}$, $p_{-S}$, $p_0$, $p_1$, and $p_S$ are 
  \begin{align*}
    p_{-1} & :P(-1_\Z) \\*
    p_{-S} & : \prd{n:\N}P(\inneg(n))\to P(\inneg(\succN(n)))\\*
    p_{0} & : P(0_\Z) \\*
    p_{1} & : P(1_\Z) \\*
    p_{S} & : \prd{n:\N}P(\inpos(n))\to P(\inpos(\succN(n))).
  \end{align*}
\end{rmk}

\begin{defn}
We define the \define{successor function}\index{successor function!on Z@{on $\Z$}|textbf} on the integers $\succZ:\Z\to\Z$\index{succ Z@{$\succZ$}|textbf}\index{integers!succ Z@{$\succZ$}|textbf} using the induction principle of \cref{lem:Z_ind}, taking
\begin{align*}
\succZ(-1_\Z) & \defeq \zeroZ \\*
\succZ(\inneg(\succN(n))) & \defeq \inneg(n) \\*
\succZ(0_\Z) & \defeq \oneZ \\*
\succZ(1_\Z) & \defeq \inpos(1_\N) \\*
\succZ(\inpos(\succN(n))) & \defeq \inpos(\succN(\succN(n))).
\end{align*}
\end{defn}
\index{integers|)}

\subsection{Dependent pair types}

\index{dependent pair type|(}
\index{inductive type!dependent pair type|(}

Given a type family $B$ over $A$, we may consider pairs $(a,b)$ of terms, where $a:A$ and $b:B(a)$. Note that the type of $b$ depends on the first term in the pair. Therefore we call such a pair a \define{dependent pair}\index{dependent pair|textbf}. The type of such dependent pairs is the inductive type that is generated by the dependent pairs.

\begin{defn}
  Consider a type family $B$ over $A$.
  The \define{dependent pair type} (or \define{$\Sigma$-type}) \index{dependent pair type|textbf}\index{S-type@{$\Sigma$-type}|see {dependent pair type}}\index{S-type@{$\Sigma$-type}|textbf}is defined to be the inductive type $\sm{x:A}B(x)$ equipped with a \define{pairing function}\index{pairing function|textbf}\index{pair@{$\pair$}|textbf}\index{dependent pair type!pair@{$\pair$}|textbf}
  \begin{equation*}
    \pair :\prd{x:A} \Big(B(x)\to \sm{y:A}B(y)\Big).
  \end{equation*}
  The induction principle\index{induction principle!of Sigma types@{of $\Sigma$-types}|textbf}\index{dependent pair type!induction principle|textbf} for $\sm{x:A}B(x)$ asserts that for any family of types $P(p)$ indexed by $p:\sm{x:A}B(x)$, there is a function\index{dependent pair type!indSigma@{$\indSigma$}|textbf}\index{ind Sigma@{$\indSigma$}|textbf}
  \begin{equation*}
    \indSigma:\Big(\prd{x:A}\prd{y:B(x)}P(\pair(x,y))\Big)\to\Big(\prd{z:\sm{x:A}B(x)}P(z)\Big).
  \end{equation*}
  satisfying the computation rule\index{computation rules!for S-types@{for $\Sigma$-types}|textbf}\index{dependent pair type!computation rule|textbf}
  \begin{equation*}
    \indSigma(g,\pair(x,y))\jdeq g(x,y).
  \end{equation*}
  Alternatively, a definition of a dependent function $f:\prd{z:\sm{x:A}B(x)}P(z)$ by induction using a function $g:\prd{x:A}\prd{y:B(x)}P((x,y))$ can be presented by pattern matching as
  \begin{equation*}
    f(\pair(x,y))\defeq g(x,y).
  \end{equation*}
  We will usually write $(x,y)$ for $\pair(x,y)$\index{(x,y)@{$(x,y)$}|see {dependent pair}}\index{(x,y)@{$(x,y)$}|textbf}.
\end{defn}

The induction principle of $\Sigma$-types can be used to define the projection functions.

\begin{defn}
  Consider a type $A$ and a type family $B$ over $A$.
  \begin{enumerate}
  \item The \define{first projection map}\index{first projection map|textbf}\index{projection map!first projection|textbf}\index{dependent pair type!pr 1@{$\proj 1$}|textbf}\index{pr 1@{$\proj 1$}|textbf}\index{pr 1@{$\proj 1$}|see{first projection map}}
    \begin{equation*}
      \proj 1:\Big(\sm{x:A}B(x)\Big)\to A
    \end{equation*}
    is defined by induction as
    \begin{equation*}
      \proj 1(x,y) \defeq x.
    \end{equation*}
  \item The \define{second projection map}\index{second projection map|textbf}\index{projection map!second projection|textbf}\index{dependent pair type!pr 2@{$\proj 2$}|textbf}\index{pr 2@{$\proj 2$}|textbf}\index{pr 2@{$\proj 2$}|see{second projection map}} is a dependent function
    \begin{equation*}
      \proj 2 : \prd{p:\sm{x:A}B(x)} B(\proj 1(p)),
    \end{equation*}
    defined by induction as
    \begin{equation*}
      \proj 2(x,y) \defeq y.
    \end{equation*}
  \end{enumerate}
\end{defn}
\index{dependent pair type|)}
\index{inductive type!dependent pair type|)}

\begin{rmk}
  If we want to construct a function
  \begin{equation*}
    f:\prd{z:\sm{x:A}B(x)}P(z)
  \end{equation*}
  by $\Sigma$-induction, then we get to assume a pair $(x,y)$ consisting of $x:A$ and $y:B(x)$ and our goal will be to construct an element of type $P(x,y)$. The induction principle of $\Sigma$-types is therefore converse to the \define{currying operation}, a familiar concept from the theory of programming languages, which is given by the function
  \begin{equation*}
    \evpair : \Big(\prd{z:\sm{x:A}B(x)}P(z)\Big)\to \Big(\prd{x:A}\prd{y:B(x)}P(x,y)\Big)
  \end{equation*}
  given by $f\mapsto\lam{x}\lam{y}f(x,y)$. The induction principle $\indSigma$ is therefore also known as the \define{uncurrying operation}. 
\end{rmk}

\index{cartesian product type|(}
\index{inductive type!cartesian product|(}
A common special case of the $\Sigma$-type occurs when the $B$ is a constant family over $A$, i.e., when $B$ is just a type weakened by $A$.
In this case, the type $\sm{x:A}B$ is the type of \emph{ordinary} pairs $(x,y)$ where $x:A$ and $y:B$, where the type of $y$ does not depend on $x$. The type of ordinary pairs $(x,y)$ consisting of $x:A$ and $y:B$ is of course the \emph{product} of $A$ and $B$, so we see that product types arise as a special case of $\Sigma$-types in a similar way to how function types were defined as a special case of $\Pi$-types.

\begin{defn}
  Consider two types $A$ and $B$. Then we define the \define{(cartesian) product}\index{cartesian product type|textbf}\index{product of types|textbf}\index{A x B@{$A\times B$}|see {cartesian product}}\index{A x B@{$A\times B$}|textbf} $A\times B$ of $A$ and $B$ by
  \begin{equation*}
    A\times B \defeq \sm{x:A}B.
  \end{equation*}
\end{defn}

\begin{rmk}
  Since $A\times B$ is defined as a $\Sigma$-type, it follows that cartesian products also satisfy the induction principle of $\Sigma$-types. In this special case, the induction principle\index{induction principle!of cartesian products|textbf}\index{cartesian product type!induction principle|textbf} for $A\times B$ asserts that for any type family $P$ over $A\times B$ there is a function\index{ind times@{$\ind{\times}$}|textbf}\index{cartesian product type!indtimes@{$\ind{\times}$}|textbf}
\begin{equation*}
\ind{\times} : \Big(\prd{x:A}\prd{y:B}P(x,y)\Big)\to\Big(\prd{z:A\times B} P(z)\Big)
\end{equation*}
that satisfies the computation rule\index{computation rules!for cartesian products}\index{cartesian product type!computation rule|textbf}
\begin{align*}
\ind{\times}(g,(x,y)) & \jdeq g(x,y).
\end{align*}
\end{rmk}

The projection maps are defined similarly to the projection maps of $\Sigma$-types. When one thinks of types as propositions\index{propositions as types!conjunction}, then $A\times B$ is interpreted as the conjunction of $A$ and $B$.
\index{cartesian product type|)}
\index{inductive type!cartesian product|)}

\begin{exercises}
  \exitem
  \begin{subexenum}
  \item \label{ex:int_pred}\index{integers|(}\index{predecessor function|textbf}\index{integers!pred Z@{$\predZ$}|textbf}\index{pred Z@{$\predZ$}|textbf}Define the predecessor function $\predZ:\Z\to \Z$.
  \item \label{ex:int_group_ops}Define the group operations\index{add Z@{$\addZ$}|textbf}\index{integers!add Z@{$\addZ$}|textbf}\index{neg Z@{$\negZ$}}\index{integers!neg Z@{$\negZ$}}
    \begin{align*}
      \addZ & : \Z \to (\Z \to \Z) \\*
      \negZ & : \Z \to \Z.
    \end{align*}
  \item \label{ex:mulZ}Define the multiplication operation $\mulZ : \Z \to (\Z \to \Z)$.\index{mul Z@{$\mulZ$}}\index{integers!mul Z@{$\mulZ$}}
  \end{subexenum}
  \exitem \label{ex:bool}The type of \define{booleans}\index{booleans|textbf}\index{bool@{$\bool$}|see {booleans}}\index{bool@{$\bool$}|textbf} is defined to be an inductive type $\bool$ that comes equipped with\index{booleans!true@{$\btrue$}|textbf}\index{booleans!false@{$\bfalse$}|textbf}\index{false@{$\bfalse$}|textbf}\index{true@{$\btrue$}|textbf}
  \begin{equation*}
    \bfalse : \bool\qquad\text{and}\qquad\btrue : \bool.
  \end{equation*}
  The induction principle\index{induction principle!of the booleans|textbf}\index{booleans!induction principle|textbf} of the booleans asserts that for any family of types $P(x)$ indexed by $x:\bool$, there is a term\index{ind_bool@{$\indbool$}|textbf}
  \begin{equation*}
    \indbool : P(\bfalse)\to \Big(P(\btrue)\to \prd{x:\bool}P(x)\Big)
  \end{equation*}
  for which the computation rules\index{computation rules!for the booleans|textbf}\index{booleans!computation rules|textbf}
  \begin{align*}
    \indbool(p_0,p_1,\bfalse) & \jdeq p_0 \\*
    \indbool(p_0,p_1,\btrue) & \jdeq p_1
  \end{align*}
  hold.
  \begin{subexenum}
  \item Construct the \define{boolean negation} function $\negbool:\bool\to\bool$\index{neg-bool@{$\negbool$}|textbf}\index{booleans!neg-bool@{$\negbool$}|textbf}.
  \item Construct the \define{boolean conjunction} operation $\blank\land\blank : \bool\to(\bool\to\bool)$.\index{boolean conjunction|textbf}\index{booleans!conjunction|textbf}
  \item Construct the \define{boolean disjunction} operation $\blank\lor\blank : \bool\to(\bool\to\bool)$.\index{boolean disjunction|textbf}\index{booleans!disjunction|textbf}
  \end{subexenum}
  \exitem Let $P$ and $Q$ be types. We will write $P\leftrightarrow Q$ for the type of \define{bi-implications}\index{bi-implication|textbf} ${(P\to Q)}\times {(Q\to P)}$. Use the fact that $\neg P$\index{negation} is defined as the type $P\to\emptyt$ of functions from $P$ to the empty type to give type theoretic proofs of the constructive tautologies in this exercise.\label{ex:dne-dec}
  \begin{subexenum}
  \item \label{ex:no-fixed-points-neg}Show that
    \begin{enumerate}
    \item $\neg(P\times \neg P)$
    \item $\neg(P\leftrightarrow \neg P)$.
    \end{enumerate}
  \item \label{ex:dn-monad}Construct the following maps in the structure of the \define{double negation monad}:
    \begin{enumerate}
    \item $P\to\neg\neg P$
    \item $(P\to Q)\to(\neg\neg P\to\neg\neg Q)$
    \item $(P\to \neg\neg Q)\to (\neg\neg P \to\neg\neg Q)$.
    \end{enumerate}
  \item Prove that the following double negations of classical laws hold:
    \begin{enumerate}
    \item $\neg\neg(\neg\neg P \to P)$
    \item $\neg\neg(((P\to Q)\to P)\to P)$
    \item $\neg\neg((P\to Q)+(Q\to P))$
    \item $\neg\neg(P+\neg P)$.
    \end{enumerate}
  \item \label{ex:dne-is-decidable}Show that
    \begin{enumerate}
    \item $(P+\neg P)\to(\neg\neg P\to P)$
    \item $\neg\neg(Q\to P)\leftrightarrow ((P+\neg P)\to (Q\to P))$.    
    \end{enumerate}
  \item Prove the following tautologies, showing that $\neg P$, $P\to\neg\neg Q$, and $\neg\neg P\times\neg\neg Q$ are \define{double negation stable}:
    \begin{enumerate}
    \item $\neg\neg\neg P \to \neg P$
    \item $\neg\neg(P \to \neg\neg Q)\to (P\to\neg\neg Q)$
    \item $\neg\neg((\neg\neg P)\times(\neg\neg Q))\to (\neg\neg P)\times(\neg\neg Q)$.
    \end{enumerate}
  \item Show that
    \begin{enumerate}
    \item $\neg\neg(P\times Q)\leftrightarrow (\neg\neg P)\times(\neg\neg Q)$
    \item $\neg\neg(P+Q)\leftrightarrow \neg (\neg P \times \neg Q)$
    \item $\neg\neg(P\to Q)\leftrightarrow (\neg\neg P\to\neg\neg Q)$.
    \end{enumerate}
  \end{subexenum}
\exitem \label{ex:lists}For any type $A$ we can define the type $\lst(A)$\index{list A@{$\lst(A)$}|see {lists in $A$}}\index{list A@{$lst(A)$}|textbf} of \define{lists}\index{lists in A@{lists in $A$}|textbf}\index{inductive type!lists of elements of A@{lists of elements of $A$}|textbf} of elements of $A$ as the inductive type with constructors\index{lists in A@{lists in $A$}!nil@{$\nil$}|textbf}\index{nil@{$\nil$}|textbf}\index{cons(a,l)@{$\cons(a,l)$}|textbf}\index{lists in A@{lists in $A$}!cons@{$\cons$}|textbf}
  \begin{align*}
    \nil & : \lst(A) \\*
    \cons & : A \to (\lst(A) \to \lst(A)).
  \end{align*}
  \begin{subexenum}
  \item Write down the induction principle and the computation rules for $\lst(A)$.\index{induction principle!of list A@{of $\lst(A)$}|textbf}\index{lists in A@{lists in $A$}!induction principle|textbf}
  \item Let $A$ and $B$ be types, suppose that $b:B$, and consider a binary operation $\mu:A\to (B \to B)$. Define a function\index{fold-list@{$\foldlist$}|textbf}\index{lists in A@{lists in $A$}!fold-list@{$\foldlist$}|textbf}
    \begin{equation*}
      \foldlist(\mu) : \lst(A)\to B
    \end{equation*}
    that iterates the operation $\mu$, starting with $\foldlist(\mu,\nil)\defeq b$.
  \item Define the operation
    \begin{equation*}
      \maplist : (A\to B) \to (\lst(A)\to\lst(B))
    \end{equation*}
    for any two types $A$ and $B$.
  \item Define a function $\lengthlist:\lst(A)\to\N$.\index{length-list@{$\lengthlist$}|textbf}\index{lists in A@{lists in $A$}!length-list@{$\lengthlist$}|textbf}
  \item Define the functions\index{sum-list@{$\sumlist$}|textbf}\index{lists in A@{lists in $A$}!sum-list@{$\sumlist$}|textbf}
    \begin{align*}
      \sumlist & : \lst(\N) \to \N \\
      \productlist & : \lst(\N)\to\N,
    \end{align*}
    where $\sumlist$ adds all the elements in a list of natural numbers, and $\productlist$ takes their product.
  \item Define a function\index{concat-list@{$\concatlist$}|textbf}\index{lists in A@{lists in $A$}!concat-list@{$\concatlist$}|textbf}\index{concatenation!of lists|textbf}
    \begin{equation*}
      \concatlist : \lst(A) \to (\lst(A) \to \lst(A))
    \end{equation*}
    that concatenates any two lists of elements in $A$.
  \item Define a function\index{flatten-list@{$\flattenlist$}|textbf}\index{lists in A@{lists in $A$}!flatten-list@{$\flattenlist$}|textbf}
    \begin{equation*}
      \flattenlist : \lst(\lst(A)) \to \lst(A)
    \end{equation*}
    that concatenates all the lists in a lists of lists in $A$.
  \item Define a function $\reverselist : \lst(A) \to \lst(A)$ that reverses the order of the elements in any list.\index{reverse-list@{$\reverselist$}|textbf}\index{lists in A@{lists in $A$}!reverse-list@{$\reverselist$}|textbf}
  \end{subexenum}
\end{exercises}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "hott-intro"
%%% End:
